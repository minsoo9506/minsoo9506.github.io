<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1">
        <title>[PRML] Chapter6 - Kernel Method (2) : GP - minsoo9506</title><meta name="Description" content="This is My New Hugo Site"><meta property="og:title" content="[PRML] Chapter6 - Kernel Method (2) : GP" />
<meta property="og:description" content="Gaussian Process에 대해 정리하였다." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://minsoo9506.github.io/prml-chap06-2/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-11-29T10:59:46+09:00" />
<meta property="article:modified_time" content="2021-11-29T10:59:46+09:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="[PRML] Chapter6 - Kernel Method (2) : GP"/>
<meta name="twitter:description" content="Gaussian Process에 대해 정리하였다."/>
<meta name="application-name" content="minsoo9506">
<meta name="apple-mobile-web-app-title" content="minsoo9506"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="http://minsoo9506.github.io/prml-chap06-2/" /><link rel="prev" href="http://minsoo9506.github.io/prml-chap04-3/" /><link rel="next" href="http://minsoo9506.github.io/prml-chap06-3/" /><link rel="stylesheet" href="/lib/normalize/normalize.min.css"><link rel="stylesheet" href="/css/style.min.css"><link rel="stylesheet" href="/lib/fontawesome-free/all.min.css"><link rel="stylesheet" href="/lib/animate/animate.min.css"><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "[PRML] Chapter6 - Kernel Method (2) : GP",
        "inLanguage": "en",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "http:\/\/minsoo9506.github.io\/prml-chap06-2\/"
        },"genre": "posts","keywords": "PRML, Gassian Process","wordcount":  1054 ,
        "url": "http:\/\/minsoo9506.github.io\/prml-chap06-2\/","datePublished": "2021-11-29T10:59:46+09:00","dateModified": "2021-11-29T10:59:46+09:00","publisher": {
            "@type": "Organization",
            "name": "minsoo9506"},"author": {
                "@type": "Person",
                "name": "minsoo9506"
            },"description": ""
    }
    </script></head>
    <body header-desktop="auto" header-mobile="auto"><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="minsoo9506">minsoo9506 study note</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/posts/"> Posts </a><a class="menu-item" href="/tags/"> Tags </a><a class="menu-item" href="/categories/"> Categories </a><span class="menu-item delimiter"></span><span class="menu-item search" id="search-desktop">
                        <input type="text" placeholder="Search titles or contents..." id="search-input-desktop">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="Search">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="Clear">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-desktop">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </span><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                    <i class="fas fa-adjust fa-fw"></i>
                </a>
            </div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="minsoo9506">minsoo9506 study note</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><div class="search-wrapper">
                    <div class="search mobile" id="search-mobile">
                        <input type="text" placeholder="Search titles or contents..." id="search-input-mobile">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="Search">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="Clear">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-mobile">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </div>
                    <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
                        Cancel
                    </a>
                </div><a class="menu-item" href="/posts/" title="">Posts</a><a class="menu-item" href="/tags/" title="">Tags</a><a class="menu-item" href="/categories/" title="">Categories</a><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                <i class="fas fa-adjust fa-fw"></i>
            </a></div>
    </div>
</header>
<div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
</div>
<div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
</div>
<main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">Contents</h2>
            <div class="toc-content" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animated flipInX">[PRML] Chapter6 - Kernel Method (2) : GP</h1><div class="post-meta">
            <div class="post-meta-line"><span class="post-author"><a href="https://github.com/minsoo9506" title="Author" target="_blank" rel="noopener noreffer author" class="author"><i class="fas fa-user-circle fa-fw"></i>minsoo9506</a></span>&nbsp;<span class="post-category">included in <a href="/categories/prml/"><i class="far fa-folder fa-fw"></i>PRML</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime="2021-11-29">2021-11-29</time>&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;1054 words&nbsp;
                <i class="far fa-clock fa-fw"></i>&nbsp;5 minutes&nbsp;</div>
        </div><div class="details toc" id="toc-static"  kept="true">
                <div class="details-summary toc-title">
                    <span>Contents</span>
                    <span><i class="details-icon fas fa-angle-right"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#64-gaussian-processes">6.4 Gaussian Processes</a>
      <ul>
        <li><a href="#continuous-domain-data">Continuous Domain Data</a></li>
        <li><a href="#underlying-function-and-observations">Underlying Function and Observations</a></li>
        <li><a href="#simple-analyses-without-domain-correlation">Simple Analyses without Domain Correlation</a></li>
        <li><a href="#simple-analyses-with-domain-correlation">Simple Analyses with Domain Correlation</a></li>
      </ul>
    </li>
    <li><a href="#random-process">Random Process</a></li>
    <li><a href="#gaussian-process">Gaussian Process</a></li>
    <li><a href="#derivation-of-gaussian-process">Derivation of Gaussian Process</a>
      <ul>
        <li><a href="#mapping-functions">Mapping Functions</a></li>
        <li><a href="#linear-regression-with-basis-function">Linear regression with basis function</a></li>
        <li><a href="#modeling-noise-with-gaussian-distribution">Modeling Noise with Gaussian distribution</a></li>
        <li><a href="#sampling-of-pt">Sampling of $P(T)$</a></li>
        <li><a href="#mean-and-covariance-of-pt_n1--t_n">Mean and Covariance of $P(t_{N+1} | T_N)$</a></li>
        <li><a href="#hyperparameter-of-gaussian-process-regression">Hyperparameter of Gaussian Process Regression</a></li>
      </ul>
    </li>
    <li><a href="#gaussian-process-classifier">Gaussian Process Classifier</a></li>
  </ul>
</nav></div>
            </div><div class="content" id="content"><p>Gaussian Process에 대해 정리하였다.</p>
<h2 id="64-gaussian-processes">6.4 Gaussian Processes</h2>
<p>이 부분은 카이스트 문일철 교수님의 유투브영상을 보고 정리하였습니다.</p>
<h3 id="continuous-domain-data">Continuous Domain Data</h3>
<ul>
<li>GP는 continuous domain data 분석에 유용하다.
<ul>
<li>Time, Space, Spatio-Temporal&hellip;</li>
</ul>
</li>
<li>어떻게 분석, 모델링?
<ul>
<li>Estimating on the underlying function (ex. Autoregression)</li>
<li>Prediction on the unexpected point (ex. extrapolation with autoregression)</li>
</ul>
</li>
</ul>
<h3 id="underlying-function-and-observations">Underlying Function and Observations</h3>
<p>$Y = sinc(x)$ 라는 함수를 underlying function이라고 하자. 여기서 gaussian noise를 추가하여 observation들을 생성했다.</p>
<p>지금 그림은 없지만 그림1은 x에 따라 분산이 동일하고 그림2는 x에 따라 분산이 변화(x가 클수록 분산이 커짐)한다.</p>
<ul>
<li>underlying function을 구해야하므로 mean function을 찾는 것은 당연하고</li>
<li>추가로 variance(or precision) function도 중요하다.</li>
</ul>
<p>$$\mu(t), \sigma(t)^2$$</p>
<h3 id="simple-analyses-without-domain-correlation">Simple Analyses without Domain Correlation</h3>
<p>mean function을 domain correlation없이 estimate한다고 하자. 즉, 특정 1개의 point에서 mean과 variance를 계산하는 것이다. 그런데 continuous domain에서 사실 같은 $x(t)$에 대해 multiple obsevation이 나올 수 없다. 약간의 discretize라고 할 수 있다.</p>
<p>해당 domain point에서 observation이 많으면 어느 정도 smooth하게 mean function을 구할 수 있다. 하지만 반대의 경우 좋은 estimation이 어렵다.</p>
<ul>
<li>그래서 우리는 주위의 다른 domain data point도 사용하는게 좋지 않을까 라는 생각을 할 수 있다.</li>
</ul>
<h3 id="simple-analyses-with-domain-correlation">Simple Analyses with Domain Correlation</h3>
<ul>
<li>Moving average
<ul>
<li>time window(특정 구간)를 설정하고 평균</li>
<li>급격하게 변화하는 구간은 잘 안 맞을 수도 있다.</li>
<li>time window에 따라 변화
<ul>
<li>window가 커질수록 smooth해진다.</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>$$MA(x) = \frac{1}{N} \sum_{x \in W} y_i$$</p>
<p>그런데 모든 data point에 동일한 가중치를 주는게 다르게 주면 어떨까? 예를 들면,</p>
<ul>
<li>Squared Exponential
<ul>
<li>$L$이 커지면 window가 커지는 역할</li>
<li>위에서 window 크기처럼 $L$을 적절히 선택해야한다.</li>
</ul>
</li>
</ul>
<p>$$k(x,x_i;L) = exp(-\frac{|x-x_i|^2}{L^2})$$</p>
<p>위처럼 domain correlation을 다르게 생각하고 거리에 따라 가중치를 다르게 주는 것이다. 가까울수록 큰 가중치!</p>
<p>$$MA(x) = \frac{1}{\sum_{x_i \in D} k(x,x_i)}\sum_{x_i \in D} k(x,x_i) y_i$$</p>
<h2 id="random-process">Random Process</h2>
<ul>
<li>Random process(=Stochastic process)
<ul>
<li>An infinite indexed collection of random variables ${ X(w,t) , t \in T }$
<ul>
<li>index paramter : $t$ (time, space&hellip;)</li>
</ul>
</li>
<li>A function $X(t,\omega), t \in T ;\text{and}; \omega \in \Omega$
<ul>
<li>outcome : $\omega$</li>
<li>Fixed $t \rightarrow X(t,\omega)$ is a random variable over $\Omega$</li>
<li>Fixed $\omega \rightarrow X(t,\omega)$ is a deterministic function of $t$ ; sample function</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="gaussian-process">Gaussian Process</h2>
<ul>
<li>GP는 Random Process의 한 종류</li>
<li>For any set S, a GP on S is a set of random variable ($z_t : t \in S$) such that vector $[z_{t_1}, z_{t_2},&hellip;,z_{t_n}]$ is multivariate gaussian</li>
</ul>
<p>$$P(T) = N(0, (\beta I_N)^{-1} + K) \ K_{nm} = k(x_n, x_m) = \theta_0 \exp(-\frac{\theta_1}{2}||x_n - x_m||^2) + \theta_2 + \theta_3 x_n^T x_m$$</p>
<h2 id="derivation-of-gaussian-process">Derivation of Gaussian Process</h2>
<p>일단 linear regression으로 접근하고 GP에 대해 알아본다.</p>
<ul>
<li>gaussian process regression : a nonparametric bayesian regression method using the properties of Gaussian processes</li>
</ul>
<h3 id="mapping-functions">Mapping Functions</h3>
<p>non-linearly separable data set이 있다고 가정하자. 이를 위해 basis space를 증가시키면 될 것이다. mapping function $\phi$를 통해 확장시킨다.</p>
<h3 id="linear-regression-with-basis-function">Linear regression with basis function</h3>
<p>$$y(x) = w^T \phi (x)$$</p>
<p>여기서 $w$를 deterministic value가 아니라 probabilistically distributed value라고 생각하자. (Bayesian linear regression의 방법론)</p>
<p>$$P(w) = N(0, \alpha^{-1} I)$$</p>
<p>Y의 확률분포(joint distribution)에 대해 생각해보자. ($w$가 확률분포가 있으니까)</p>
<ul>
<li>$Y$도 normal 이겠구나 (multivariate gaussian)</li>
</ul>
<p>$$Y = (y_1, y_2,&hellip;,y_n)$$</p>
<ul>
<li>$K$ : Gram matrix</li>
</ul>
<p>$$E[Y] = E[\Phi w] = \Phi E[w] = 0$$</p>
<p>$$cov(Y) = E[YY^T] = E[\Phi w w^T \Phi^T]$$</p>
<p>$$= \Phi E[ww^T]\Phi^T = \frac{1}{\alpha} \Phi \Phi^T$$</p>
<p>$$K_{nm} = k(x_n,x_m) = \frac{1}{\alpha} \phi (x_n)^T \phi (x_m)$$</p>
<p>$$\therefore P(Y) = N(0,K)$$</p>
<ul>
<li>분산이 kernel function을 이용한다는 점을 기억하자</li>
</ul>
<p>이제 $Y$에 대한 분포를 파악했으니 이를 통해 prediction을 해보자.</p>
<h3 id="modeling-noise-with-gaussian-distribution">Modeling Noise with Gaussian distribution</h3>
<ul>
<li>$t_n$ : observed value with noise</li>
<li>$y_n$ : Latent, error-free value</li>
<li>$e_n$ : Error term distributed by following the gaussian distribution</li>
</ul>
<p>$$t_n = y_n + e_n \  (t_n = f(x_n)+e_n)$$</p>
<p>$$P(T|Y) = N(Y, \beta^{-1} I)$$</p>
<ul>
<li>$\beta$ : hyperparameter of the error precision</li>
<li>error term들이 independent라고 가정하기에 variance 부분에 $I$이 된다.</li>
</ul>
<p>$$P(T) = \int P(T|Y)P(Y) dY = \int N(Y,\beta^{-1} I) N(0,K) dY$$</p>
<p>위의 곱해지는 두 분포 모두 multivariate gaussian distribution 이므로 이를 이용하여 구할 것이다.</p>
<p>$$P(T|Y)P(Y) = P(T,Y) = P(Z)$$</p>
<p>$$\ln P(Z) = \ln P(T|Y) + \ln P(Y) \ = - \frac{1}{2} Y^TK^{-1}Y - \frac{1}{2}(T-Y)^T \beta I (T-Y) + const$$</p>
<p>여기서 변수는 $T,Y$이다. 여기서 second order term을 보면 (second order term을 찾으면 covariance를 찾을 수 있기에)</p>
<p>$$ = \frac{1}{2} \begin{pmatrix} Y \\ T \end{pmatrix}^T \begin{pmatrix} K^{-1} + \beta I &amp; -\beta I  \\ - \beta I &amp; \beta I \end{pmatrix} \begin{pmatrix} Y \\ T \end{pmatrix}  = \frac{1}{2}Z^T R Z$$</p>
<p>$R$은 precision matrix가 된다. 이를 inverse 하면 (공식이용)</p>
<p>$$R^{-1} = \begin{pmatrix} K &amp; K \\ K &amp; (\beta I)^{-1} + K \end{pmatrix}$$</p>
<p>$\ln (Z)$의 first order term은 없다. mean이 0라는 것을 알 수 있다. 따라서 최종 결과는</p>
<p>$$P(Z) = N(0, R^{-1})$$</p>
<p>이제 PRML chapter 2에서 봤었던 공식을 이용하면 marginal distribution을 구할 수 있다.</p>
<p>$$P(T) = N(0, (\beta I)^{-1} + K)$$</p>
<p>이제 우리가 관찰한 N개의 data를 통해 $P(T)$를 알게 되었다. 그렇다면 이제 prediction해보자. $t_{N+1}$을 알아내야 한다.</p>
<p>$$P(t_{N+1}|T_N)$$</p>
<p>이를 구하기 위해 N+1의 joint를 구하고 conditional disribution을 만들면 된다.</p>
<h3 id="sampling-of-pt">Sampling of $P(T)$</h3>
<ul>
<li>Sampling T of 101 dimension when points
<ul>
<li>$x_n = [-1,-0.98,&hellip;,1]$ : 101개의 data point</li>
</ul>
</li>
<li>mean $0$ : 101 dim zero vector</li>
<li>cov $(\beta I_N)^{-1} + K$ : 101 * 101 dim cov</li>
</ul>
<p>$$P(T) = N(0, (\beta I_N)^{-1} + K)$$</p>
<p>kernel의 parameter와 $\beta$값에 따라서 sampling data들이 이루는 모습이 달라진다.</p>
<h3 id="mean-and-covariance-of-pt_n1--t_n">Mean and Covariance of $P(t_{N+1} | T_N)$</h3>
<p>$$P(t_{N+1}|T_N) = P(T_{N+1}) / P(T_N)$$</p>
<p>$$P(T_{N+1}) = N(0, cov_{N+1})$$</p>
<p>mean은 1차원이 늘어난 zero vector이고 cov는 행과 열이 하나씩 들어간 형태일 것이다. 이는 kernel function과 $\beta$를 통해 어렵지 않게 구할 수 있다.</p>
<p>$$cov_{N+1} = \begin{pmatrix} cov_N &amp; k  \\ k^T &amp; K_{(N+1)(N+1)}+\beta^{-1} \end{pmatrix}$$</p>
<p>이제 joint distribution을 구했으니 conditional distribution을 구할 수 있다. (공식 PRML chap2에 나온다)</p>
<p>$$P(t_{N+1}|T_N) = N(0+k^T cov_N^{-1}(T_N-0),K_{(N+1)(N+1)}+\beta^{-1} -k^Tcov_N^{-1} k )$$</p>
<p>이는 결국 regression을 한 것이다. predictive distribution을 구한 것이다.</p>
<ul>
<li>평균과 분산 모두 new data $x_{N+1}$에 depend하다.</li>
<li>분산에서 inverse가 computationally 오래걸려서 approximation하는 방법들이 있다고 한다.</li>
</ul>
<p>$$\mu_{t_{N+1}} = k^T cov_N^{-1} T_N \ \sigma^2_{t_{N+1}} = K_{(N+1)(N+1)}+\beta^{-1} -k^Tcov_N^{-1} k$$</p>
<p>우리가 알고 있는 일반적인 regression과는 조금 다른 형태이다. 각 feature들의 weight들이 어디있는지 궁금할 수 있는데 kernel function안의 parameter로 들어갔다.</p>
<h3 id="hyperparameter-of-gaussian-process-regression">Hyperparameter of Gaussian Process Regression</h3>
<p>위에서 linear regression에서 parameter optimization을 하는 방법을 알아보자. 아래의 kernel hyperparameter를 추정해야 하는 것이다.</p>
<p>$$ K_{nm} = k(x_n, x_m) = \theta_0 \exp(-\frac{\theta_1}{2}||x_n - x_m||^2) + \theta_2 + \theta_3 x_n^T x_m$$</p>
<p>$$P(T;\theta) = N(0, (\beta I_N)^{-1} + K)$$</p>
<p>$\theta$를 추정하기 위해 likelihood를 최대한 높이는 방법을 택한다. $\theta$에 대해 미분하여 구하면 된다.</p>
<p>$$\frac{\partial}{\partial \theta_i} \log P(T;\theta) \overset{let}{=}0$$</p>
<p>그런데 closed form은 존재하지 않는다. 그래서 approximation해야 한다. (너무 복잡해서 derivation 생략) 우리는 pytorch와 같은 framework의 도움을 받아서 구한다.</p>
<h2 id="gaussian-process-classifier">Gaussian Process Classifier</h2>
<p>아래와 같이 일반적인 logistic regression과 거의 동일하다.</p>
<ul>
<li>Gaussian process classifier : sigmoid function + Gaussian process
<ul>
<li>Gaussian process : $f(x;\theta)$</li>
<li>Gaussian process classifier : $y=\sigma (f(x;\theta))$</li>
<li>if $t \in {0,1}$, objective function to optimize :</li>
</ul>
</li>
</ul>
<p>$$P(t | \theta) = \sigma (f(x;\theta))^t (1-\sigma (f(x;\theta)))^{1-t}$$</p></div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>Updated on 2021-11-29</span>
            </div>
            <div class="post-info-license"></div>
        </div>
        <div class="post-info-line">
            <div class="post-info-md"><span>
                            <a class="link-to-markdown" href="/prml-chap06-2/index.md" target="_blank">Read Markdown</a>
                        </span></div>
            <div class="post-info-share">
                <span></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"><i class="fas fa-tags fa-fw"></i>&nbsp;<a href="/tags/prml/">PRML</a>,&nbsp;<a href="/tags/gassian-process/">Gassian Process</a></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">Back</a></span>&nbsp;|&nbsp;<span><a href="/">Home</a></span>
        </section>
    </div>

    <div class="post-nav"><a href="/prml-chap04-3/" class="prev" rel="prev" title="[PRML] Chapter4 - Linear Models For Classification (3)"><i class="fas fa-angle-left fa-fw"></i>[PRML] Chapter4 - Linear Models For Classification (3)</a>
            <a href="/prml-chap06-3/" class="next" rel="next" title="[PRML] Bayesian Optimization">[PRML] Bayesian Optimization<i class="fas fa-angle-right fa-fw"></i></a></div>
</div>
</article></div>
            </main><footer class="footer">
        <div class="footer-container"><div class="footer-line">Powered by <a href="https://gohugo.io/" target="_blank" rel="noopener noreffer" title="Hugo 0.101.0">Hugo</a> | Theme - <a href="https://github.com/dillonzq/LoveIt" target="_blank" rel="noopener noreffer" title="LoveIt 0.2.10"><i class="far fa-kiss-wink-heart fa-fw"></i> LoveIt</a>
                </div><div class="footer-line"><i class="far fa-copyright fa-fw"></i><span itemprop="copyrightYear">2022</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="https://github.com/minsoo9506" target="_blank">minsoo9506</a></span></div>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="Back to Top">
                <i class="fas fa-arrow-up fa-fw"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="View Comments">
                <i class="fas fa-comment fa-fw"></i>
            </a>
        </div><link rel="stylesheet" href="/lib/katex/katex.min.css"><link rel="stylesheet" href="/lib/katex/copy-tex.min.css"><script type="text/javascript" src="/lib/smooth-scroll/smooth-scroll.min.js"></script><script type="text/javascript" src="/lib/autocomplete/autocomplete.min.js"></script><script type="text/javascript" src="/lib/lunr/lunr.min.js"></script><script type="text/javascript" src="/lib/lazysizes/lazysizes.min.js"></script><script type="text/javascript" src="/lib/clipboard/clipboard.min.js"></script><script type="text/javascript" src="/lib/katex/katex.min.js"></script><script type="text/javascript" src="/lib/katex/auto-render.min.js"></script><script type="text/javascript" src="/lib/katex/copy-tex.min.js"></script><script type="text/javascript" src="/lib/katex/mhchem.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"Copy to clipboard","maxShownLines":10},"comment":{},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"search":{"highlightTag":"em","lunrIndexURL":"/index.json","maxResultLength":10,"noResultsFound":"No results found","snippetLength":30,"type":"lunr"}};</script><script type="text/javascript" src="/js/theme.min.js"></script></body>
</html>
