<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1">
        <title>[PRML] Chapter11 - Sampling Method - minsoo9506</title><meta name="Description" content="This is My New Hugo Site"><meta property="og:title" content="[PRML] Chapter11 - Sampling Method" />
<meta property="og:description" content="distribution을 구하는 sampling method에 대해 정리하였다." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://minsoo9506.github.io/prml-chap11-1/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-11-29T11:38:01+09:00" />
<meta property="article:modified_time" content="2021-11-29T11:38:01+09:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="[PRML] Chapter11 - Sampling Method"/>
<meta name="twitter:description" content="distribution을 구하는 sampling method에 대해 정리하였다."/>
<meta name="application-name" content="minsoo9506">
<meta name="apple-mobile-web-app-title" content="minsoo9506"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="http://minsoo9506.github.io/prml-chap11-1/" /><link rel="prev" href="http://minsoo9506.github.io/prml-chap10-2/" /><link rel="next" href="http://minsoo9506.github.io/prml-chap14-1/" /><link rel="stylesheet" href="/lib/normalize/normalize.min.css"><link rel="stylesheet" href="/css/style.min.css"><link rel="stylesheet" href="/lib/fontawesome-free/all.min.css"><link rel="stylesheet" href="/lib/animate/animate.min.css"><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "[PRML] Chapter11 - Sampling Method",
        "inLanguage": "en",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "http:\/\/minsoo9506.github.io\/prml-chap11-1\/"
        },"genre": "posts","keywords": "Approximate Inference","wordcount":  1474 ,
        "url": "http:\/\/minsoo9506.github.io\/prml-chap11-1\/","datePublished": "2021-11-29T11:38:01+09:00","dateModified": "2021-11-29T11:38:01+09:00","publisher": {
            "@type": "Organization",
            "name": "minsoo9506"},"author": {
                "@type": "Person",
                "name": "minsoo9506"
            },"description": ""
    }
    </script></head>
    <body header-desktop="auto" header-mobile="auto"><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="minsoo9506">minsoo9506 study note</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/posts/"> Posts </a><a class="menu-item" href="/tags/"> Tags </a><a class="menu-item" href="/categories/"> Categories </a><span class="menu-item delimiter"></span><span class="menu-item search" id="search-desktop">
                        <input type="text" placeholder="Search titles or contents..." id="search-input-desktop">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="Search">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="Clear">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-desktop">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </span><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                    <i class="fas fa-adjust fa-fw"></i>
                </a>
            </div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="minsoo9506">minsoo9506 study note</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><div class="search-wrapper">
                    <div class="search mobile" id="search-mobile">
                        <input type="text" placeholder="Search titles or contents..." id="search-input-mobile">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="Search">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="Clear">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-mobile">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </div>
                    <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
                        Cancel
                    </a>
                </div><a class="menu-item" href="/posts/" title="">Posts</a><a class="menu-item" href="/tags/" title="">Tags</a><a class="menu-item" href="/categories/" title="">Categories</a><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                <i class="fas fa-adjust fa-fw"></i>
            </a></div>
    </div>
</header>
<div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
</div>
<div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
</div>
<main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">Contents</h2>
            <div class="toc-content" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animated flipInX">[PRML] Chapter11 - Sampling Method</h1><div class="post-meta">
            <div class="post-meta-line"><span class="post-author"><a href="https://github.com/minsoo9506" title="Author" target="_blank" rel="noopener noreffer author" class="author"><i class="fas fa-user-circle fa-fw"></i>minsoo9506</a></span>&nbsp;<span class="post-category">included in <a href="/categories/prml/"><i class="far fa-folder fa-fw"></i>PRML</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime="2021-11-29">2021-11-29</time>&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;1474 words&nbsp;
                <i class="far fa-clock fa-fw"></i>&nbsp;7 minutes&nbsp;</div>
        </div><div class="details toc" id="toc-static"  kept="true">
                <div class="details-summary toc-title">
                    <span>Contents</span>
                    <span><i class="details-icon fas fa-angle-right"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li><a href="#-monte-carlo-approximation">+ Monte carlo approximation</a></li>
      </ul>
    </li>
    <li><a href="#111-basic-sampling-algorithms">11.1 Basic Sampling Algorithms</a>
      <ul>
        <li><a href="#1112-rejection-sampling">11.1.2 Rejection sampling</a></li>
        <li><a href="#1114-importance-sampling">11.1.4 Importance sampling</a></li>
        <li><a href="#1116-sampling-and-the-em-algorithm">11.1.6 Sampling and the EM algorithm</a></li>
      </ul>
    </li>
    <li><a href="#112-markov-chain-monte-carlo">11.2 Markov Chain Monte Carlo</a>
      <ul>
        <li><a href="#1121-markov-chains">11.2.1 Markov chains</a></li>
        <li><a href="#1122-the-metropolis-hastings-algorithm">11.2.2 The Metropolis-Hastings algorithm</a></li>
      </ul>
    </li>
    <li><a href="#113-gibbs-sampling">11.3 Gibbs sampling</a></li>
  </ul>
</nav></div>
            </div><div class="content" id="content"><p>distribution을 구하는 sampling method에 대해 정리하였다.</p>
<p>probabilistic model에서 exact inference는 intractable한 경우가 많아서 approximation한다. 이번에는 approximate inference 방법 중 <em>Monte carlo</em> 라고 알려진 numerical sampling에 기반을 하는 방법을 공부할 것이다.</p>
<p>우리는 posterior 자체에도 관심이 있지만 주로 expectation에 관심이 있다 (for prediction). 왜?</p>
<ul>
<li>expectation으로 어떤 probability도 구할 수 있다.
<ul>
<li>$P(X \in A) = E [I(X \in A)]$</li>
</ul>
</li>
<li>intractable한 sum, integral을 계산할 수 있다.</li>
</ul>
<p>구제적으로 아래의 값을 analytical 하게 계산이 어려운 경우 Sampling을 통해 approximation한다.</p>
<p>$$E[f] = \int f(z)p(z)dz$$</p>
<p>$p(z)$에서 iid하게 sample $z_i$ 들을 뽑아서 평균에 대해 근사</p>
<p>$$\hat{f} = \frac{1}{n}\sum_{i=1}^{n}{f(z_i)}$$</p>
<p>여기서 발생 할 수 있는 문제는</p>
<ul>
<li>sampling한 data들이 independent 하지 않는 경우 존재
<ul>
<li>그래서 effective sample size가 apparent sample size보다 훨씬 작을 수도 있다</li>
</ul>
</li>
<li>$p(z), f(z)$에 따라 data가 많이 필요한 경우 존재
<ul>
<li>normal 분포같은 경우는 괜찮은데 Gaussian mixture같이 분포가 왔다갔다하는 경우는 sample에 따라 expectation값이 천차만별</li>
</ul>
</li>
</ul>
<h3 id="-monte-carlo-approximation">+ Monte carlo approximation</h3>
<ul>
<li>Goal
<ul>
<li>approximate $E[f(X)]$</li>
<li>where $X \sim P$</li>
</ul>
</li>
<li>Define
<ul>
<li>if $X_1, X_2,&hellip;,X_n \overset{iid}{\sim} P$</li>
<li>then $\hat{\mu}_n = \frac{1}{n}\sum f(X_i)$ is a monte carlo estimator of $E[f(X)]$</li>
</ul>
</li>
<li>Remark
<ul>
<li>$E[\hat{\mu}_n] = E[f(X)]$ : unbiased estimator</li>
<li>$\hat{\mu}_n \overset{p}{\rightarrow}E[f(X)]$ : consistent estimator (by WLLN)</li>
<li>$V[\hat{\mu}_n] = \frac{1}{n^2}V[\sum f(X_i)] = \frac{1}{n}V[f(X)] \rightarrow 0;\text{as};n\rightarrow\infty$</li>
</ul>
</li>
</ul>
<h2 id="111-basic-sampling-algorithms">11.1 Basic Sampling Algorithms</h2>
<p>forward sampling, regection sampling, importance sampling은 이제 별로 쓰이지 않는다고 한다. 뒤에서 배울 MCMC기법들에 조금 더 집중하자.</p>
<h3 id="1112-rejection-sampling">11.1.2 Rejection sampling</h3>
<p>complex한 분포에서 sampling하게 도와준다.</p>
<ul>
<li>$p(z)$에서 바로 sampling하기는 어려운 상태</li>
<li>단, $z$를 넣어을 때 $p(z)$의 값은 알 수 있는 상황이다.</li>
</ul>
<p>이를 위해 sampling이 쉬운 $q(z)$를 정한다.</p>
<ul>
<li>
<ol>
<li>$p(z)$를 다 포함하는 (envelop하는) 분포 $kq(z)$를 만든다.</li>
</ol>
</li>
</ul>
<p>$$kq(z) \ge p(z)$$</p>
<ul>
<li>
<ol start="2">
<li>$q(z)$ 에서 sampling한다 : $z_0$</li>
</ol>
</li>
<li>
<ol start="3">
<li>$unif[0, kq(z_0)]$ 에서 숫자를 generate 한다.</li>
</ol>
</li>
<li>
<ol start="4">
<li>해당 숫자가 $p(z_0)$ 보다 크면 reject, 아니면 sampling 한다.</li>
</ol>
</li>
</ul>
<p>따라서 $p(z)$를 잘 envelop하는 적절한 분포를 찾으면 위의 과정을 반복하여 우리가 원하는 sample들을 얻을 수 있다.</p>
<h3 id="1114-importance-sampling">11.1.4 Importance sampling</h3>
<p>expectation을 approximation하는 방법을 제안하다.</p>
<p>$$E[f] \approx \frac{1}{n}\sum f(z_i) ; \text{where} ; z_i \sim p(z)$$</p>
<p>하지만 $p(z)$에서 directly sampling하기 어려운 경우가 있다. so how?</p>
<ul>
<li>draw the samples from a proposal distribution(sampling할 수 있는), say $q(z)$</li>
<li>approximation
<ul>
<li>where $w_i= \frac{p(z_i)}{q(z_i)}, z_i \sim q(z)$</li>
</ul>
</li>
</ul>
<p>$$E[f] = \int f(z)\frac{p(z)}{q(z)}q(z)dz \approx \frac{1}{n}\sum w_i f(z_i) $$</p>
<p>rejection sampling과는 다르게 sampling한 모든 data들은 버려지지 않고 사용된다. 하지만 단점도 명확하다. 위의 식에서 $q(z)$가 매우 작은 값을 갖는 경우 가중치가 너무 커질수도 있다.</p>
<h3 id="1116-sampling-and-the-em-algorithm">11.1.6 Sampling and the EM algorithm</h3>
<p>Monte carlo를 이용하여 MLE를 구할 수도 있다. EM algorithm의 E step에서  sampling methods를 통해 approximation해보자.</p>
<ul>
<li>complete-data log likelihood</li>
</ul>
<p>$$Q({\pmb \theta}, {\pmb \theta}^{old}) = \int p(\textbf{Z}|\textbf{X}, {\pmb \theta}^{old}) \ln p(\textbf{Z},\textbf{X}|{\pmb \theta})d\textbf{Z}$$</p>
<ul>
<li>$\textbf{Z}^{(l)}$ drawn from the current estimate for the posterior distribution $p(\textbf{Z}|\textbf{X},{\pmb \theta}^{old})$</li>
</ul>
<p>$$Q({\pmb \theta}, {\pmb \theta}^{old}) \approx \frac{1}{L}\sum_{l=1}^{L} \ln p(\textbf{Z}^{(l)}, \textbf{X}| {\pmb \theta})$$</p>
<p>이후에 똑같이 M-step으로 optimize한다. 이런 과정을 <em>Monte Carlo EM algorithm</em> 이라고 한다.</p>
<h2 id="112-markov-chain-monte-carlo">11.2 Markov Chain Monte Carlo</h2>
<p>지금까지 살펴본 sampling 방법들은 high dimension에서 한계점을 갖고 있다. 이제 더 좋은 방법인 MCMC에 대해 공부해보고자 한다.</p>
<ul>
<li>이전의 방법들과 마찬가지로 proposal distribution에서 sampling한다.
<ul>
<li>proposal distribution : $q(\textbf{z}|\textbf{z}^{(\tau)})$</li>
<li>다른점은 current state $\textbf{z}^{(\tau)}$ 를 given으로 하는 것이다.</li>
<li>이런 통해 만들어진 sample들은 Markov chain을 형성한다.</li>
</ul>
</li>
<li>$p(\textbf{z}) = \tilde{p}(\textbf{z})/Z_p$ 에서 $Z_p$는 모르는 상태여도 상관없고 $\tilde{p}(\textbf{z})$의 값은 구할 수 있다고 가정한다.
<ul>
<li>$Z_p$는 unknown constant</li>
<li>$p(\textbf{z})$에서 directly sampling은 어려운 상태이다.</li>
</ul>
</li>
<li>proposal distribution에서 sample을 뽑고 적절한 기준으로 이를 sample로 인정할지 말지 결정한다.</li>
</ul>
<p>위와 같은 과정을 하는 basic <em>Metropolis</em> algorithm에 대해 살펴보자.</p>
<ul>
<li>proposal distribution은 symmetric하게 지정한다.
<ul>
<li>뒤에서 알게 되겠지만 symmetric하면 Markov chain이 time reversible하게 되고 이를 통해 stationary distribution ($p(\textbf{z})$을 의미) 이 존재한다.</li>
</ul>
</li>
</ul>
<p>$$q(\textbf{z}_A | \textbf{z}_B) = q(\textbf{z}_B | \textbf{z}_A)$$</p>
<ul>
<li>확률적으로 sample로 인정한다, 아래의 식이 accept 확률이다.
<ul>
<li>딱 봤을때 적절하다는 생각이 든다. 이렇게 반복하다 보면 우리가 원하는 $p(\textbf{z})$의 모양으로 sampling이 될 것이다.</li>
<li>$\frac{p(\textbf{z}^{ * })}{p(\textbf{z}^{(\tau)})} = \frac{\tilde{p}(\textbf{z}^{ * })}{\tilde{p}(\textbf{z}^{(\tau)})}  \frac{Z_p}{Z_p} = \frac{\tilde{p}(\textbf{z}^{ * })}{\tilde{p}(\textbf{z}^{(\tau)})}$ 라서 정확한 $p(\textbf{z})$의 값을 몰라도 합리적인 acceptance probability를 구할 수 있다.</li>
</ul>
</li>
</ul>
<p>$$A(\textbf{z}^{ * }, \textbf{z}^{(\tau)} ) = min (1, \frac{\tilde{p}(\textbf{z}^{ * })}{\tilde{p}(\textbf{z}^{(\tau)})})$$</p>
<ul>
<li>unif(0,1)에서 random number $u$를 뽑는다. $A(\textbf{z}^{ * }, \textbf{z}^{(\tau)} ) &gt; u$이면 sample을 accept한다.</li>
</ul>
<p>candidate sample이 accpet되면 그 sample을 sample list에 저장한다. 그리고 그 sample을 given한 상태로 다시 알고리즘을 진행한다. 만약 reject되면 그 때 당시의 given sample을 sample list에 추가하고 다시 알고리즘을 진행한다. 각 sequence sample은 independent한 sample이 아니다.  highly correlated되어 있다면 sample list에서 띄엄띄엄 사용하던가 초반 sample을 버리면 된다.</p>
<h3 id="1121-markov-chains">11.2.1 Markov chains</h3>
<p>대표적인 MCMC 알고리즘을 살펴보기 전에 Markov chain에 대해 공부해보자.</p>
<p>각 state에 해당하는 random variable $\textbf{z}^{(1)}, \textbf{z}^{(2)} ,&hellip;,\textbf{z}^{(M)}$ 가 있다. 이들이 아래와 같은 conditional independence property를 갖을 때, 이러한 stochastic process를 Markov chain이라고 한다.</p>
<p>$$p(\textbf{z}^{(m+1)}|\textbf{z}^{(1)}, \textbf{z}^{(2)} ,&hellip;,\textbf{z}^{(m)}) = p(\textbf{z}^{(m+1)}|\textbf{z}^{(m)}),; m \in {1,..,M-1}$$</p>
<ul>
<li>transition probability</li>
</ul>
<p>$$T(\textbf{z}^{(m)}, \textbf{z}^{(m+1)}) \equiv p(\textbf{z}^{(m+1)}| \textbf{z}^{(m)}) \equiv T_{\textbf{z}^{(m)}, \textbf{z}^{(m+1)}}$$</p>
<p>이제 Markov chain의 몇 가지 특징들에 대해 살펴보자.</p>
<ul>
<li>
<p><strong>accesible</strong></p>
<ul>
<li>$i \rightarrow j$ : state $j$ is <em>accessible</em> from $i$ if $T_{i,j}^m &gt; 0$
<ul>
<li>즉 state $i$에서 언젠가는 state $j$에 방문한다는 의미</li>
</ul>
</li>
<li>$i \leftrightarrow j$ : state $i, j$ <em>communicate</em> if $i \rightarrow j$ and $j \rightarrow i$</li>
</ul>
</li>
<li>
<p><strong>reducibility</strong></p>
<ul>
<li>모든 state $i,j$가 communicate하다면 그 Markov chain은 <em>irreducible</em> 하다고 한다.</li>
</ul>
</li>
<li>
<p><strong>periodicity</strong></p>
<ul>
<li>state $i$ has <em>peoriod d</em> if $d = gcd{n:T_{i,j}^m &gt;0}$</li>
<li>if d = 1, state $i$ is <em>aperiodic</em></li>
</ul>
</li>
<li>
<p><strong>transience</strong></p>
<ul>
<li>state $j$ is <em>recurrent</em> if  $j$에서 시작해서 언젠가는 다시 $j$를 방문할 확률이 1인 경우</li>
<li>state which is not recurrent is <em>transient</em></li>
<li><em>positive recurrent</em> : expected time until the process starting in state $i$ returns to $i$ is finite</li>
</ul>
</li>
<li>
<p><strong>ergodicity</strong></p>
<ul>
<li>irreducible, aperiodic, positive recurrent Markov chain on a countable state space is called <em>ergodic</em>
<ul>
<li>참고로 irreducible가 성립하면 자동으로 positive  recurrent가 성립한다.</li>
<li>따라서 어떤 책에는 ergodic의 조건으로 irreducible, aperiodic 만을 언급하기도 한다.</li>
<li>countable state space가 아닌 general한 경우는 ergodicity를 확인하기 복잡하다.</li>
<li>(어떤 책에는) For countable state spaces, an irreducible, aperiodic Markov chain having a stationary distribution is ergodic.</li>
</ul>
</li>
<li>ergodic Markov chain은 unique stationary distribution을 갖고 있다.</li>
</ul>
</li>
<li>
<p><strong>Stationary distribution</strong></p>
<ul>
<li>regular MC는 limiting probability distribution ${\pmb \pi} = (\pi_0,&hellip;,\pi_N)$을 갖는다.
<ul>
<li>transition matrix $\textbf{T}^{(m)}$의 모든 원소가 0보다 크면 MC가 <em>regular</em> 하다고 한다.</li>
<li>$\pi_j = lim_{n \rightarrow \infty}T_{i,j}^{(n)}$</li>
</ul>
</li>
<li>stationary distribution은 존재하지 않을 수도 있고 여러 개일 수도 있다.</li>
<li>아래와 같은 식을 만족하는 limiting distribution을 stationary distribution이라고 부른다.</li>
</ul>
<p>$$\pi_j = \sum_{k=0}^K \pi_k T_{k,j}$$</p>
</li>
<li>
<p><strong>detailed balance condition</strong></p>
<ul>
<li>Markov chain이 아래와 같은 식을 만족하면 <em>time reversible</em> 하다고 한다.
<ul>
<li>$P(\textbf{z}^{(n)} = j| \textbf{z}^{(n+1)} = i) = P(\textbf{z}^{(n+1)} = j| \textbf{z}^{(n)} = i)$</li>
</ul>
</li>
<li>time reversibility의 조건은 아래와 같이도 표현할 수 있는데 이를 <em>detailed balance condition</em> 이라고 한다. (detailed balance condition $\Leftrightarrow$ reversibility)</li>
</ul>
</li>
</ul>
<p>$$\pi_i T_{i,j} = \pi_j T_{j,i}$$</p>
<ul>
<li>detailed balance condition을 만족하면 stationary distribution을 갖는다. (unique한지는 확신할 수 없다)
<ul>
<li>proof</li>
</ul>
</li>
</ul>
<p>$$\pi_i T_{i,j} = \pi_j T_{j,i} \ \sum_i \pi_i T_{i,j} =\sum_i \pi_j T_{j,i} \ \sum_i \pi_i T_{i,j} =\pi_j \sum_i  T_{j,i} \ \sum_i \pi_i T_{i,j} =\pi_j$$</p>
<p>지금까지 Markov chain에 대해 알아보았다. 이 특성들을 이용하여 우리는 MCMC algorithm을 진행한다. 일단 전통적인 Markov chain 이론과 MCMC의 구별되는 특징에 대해 알아보면</p>
<ul>
<li>In the traditional Markov chain theory,
<ul>
<li>Given a transition rule, $P(\textbf{z}^{n+1} = j | \textbf{z}^{(n)} = i)$</li>
<li>Interested in finding its stationary distribution $\pi$</li>
</ul>
</li>
<li>In the MCMC,
<ul>
<li>Given a target stationary distribution $\pi$</li>
<li>Interested in prescribing and efficient transition rule to reach $\pi$</li>
</ul>
</li>
</ul>
<p>이 내용을 위에서 봤던 Metropolis algorithm과 잘 연결시켜서 이해하도록 하자.</p>
<ul>
<li>ergodic MC는 unique stationary distribution을 갖고 있다. 하지만 종종 ergodic 여부를 판단하기 어려운 상황이 발생한다.</li>
<li>in practice, reversible MC는 detailed balance condition을 만족하고 이는 stationary distribution가 존재함을 위미한다. 따라서 reversible MC를 주로 이용하고 starting value를 여러가지로 진행하여 unique함을 확인한다.</li>
</ul>
<h3 id="1122-the-metropolis-hastings-algorithm">11.2.2 The Metropolis-Hastings algorithm</h3>
<p>이전에 Metropolis algorithm에서는 proposal distribution(= transition kernel)이 symmetric했다. 하지만 이제는 그렇지 않다. 단, $q(\textbf{z}_A | \textbf{z}_B) &gt;0 \Leftrightarrow q(\textbf{z}_B | \textbf{z}_A) &gt; 0$ 을 만족해야 한다.</p>
<ul>
<li>현재 state는 $\textbf{z}^{(\tau)}$</li>
<li>distribution $q(\textbf{z} | \textbf{z}^{(\tau)})$로부터 sample $\textbf{z}^{ * }$을 뽑는다.
<ul>
<li>normal 분포를 주로 사용한다. 단, 분산을 적절하게 선택해야 한다.</li>
</ul>
</li>
<li>아래의 확률에 따라 accept한다.</li>
</ul>
<p>$$A(\textbf{z}^{ * }, \textbf{z}^{(\tau)} ) = min (1, \frac{\tilde{p}(\textbf{z}^{ * })q(\textbf{z}^{(\tau)} | \textbf{z}^{ * })}{\tilde{p}(\textbf{z}^{(\tau)})q(\textbf{z}^{ * } | \textbf{z}^{(\tau)})})$$</p>
<ul>
<li>Metropolis-Hastings은 detailed balance condition을 만족한다.</li>
</ul>
<p>$$p(\textbf{z}) T_{\textbf{z},\textbf{z}'} $$
$$= p(\textbf{z})q(\textbf{z}'|\textbf{z})A(\textbf{z}' , \textbf{z}) $$
$$ = \min {p(\textbf{z})q(\textbf{z}'|\textbf{z}), p(\textbf{z}')q(\textbf{z}|\textbf{z}') }$$
$$= \min { p(\textbf{z}')q(\textbf{z}|\textbf{z}'),p(\textbf{z})q(\textbf{z}'|\textbf{z}) }$$
$$= p(\textbf{z}')q(\textbf{z}|\textbf{z}')A(\textbf{z} , \textbf{z}') $$
$$= p(\textbf{z}') T_{\textbf{z}',\textbf{z}} $$</p>
<p>detailed balance condition을 만족하기에 우리가 sampling하여 만들어지는 MC가 stationary distribution을 갖게 된다. 따라서 stationary distribution으로 수렴하기전의 sampling 초반의 sample들은 버리고 (해당 구간을 burn-in period 라고 한다) 뒷부분의 sample들을 이용한다. 해당 sample list는 stationary distribution의 형태를 갖고 있을 것이다. 결국 우리가 구하고자하는 (unormalized) density를 구할 수 있는 것이다. 주로 posterior distribution을 구하는 것이 목적인 경우가 많다.</p>
<h2 id="113-gibbs-sampling">11.3 Gibbs sampling</h2>
<p>Metropolis-Hastings algorithm의 특별한 케이스이다. 우리가 sample을 뽑고 싶어하는 $p(\textbf{z}) = p(z_1,z_1,&hellip;,z_M)$ distribution이 있다. 이전에 우리는 proposal distribution을 따로 정해서 사용하였지만 Gibbs sampling에서는 그렇지 않다. 먼저 1부터 순서대로 $z_i$를 distribution $p(z_i|\textbf{z}_{-i})$에서 뽑는다. 이를 M까지 반복한다.</p>
<ul>
<li>Initialize ${z_i : i=1,&hellip;,M}$</li>
<li>For $\tau = 1,&hellip;,T:$
<ul>
<li>Sample $z_1^{(\tau+1)} \sim p(z_1 | z_2^{(\tau)}, z_3^{(\tau)},&hellip;, z_M^{(\tau)})$</li>
<li>Sample $z_2^{(\tau+1)} \sim p(z_2 | z_1^{(\tau+1)}, z_3^{(\tau)},&hellip;, z_M^{(\tau)})$</li>
<li>&hellip;</li>
<li>Sample $z_M^{(\tau+1)} \sim p(z_M | z_1^{(\tau+1)}, z_2^{(\tau+1)},&hellip;, z_{M-1}^{(\tau+1)})$</li>
</ul>
</li>
</ul>
<p>즉, Gibbs sampling에서는 acceptance probability를 사용하지 않는다. 모든 sample을 그대로 사용한다. 그렇게 해도 detailed balance condition을 만족하는지 살펴보자. 즉, 특정한 distribution으로 수렴하는지 확인.</p>
<ul>
<li>Gibbs sampling에서 $q(\textbf{z}|\textbf{z}') = p(z_i | \textbf{z}_{-i}')$ 이고</li>
<li>$p(\textbf{z}')q(\textbf{z} | \textbf{z}') = p(\textbf{z})q(\textbf{z}' | \textbf{z})$ 임을 확인해보자.</li>
</ul>
<p>$$p(\textbf{z}')q(\textbf{z} | \textbf{z}') = p(z_i', \textbf{z} _ {-i}')p(z_i| \textbf{z} _ {-i}')$$
$$=p(z_i'|\textbf{z} _ {-i}')p(\textbf{z} _ {-i}')p(z_i| \textbf{z} _ {-i}') $$
$$= p(z_i'|\textbf{z} _ {-i}') p(z_i , \textbf{z} _ {-i}') = q(\textbf{z}'| \textbf{z})p(\textbf{z})$$</p>
<p>항상 detailed balance condition이 성립한다.</p>
<p>더 advanced한 MCMC 알고리즘으로는 Hamilton이 있는 것 같다. MCMC가 주 관심분야는 아니기 때문에 여기까지만 정리하기로 한다.</p></div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>Updated on 2021-11-29</span>
            </div>
            <div class="post-info-license"></div>
        </div>
        <div class="post-info-line">
            <div class="post-info-md"><span>
                            <a class="link-to-markdown" href="/prml-chap11-1/index.md" target="_blank">Read Markdown</a>
                        </span></div>
            <div class="post-info-share">
                <span></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"><i class="fas fa-tags fa-fw"></i>&nbsp;<a href="/tags/approximate-inference/">Approximate Inference</a></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">Back</a></span>&nbsp;|&nbsp;<span><a href="/">Home</a></span>
        </section>
    </div>

    <div class="post-nav"><a href="/prml-chap10-2/" class="prev" rel="prev" title="[PRML] Chapter10 - Approximate Inference (2)"><i class="fas fa-angle-left fa-fw"></i>[PRML] Chapter10 - Approximate Inference (2)</a>
            <a href="/prml-chap14-1/" class="next" rel="next" title="[PRML] Chapter 14 : Combining Models">[PRML] Chapter 14 : Combining Models<i class="fas fa-angle-right fa-fw"></i></a></div>
</div>
</article></div>
            </main><footer class="footer">
        <div class="footer-container"><div class="footer-line">Powered by <a href="https://gohugo.io/" target="_blank" rel="noopener noreffer" title="Hugo 0.89.4">Hugo</a> | Theme - <a href="https://github.com/dillonzq/LoveIt" target="_blank" rel="noopener noreffer" title="LoveIt 0.2.10"><i class="far fa-kiss-wink-heart fa-fw"></i> LoveIt</a>
                </div><div class="footer-line"><i class="far fa-copyright fa-fw"></i><span itemprop="copyrightYear">2021</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="https://github.com/minsoo9506" target="_blank">minsoo9506</a></span></div>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="Back to Top">
                <i class="fas fa-arrow-up fa-fw"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="View Comments">
                <i class="fas fa-comment fa-fw"></i>
            </a>
        </div><link rel="stylesheet" href="/lib/katex/katex.min.css"><link rel="stylesheet" href="/lib/katex/copy-tex.min.css"><script type="text/javascript" src="/lib/smooth-scroll/smooth-scroll.min.js"></script><script type="text/javascript" src="/lib/autocomplete/autocomplete.min.js"></script><script type="text/javascript" src="/lib/lunr/lunr.min.js"></script><script type="text/javascript" src="/lib/lazysizes/lazysizes.min.js"></script><script type="text/javascript" src="/lib/clipboard/clipboard.min.js"></script><script type="text/javascript" src="/lib/katex/katex.min.js"></script><script type="text/javascript" src="/lib/katex/auto-render.min.js"></script><script type="text/javascript" src="/lib/katex/copy-tex.min.js"></script><script type="text/javascript" src="/lib/katex/mhchem.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"Copy to clipboard","maxShownLines":10},"comment":{},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"search":{"highlightTag":"em","lunrIndexURL":"/index.json","maxResultLength":10,"noResultsFound":"No results found","snippetLength":30,"type":"lunr"}};</script><script type="text/javascript" src="/js/theme.min.js"></script></body>
</html>
