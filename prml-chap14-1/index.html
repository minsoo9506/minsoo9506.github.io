<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1">
        <title>[PRML] Chapter14 - Combining Models - minsoo9506</title><meta name="Description" content="This is My New Hugo Site"><meta property="og:title" content="[PRML] Chapter14 - Combining Models" />
<meta property="og:description" content="Ensemble method에 대해 정리하였다.
14. Combining Models 말 그대로 모델들을 섞는 것이다. 머신러닝 예측 모델에서 가장 좋은 성능을 보이고 있다는 Boosting이 이 부분의 내용이다.
14.1 Bayesian Model Averaging model combination methods 와 Bayesian model averaging 을 구분하는 것은 중요하다. Density estimation using a mixture of Gaussians 예시를 통해 살펴보자.
model combination 각 data들은 iid, $X = {\textbf{x}_1, \textbf{x}_2,&hellip;,\textbf{x}_n }$ $X$는 전체 dataset을 의미 $$p(X) = \prod_{n=1}^{N}{p(\textbf{x} _ n)} = \prod_{n=1}^{N}{[\sum_{z_n}p(\textbf{x}_n, \textbf{z}_n)]}$$" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://minsoo9506.github.io/prml-chap14-1/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-11-29T11:40:01+09:00" />
<meta property="article:modified_time" content="2021-11-29T11:40:01+09:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="[PRML] Chapter14 - Combining Models"/>
<meta name="twitter:description" content="Ensemble method에 대해 정리하였다.
14. Combining Models 말 그대로 모델들을 섞는 것이다. 머신러닝 예측 모델에서 가장 좋은 성능을 보이고 있다는 Boosting이 이 부분의 내용이다.
14.1 Bayesian Model Averaging model combination methods 와 Bayesian model averaging 을 구분하는 것은 중요하다. Density estimation using a mixture of Gaussians 예시를 통해 살펴보자.
model combination 각 data들은 iid, $X = {\textbf{x}_1, \textbf{x}_2,&hellip;,\textbf{x}_n }$ $X$는 전체 dataset을 의미 $$p(X) = \prod_{n=1}^{N}{p(\textbf{x} _ n)} = \prod_{n=1}^{N}{[\sum_{z_n}p(\textbf{x}_n, \textbf{z}_n)]}$$"/>
<meta name="application-name" content="minsoo9506">
<meta name="apple-mobile-web-app-title" content="minsoo9506"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="http://minsoo9506.github.io/prml-chap14-1/" /><link rel="prev" href="http://minsoo9506.github.io/prml-chap11-1/" /><link rel="next" href="http://minsoo9506.github.io/ds-01/" /><link rel="stylesheet" href="/lib/normalize/normalize.min.css"><link rel="stylesheet" href="/css/style.min.css"><link rel="stylesheet" href="/lib/fontawesome-free/all.min.css"><link rel="stylesheet" href="/lib/animate/animate.min.css"><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "[PRML] Chapter14 - Combining Models",
        "inLanguage": "en",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "http:\/\/minsoo9506.github.io\/prml-chap14-1\/"
        },"genre": "posts","keywords": "Ensemble","wordcount":  857 ,
        "url": "http:\/\/minsoo9506.github.io\/prml-chap14-1\/","datePublished": "2021-11-29T11:40:01+09:00","dateModified": "2021-11-29T11:40:01+09:00","publisher": {
            "@type": "Organization",
            "name": "minsoo9506"},"author": {
                "@type": "Person",
                "name": "minsoo9506"
            },"description": ""
    }
    </script></head>
    <body header-desktop="auto" header-mobile="auto"><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="minsoo9506">minsoo9506 study note</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/posts/"> Posts </a><a class="menu-item" href="/tags/"> Tags </a><a class="menu-item" href="/categories/"> Categories </a><span class="menu-item delimiter"></span><span class="menu-item search" id="search-desktop">
                        <input type="text" placeholder="Search titles or contents..." id="search-input-desktop">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="Search">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="Clear">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-desktop">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </span><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                    <i class="fas fa-adjust fa-fw"></i>
                </a>
            </div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="minsoo9506">minsoo9506 study note</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><div class="search-wrapper">
                    <div class="search mobile" id="search-mobile">
                        <input type="text" placeholder="Search titles or contents..." id="search-input-mobile">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="Search">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="Clear">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-mobile">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </div>
                    <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
                        Cancel
                    </a>
                </div><a class="menu-item" href="/posts/" title="">Posts</a><a class="menu-item" href="/tags/" title="">Tags</a><a class="menu-item" href="/categories/" title="">Categories</a><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                <i class="fas fa-adjust fa-fw"></i>
            </a></div>
    </div>
</header>
<div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
</div>
<div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
</div>
<main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">Contents</h2>
            <div class="toc-content" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animated flipInX">[PRML] Chapter14 - Combining Models</h1><div class="post-meta">
            <div class="post-meta-line"><span class="post-author"><a href="https://github.com/minsoo9506" title="Author" target="_blank" rel="noopener noreffer author" class="author"><i class="fas fa-user-circle fa-fw"></i>minsoo9506</a></span>&nbsp;<span class="post-category">included in <a href="/categories/prml/"><i class="far fa-folder fa-fw"></i>PRML</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime="2021-11-29">2021-11-29</time>&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;857 words&nbsp;
                <i class="far fa-clock fa-fw"></i>&nbsp;5 minutes&nbsp;</div>
        </div><div class="details toc" id="toc-static"  kept="true">
                <div class="details-summary toc-title">
                    <span>Contents</span>
                    <span><i class="details-icon fas fa-angle-right"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#141-bayesian-model-averaging">14.1 Bayesian Model Averaging</a></li>
    <li><a href="#142-committees">14.2 Committees</a></li>
    <li><a href="#143-boosting">14.3 Boosting</a>
      <ul>
        <li><a href="#adaboost">AdaBoost</a></li>
        <li><a href="#1431-minimizing-exponential-error">14.3.1 Minimizing exponential error</a></li>
        <li><a href="#1432-error-functions-for-boosting">14.3.2 Error functions for boosting</a></li>
      </ul>
    </li>
    <li><a href="#144-tree-based-models">14.4 Tree-based Models</a></li>
    <li><a href="#145-conditional-mixture-models">14.5 Conditional Mixture Models</a>
      <ul>
        <li><a href="#1451-mixtures-of-linear-regression-models">14.5.1 Mixtures of linear regression models</a></li>
        <li><a href="#1452-mixtures-of-logistic-models">14.5.2 Mixtures of logistic models</a></li>
        <li><a href="#1453-mixtures-of-experts">14.5.3 Mixtures of experts</a></li>
      </ul>
    </li>
  </ul>
</nav></div>
            </div><div class="content" id="content"><p>Ensemble method에 대해 정리하였다.</p>
<h1 id="14-combining-models">14. Combining Models</h1>
<p>말 그대로 모델들을 섞는 것이다. 머신러닝 예측 모델에서 가장 좋은 성능을 보이고 있다는 Boosting이 이 부분의 내용이다.</p>
<h2 id="141-bayesian-model-averaging">14.1 Bayesian Model Averaging</h2>
<p>model combination methods 와 Bayesian model averaging 을 구분하는 것은 중요하다. Density estimation using a mixture of Gaussians 예시를 통해 살펴보자.</p>
<ul>
<li>model combination
<ul>
<li>각 data들은 iid, $X = {\textbf{x}_1, \textbf{x}_2,&hellip;,\textbf{x}_n }$</li>
<li>$X$는 전체 dataset을 의미</li>
</ul>
</li>
</ul>
<p>$$p(X) = \prod_{n=1}^{N}{p(\textbf{x} _ n)} = \prod_{n=1}^{N}{[\sum_{z_n}p(\textbf{x}_n, \textbf{z}_n)]}$$</p>
<ul>
<li>bayesian model averaging
<ul>
<li>models indexed by $h=1,&hellip;,H$ with prior</li>
</ul>
</li>
</ul>
<p>$$p(X) = \sum_{h=1}^{H}{p(X|h)p(h)}$$</p>
<p>이 둘의 차이점은</p>
<ul>
<li>model combination의 경우 각 data point는 latent variable $z$로 부터 generated되고 bayesian model averaging은 single model이 전체 dataset을 generate하는 과정을 담는 것이다.</li>
</ul>
<h2 id="142-committees">14.2 Committees</h2>
<p>bootstrap으로 M개의 data sets을 만들었고 각각 $y_m(\textbf{x})$ 모델을 훈련시켰다고 가정</p>
<p>$$y_{COM}(\textbf{x}) = \frac{1}{M}\sum_{m}^{M}{y_m(\textbf{x})}$$</p>
<p>이를 <strong>bagging</strong> 이라고 한다. (bagging은 variance를 줄이는 방법론)</p>
<p>우리가 구하고 싶은 true regression predict function을 $h(\textbf{x})$ 라고 하면</p>
<p>$$y_m(\textbf{x}) = h(\textbf{x}) + \epsilon_m(\textbf{x})$$</p>
<p>average sum-of-squares error는</p>
<p>$$E_{\textbf{x}}[{y_m(\textbf{x}) - h(\textbf{x}) }^2]$$</p>
<p>따라서 average error는</p>
<p>$$E_{AV} = \frac{1}{M}\sum_{m=1}^{M}{E_x[\epsilon_m(\textbf{x})^2]}$$</p>
<p>Committees의 expected error는</p>
<p>$$E_{COM} = E_{\textbf{x}} [{ \frac{1}{M}\sum_{m=1}^{M}{y_m(\textbf{x}) - h(\textbf{x})} }^2]=E_{\textbf{x}}[{ \frac{1}{M}{\sum_{m=1}^{M}{\epsilon_m(\textbf{x})}} }^2]$$</p>
<p>여기서 error term에 대한 가정은</p>
<ul>
<li>$E[\epsilon_m(\textbf{x})] = 0$</li>
<li>$E[\epsilon_m(\textbf{x})\epsilon_n(\textbf{x})]=0, m \neq n$</li>
</ul>
<p>따라서 우리는 $E_{COM} = \frac{1}{m}E_{AV}$ 라는 결과를 얻는다. 하지만 현실에서는 error term의 가정이 지켜지기 어렵다. error term이 highly correlated되어 있기 때문이다. 그래도 COM의 E가 AV 이하라는 것은 변하지 않는다.</p>
<p>$${ \frac{1}{M}{\sum_{m=1}^{M}{\epsilon_m(\textbf{x})}} }^2 \le \frac{1}{M}\sum_{m=1}^{M}\epsilon_m(\textbf{x})^2;;\because \text{Cauchy&rsquo;s inequality}$$</p>
<h2 id="143-boosting">14.3 Boosting</h2>
<p>간단히 말하자면 weak learner 모델을을 순차적으로 학습하는 것이다. PRML에서는 Adaboost만 다루고 있다.</p>
<h3 id="adaboost">AdaBoost</h3>
<ol>
<li>
<p>Intialize the data weighting coefficients by setting $w_n^{(1)} = 1/N$, n=1,&hellip;,N</p>
</li>
<li>
<p>For m=1,&hellip;,M</p>
</li>
</ol>
<p>(a) Fit a Classifer $y_m(\textbf{x})$ to the training data by minimizing the weighted error function</p>
<p>$$J_m = \sum_{n=1}^{N}w_n^{(m)} I (y_m (\textbf{x}_n)\neq t_n)$$</p>
<p>(b) Evaluate the quantities</p>
<p>$$\epsilon_m = \frac{\sum_{n=1}^{N}{w_n^{(m)}I(y_m(\textbf{x}) \neq t_n)}}{\sum_{n=1}^{N}{w_n^{(m)}}}$$</p>
<p>and then use these to evaluate</p>
<p>$$\alpha_m = \ln { \frac{1-\epsilon_m}{\epsilon_m} }$$</p>
<p>(c) Update the data weighting coefficients</p>
<p>$$w_n^{(m+1)} = w_n^{(m)} \exp { \alpha_m I(y_m(\textbf{x}_n) \neq t_n)  }$$</p>
<ol start="3">
<li>Make prediction using the final model, which is given by</li>
</ol>
<p>$$Y_M(x) = \text{sign}(\sum_{m=1}^{M}{\alpha_m y_m (x)})$$</p>
<p>위의 과정을 다시 한 번 정리해보자.</p>
<ul>
<li>일단 각 data point는 uniform한 가중치를 갖는다.</li>
<li>weak model과 해당 시점의 가중치를 이용하여 train한다.</li>
<li>해당 model과 가중치를 이용하여 해당 model의 error $\epsilon_m$을 구한다.</li>
<li>$\epsilon_m$을 이용하여 해당 model의 가중치를 의미하는 $\alpha_m$을 구한다.
<ul>
<li>여기서 해당 model의 error가 작을수록 $\alpha_m$은 큰 값을 가진다.</li>
</ul>
</li>
<li>다음 시점의 각 data point별 가중치를 update한다.
<ul>
<li>$w_n^{(m+1)} = w_n^{(m)} \exp { \alpha_m I(y_m(\textbf{x}_n) \neq t_n)  })$</li>
<li>좋은 model ($\alpha_m$가 큰)이 틀린 data point는 다음 시점에서 더 큰 가중치를 갖는다.</li>
<li>나쁜 model이 틀린 data point의 경우 가중치는 더 커지지만 위의 경우보다는 작다.</li>
<li>맞춘 data point는 동일한 가중치를 갖는다.</li>
</ul>
</li>
</ul>
<h3 id="1431-minimizing-exponential-error">14.3.1 Minimizing exponential error</h3>
<p>Friedman이 2000년에 논문을 통해 boosting에 대한 다른 시점을 발표했다. boosting을 sequential minimization of an exponential error function으로 바라보는 과정을 알아보자.</p>
<ul>
<li>exponential error function</li>
</ul>
<p>$$E = \sum_{n=1}^{N}{\exp { -t_n f_m(\textbf{x} _ n)}} \\  \text{where}\; f_m(\textbf{x}) = \frac{1}{2} \sum_{l=1}^{m}{\alpha_l y_l (\textbf{x})} \text{: linear combination of base classifiers}$$</p>
<p>우리의 목적은 parameter $\alpha_l, y_l (x)$ 에 대해 E를 최소화하는 것이다. global error function minimization 대신에 $\alpha_m, y_m (x)$를 제외한 나머지 값들을 fixed시키고 진행한다. 그러면</p>
<p>$$E = \sum_{n=1}^{N}{\exp { -t_n f_{m-1}(\textbf{x} _ n) - \frac{1}{2}t_n \alpha_m y_m (\textbf{x} _ n) }} \\ = \sum_{n=1}^{N}{w_n^{(m)} \exp { -\frac{1}{2} t_n \alpha_m y_m (\textbf{x}_n) }}$$</p>
<p>$T_m$을 잘 분류한 data point라고 하고 $M_m$을 틍린 data point라고 하면</p>
<p>$$E = e^{-\alpha_m / 2}\sum_{n \in T_m}{w_n^{(m)}} + e^{\alpha_m / 2} \sum_{n \in M_m}{w_n^{(m)}} $$
$$ = (e^{\alpha_m / 2} - e^{- \alpha_m / 2}) \sum_{n=1}^{N}{w_n^{(m)} I(y_m (\textbf{x} _ n) \neq t_n)} + e^{-\alpha_m / 2} \sum_{n=1}^{N}{w_n^{(m)}}$$</p>
<ul>
<li>$y_m (x)$에 대해 최소화하면 두번째 term은 constant가 된다. 그래서 2-(a)가 나온것</li>
<li>$\alpha_m$에 대해서 계산하면 2-(b)가 나온것</li>
<li>$w_n$ 의 update도 이렇게 나온 것</li>
</ul>
<h3 id="1432-error-functions-for-boosting">14.3.2 Error functions for boosting</h3>
<p>Expected error는</p>
<p>$$E_{\textbf{x},t}[\exp { -ty(\textbf{x}) }]=\sum_t \int \exp { -ty(\textbf{x}) }p(t|\textbf{x})p(\textbf{x})d\textbf{x}$$</p>
<p>위의 식을 variational minimization으로 $y(\textbf{x})$을 구하면</p>
<p>$$y(\textbf{x}) = \frac{1}{2}{ \frac{p(t=1|\textbf{x})}{p(t=-1|\textbf{x})} }$$</p>
<p>임을 알 수 있다. 이를 통해</p>
<blockquote>
<p>AdaBoost is seeking the best approximation to the log odds ratio, within the space of functions represented by the linear combination of base classifiers, subject to the constrained minimization resulting from the sequential optimization.</p>
</blockquote>
<ul>
<li>exponential loss는 cross-entropy보다 outiler에 덜 robust하다. error에 대한 가중치가 더 크다.</li>
<li>exponential loss는 cross-entropy와 다르게 $K&gt;2$ class의 경우로 일반화할 수 없다.</li>
</ul>
<h2 id="144-tree-based-models">14.4 Tree-based Models</h2>
<p>이 부분은 이미 알고 있는 내용이여서 자세히 정리하지는 않을 것이다.</p>
<ul>
<li>어떤 변수를 나눌 것인가? 나눈다면 그 threshlod는? 이에 대해서는 greedy 하게 최적점을 찾는다. optimal한 기준을 찾는 기준은 regression에서는 sum of square error, classification에서는 gini index, cross entropy 일 것이다.</li>
<li>node를 몇 개까지 만들것인지도 정해야 한다. 이는 model complexity를 정하게 해주므로 cross validation과 같은 방법으로 찾는다.</li>
</ul>
<h2 id="145-conditional-mixture-models">14.5 Conditional Mixture Models</h2>
<ul>
<li>standard decision trees are restricted by hard, axis-aligned splits of the input space.</li>
<li>그래서 이를 완화하는 방법으로 soft, probabilistic splits that can be functions of all of the input variables !</li>
</ul>
<h3 id="1451-mixtures-of-linear-regression-models">14.5.1 Mixtures of linear regression models</h3>
<p>$K$개의 linear model을 이용한다. GMM과 비슷한 맥락을 가진다.</p>
<p>$$p(t | \theta) = \sum_{k=1}^{K}{\pi_k N(t | w_k^T \phi, \beta^{-1})}$$</p>
<p>이를 통해 parameter를 구하기 위해 이전에 배웠던 GMM에서의 EM과 같은 방법을 이용하여 구하면 된다.</p>
<p>$$\ln p(\textbf{t}, \textbf{Z} | \theta) = \sum_{n=1}^{N}\sum_{k=1}^{K}{z_{nk}\ln{ \pi_k N(t_n | w_k^T\phi_n, \beta^{-1}) }}$$</p>
<p>결과는 아래의 사진을 참고하자.</p>
<center><img src="../img/chap14-1.jpg" width="80%"></center>
<h3 id="1452-mixtures-of-logistic-models">14.5.2 Mixtures of logistic models</h3>
<p>위와 같은 방법인데 logistic의 경우에 해당한다.</p>
<h3 id="1453-mixtures-of-experts">14.5.3 Mixtures of experts</h3>
<p>위의 방법들보다 조금 더 advanced한 방법론이다. mixing coefficients를 input의 함수로 정의한다.</p>
<p>$$p(t | \theta) = \sum_{k=1}^{K}{\pi_k(x) p_k(t | x)}$$</p>
</div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>Updated on 2021-11-29</span>
            </div>
            <div class="post-info-license"></div>
        </div>
        <div class="post-info-line">
            <div class="post-info-md"><span>
                            <a class="link-to-markdown" href="/prml-chap14-1/index.md" target="_blank">Read Markdown</a>
                        </span></div>
            <div class="post-info-share">
                <span></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"><i class="fas fa-tags fa-fw"></i>&nbsp;<a href="/tags/ensemble/">Ensemble</a></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">Back</a></span>&nbsp;|&nbsp;<span><a href="/">Home</a></span>
        </section>
    </div>

    <div class="post-nav"><a href="/prml-chap11-1/" class="prev" rel="prev" title="[PRML] Chapter11 - Sampling Method"><i class="fas fa-angle-left fa-fw"></i>[PRML] Chapter11 - Sampling Method</a>
            <a href="/ds-01/" class="next" rel="next" title="[자료구조] 배열">[자료구조] 배열<i class="fas fa-angle-right fa-fw"></i></a></div>
</div>
</article></div>
            </main><footer class="footer">
        <div class="footer-container"><div class="footer-line">Powered by <a href="https://gohugo.io/" target="_blank" rel="noopener noreffer" title="Hugo 0.101.0">Hugo</a> | Theme - <a href="https://github.com/dillonzq/LoveIt" target="_blank" rel="noopener noreffer" title="LoveIt 0.2.10"><i class="far fa-kiss-wink-heart fa-fw"></i> LoveIt</a>
                </div><div class="footer-line"><i class="far fa-copyright fa-fw"></i><span itemprop="copyrightYear">2023</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="https://github.com/minsoo9506" target="_blank">minsoo9506</a></span></div>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="Back to Top">
                <i class="fas fa-arrow-up fa-fw"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="View Comments">
                <i class="fas fa-comment fa-fw"></i>
            </a>
        </div><link rel="stylesheet" href="/lib/katex/katex.min.css"><link rel="stylesheet" href="/lib/katex/copy-tex.min.css"><script type="text/javascript" src="/lib/smooth-scroll/smooth-scroll.min.js"></script><script type="text/javascript" src="/lib/autocomplete/autocomplete.min.js"></script><script type="text/javascript" src="/lib/lunr/lunr.min.js"></script><script type="text/javascript" src="/lib/lazysizes/lazysizes.min.js"></script><script type="text/javascript" src="/lib/clipboard/clipboard.min.js"></script><script type="text/javascript" src="/lib/katex/katex.min.js"></script><script type="text/javascript" src="/lib/katex/auto-render.min.js"></script><script type="text/javascript" src="/lib/katex/copy-tex.min.js"></script><script type="text/javascript" src="/lib/katex/mhchem.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"Copy to clipboard","maxShownLines":10},"comment":{},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"search":{"highlightTag":"em","lunrIndexURL":"/index.json","maxResultLength":10,"noResultsFound":"No results found","snippetLength":30,"type":"lunr"}};</script><script type="text/javascript" src="/js/theme.min.js"></script></body>
</html>
