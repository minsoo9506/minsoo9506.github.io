[{"categories":["자료구조"],"content":"비선형적인 자료구조 트라이에 대해 정리 ","date":"2021-12-01","objectID":"/ds-09/:0:0","tags":["트라이"],"title":"[자료구조] 트라이","uri":"/ds-09/"},{"categories":["자료구조"],"content":"트라이 검색 트리의 일종으로 일반적으로 키가 문자열인 동적 배열 또는 연관 배열을 저장하는데 사용되는 정렬된 트리 자료구조 ","date":"2021-12-01","objectID":"/ds-09/:1:0","tags":["트라이"],"title":"[자료구조] 트라이","uri":"/ds-09/"},{"categories":["자료구조"],"content":"트라이 구현 (python) import collections class TrieNode: def __init__(self): self.word = False self.children = collections.defaultdict(TrieNode) class Trie: def __init__(self): self.root = TrieNode() def insert(self, word): node = self.root for char in word: node = node.children[char] node.word = True def search(self, word): node = self.root for char in word: if char not in node.children: return False node = node.children[char] return node.word def startWith(self, prefix): node = self.node for char in prefix: if char not in node.children: return False node = node.children[char] return True ","date":"2021-12-01","objectID":"/ds-09/:2:0","tags":["트라이"],"title":"[자료구조] 트라이","uri":"/ds-09/"},{"categories":["자료구조"],"content":"Reference 파이썬 알고리즘 인터뷰 (박상길 지음) ","date":"2021-12-01","objectID":"/ds-09/:3:0","tags":["트라이"],"title":"[자료구조] 트라이","uri":"/ds-09/"},{"categories":["힙"],"content":"비선형적인 자료구조 힙에 대해 정리 ","date":"2021-12-01","objectID":"/ds-08/:0:0","tags":null,"title":"[자료구조] 힙","uri":"/ds-08/"},{"categories":["힙"],"content":"힙 트리 기반의 자료구조 우선순위 큐를 주로 힙으로 구현한다. 이전에도 heapq를 사용했었다. (근데 힙은 주로 배열로 구현) 여러 개의 값들 중에서 최댓값이나 최솟값을 빠르게 찾아내도록 만들어진 자료구조이다. 힙은 정렬된 구조는 아니다. 힙 트리에서는 중복된 값을 허용한다. (이진 탐색 트리에서는 중복된 값을 허용하지 않는다.) ","date":"2021-12-01","objectID":"/ds-08/:1:0","tags":null,"title":"[자료구조] 힙","uri":"/ds-08/"},{"categories":["힙"],"content":"힙의 종류 이진 힙 자식이 둘인 힙 힙을 애기할때는 주로 이진힙을 의미 최소 힙 부모가 항상 자식보다 작거나 같다 최대 힙 최소 힙과 반대 ","date":"2021-12-01","objectID":"/ds-08/:2:0","tags":null,"title":"[자료구조] 힙","uri":"/ds-08/"},{"categories":["힙"],"content":"힙 구현 대개 트리의 배열 표현의 경우 index 계산을 편하게 하기 위해 index는 1부터 시작한다. 이진힙에서 부모의 index를 계산할 때 본인 index를 2로 나눈 몫 # 최소힙구현 class BinaryHeap: def __init__(self): self.items = [None] def __len__(self): return len(self.items) - 1 # 삽입 : O(logn) # 반복 구조 def _percolate_up(self): # 배열 가장 마지막에 먼저 삽입 i = len(self) parent = i // 2 # 부모가 더 큰 값을 가지는 경우 스왑 while parent \u003e 0: if self.items[i] \u003c self.items[parent]: self.items[parent], self.itmes[i] = \\ self.items[i], self.items[parent] i = parent parent = i // 2 def insert(self, k): self.items.append(k) self._percolate_up() # 추출 : O(logn) # 재귀 구조 def _percolate_down(self, idx): left = idx * 2 right = idx * 2 + 1 smallest = idx if left \u003c= len(self) and self.items[left] \u003c self.items[smallest]: smallest = left if right \u003c= len(self) and self.items[right] \u003c self.items[smallest]: smallest = right if smallest != idx: self.items[idx], self.items[smallest] = \\ self.items[smallest], self.items[idx] self._percolate_down(smallest) def extract(self): extracted = self.items[1] self.items[1] = self.items[len(self)] self.items.pop() self._percolate_down(1) return extracted ","date":"2021-12-01","objectID":"/ds-08/:3:0","tags":null,"title":"[자료구조] 힙","uri":"/ds-08/"},{"categories":["힙"],"content":"Python 예시 Link 배열의 K번째 큰 값 찾기 heapq 사용법 heapq.heapify(my_list) 를 통해 리스트를 heap으로 만든다. heapq.nlargest(k, my_list)를 통해 리스트에서 큰 순서대로 k개 return한다. ","date":"2021-12-01","objectID":"/ds-08/:4:0","tags":null,"title":"[자료구조] 힙","uri":"/ds-08/"},{"categories":["힙"],"content":"Reference 파이썬 알고리즘 인터뷰 (박상길 지음) ","date":"2021-12-01","objectID":"/ds-08/:5:0","tags":null,"title":"[자료구조] 힙","uri":"/ds-08/"},{"categories":["자료구조"],"content":"비선형적인 자료구조 트리에 대해 정리 ","date":"2021-12-01","objectID":"/ds-07/:0:0","tags":["트리"],"title":"[자료구조] 트리","uri":"/ds-07/"},{"categories":["자료구조"],"content":"트리 그래프 vs 트리 트리는 순환 구조를 갖지 않는 그래프 트리에서 부모 노드는 단 하나, 루트도 하나 ","date":"2021-12-01","objectID":"/ds-07/:1:0","tags":["트리"],"title":"[자료구조] 트리","uri":"/ds-07/"},{"categories":["자료구조"],"content":"이진 트리 가장 널리 사용되는 트리는 이진트리와 이진탐색트리(BST) 일반적으로 트리라고 하면 대부분 이진트리를 의미 이진트리는 노드의 차수가 2이하인 트리 이진트리 표현법 배열, 리스트 노드와 링크로 직접 class 구현 ","date":"2021-12-01","objectID":"/ds-07/:2:0","tags":["트리"],"title":"[자료구조] 트리","uri":"/ds-07/"},{"categories":["자료구조"],"content":"트리순회 그래프 순회의 한 형태로 트리 자료구조에서 각 노드를 정확히 한 번 방문하는 과정 종류 pre-order in-order post-order # 전위(Pre-Order) 순회 : NLR def preorder(node): if node is None: return print(node.val) preorder(node.left) preorder(node.right) # 중의(In-Order) 순회 : LNR def inorder(node): if node is None: return inorder(node.left) print(node.val) inorder(node.right) # 후위(Post-Order) 순회 : LRN def postorder(node): if node in None: return postorder(node.left) postorder(node.right) print(node.val) ","date":"2021-12-01","objectID":"/ds-07/:3:0","tags":["트리"],"title":"[자료구조] 트리","uri":"/ds-07/"},{"categories":["자료구조"],"content":"이진 탐색 트리 (Binary Search Tree) 여기서 탐색이란 정렬되었다는 것을 의미한다. 노드의 왼쪽에는 작은 값, 오른쪽에는 같거나 큰 값이 위치한다. 장점은? 탐색이 $O(\\log n)$ # BST # search def search(self, key): if self.size == 0: return None v = self.root while v != None: if v.key == key : return v elif v.key \u003c key: v = v.right else: v = v.left ","date":"2021-12-01","objectID":"/ds-07/:4:0","tags":["트리"],"title":"[자료구조] 트리","uri":"/ds-07/"},{"categories":["자료구조"],"content":"균형 이진 탐색 트리 (Balanced BST) 트리의 높이가 너무 높아지지 않도록 조정 rotation 회전을 통해 조정 종류 AVL tree Red-Black (2,3,4) tree splay tree ","date":"2021-12-01","objectID":"/ds-07/:5:0","tags":["트리"],"title":"[자료구조] 트리","uri":"/ds-07/"},{"categories":["자료구조"],"content":"Python 예시 Link 이진트리 최대깊이 deque를 이용하여 bfs 이진 트리의 직경 dfs 가장 긴 동일값의 경로 dfs 이진트리반전 재귀, 큐, 스택 두 이진 트리 병합 재귀 이진 트리 직렬화 bfs 균형 이진 트리 정렬된 배열의 이진 탐색 트리 변환 이진 탐색 트리를 더 큰 수 합계 트리로 이진 탐색 트리 합의 범위 ","date":"2021-12-01","objectID":"/ds-07/:6:0","tags":["트리"],"title":"[자료구조] 트리","uri":"/ds-07/"},{"categories":["자료구조"],"content":"Reference 파이썬 알고리즘 인터뷰 (박상길 지음) 신찬수, 한국외대, 컴퓨터전자시스템공학부, 자료구조 2020-1 ","date":"2021-12-01","objectID":"/ds-07/:7:0","tags":["트리"],"title":"[자료구조] 트리","uri":"/ds-07/"},{"categories":["자료구조"],"content":"비선형적인 자료구조 그래프에 대해 정리 ","date":"2021-12-01","objectID":"/ds-06/:0:0","tags":["그래프"],"title":"[자료구조] 그래프","uri":"/ds-06/"},{"categories":["자료구조"],"content":"그래프 탐색 BFS 주로 큐로 구현 DFS 주로 스택, 재귀로 구현 그래프를 표현하는 방법 인접리스트 인접행렬 # 인접리스트 graph = { 1 : [2,3,4], 2 : [5], 3 : [5], 4 : [], 5 : [6,7], 6 : [], 7 : [3], } # DFS (재귀) def recursive_dfs(v, discovered=[]): discovered.append(v) for w in graph[v]: if not w in discovered: discovered = recursive_dfs(w, discovered) return discovered # BFS def iterative_bfs(start_v): discovered = [start_v] queue = [start_v] while queue: v = queue.pop(0) for w in graph[v]: if w is not in discovered: discovered.append(w) queue.append(w) return discovered ","date":"2021-12-01","objectID":"/ds-06/:1:0","tags":["그래프"],"title":"[자료구조] 그래프","uri":"/ds-06/"},{"categories":["자료구조"],"content":"Python 예시 Link 섬의 갯수 dfs, 재귀 전화번호 문자 조합 dfs, 재귀 순열 객체 복사는 copy()를 사용, 복잡한 리스트의 경우는 copy.deepcopy()로 처리 itertools.permutations()를 통해서 쉽게 permutation을 계산할 수 있다. 조합 itertools.combinations() 조합의 합 dfs, 재귀 부분 집합 dfs 일정 재구성 dfs ","date":"2021-12-01","objectID":"/ds-06/:2:0","tags":["그래프"],"title":"[자료구조] 그래프","uri":"/ds-06/"},{"categories":["자료구조"],"content":"Reference 파이썬 알고리즘 인터뷰 (박상길 지음) ","date":"2021-12-01","objectID":"/ds-06/:3:0","tags":["그래프"],"title":"[자료구조] 그래프","uri":"/ds-06/"},{"categories":["자료구조"],"content":"선형적인 자료구조 해시 테이블에 대해 정리 ","date":"2021-12-01","objectID":"/ds-05/:0:0","tags":["해시테이블"],"title":"[자료구조] 해시 테이블","uri":"/ds-05/"},{"categories":["자료구조"],"content":"해시 테이블 (Hash Table) 키를 값에 매핑할 수 있는 구조인 연관 배열 추상 자료형을 구현하는 자료구조 대부분 연산의 시간 복잡도가 $O(1)$ Python에서 해시 테이블로 구현된 자료형 : dictionary ","date":"2021-12-01","objectID":"/ds-05/:1:0","tags":["해시테이블"],"title":"[자료구조] 해시 테이블","uri":"/ds-05/"},{"categories":["자료구조"],"content":"로드 팩터 (Load Factor) 해시 테이블에 저장된 데이터 개수 $n$을 버킷의 개수 $k$로 나눈 것 ","date":"2021-12-01","objectID":"/ds-05/:2:0","tags":["해시테이블"],"title":"[자료구조] 해시 테이블","uri":"/ds-05/"},{"categories":["자료구조"],"content":"해시 함수(Hash Function) 해시함수 임의 크기 데이터를 고정 크기 값으로 매핑하는데 사용하는 함수 해시함수를 만드는 방법은 다양하다. 좋은 해시함수? less collision fast computation ","date":"2021-12-01","objectID":"/ds-05/:3:0","tags":["해시테이블"],"title":"[자료구조] 해시 테이블","uri":"/ds-05/"},{"categories":["자료구조"],"content":"충돌 (Collision) 충돌이 일어나는 경우 이를 방지하기 위한 방법이 필요하다. 체이닝 (Chaining), 오픈 어드레싱 (Open addressing) Python은 Open addressing 방법을 사용 Chaining 충돌이 발생하면 연결리스트로 연결한다. 충돌이 많지 않으면 대부분의 탐색은 $O(1)$ 최악은 $O(n)$ Open addressing 충돌이 일어나면 그 뒤의 가장 가까운 다음 빈 위치를 탐사 (linear probing 방법) linear probing, quadratic probing, double hashing … 연산 set(key, value) 해시테이블에서 key를 찾아서 있으면 key update, 없으면 key와 value 삽입한다. search(key) 찾았는데 없으면 다음칸에 빈칸이 나올 때까지 찾는다. remove(key) 충돌이 일어나서 이어지는 경우 중간에 빈칸이 없도록 해야한다. 평균적으로 50% 이상 빈슬롯이면 위의 연산 모두 $O(1)$이다. 성능평가 cluster size : 해시테이블에서 뭉쳐진 cluster가 최소 충돌비율 등등 ","date":"2021-12-01","objectID":"/ds-05/:4:0","tags":["해시테이블"],"title":"[자료구조] 해시 테이블","uri":"/ds-05/"},{"categories":["자료구조"],"content":"Python 예시 Link 해시맵 디자인 chaining 방식 직접 해시함수를 구현 collections.defaultdict 사용 보석과 돌 A문자열이 B문자열에 얼마나 등장하는지 중복 문자 없는 가장 긴 부분 문자열 상위 K빈도 요소 Python에서 zip, * 의 사용법 zip은 제너레이터를 리턴 zip은 2개 이상의 시퀀스를 짧은 길이를 기준으로 일대일 대응하는 새로운 튜플 시쿼스를 만든다. ","date":"2021-12-01","objectID":"/ds-05/:5:0","tags":["해시테이블"],"title":"[자료구조] 해시 테이블","uri":"/ds-05/"},{"categories":["자료구조"],"content":"Reference 파이썬 알고리즘 인터뷰 (박상길 지음) 신찬수, 한국외대, 컴퓨터전자시스템공학부, 자료구조 2020-1 ","date":"2021-12-01","objectID":"/ds-05/:6:0","tags":["해시테이블"],"title":"[자료구조] 해시 테이블","uri":"/ds-05/"},{"categories":["자료구조"],"content":"선형적인 자료구조 데크과 우선순위 큐에 대해 정리 ","date":"2021-12-01","objectID":"/ds-04/:0:0","tags":["deque","우선순위큐"],"title":"[자료구조] deque, 우선순위 큐","uri":"/ds-04/"},{"categories":["자료구조"],"content":"데크 양쪽 끝을 모두 추출할 수 있는, 큐를 일반화한 형태의 추상 자료형 Python에서 제공하는 collections.deque는 이중 연결 리스트로 구현되어 있다. ","date":"2021-12-01","objectID":"/ds-04/:1:0","tags":["deque","우선순위큐"],"title":"[자료구조] deque, 우선순위 큐","uri":"/ds-04/"},{"categories":["자료구조"],"content":"우선순위 큐 우선순위가 높은 요소가 추출되는 자료형 최단 경로를 탐색하는 다익스트라 알고리즘, 힙 자료구조 와도 관련이 깊다. Python에서는 heapq를 사용 최소 힙 파이썬의 보통 리스트를 마치 최소 힙처럼 다룰 수 있도록 도와준다. 최대 힙을 만들려면 각 값에 대한 우선 순위를 구한 후, (우선 순위, 값) 구조의 튜플(tuple)을 힙에 추가하거나 삭제 import heapq heap = [] heapq.heappush(heap, (-num, num)) # (우선 순위, 값) ","date":"2021-12-01","objectID":"/ds-04/:2:0","tags":["deque","우선순위큐"],"title":"[자료구조] deque, 우선순위 큐","uri":"/ds-04/"},{"categories":["자료구조"],"content":"Python Link 원형 데크 디자인 직접 deque를 구현 k개 정렬 리스트 병합 heapq ","date":"2021-12-01","objectID":"/ds-04/:3:0","tags":["deque","우선순위큐"],"title":"[자료구조] deque, 우선순위 큐","uri":"/ds-04/"},{"categories":["자료구조"],"content":"Reference 파이썬 알고리즘 인터뷰 (박상길 지음) ","date":"2021-12-01","objectID":"/ds-04/:4:0","tags":["deque","우선순위큐"],"title":"[자료구조] deque, 우선순위 큐","uri":"/ds-04/"},{"categories":["자료구조"],"content":"선형적인 자료구조 스택과 큐에 대해 정리 ","date":"2021-12-01","objectID":"/ds-03/:0:0","tags":["스택","큐"],"title":"[자료구조] 스택, 큐","uri":"/ds-03/"},{"categories":["자료구조"],"content":"스택 LIFO (Last In First Out) Python에서는 스택 자료형을 따로 제공하지는 않지만 리스트가 스택의 연산들을 모두 제공한다. 리스트에서 append, pop이 O(1)로 빠르기 때문에 리스트를 스택을 구현한다. ","date":"2021-12-01","objectID":"/ds-03/:1:0","tags":["스택","큐"],"title":"[자료구조] 스택, 큐","uri":"/ds-03/"},{"categories":["자료구조"],"content":"큐 FIFO (First In First Out) Python에서 리스트를 사용하면 된지만 큐 연산을 수행하기에는 효율적이지는 않다. 그래서 deque라는 별도의 자료형을 사용하면 더 좋은 성능을 이용할 수 있다. ","date":"2021-12-01","objectID":"/ds-03/:2:0","tags":["스택","큐"],"title":"[자료구조] 스택, 큐","uri":"/ds-03/"},{"categories":["자료구조"],"content":"Python Link 유효한 괄호 중복 문자 제거 일일 온도 큐를 이용한 스택 구현 deque 이용 스택을 이용한 큐 구현 두 개의 스택(리스트)을 이용 원형 큐 디자인 ","date":"2021-12-01","objectID":"/ds-03/:3:0","tags":["스택","큐"],"title":"[자료구조] 스택, 큐","uri":"/ds-03/"},{"categories":["자료구조"],"content":"Reference 파이썬 알고리즘 인터뷰 (박상길 지음) ","date":"2021-12-01","objectID":"/ds-03/:4:0","tags":["스택","큐"],"title":"[자료구조] 스택, 큐","uri":"/ds-03/"},{"categories":["자료구조"],"content":"선형적인 자료구조 연결리스트에 대해 정리 ","date":"2021-12-01","objectID":"/ds-02/:0:0","tags":["연결리스트"],"title":"[자료구조] 연결리스트","uri":"/ds-02/"},{"categories":["자료구조"],"content":"연결 리스트 선형 자료구조 동적으로 새로운 노드를 삽입하거나 삭제하기 간편하다. 메모리에 물리적인 순서대로 저장되지는 않는다. 단, 탐색에는 O(n)이 소요된다. ","date":"2021-12-01","objectID":"/ds-02/:1:0","tags":["연결리스트"],"title":"[자료구조] 연결리스트","uri":"/ds-02/"},{"categories":["자료구조"],"content":"deque python의 list에서 pop(0)을 통해 맨 앞의 원소를 뽑아내는 것은 비효율적이다. list의 원소들이 하나씩 shifting되기 때문이다. 따라서 collections.deque()를 이용하면 좋다. q.append(some value)를 하고 q.popleft(), q.pop() 이런식으로 앞뒤에서 빠르게 원소를 뽑아낼 수 있다. ","date":"2021-12-01","objectID":"/ds-02/:2:0","tags":["연결리스트"],"title":"[자료구조] 연결리스트","uri":"/ds-02/"},{"categories":["자료구조"],"content":"Python code 예시 Link 펠린드롬 연결 리스트 deque, 러너 이용 두 정렬 리스트의 병합 재귀 이용 역순 연결 리스트 1 반복 구조로 뒤집기 두 수의 덧셈 페어의 노드 스왑 홀짝 연결 리스트 역순 연결 리스트 2 ","date":"2021-12-01","objectID":"/ds-02/:3:0","tags":["연결리스트"],"title":"[자료구조] 연결리스트","uri":"/ds-02/"},{"categories":["자료구조"],"content":"Reference 파이썬 알고리즘 인터뷰 (박상길 지음) ","date":"2021-12-01","objectID":"/ds-02/:4:0","tags":["연결리스트"],"title":"[자료구조] 연결리스트","uri":"/ds-02/"},{"categories":["자료구조"],"content":"선형적인 자료구조 배열에 대해 정리 ","date":"2021-12-01","objectID":"/ds-01/:0:0","tags":["배열"],"title":"[자료구조] 배열","uri":"/ds-01/"},{"categories":["자료구조"],"content":"배열 메모리 공간 기반의 연속적인 방식의 가장 기본이 되는 자료형 파이썬의 동적 배열 자료형 : 리스트 Cpython의 내부 구현을 보면, 배열의 정해진 공간보다 추가적으로 원소가 들어오면 조금씩 용량을 늘린다. 정적 배열과 달리 크기를 지정할 필요가 없다. 크기가 꽉 차면 새로운 메모리 공간에 더 큰 크기의 배열을 할당하고 기존 데이터를 복사하는 작업이 필요해서 O(n)의 비용이 발생한다. ","date":"2021-12-01","objectID":"/ds-01/:1:0","tags":["배열"],"title":"[자료구조] 배열","uri":"/ds-01/"},{"categories":["자료구조"],"content":"Python code 예시 Link 두 수의 합 빗물 트래핑 투 포인터로 합 계산 짝수합 자신을 제외한 배열의 곱 주식을 사고팔기 가장 좋은 시점 ","date":"2021-12-01","objectID":"/ds-01/:2:0","tags":["배열"],"title":"[자료구조] 배열","uri":"/ds-01/"},{"categories":["자료구조"],"content":"Reference 파이썬 알고리즘 인터뷰 (박상길 지음) ","date":"2021-12-01","objectID":"/ds-01/:3:0","tags":["배열"],"title":"[자료구조] 배열","uri":"/ds-01/"},{"categories":["PRML"],"content":"Ensemble method에 대해 정리하였다. 14. Combining Models 말 그대로 모델들을 섞는 것이다. 머신러닝 예측 모델에서 가장 좋은 성능을 보이고 있다는 Boosting이 이 부분의 내용이다. ","date":"2021-11-29","objectID":"/prml-chap14-1/:0:0","tags":["Ensemble"],"title":"[PRML] Chapter 14 : Combining Models","uri":"/prml-chap14-1/"},{"categories":["PRML"],"content":"14.1 Bayesian Model Averaging model combination methods 와 Bayesian model averaging 을 구분하는 것은 중요하다. Density estimation using a mixture of Gaussians 예시를 통해 살펴보자. model combination 각 data들은 iid, $X = {\\textbf{x}_1, \\textbf{x}_2,…,\\textbf{x}_n }$ $X$는 전체 dataset을 의미 $$p(X) = \\prod_{n=1}^{N}{p(\\textbf{x} _ n)} = \\prod_{n=1}^{N}{[\\sum_{z_n}p(\\textbf{x}_n, \\textbf{z}_n)]}$$ bayesian model averaging models indexed by $h=1,…,H$ with prior $$p(X) = \\sum_{h=1}^{H}{p(X|h)p(h)}$$ 이 둘의 차이점은 model combination의 경우 각 data point는 latent variable $z$로 부터 generated되고 bayesian model averaging은 single model이 전체 dataset을 generate하는 과정을 담는 것이다. ","date":"2021-11-29","objectID":"/prml-chap14-1/:1:0","tags":["Ensemble"],"title":"[PRML] Chapter 14 : Combining Models","uri":"/prml-chap14-1/"},{"categories":["PRML"],"content":"14.2 Committees bootstrap으로 M개의 data sets을 만들었고 각각 $y_m(\\textbf{x})$ 모델을 훈련시켰다고 가정 $$y_{COM}(\\textbf{x}) = \\frac{1}{M}\\sum_{m}^{M}{y_m(\\textbf{x})}$$ 이를 bagging 이라고 한다. (bagging은 variance를 줄이는 방법론) 우리가 구하고 싶은 true regression predict function을 $h(\\textbf{x})$ 라고 하면 $$y_m(\\textbf{x}) = h(\\textbf{x}) + \\epsilon_m(\\textbf{x})$$ average sum-of-squares error는 $$E_{\\textbf{x}}[{y_m(\\textbf{x}) - h(\\textbf{x}) }^2]$$ 따라서 average error는 $$E_{AV} = \\frac{1}{M}\\sum_{m=1}^{M}{E_x[\\epsilon_m(\\textbf{x})^2]}$$ Committees의 expected error는 $$E_{COM} = E_{\\textbf{x}} [{ \\frac{1}{M}\\sum_{m=1}^{M}{y_m(\\textbf{x}) - h(\\textbf{x})} }^2]=E_{\\textbf{x}}[{ \\frac{1}{M}{\\sum_{m=1}^{M}{\\epsilon_m(\\textbf{x})}} }^2]$$ 여기서 error term에 대한 가정은 $E[\\epsilon_m(\\textbf{x})] = 0$ $E[\\epsilon_m(\\textbf{x})\\epsilon_n(\\textbf{x})]=0, m \\neq n$ 따라서 우리는 $E_{COM} = \\frac{1}{m}E_{AV}$ 라는 결과를 얻는다. 하지만 현실에서는 error term의 가정이 지켜지기 어렵다. error term이 highly correlated되어 있기 때문이다. 그래도 COM의 E가 AV 이하라는 것은 변하지 않는다. $${ \\frac{1}{M}{\\sum_{m=1}^{M}{\\epsilon_m(\\textbf{x})}} }^2 \\le \\frac{1}{M}\\sum_{m=1}^{M}\\epsilon_m(\\textbf{x})^2;;\\because \\text{Cauchy’s inequality}$$ ","date":"2021-11-29","objectID":"/prml-chap14-1/:2:0","tags":["Ensemble"],"title":"[PRML] Chapter 14 : Combining Models","uri":"/prml-chap14-1/"},{"categories":["PRML"],"content":"14.3 Boosting 간단히 말하자면 weak learner 모델을을 순차적으로 학습하는 것이다. PRML에서는 Adaboost만 다루고 있다. ","date":"2021-11-29","objectID":"/prml-chap14-1/:3:0","tags":["Ensemble"],"title":"[PRML] Chapter 14 : Combining Models","uri":"/prml-chap14-1/"},{"categories":["PRML"],"content":"AdaBoost Intialize the data weighting coefficients by setting $w_n^{(1)} = 1/N$, n=1,…,N For m=1,…,M (a) Fit a Classifer $y_m(\\textbf{x})$ to the training data by minimizing the weighted error function $$J_m = \\sum_{n=1}^{N}w_n^{(m)} I (y_m (\\textbf{x}_n)\\neq t_n)$$ (b) Evaluate the quantities $$\\epsilon_m = \\frac{\\sum_{n=1}^{N}{w_n^{(m)}I(y_m(\\textbf{x}) \\neq t_n)}}{\\sum_{n=1}^{N}{w_n^{(m)}}}$$ and then use these to evaluate $$\\alpha_m = \\ln { \\frac{1-\\epsilon_m}{\\epsilon_m} }$$ (c) Update the data weighting coefficients $$w_n^{(m+1)} = w_n^{(m)} \\exp { \\alpha_m I(y_m(\\textbf{x}_n) \\neq t_n) }$$ Make prediction using the final model, which is given by $$Y_M(x) = \\text{sign}(\\sum_{m=1}^{M}{\\alpha_m y_m (x)})$$ 위의 과정을 다시 한 번 정리해보자. 일단 각 data point는 uniform한 가중치를 갖는다. weak model과 해당 시점의 가중치를 이용하여 train한다. 해당 model과 가중치를 이용하여 해당 model의 error $\\epsilon_m$을 구한다. $\\epsilon_m$을 이용하여 해당 model의 가중치를 의미하는 $\\alpha_m$을 구한다. 여기서 해당 model의 error가 작을수록 $\\alpha_m$은 큰 값을 가진다. 다음 시점의 각 data point별 가중치를 update한다. $w_n^{(m+1)} = w_n^{(m)} \\exp { \\alpha_m I(y_m(\\textbf{x}_n) \\neq t_n) })$ 좋은 model ($\\alpha_m$가 큰)이 틀린 data point는 다음 시점에서 더 큰 가중치를 갖는다. 나쁜 model이 틀린 data point의 경우 가중치는 더 커지지만 위의 경우보다는 작다. 맞춘 data point는 동일한 가중치를 갖는다. ","date":"2021-11-29","objectID":"/prml-chap14-1/:3:1","tags":["Ensemble"],"title":"[PRML] Chapter 14 : Combining Models","uri":"/prml-chap14-1/"},{"categories":["PRML"],"content":"14.3.1 Minimizing exponential error Friedman이 2000년에 논문을 통해 boosting에 대한 다른 시점을 발표했다. boosting을 sequential minimization of an exponential error function으로 바라보는 과정을 알아보자. exponential error function $$E = \\sum_{n=1}^{N}{\\exp { -t_n f_m(\\textbf{x} _ n)}} \\\\ \\text{where}\\; f_m(\\textbf{x}) = \\frac{1}{2} \\sum_{l=1}^{m}{\\alpha_l y_l (\\textbf{x})} \\text{: linear combination of base classifiers}$$ 우리의 목적은 parameter $\\alpha_l, y_l (x)$ 에 대해 E를 최소화하는 것이다. global error function minimization 대신에 $\\alpha_m, y_m (x)$를 제외한 나머지 값들을 fixed시키고 진행한다. 그러면 $$E = \\sum_{n=1}^{N}{\\exp { -t_n f_{m-1}(\\textbf{x} _ n) - \\frac{1}{2}t_n \\alpha_m y_m (\\textbf{x} _ n) }} \\\\ = \\sum_{n=1}^{N}{w_n^{(m)} \\exp { -\\frac{1}{2} t_n \\alpha_m y_m (\\textbf{x}_n) }}$$ $T_m$을 잘 분류한 data point라고 하고 $M_m$을 틍린 data point라고 하면 $$E = e^{-\\alpha_m / 2}\\sum_{n \\in T_m}{w_n^{(m)}} + e^{\\alpha_m / 2} \\sum_{n \\in M_m}{w_n^{(m)}} $$ $$ = (e^{\\alpha_m / 2} - e^{- \\alpha_m / 2}) \\sum_{n=1}^{N}{w_n^{(m)} I(y_m (\\textbf{x} _ n) \\neq t_n)} + e^{-\\alpha_m / 2} \\sum_{n=1}^{N}{w_n^{(m)}}$$ $y_m (x)$에 대해 최소화하면 두번째 term은 constant가 된다. 그래서 2-(a)가 나온것 $\\alpha_m$에 대해서 계산하면 2-(b)가 나온것 $w_n$ 의 update도 이렇게 나온 것 ","date":"2021-11-29","objectID":"/prml-chap14-1/:3:2","tags":["Ensemble"],"title":"[PRML] Chapter 14 : Combining Models","uri":"/prml-chap14-1/"},{"categories":["PRML"],"content":"14.3.2 Error functions for boosting Expected error는 $$E_{\\textbf{x},t}[\\exp { -ty(\\textbf{x}) }]=\\sum_t \\int \\exp { -ty(\\textbf{x}) }p(t|\\textbf{x})p(\\textbf{x})d\\textbf{x}$$ 위의 식을 variational minimization으로 $y(\\textbf{x})$을 구하면 $$y(\\textbf{x}) = \\frac{1}{2}{ \\frac{p(t=1|\\textbf{x})}{p(t=-1|\\textbf{x})} }$$ 임을 알 수 있다. 이를 통해 AdaBoost is seeking the best approximation to the log odds ratio, within the space of functions represented by the linear combination of base classifiers, subject to the constrained minimization resulting from the sequential optimization. exponential loss는 cross-entropy보다 outiler에 덜 robust하다. error에 대한 가중치가 더 크다. exponential loss는 cross-entropy와 다르게 $K\u003e2$ class의 경우로 일반화할 수 없다. ","date":"2021-11-29","objectID":"/prml-chap14-1/:3:3","tags":["Ensemble"],"title":"[PRML] Chapter 14 : Combining Models","uri":"/prml-chap14-1/"},{"categories":["PRML"],"content":"14.4 Tree-based Models 이 부분은 이미 알고 있는 내용이여서 자세히 정리하지는 않을 것이다. 어떤 변수를 나눌 것인가? 나눈다면 그 threshlod는? 이에 대해서는 greedy 하게 최적점을 찾는다. optimal한 기준을 찾는 기준은 regression에서는 sum of square error, classification에서는 gini index, cross entropy 일 것이다. node를 몇 개까지 만들것인지도 정해야 한다. 이는 model complexity를 정하게 해주므로 cross validation과 같은 방법으로 찾는다. ","date":"2021-11-29","objectID":"/prml-chap14-1/:4:0","tags":["Ensemble"],"title":"[PRML] Chapter 14 : Combining Models","uri":"/prml-chap14-1/"},{"categories":["PRML"],"content":"14.5 Conditional Mixture Models standard decision trees are restricted by hard, axis-aligned splits of the input space. 그래서 이를 완화하는 방법으로 soft, probabilistic splits that can be functions of all of the input variables ! ","date":"2021-11-29","objectID":"/prml-chap14-1/:5:0","tags":["Ensemble"],"title":"[PRML] Chapter 14 : Combining Models","uri":"/prml-chap14-1/"},{"categories":["PRML"],"content":"14.5.1 Mixtures of linear regression models $K$개의 linear model을 이용한다. GMM과 비슷한 맥락을 가진다. $$p(t | \\theta) = \\sum_{k=1}^{K}{\\pi_k N(t | w_k^T \\phi, \\beta^{-1})}$$ 이를 통해 parameter를 구하기 위해 이전에 배웠던 GMM에서의 EM과 같은 방법을 이용하여 구하면 된다. $$\\ln p(\\textbf{t}, \\textbf{Z} | \\theta) = \\sum_{n=1}^{N}\\sum_{k=1}^{K}{z_{nk}\\ln{ \\pi_k N(t_n | w_k^T\\phi_n, \\beta^{-1}) }}$$ 결과는 아래의 사진을 참고하자. ","date":"2021-11-29","objectID":"/prml-chap14-1/:5:1","tags":["Ensemble"],"title":"[PRML] Chapter 14 : Combining Models","uri":"/prml-chap14-1/"},{"categories":["PRML"],"content":"14.5.2 Mixtures of logistic models 위와 같은 방법인데 logistic의 경우에 해당한다. ","date":"2021-11-29","objectID":"/prml-chap14-1/:5:2","tags":["Ensemble"],"title":"[PRML] Chapter 14 : Combining Models","uri":"/prml-chap14-1/"},{"categories":["PRML"],"content":"14.5.3 Mixtures of experts 위의 방법들보다 조금 더 advanced한 방법론이다. mixing coefficients를 input의 함수로 정의한다. $$p(t | \\theta) = \\sum_{k=1}^{K}{\\pi_k(x) p_k(t | x)}$$ ","date":"2021-11-29","objectID":"/prml-chap14-1/:5:3","tags":["Ensemble"],"title":"[PRML] Chapter 14 : Combining Models","uri":"/prml-chap14-1/"},{"categories":["PRML"],"content":"distribution을 구하는 sampling method에 대해 정리하였다. probabilistic model에서 exact inference는 intractable한 경우가 많아서 approximation한다. 이번에는 approximate inference 방법 중 Monte carlo 라고 알려진 numerical sampling에 기반을 하는 방법을 공부할 것이다. 우리는 posterior 자체에도 관심이 있지만 주로 expectation에 관심이 있다 (for prediction). 왜? expectation으로 어떤 probability도 구할 수 있다. $P(X \\in A) = E [I(X \\in A)]$ intractable한 sum, integral을 계산할 수 있다. 구제적으로 아래의 값을 analytical 하게 계산이 어려운 경우 Sampling을 통해 approximation한다. $$E[f] = \\int f(z)p(z)dz$$ $p(z)$에서 iid하게 sample $z_i$ 들을 뽑아서 평균에 대해 근사 $$\\hat{f} = \\frac{1}{n}\\sum_{i=1}^{n}{f(z_i)}$$ 여기서 발생 할 수 있는 문제는 sampling한 data들이 independent 하지 않는 경우 존재 그래서 effective sample size가 apparent sample size보다 훨씬 작을 수도 있다 $p(z), f(z)$에 따라 data가 많이 필요한 경우 존재 normal 분포같은 경우는 괜찮은데 Gaussian mixture같이 분포가 왔다갔다하는 경우는 sample에 따라 expectation값이 천차만별 ","date":"2021-11-29","objectID":"/prml-chap11-1/:0:0","tags":["Approximate Inference"],"title":"[PRML] Chapter11 - Sampling Method","uri":"/prml-chap11-1/"},{"categories":["PRML"],"content":"+ Monte carlo approximation Goal approximate $E[f(X)]$ where $X \\sim P$ Define if $X_1, X_2,…,X_n \\overset{iid}{\\sim} P$ then $\\hat{\\mu}_n = \\frac{1}{n}\\sum f(X_i)$ is a monte carlo estimator of $E[f(X)]$ Remark $E[\\hat{\\mu}_n] = E[f(X)]$ : unbiased estimator $\\hat{\\mu}_n \\overset{p}{\\rightarrow}E[f(X)]$ : consistent estimator (by WLLN) $V[\\hat{\\mu}_n] = \\frac{1}{n^2}V[\\sum f(X_i)] = \\frac{1}{n}V[f(X)] \\rightarrow 0;\\text{as};n\\rightarrow\\infty$ ","date":"2021-11-29","objectID":"/prml-chap11-1/:0:1","tags":["Approximate Inference"],"title":"[PRML] Chapter11 - Sampling Method","uri":"/prml-chap11-1/"},{"categories":["PRML"],"content":"11.1 Basic Sampling Algorithms forward sampling, regection sampling, importance sampling은 이제 별로 쓰이지 않는다고 한다. 뒤에서 배울 MCMC기법들에 조금 더 집중하자. ","date":"2021-11-29","objectID":"/prml-chap11-1/:1:0","tags":["Approximate Inference"],"title":"[PRML] Chapter11 - Sampling Method","uri":"/prml-chap11-1/"},{"categories":["PRML"],"content":"11.1.2 Rejection sampling complex한 분포에서 sampling하게 도와준다. $p(z)$에서 바로 sampling하기는 어려운 상태 단, $z$를 넣어을 때 $p(z)$의 값은 알 수 있는 상황이다. 이를 위해 sampling이 쉬운 $q(z)$를 정한다. $p(z)$를 다 포함하는 (envelop하는) 분포 $kq(z)$를 만든다. $$kq(z) \\ge p(z)$$ $q(z)$ 에서 sampling한다 : $z_0$ $unif[0, kq(z_0)]$ 에서 숫자를 generate 한다. 해당 숫자가 $p(z_0)$ 보다 크면 reject, 아니면 sampling 한다. 따라서 $p(z)$를 잘 envelop하는 적절한 분포를 찾으면 위의 과정을 반복하여 우리가 원하는 sample들을 얻을 수 있다. ","date":"2021-11-29","objectID":"/prml-chap11-1/:1:1","tags":["Approximate Inference"],"title":"[PRML] Chapter11 - Sampling Method","uri":"/prml-chap11-1/"},{"categories":["PRML"],"content":"11.1.4 Importance sampling expectation을 approximation하는 방법을 제안하다. $$E[f] \\approx \\frac{1}{n}\\sum f(z_i) ; \\text{where} ; z_i \\sim p(z)$$ 하지만 $p(z)$에서 directly sampling하기 어려운 경우가 있다. so how? draw the samples from a proposal distribution(sampling할 수 있는), say $q(z)$ approximation where $w_i= \\frac{p(z_i)}{q(z_i)}, z_i \\sim q(z)$ $$E[f] = \\int f(z)\\frac{p(z)}{q(z)}q(z)dz \\approx \\frac{1}{n}\\sum w_i f(z_i) $$ rejection sampling과는 다르게 sampling한 모든 data들은 버려지지 않고 사용된다. 하지만 단점도 명확하다. 위의 식에서 $q(z)$가 매우 작은 값을 갖는 경우 가중치가 너무 커질수도 있다. ","date":"2021-11-29","objectID":"/prml-chap11-1/:1:2","tags":["Approximate Inference"],"title":"[PRML] Chapter11 - Sampling Method","uri":"/prml-chap11-1/"},{"categories":["PRML"],"content":"11.1.6 Sampling and the EM algorithm Monte carlo를 이용하여 MLE를 구할 수도 있다. EM algorithm의 E step에서 sampling methods를 통해 approximation해보자. complete-data log likelihood $$Q({\\pmb \\theta}, {\\pmb \\theta}^{old}) = \\int p(\\textbf{Z}|\\textbf{X}, {\\pmb \\theta}^{old}) \\ln p(\\textbf{Z},\\textbf{X}|{\\pmb \\theta})d\\textbf{Z}$$ $\\textbf{Z}^{(l)}$ drawn from the current estimate for the posterior distribution $p(\\textbf{Z}|\\textbf{X},{\\pmb \\theta}^{old})$ $$Q({\\pmb \\theta}, {\\pmb \\theta}^{old}) \\approx \\frac{1}{L}\\sum_{l=1}^{L} \\ln p(\\textbf{Z}^{(l)}, \\textbf{X}| {\\pmb \\theta})$$ 이후에 똑같이 M-step으로 optimize한다. 이런 과정을 Monte Carlo EM algorithm 이라고 한다. ","date":"2021-11-29","objectID":"/prml-chap11-1/:1:3","tags":["Approximate Inference"],"title":"[PRML] Chapter11 - Sampling Method","uri":"/prml-chap11-1/"},{"categories":["PRML"],"content":"11.2 Markov Chain Monte Carlo 지금까지 살펴본 sampling 방법들은 high dimension에서 한계점을 갖고 있다. 이제 더 좋은 방법인 MCMC에 대해 공부해보고자 한다. 이전의 방법들과 마찬가지로 proposal distribution에서 sampling한다. proposal distribution : $q(\\textbf{z}|\\textbf{z}^{(\\tau)})$ 다른점은 current state $\\textbf{z}^{(\\tau)}$ 를 given으로 하는 것이다. 이런 통해 만들어진 sample들은 Markov chain을 형성한다. $p(\\textbf{z}) = \\tilde{p}(\\textbf{z})/Z_p$ 에서 $Z_p$는 모르는 상태여도 상관없고 $\\tilde{p}(\\textbf{z})$의 값은 구할 수 있다고 가정한다. $Z_p$는 unknown constant $p(\\textbf{z})$에서 directly sampling은 어려운 상태이다. proposal distribution에서 sample을 뽑고 적절한 기준으로 이를 sample로 인정할지 말지 결정한다. 위와 같은 과정을 하는 basic Metropolis algorithm에 대해 살펴보자. proposal distribution은 symmetric하게 지정한다. 뒤에서 알게 되겠지만 symmetric하면 Markov chain이 time reversible하게 되고 이를 통해 stationary distribution ($p(\\textbf{z})$을 의미) 이 존재한다. $$q(\\textbf{z}_A | \\textbf{z}_B) = q(\\textbf{z}_B | \\textbf{z}_A)$$ 확률적으로 sample로 인정한다, 아래의 식이 accept 확률이다. 딱 봤을때 적절하다는 생각이 든다. 이렇게 반복하다 보면 우리가 원하는 $p(\\textbf{z})$의 모양으로 sampling이 될 것이다. $\\frac{p(\\textbf{z}^{ * })}{p(\\textbf{z}^{(\\tau)})} = \\frac{\\tilde{p}(\\textbf{z}^{ * })}{\\tilde{p}(\\textbf{z}^{(\\tau)})} \\frac{Z_p}{Z_p} = \\frac{\\tilde{p}(\\textbf{z}^{ * })}{\\tilde{p}(\\textbf{z}^{(\\tau)})}$ 라서 정확한 $p(\\textbf{z})$의 값을 몰라도 합리적인 acceptance probability를 구할 수 있다. $$A(\\textbf{z}^{ * }, \\textbf{z}^{(\\tau)} ) = min (1, \\frac{\\tilde{p}(\\textbf{z}^{ * })}{\\tilde{p}(\\textbf{z}^{(\\tau)})})$$ unif(0,1)에서 random number $u$를 뽑는다. $A(\\textbf{z}^{ * }, \\textbf{z}^{(\\tau)} ) \u003e u$이면 sample을 accept한다. candidate sample이 accpet되면 그 sample을 sample list에 저장한다. 그리고 그 sample을 given한 상태로 다시 알고리즘을 진행한다. 만약 reject되면 그 때 당시의 given sample을 sample list에 추가하고 다시 알고리즘을 진행한다. 각 sequence sample은 independent한 sample이 아니다. highly correlated되어 있다면 sample list에서 띄엄띄엄 사용하던가 초반 sample을 버리면 된다. ","date":"2021-11-29","objectID":"/prml-chap11-1/:2:0","tags":["Approximate Inference"],"title":"[PRML] Chapter11 - Sampling Method","uri":"/prml-chap11-1/"},{"categories":["PRML"],"content":"11.2.1 Markov chains 대표적인 MCMC 알고리즘을 살펴보기 전에 Markov chain에 대해 공부해보자. 각 state에 해당하는 random variable $\\textbf{z}^{(1)}, \\textbf{z}^{(2)} ,…,\\textbf{z}^{(M)}$ 가 있다. 이들이 아래와 같은 conditional independence property를 갖을 때, 이러한 stochastic process를 Markov chain이라고 한다. $$p(\\textbf{z}^{(m+1)}|\\textbf{z}^{(1)}, \\textbf{z}^{(2)} ,…,\\textbf{z}^{(m)}) = p(\\textbf{z}^{(m+1)}|\\textbf{z}^{(m)}),; m \\in {1,..,M-1}$$ transition probability $$T(\\textbf{z}^{(m)}, \\textbf{z}^{(m+1)}) \\equiv p(\\textbf{z}^{(m+1)}| \\textbf{z}^{(m)}) \\equiv T_{\\textbf{z}^{(m)}, \\textbf{z}^{(m+1)}}$$ 이제 Markov chain의 몇 가지 특징들에 대해 살펴보자. accesible $i \\rightarrow j$ : state $j$ is accessible from $i$ if $T_{i,j}^m \u003e 0$ 즉 state $i$에서 언젠가는 state $j$에 방문한다는 의미 $i \\leftrightarrow j$ : state $i, j$ communicate if $i \\rightarrow j$ and $j \\rightarrow i$ reducibility 모든 state $i,j$가 communicate하다면 그 Markov chain은 irreducible 하다고 한다. periodicity state $i$ has peoriod d if $d = gcd{n:T_{i,j}^m \u003e0}$ if d = 1, state $i$ is aperiodic transience state $j$ is recurrent if $j$에서 시작해서 언젠가는 다시 $j$를 방문할 확률이 1인 경우 state which is not recurrent is transient positive recurrent : expected time until the process starting in state $i$ returns to $i$ is finite ergodicity irreducible, aperiodic, positive recurrent Markov chain on a countable state space is called ergodic 참고로 irreducible가 성립하면 자동으로 positive recurrent가 성립한다. 따라서 어떤 책에는 ergodic의 조건으로 irreducible, aperiodic 만을 언급하기도 한다. countable state space가 아닌 general한 경우는 ergodicity를 확인하기 복잡하다. (어떤 책에는) For countable state spaces, an irreducible, aperiodic Markov chain having a stationary distribution is ergodic. ergodic Markov chain은 unique stationary distribution을 갖고 있다. Stationary distribution regular MC는 limiting probability distribution ${\\pmb \\pi} = (\\pi_0,…,\\pi_N)$을 갖는다. transition matrix $\\textbf{T}^{(m)}$의 모든 원소가 0보다 크면 MC가 regular 하다고 한다. $\\pi_j = lim_{n \\rightarrow \\infty}T_{i,j}^{(n)}$ stationary distribution은 존재하지 않을 수도 있고 여러 개일 수도 있다. 아래와 같은 식을 만족하는 limiting distribution을 stationary distribution이라고 부른다. $$\\pi_j = \\sum_{k=0}^K \\pi_k T_{k,j}$$ detailed balance condition Markov chain이 아래와 같은 식을 만족하면 time reversible 하다고 한다. $P(\\textbf{z}^{(n)} = j| \\textbf{z}^{(n+1)} = i) = P(\\textbf{z}^{(n+1)} = j| \\textbf{z}^{(n)} = i)$ time reversibility의 조건은 아래와 같이도 표현할 수 있는데 이를 detailed balance condition 이라고 한다. (detailed balance condition $\\Leftrightarrow$ reversibility) $$\\pi_i T_{i,j} = \\pi_j T_{j,i}$$ detailed balance condition을 만족하면 stationary distribution을 갖는다. (unique한지는 확신할 수 없다) proof $$\\pi_i T_{i,j} = \\pi_j T_{j,i} \\ \\sum_i \\pi_i T_{i,j} =\\sum_i \\pi_j T_{j,i} \\ \\sum_i \\pi_i T_{i,j} =\\pi_j \\sum_i T_{j,i} \\ \\sum_i \\pi_i T_{i,j} =\\pi_j$$ 지금까지 Markov chain에 대해 알아보았다. 이 특성들을 이용하여 우리는 MCMC algorithm을 진행한다. 일단 전통적인 Markov chain 이론과 MCMC의 구별되는 특징에 대해 알아보면 In the traditional Markov chain theory, Given a transition rule, $P(\\textbf{z}^{n+1} = j | \\textbf{z}^{(n)} = i)$ Interested in finding its stationary distribution $\\pi$ In the MCMC, Given a target stationary distribution $\\pi$ Interested in prescribing and efficient transition rule to reach $\\pi$ 이 내용을 위에서 봤던 Metropolis algorithm과 잘 연결시켜서 이해하도록 하자. ergodic MC는 unique stationary distribution을 갖고 있다. 하지만 종종 ergodic 여부를 판단하기 어려운 상황이 발생한다. in practice, reversible MC는 detailed balance condition을 만족하고 이는 stationary distribution가 존재함을 위미한다. 따라서 reversible MC를 주로 이용하고 starting value를 여러가지로 진행하여 unique함을 확인한다. ","date":"2021-11-29","objectID":"/prml-chap11-1/:2:1","tags":["Approximate Inference"],"title":"[PRML] Chapter11 - Sampling Method","uri":"/prml-chap11-1/"},{"categories":["PRML"],"content":"11.2.2 The Metropolis-Hastings algorithm 이전에 Metropolis algorithm에서는 proposal distribution(= transition kernel)이 symmetric했다. 하지만 이제는 그렇지 않다. 단, $q(\\textbf{z}_A | \\textbf{z}_B) \u003e0 \\Leftrightarrow q(\\textbf{z}_B | \\textbf{z}_A) \u003e 0$ 을 만족해야 한다. 현재 state는 $\\textbf{z}^{(\\tau)}$ distribution $q(\\textbf{z} | \\textbf{z}^{(\\tau)})$로부터 sample $\\textbf{z}^{ * }$을 뽑는다. normal 분포를 주로 사용한다. 단, 분산을 적절하게 선택해야 한다. 아래의 확률에 따라 accept한다. $$A(\\textbf{z}^{ * }, \\textbf{z}^{(\\tau)} ) = min (1, \\frac{\\tilde{p}(\\textbf{z}^{ * })q(\\textbf{z}^{(\\tau)} | \\textbf{z}^{ * })}{\\tilde{p}(\\textbf{z}^{(\\tau)})q(\\textbf{z}^{ * } | \\textbf{z}^{(\\tau)})})$$ Metropolis-Hastings은 detailed balance condition을 만족한다. $$p(\\textbf{z}) T_{\\textbf{z},\\textbf{z}'} $$ $$= p(\\textbf{z})q(\\textbf{z}'|\\textbf{z})A(\\textbf{z}' , \\textbf{z}) $$ $$ = \\min {p(\\textbf{z})q(\\textbf{z}'|\\textbf{z}), p(\\textbf{z}')q(\\textbf{z}|\\textbf{z}') }$$ $$= \\min { p(\\textbf{z}')q(\\textbf{z}|\\textbf{z}'),p(\\textbf{z})q(\\textbf{z}'|\\textbf{z}) }$$ $$= p(\\textbf{z}')q(\\textbf{z}|\\textbf{z}')A(\\textbf{z} , \\textbf{z}') $$ $$= p(\\textbf{z}') T_{\\textbf{z}',\\textbf{z}} $$ detailed balance condition을 만족하기에 우리가 sampling하여 만들어지는 MC가 stationary distribution을 갖게 된다. 따라서 stationary distribution으로 수렴하기전의 sampling 초반의 sample들은 버리고 (해당 구간을 burn-in period 라고 한다) 뒷부분의 sample들을 이용한다. 해당 sample list는 stationary distribution의 형태를 갖고 있을 것이다. 결국 우리가 구하고자하는 (unormalized) density를 구할 수 있는 것이다. 주로 posterior distribution을 구하는 것이 목적인 경우가 많다. ","date":"2021-11-29","objectID":"/prml-chap11-1/:2:2","tags":["Approximate Inference"],"title":"[PRML] Chapter11 - Sampling Method","uri":"/prml-chap11-1/"},{"categories":["PRML"],"content":"11.3 Gibbs sampling Metropolis-Hastings algorithm의 특별한 케이스이다. 우리가 sample을 뽑고 싶어하는 $p(\\textbf{z}) = p(z_1,z_1,…,z_M)$ distribution이 있다. 이전에 우리는 proposal distribution을 따로 정해서 사용하였지만 Gibbs sampling에서는 그렇지 않다. 먼저 1부터 순서대로 $z_i$를 distribution $p(z_i|\\textbf{z}_{-i})$에서 뽑는다. 이를 M까지 반복한다. Initialize ${z_i : i=1,…,M}$ For $\\tau = 1,…,T:$ Sample $z_1^{(\\tau+1)} \\sim p(z_1 | z_2^{(\\tau)}, z_3^{(\\tau)},…, z_M^{(\\tau)})$ Sample $z_2^{(\\tau+1)} \\sim p(z_2 | z_1^{(\\tau+1)}, z_3^{(\\tau)},…, z_M^{(\\tau)})$ … Sample $z_M^{(\\tau+1)} \\sim p(z_M | z_1^{(\\tau+1)}, z_2^{(\\tau+1)},…, z_{M-1}^{(\\tau+1)})$ 즉, Gibbs sampling에서는 acceptance probability를 사용하지 않는다. 모든 sample을 그대로 사용한다. 그렇게 해도 detailed balance condition을 만족하는지 살펴보자. 즉, 특정한 distribution으로 수렴하는지 확인. Gibbs sampling에서 $q(\\textbf{z}|\\textbf{z}') = p(z_i | \\textbf{z}_{-i}')$ 이고 $p(\\textbf{z}')q(\\textbf{z} | \\textbf{z}') = p(\\textbf{z})q(\\textbf{z}' | \\textbf{z})$ 임을 확인해보자. $$p(\\textbf{z}')q(\\textbf{z} | \\textbf{z}') = p(z_i', \\textbf{z} _ {-i}')p(z_i| \\textbf{z} _ {-i}')$$ $$=p(z_i'|\\textbf{z} _ {-i}')p(\\textbf{z} _ {-i}')p(z_i| \\textbf{z} _ {-i}') $$ $$= p(z_i'|\\textbf{z} _ {-i}') p(z_i , \\textbf{z} _ {-i}') = q(\\textbf{z}'| \\textbf{z})p(\\textbf{z})$$ 항상 detailed balance condition이 성립한다. 더 advanced한 MCMC 알고리즘으로는 Hamilton이 있는 것 같다. MCMC가 주 관심분야는 아니기 때문에 여기까지만 정리하기로 한다. ","date":"2021-11-29","objectID":"/prml-chap11-1/:3:0","tags":["Approximate Inference"],"title":"[PRML] Chapter11 - Sampling Method","uri":"/prml-chap11-1/"},{"categories":["PRML"],"content":"VI, EP 에 대한 정리 (예시 제외) probabilistic model의 중요 목표는 posterior distribution $p(\\textbf{Z}|\\textbf{X})$ of the latent variable $\\textbf{Z}$ given the observed data $\\textbf{X}$ 추정 posterior distribution을 이용한 expectation 추정 라고 할 수 있다. In practice 에서는 posterior와 expectation을 구하기가 infeasible한 경우가 존재한다. 이는 latent space가 too high dimension이라 directly 어려운 경우 posterior distribution이 너무 복잡하여 expectation이 analytically intractable한 경우 때문이다. 따라서 우리는 approximation을 해야 한다. 이 방법으로는 크게 두 가지로 나누어서 생각할 수 있다. Stochastic 방법 : MCMC Deterministic 방법 : (analytical approximations to the posterior distribution) variational inference(or Bayes) ","date":"2021-11-29","objectID":"/prml-chap10-2/:0:0","tags":["Approximate Inference"],"title":"[PRML] Chapter10 - Approximate Inference (2)","uri":"/prml-chap10-2/"},{"categories":["PRML"],"content":"10.1 Variational Inference functional : mapping that takes a function as the input and that returns the value of the functional as the output 우리는 이런 functional을 optimize해서 목표를 이룰 것이다. fully Bayesian model 을 가정해보자. 즉, 모든 parameter들이 prior 존재한다고 가정하는 것이다. model은 latent variable, latent parameter 가 존재한다. 이들은 모두 $\\textbf{Z}$ 로 표현하고 observed variables는 $\\textbf{X}$로 표현한다. 우리의 목표는 find approximation for the posterior distribution $p(\\textbf{Z} | \\textbf{X})$ and model evidence $p(\\textbf{X})$ log marginal probability를 분해하면 $$\\ln p(\\textbf{X}) = L(q) - KL(q||p)$$ $$L(q) = \\int q(\\textbf{Z}) \\ln { \\frac{p(\\textbf{X},\\textbf{Z})}{q(\\textbf{Z})} } d \\textbf{Z} \\ KL(q||p) = \\int q(\\textbf{Z}) \\ln { \\frac{p(\\textbf{Z}|\\textbf{X})}{q(\\textbf{Z})} }$$ 이전의 EM과 다른 부분은 parameter vector ${\\pmb \\theta}$가 안보인다는 점이다. 이는 parameter가 이제 stochastic variable이기 때문에 $\\textbf{Z}$에 흡수되서 그렇다. 이제 우리가 할 일은 알다시피 KL을 0으로 만들어주는 과정이 필요하다. 이전에는 latent의 posterior와 동일한 분포를 가정하면 됐지만 지금은 해당 분포가 intractable하다고 가정하고 있다. 그렇다면 제약적이지만 최대한 flexible한 분포를 통해 approximation 해야 한다. 그래서 family of approximation distribution을 parametric distribution으로 제한한다. parameter $\\omega$로 $p(\\textbf{Z}|\\omega)$를 이용하는 것이다. Lower bound가 $\\omega$에 대한 식이 되고 이를 optimization하는 problem을 해결한다. ","date":"2021-11-29","objectID":"/prml-chap10-2/:1:0","tags":["Approximate Inference"],"title":"[PRML] Chapter10 - Approximate Inference (2)","uri":"/prml-chap10-2/"},{"categories":["PRML"],"content":"10.1.1 Factorized distributions $\\textbf{Z}$의 각 element들을 disjoint하게 나눈다. $$q(\\textbf{Z}) = \\prod_{i=1}^{M} q_i (\\textbf{Z}_i)$$ 이를 바로 이용해보자! $$L(q) = \\int \\prod_i q_i(\\textbf{Z}_i) \\ln { \\frac{p(\\textbf{X},\\textbf{Z})}{\\prod_i q_i(\\textbf{Z}_i)}} d \\textbf{Z}$$ $$ = \\int q_j(\\textbf{Z} _ j ) { \\int \\ln p(\\textbf{X},\\textbf{Z})\\prod_{i \\neq j}q_i(\\textbf{Z}_i) d \\textbf{Z}_i } d \\textbf{Z}_j - \\int q_j(\\textbf{Z}_j) \\ln q_j (\\textbf{Z}_j) + const $$ $$= \\int q_j (\\textbf{Z}_j) \\ln \\tilde{p} (\\textbf{X},\\textbf{Z}_j) d \\textbf{Z}_j - \\int q_j(\\textbf{Z}_j) \\ln q_j (\\textbf{Z}_j) d\\textbf{Z}_j + const$$ $$\\text{where}\\; \\ln \\tilde{p} (\\textbf{X},\\textbf{Z} _ j) = E_{i \\neq j}[\\ln p(\\textbf{X,Z})]+const $$ $$ E_{i \\neq j}[\\ln p(\\textbf{X,Z})] = \\int \\ln p(\\textbf{X},\\textbf{Z})\\prod_{i \\neq j}q_i(\\textbf{Z}_i) d \\textbf{Z}_i $$ negative KL divergence의 형태가 나오고 lower bound $L(q)$를 최대로 올리기 위해서는 $$q_j(\\textbf{Z} _ j) = \\tilde{p}(\\textbf{X,Z})$$ general expression for the optimal solution $q_j (\\textbf{Z}_j)$는 $$ \\ln q_j(\\textbf{Z} _ j) = E_{i \\neq j}[\\ln p(\\textbf{X,Z})]+const$$ 위에서 const는 normalizing const이다. log를 지워보면서 아래와 같은 식이 나오는데 실제로 사용할때는 위의 식이 더 편하다고 한다. $$q_j(\\textbf{Z} _ j) = \\frac{\\exp(E_{i \\neq j}[\\ln p(\\textbf{X,Z})])}{\\int \\exp(E_{i \\neq j}[\\ln p(\\textbf{X,Z})])d\\textbf{Z}_j}$$ 이 식의 값을 구하기 위해서는 iterative하게 반복해야 한다. $\\textbf{Z}$의 모든 element에 적절한 초깃값으로 시작한다. $j$를 제외한 나머지 값들로 $q_j$를 구한다. 이 과정을 모든 element에 반복하면 된다. convergence를 이미 증명되어 있다. ","date":"2021-11-29","objectID":"/prml-chap10-2/:1:1","tags":["Approximate Inference"],"title":"[PRML] Chapter10 - Approximate Inference (2)","uri":"/prml-chap10-2/"},{"categories":["PRML"],"content":"10.1.2 Properties of factorized approximations minimization of $KL(q||p)$ : tend to find one of modes minimization of $KL(p||q)$ : resulting approximations would average across all of the modes ","date":"2021-11-29","objectID":"/prml-chap10-2/:1:2","tags":["Approximate Inference"],"title":"[PRML] Chapter10 - Approximate Inference (2)","uri":"/prml-chap10-2/"},{"categories":["PRML"],"content":"예시들 10.1.3 Example : The univariate Gaussian 10.1.4 Model comparison 10.2 Illustration: Variational Mixture of Gaussians 10.3 Variational Linear Regression 10.4 Exponential Family Distributions 10.5 Local Variational Methods 10.6 Variational Logistic Regression ","date":"2021-11-29","objectID":"/prml-chap10-2/:1:3","tags":["Approximate Inference"],"title":"[PRML] Chapter10 - Approximate Inference (2)","uri":"/prml-chap10-2/"},{"categories":["PRML"],"content":"10.7 Expectation Propagation deteministic한 또 다른 방법을 알아보자. 아래의 KL-Divergence를 최소화해야 하는 상황이다. $$KL(p||q)$$ $p(\\textbf{z})$ is fixed $q(\\textbf{z})$ is exponential family $$q(\\textbf{z}) = h(\\textbf{z})g({\\pmb \\eta})\\exp{ {\\pmb \\eta}^T u(\\textbf{z}) }$$ $\\eta$에 대한 함수인 KL을 구하면 $$KL(p||q) = - \\ln q({\\pmb \\eta}) - {\\pmb \\eta}^T E_p [u(\\textbf{z})] + const$$ 이를 최소화하기 위해 $\\eta$에 대해 미분하여 0으로 하면 $$- \\nabla \\ln g({\\pmb \\eta}) = E_p [u(\\textbf{z})]$$ 임을 알 수 있다. 그런데 우리가 2장에서 공부했던 내용을 이용하면 ($q(z)$를 parameter에 대해 미분) 아래와 같은 사실을 알 수 있다. $$- \\nabla \\ln g({\\pmb \\eta}) = E_q [u(\\textbf{z})]\\ \\therefore E_q [u(\\textbf{z})] = E_p [u(\\textbf{z})]$$ 따라서 KL를 최소화하는 optimum solution은 충분통계량의 expectation을 이용하는 것이다. 예를 들어, $q(\\textbf{z}) \\sim N(\\mu, \\Sigma)$ 이면 KL을 최소화하기 위해 $p(\\textbf{z})$의 mean과 covariance와 같아지면 된다. 이를 moment matching 이라고 한다. 이제 approximation을 해보자. 많은 probabilistic model들은 joint distribution of data $D$ and hidden variables $\\theta$ comprises a product of fators in the form 예를 들면, 각 data들은 iid $f_n({\\pmb \\theta}) = p(\\textbf{x}_n | {\\pmb \\theta})$ $f_0({\\pmb \\theta})$는 prior $$p(D, {\\pmb \\theta}) = \\prod_i f_i ({\\pmb \\theta})$$ 우리의 관심은 예측을 위한 posterior distrbution $p({\\pmb \\theta} | D)$, model comparison을 위한 model evidence $p(D)$ 이다. $$p({\\pmb \\theta}|D) = \\frac{1}{p(D)} \\prod_i f_i ({\\pmb \\theta}) \\ p(D) = \\int \\prod_i f_i({\\pmb \\theta}) d {\\pmb \\theta}$$ Expectation propagation은 posterior distribution을 아래와 같이 approximation하는 것이다. $\\tilde{f}_i$는 각각 이에 해당하는 $f_i$를 approximate $Z$는 normalizing constant $$q({\\pmb \\theta}) = \\frac{1}{Z} \\prod_i \\tilde{f}_i ({\\pmb \\theta})$$ $\\tilde{f}_i({\\pmb\\theta})$를 exponential family로 제한할 것이다. 그래서 충분통계량을 이용할 것이다. 지금까지를 통해 KL을 구하면 $$KL(p||q) = KL(\\frac{1}{p(D)} \\prod_i f_i ({\\pmb \\theta}) ||\\frac{1}{Z} \\prod_i \\tilde{f}_i ({\\pmb \\theta}))$$ 그런데 KL에 true distribution이 있기에 intractable하다. 이를 위해 우리는 전체가 아닌 개별의 factor에 대해 KL을 최소화할 것이다. 이는 훨씬 간단해졌다. 또한 noniterative하다. 하지만 개별 factor를 approximation하다보니 이들을 다 product하면 좋지 않은 결과가 나올 수도 있다. factor $\\tilde{f}_j({\\pmb \\theta})$를 구해보자. 먼저 j factor와 나머지 factor로 나누어서 생각한다. $$q^{new}({\\pmb \\theta}) \\propto \\tilde{f} _ j ({\\pmb \\theta}) \\prod_{i \\neq j} \\tilde{f}_i ({\\pmb \\theta})$$ 위의 식은 아래의 식과 최대한 비슷하게 만든다. $$f_j ({\\pmb \\theta}) \\prod_{i \\neq j} \\tilde{f}_i ({\\pmb \\theta})$$ 이를 위해 approximation $q({\\pmb \\theta})$에서 j를 제외하여 unnormalized distribution을 만들면 $$q^{-j}({\\pmb \\theta}) = \\frac{q({\\pmb \\theta})}{\\tilde{f}_j ({\\pmb \\theta})}$$ 이를 기존 factor와 결합하여 $Z_j = \\int f_j ({\\pmb \\theta}) q^{-j} ({\\pmb \\theta}) d{\\pmb \\theta}$ : normalizing const $$\\frac{1}{Z_j} f_j ({\\pmb \\theta}) q^{-j} ({\\pmb \\theta})$$ 이를 이용하여 KL을 최소화하여 우리가 구하고자하는 $\\tilde{f}_j$를 구해보자. $$KL( \\frac{f_j({\\pmb \\theta}) q^{-j}({\\pmb \\theta})}{Z_j} || q^{new}({\\pmb \\theta}) )$$ 이는 $q^{new}({{\\pmb \\theta}})$가 exponetial family로 만들어졌고 따라서 parameter들이 $\\frac{f_j({\\pmb \\theta}) q^{-j}({\\pmb \\theta})}{Z_j}$와 expected sufficient statistic을 맞춤으로 구할 수 있다. (moment matching) exponential family에서 expected statistic은 normalization coefficient의 derivative와 관련이 되어 있기에 더 쉽게 구할 수 있다. 이전에 구했던 식을 이용하면 아래와 같이 구할 수 있다. $$\\tilde{f}_j ({\\pmb \\theta}) = K \\frac{q^{new}({\\pmb \\theta})}{q^{-j}({\\pmb \\theta})}$$ $q^{new}({\\pmb \\theta})$가 normalized되었다는 사실을 이용하면 $$K = \\int \\tilde{f}_j ({\\pmb \\theta}) q^{-j}({\\pmb \\theta}) d {\\pmb \\theta}$$ 그리고 $K$의 값은 matching zeroth-order moments를 통해 $K=Z_j$라는 것을 알 수 있다. 따라서 $$\\tilde{f}_j ({\\pmb \\theta}) = Z_j \\frac{q^{new}({\\pmb \\theta})}{q^{-j}({\\pmb \\theta})}$$ 이렇게 approximation factor를 적절한 값으로 초기화하고 converge할 때까지 반복한다. EP의 단점은 converge한다는 보장이 없다. mixture의 경우는 EP가 적절하지 않다. variational inference는 $KL(q||p)$ EP는 $KL(p||q)$ $p({\\theta})$가 multimodal인 경우 EP는 approximation이 잘 안된다. 하지만 logistic-type models 에서는 EP가 좋다고 한다. ","date":"2021-11-29","objectID":"/prml-chap10-2/:2:0","tags":["Approximate Inference"],"title":"[PRML] Chapter10 - Approximate Inference (2)","uri":"/prml-chap10-2/"},{"categories":["PRML"],"content":"PRML chapter10 에 대한 카이스트 문일철 교수님 강의 정리하였다. ","date":"2021-11-29","objectID":"/prml-chap10-1/:0:0","tags":["Approximate Inference"],"title":"[PRML] Chapter10 - Approximate Inference (1)","uri":"/prml-chap10-1/"},{"categories":["PRML"],"content":"Variational transform concave한 $y = \\ln (x)$ 를 조금 더 간단한 함수(linear)로 근사하고자 한다. (특정 $x$에서) linear model $f(x) = \\lambda x + b(\\lambda)$ 으로 근사하자. How? $\\min_x (\\lambda x + b(\\lambda) -\\ln x)$ 이를 위해 $x$에 대해 미분한다. 미분해서 구하면 $\\lambda= \\frac{1}{x}$ 이를 이용하면 $b(\\lambda) = -\\ln \\lambda -1$ $f(x) = \\lambda x - \\ln \\lambda -1$ 의 결과가 나온다. $x$에 대해서 선형인 결과이다. 하지만 optimization하기에 non linear한 $\\lambda$가 다시 생긴다. 그렇다면 logistic function에서는 variation transform이 가능할까? s curve라 concave하지도 convex하지도 않다. 이런 경우 log 을 취해준다. $$\\log \\frac{1}{1+e^{x}} = -\\log(1+e^x)$$ 이렇게 하면 log함수의 형태이므로 linear approximation(variational transform)이 가능하다. 그리고 linear model을 다시 exp를 취해주면 될 것이다. ","date":"2021-11-29","objectID":"/prml-chap10-1/:0:1","tags":["Approximate Inference"],"title":"[PRML] Chapter10 - Approximate Inference (1)","uri":"/prml-chap10-1/"},{"categories":["PRML"],"content":"Convex duality 그렇다면 위와 같은 경우를 좀 더 systematic variational transform할 수 없을까? Utilize the convex duality 우리는 log같은 concave(or convex) function의 형태만 되면 선형으로 근사할 수 있다. Dual function(=Conjugate function) : $f^{ * }(\\lambda)$ $$f(x)=\\min_{\\lambda}{ \\lambda^T x - f^{* }(\\lambda) } \\Leftrightarrow f^{* }(\\lambda)=\\min_{x}{ \\lambda^T x - f(x)}$$ 위에서 봤듯이 복잡한 함수를 approximate했지만 그 복잡성은 사라지는 것이 아니고 $\\lambda$와 같이 파라미터의 형태로 존재하게 된다. 앞에서 배운 내용을 확률모델에서 생각해보자. probability distribution function도 결국 function이니까 그대로 이용할 수 있다. (variational transform) 아래 식에서 $\\pi (i)$는 $i$의 given을 의미 eg. $P(S) = P(S_1)P(S_2|P_1,P_3)P(S_3)$ 에서 $\\pi(2)={1,3}$ variational parameter $\\lambda_i^U$ $$P(S) = \\prod P(S_i | S_{\\pi(i)}) = \\min_{\\lambda}P^U (S_i | S_{\\pi(i)}, \\lambda^U_i )$$ ","date":"2021-11-29","objectID":"/prml-chap10-1/:0:2","tags":["Approximate Inference"],"title":"[PRML] Chapter10 - Approximate Inference (1)","uri":"/prml-chap10-1/"},{"categories":["PRML"],"content":"Variables of E and H $E$ is observed, fixed $H$ is estimated, infered $E \\cup H = S$ (전체) 라고 할 때 $P(E) = \\sum_H P(H,E) = \\sum_H P(S) = \\sum_H \\prod_i P(S_i | S_{\\pi(i)})$ 우리가 구하고자 하는 것은 $P(H|E) = P(H,E) / P(E)$ 이다. variational inference를 통해 $P(E)$를 approximate해야 한다. (바로 구하기 어려운 경우) ","date":"2021-11-29","objectID":"/prml-chap10-1/:0:3","tags":["Approximate Inference"],"title":"[PRML] Chapter10 - Approximate Inference (1)","uri":"/prml-chap10-1/"},{"categories":["PRML"],"content":"Setting the minimum criteria $$\\ln P(E) = \\ln \\sum_H P(H,E) = \\ln \\sum_H Q(H|E) \\frac{P(H,E)}{Q(H|E)}$$ log는 concave(위로 볼록) 하기에 $$\\ln \\sum_H Q(H|E) \\frac{P(H,E)}{Q(H|E)} \\ge \\sum_H Q(H|E) \\ln \\frac{P(H,E)}{Q(H|E)} \\ = \\sum_H Q(H|E)[{ \\ln P(E|H) + \\ln P(H) } - \\ln Q(H|E)] \\= E_{Q(H|E)}\\ln P(E|H) - KL(Q(H|E) || P(H))$$ ","date":"2021-11-29","objectID":"/prml-chap10-1/:0:4","tags":["Approximate Inference"],"title":"[PRML] Chapter10 - Approximate Inference (1)","uri":"/prml-chap10-1/"},{"categories":["PRML"],"content":"Optimizing the Lower Bound $Q(H | E,\\lambda)$ : variational function(distribution) $\\lambda$ : variational parameter $\\theta$는 model parameter $$\\ln P(E | \\theta) \\ge E_{Q(H|E)}\\ln P(E|H,\\theta) - KL(Q(H|E) || P(H|\\theta))$$ ELBO(evidence lower bound) $$L(\\theta, \\lambda) = \\sum_H Q(H|E,\\lambda)\\ln P(H,E | \\theta) - Q(H|E,\\lambda)\\ln Q(H|E,\\lambda)$$ 이를 최적화하기 위해서 (9장에서 공부한 EM과 거의 유사) KL을 0으로 만들고 $Q(H|E,\\lambda)=P(H|E,\\theta)$으로 만든다. $\\lambda^{t+1} = \\arg\\max_{\\lambda}L(\\theta^t, \\lambda^t)$ 그리고 $\\theta$를 optimization한다. (미분해서) $\\theta^{t+1} = \\arg\\max_{\\theta}L(\\theta^t, \\lambda^{t+1})$ 그렇다면 어떻게 Q를 구할까? ","date":"2021-11-29","objectID":"/prml-chap10-1/:0:5","tags":["Approximate Inference"],"title":"[PRML] Chapter10 - Approximate Inference (1)","uri":"/prml-chap10-1/"},{"categories":["PRML"],"content":"Factorizing Q Q를 안다는 것은 좋은 $\\lambda$와 Q의 distribution 형태를 골라야하는 것이다. 이전에는 Q가 $P(H|E,\\theta)$이 되도록 하였지만 이를 쉽게 구하기 어려운 경우도 존재한다. 그렇다면 Q를 approximate 해보자. Mean field approximation hidden variable들이 독립이라는 가정 given variational parameter simple, easier to hadle strong assumption $$Q(H) = \\prod_{i \\le |H|}q_i(H_i | \\lambda_i)$$ ","date":"2021-11-29","objectID":"/prml-chap10-1/:0:6","tags":["Approximate Inference"],"title":"[PRML] Chapter10 - Approximate Inference (1)","uri":"/prml-chap10-1/"},{"categories":["PRML"],"content":"Focusing on Single Variable in Q 이번에는 Factorizing한 Q에서 하나의 variable에 대해 살펴보자. $$L(\\theta, \\lambda) = \\sum_H [ \\prod_{i \\le |H|}q_i(H_i |E, \\lambda_i)\\ln P(H,E | \\theta) \\\\ - \\prod_{i \\le |H|}q_i(H_i |E, \\lambda_i)\\ln \\prod_{i \\le |H|}q_i(H_i | E,\\lambda_i) ]$$ 위에서 single variable에 대해 정리하면 (j와 관련없으면 constant C로 처리) $$L(\\lambda_j) = \\sum_H [ \\prod_{i \\le |H|}q_i(H_i |E, \\lambda_i)\\ln P(H,E | \\theta) \\\\ - \\prod_{i \\le |H|}q_i(H_i |E, \\lambda_i)\\ln \\prod_{i \\le |H|}q_i(H_i | E,\\lambda_i) ]$$ $$= \\sum_H [ \\prod_{i \\le |H|}q_i(H_i |E, \\lambda_i) { \\ln P(H,E | \\theta) - \\ln \\prod_{i \\le |H|}q_i(H_i | E,\\lambda_i)} ] $$ $$= \\sum_{H_j} q_j (H_j | E, \\lambda_j) \\sum_{H_{-j}} \\prod_{i \\le |H|, i \\neq j} q_i(H_i |E,\\lambda_i) \\ln P(H,E|\\theta) \\\\ -\\sum_{H_j} q_j (H_j|E,\\lambda_j) \\ln q_j (H_j|E,\\lambda_j)+C$$ 이제 새로운 P function을 정의하면 $$\\ln \\tilde{P}(H,E | \\theta) = \\sum_{H_{-j}}\\prod_{i\\le |H|, i \\neq j}q_i(H_i | E,\\lambda_i) \\ln P(H,E | \\theta) $$ $$ = E_{q_{i \\neq j} }[\\ln P(H,E | \\theta)]+C$$ 이 새로운 P function을 $L(\\lambda_j)$ 에 대입하면 이전에 우리가 봤던 형태가 나온다. 그렇다 KL divergence! 이를 최적화하기 위해서는 KL divergence = 0 을 만드는 분포를 이용하면 된다. 따라서 $$\\ln q_j (H_j | E, \\lambda_j) = \\ln \\tilde{P}(H,E | \\theta)=E_{q_{i \\neq j}}[\\ln P(H,E | \\theta)] + C$$ ","date":"2021-11-29","objectID":"/prml-chap10-1/:0:7","tags":["Approximate Inference"],"title":"[PRML] Chapter10 - Approximate Inference (1)","uri":"/prml-chap10-1/"},{"categories":["PRML"],"content":"예시 $\\mu \\sim N(\\mu_0, \\frac{1}{\\lambda_0 \\tau})$ $\\tau \\sim Gamma(a_0, b_0)$ $x_i \\sim N(\\mu, \\frac{1}{\\tau})$ H : $\\mu, \\tau$ E : x 먼저 joint 부터 구하면 $$p(H,E | \\theta) = p(X,\\mu,\\tau | \\mu_0, \\lambda_0, a_0, b_0)$$ $$ =p(X| \\mu, \\tau)p(\\mu | \\tau, \\mu_0, \\lambda_0)p(\\tau | a_0, b_0)$$ $$=\\prod_i p(x_i | \\mu, \\tau)p(\\mu | \\tau, \\mu_0, \\lambda_0)p(\\tau | a_0, b_0)$$ 우리는 2개의 variational parameter가 필요하다. by mean field approximation $$Q(H|E,\\lambda) = Q(\\mu,\\tau | X,\\mu', \\tau') = q(\\mu | X,\\mu')q(\\tau | X,\\tau')$$ 그럼 이제 optimal variational parameter를 구해보자. 일단 $\\mu$에 관하여 진행 $$\\ln q(\\mu | X,\\mu') = E_{\\tau}[\\ln p(X,\\mu, \\tau | \\mu_0,\\lambda_0, a_0, b_0)]+C_1 $$ $$ = E_{\\tau}[\\ln \\prod_i p(x_i | \\mu, \\tau)p(\\mu | \\tau, \\mu_0, \\lambda_0)p(\\tau | a_0, b_0)]+C_1 \\\\ = E_{\\tau}[\\sum(\\frac{1}{2}(\\ln \\tau - \\ln 2\\pi) - \\frac{(x_i-\\mu)^2 \\tau}{2})] \\\\ + E_{\\tau}[\\frac{1}{2}(\\ln \\lambda_0 + \\ln \\tau - \\ln 2 \\pi) - \\frac{(\\mu - \\mu_0)^2 \\lambda_0 \\tau}{2}]+C_2 \\\\ = - \\frac{E_{\\tau}[\\tau]}{2}{ \\sum (x_i - \\mu)^2 + (\\mu - \\mu_0)^2 \\lambda_0 }+C_3$$ $$ = - \\frac{1}{2}{ (\\lambda_0+N)E_{\\tau}[\\tau] (\\mu - \\frac{\\lambda_0 \\mu_0 + \\sum x_i}{\\lambda_0 + N})^2 } + C_4$$ 그렇다면 이제 $q(\\mu | X,\\mu')$를 normal이라고 가정해보면 (우리는 $q(\\mu;i;p)$에 대한 아무런 가정이 없기 때문에 이렇게 접근하는 것) $$q(\\mu | X,\\mu') \\sim N(\\frac{\\lambda_0 \\mu_0 + \\sum x_i}{\\lambda_0 + N},\\frac{1}{(\\lambda_0 +N)E_{\\tau}[\\tau]})$$ 위에서 우리가 모르는 부분은 $E_{\\tau}[\\tau]$ 이므로 위와 똑같은 과정을 반복해서 모르는 부분에 대해 찾아야 한다. $$\\ln q(\\tau | X,\\tau') = E_{\\mu}[\\ln p(X,\\mu,\\tau | \\mu_0, \\lambda_0, a_0, b_0)]+C_1$$ $$= -\\tau{ b_0 + \\frac{1}{2}E_{\\mu}[\\sum(x_i - \\mu)^2 + (\\mu-\\mu_0)^2 \\lambda_0]} + (a_0 + \\frac{N+1}{2}-1)\\ln \\tau + C_2$$ 이를 잘 보면 $q(\\tau | X,\\tau')$ 는 Gamma 꼴이라고 생각할 수 있다. $$q(\\tau | X,\\tau') \\sim Gamma(a_0 + \\frac{N+1}{2}, b_0 + \\frac{1}{2}E_{\\tau}[\\sum(x_i - \\mu)^2 + (\\mu - \\mu_0)^2\\lambda_0])$$ 이를 통해 우리가 구해야 하는 모든 것을 구했다. 정리하면 $E_{\\tau}[\\tau] : E_{\\mu}[\\mu],E_{\\mu}[\\mu^2]$ 이 필요하다 $E_{\\mu}[\\mu]$ 는 바로 구할 수 있음 $E_{\\mu}[\\mu^2] : E_{\\tau}[\\tau]$ 필요 $\\lambda$ 는 임의의 수로 시작 interlocked 된 상태이기에 iterative하게 구하면 된다. ","date":"2021-11-29","objectID":"/prml-chap10-1/:0:8","tags":["Approximate Inference"],"title":"[PRML] Chapter10 - Approximate Inference (1)","uri":"/prml-chap10-1/"},{"categories":["PRML"],"content":"기타 예시 prof.Moon Latent Dirichlet Allocation ","date":"2021-11-29","objectID":"/prml-chap10-1/:0:9","tags":["Approximate Inference"],"title":"[PRML] Chapter10 - Approximate Inference (1)","uri":"/prml-chap10-1/"},{"categories":["PRML"],"content":"GMM과 EM 알고리즘에 대해 정리하였다.GMM과 EM 알고리즘에 대해 정리하였다. observed variable와 latent variable에 대한 joint distribution을 정의한다고 해보자. 이 때 observed variable에 대한 확률 분포를 구하고 싶은 경우 latent variable의 marginalization을 진행하면 된다. 이 의미는 복잡한 형태의 분포를 가진 observed variable에 대한 분포를 다룰 때, 좀 더 다루기 쉬운 observed variable와 latent variable의 joint distribution을 이용할 수 있다는 것이다. 즉, latent variable을 도입함으로서 복잡한 분포 모델을 좀 더 쉬운 형태의 분포들의 조합으로 변경할 수 있다. 여기서는 K-mean, Gaussian mixture model, EM algorithm 에 대해 공부할 것이다. discrete latent variable의 경우에 해당한다. (continuous latent는 12장에서 공부한다) ","date":"2021-11-29","objectID":"/prml-chap09-1/:0:0","tags":["GMM","EM Algorithm"],"title":"[PRML] Chapter9 - Mixture Models and EM","uri":"/prml-chap09-1/"},{"categories":["PRML"],"content":"9.1 K-means Clustering D 차원의 데이터가 N개 있다 우리는 이 데이터들을 K개의 cluster로 분류하고자 한다. 각 cluster의 중심점을 ${\\pmb \\mu}_k$ 라고 하자. $r_{nk} \\in {0,1}$ : data가 k cluster에 속하면 1, 나머지는 0 object function (distortion measure 라고 부른다) : $$J = \\sum_{n=1}^{N}{ \\sum_{k=1}^{K}{r_{nk}| \\textbf{x}_n -{\\pmb \\mu}_k |^2} }$$ 각 cluster에 속하는 data들과 중심점의 거리를 더한식이다. 우리는 이 식을 최소화하는 $r_{nk},{\\pmb \\mu}_k$ 를 iterative 하게 찾으면 된다. 먼저, ${\\pmb \\mu}_k$의 초깃값을 설정한다. 그리고 $r_{nk}$에 대해 object function을 최소화 한다. (E-step) 다음 $r_{nk}$를 고정하고 object function을 ${\\pmb \\mu}_k$에 대해 최소화 한다. (M-step) converge할때까지 반복한다. 단, global이 아닌 local minimum으로 converge할수 있다. $r_{nk}$의 경우 쉽게 말해 데이터가 각 k개의 중심점들 중에 가장 가까운 k 에 1의 값을 가진다. ${\\pmb \\mu}_k$의 경우 J에서 quadratic 형태이므로 미분하여 그 값을 구한다. J를 미분하면 ${\\pmb \\mu}_k = \\frac{\\sum{r _{nk} \\textbf{x} _n}}{\\sum{r _{nk}}}$ 의 값을 가지고 이는 해당 k cluster에 속하는 data들의 평균값을 의미한다. 그래서 K-means 알고리즘이라고 불린다. K-means 알고리즘의 몇 가지 특징을 살펴보자. 유클리디안 기법을 사용하기 때문에 각 변수별로 scale을 맞출 필요가 있다. 모든 data별로 거리를 계산하기 때문에 속도가 느릴 수 있고 이를 해결하기 위한 논문이 많이 나와 있다.(tree, sequential update…) cluster 갯수를 직접 정해야 한다. Bayesian 접근법으로 문제를 해결할 수 있다. Hard clustering이다. 확률적인 접근이 없다. data와 중심점을 유클리디안으로 계산하기 때문에 categorical 변수에는 적합하지 않고 outlier에 취약하다. 이에 대해 data point간의 dissimilarity를 다르게 계산(유클리디안 거리이외의 다른 방법)하는 K-medoids 알고리즘이 있다. (써봤는데 그닥 좋은지 모르겠다) ","date":"2021-11-29","objectID":"/prml-chap09-1/:1:0","tags":["GMM","EM Algorithm"],"title":"[PRML] Chapter9 - Mixture Models and EM","uri":"/prml-chap09-1/"},{"categories":["PRML"],"content":"9.2 Mixtures of Gaussians PRML 2장에서는 GMM을 Gaussian component의 linear 조합으로 생각했지만 이번에는 latent variable의 개념을 추가해서 이해해보자. Gaussian mixture distribution $\\pi_k$는 weight의 역할을 하며 multinomial distribution에서의 확률이고 뒤의 mixture component $N$은 multivariate gaussian distribution이다. $$p(\\textbf{x}) = \\sum_{k=1}^{K}{\\pi_k N( \\textbf{x} | {\\pmb \\mu}_k, \\Sigma_k)}$$ $\\textbf{z}$ 는 discrete latent variable이다. K 차원의 binary random variable이며 하나의 원소만 1을 가지며 나머지는 0을 갖는다. $z_k \\in {1,0}$ 인 것이다. 이는 multinomial distribution의 확률변수라는 것을 알 수 있다. marginal distribution of z $$p(z_k=1) = \\pi_k$$ $0 \\le \\pi_k \\le 1$ $\\sum_{k=1}^{K}{\\pi_k}=1$ $$p(\\textbf{z}) = \\prod_{k=1}^{K}{\\pi_k^{z_{k} } }$$ conditional distribution of x $$p(\\textbf{x}|\\textbf{z}) = \\prod_{k=1}^{K}{N(\\textbf{x}| {\\pmb \\mu}_k,\\Sigma_k)^{z_k}}$$ 위의 식들을 이용하여 우리는 처음에 보았던 Gaussian mixture distribution을 구할 수 있다 $$p(\\textbf{x}) = \\sum_{\\textbf{z}}{p(\\textbf{z})p(\\textbf{x}|\\textbf{z})} = \\sum_{k=1}^{K}{\\pi_k N(\\textbf{x} | {\\pmb \\mu}_k, \\Sigma_k)}$$ Conditional probability of z given x it can be viewd as the responsibility the component k takes for ‘explaning’ the observation x posterior 로 이해할 수 있다. $$\\gamma(z_{nk}) = p(z_k = 1 | \\textbf{x} _ n) = \\frac{p(z_k=1) p(\\textbf{x} _ n |z_k=1)}{\\sum_{j=1}^{K}{p(z_j=1)p(\\textbf{x} _ n|z_j=1)}} \\\\ = \\frac{\\pi_k N(\\textbf{x} _ n| {\\pmb \\mu} _ k,\\Sigma_k)}{\\sum_{j=1}^{K}{\\pi_j N(\\textbf{x} _ n|{\\pmb \\mu}_j,\\Sigma_j)}}$$ ","date":"2021-11-29","objectID":"/prml-chap09-1/:2:0","tags":["GMM","EM Algorithm"],"title":"[PRML] Chapter9 - Mixture Models and EM","uri":"/prml-chap09-1/"},{"categories":["PRML"],"content":"9.2.1 Maximum likelihood N * D data set X N * K latent matrix Z Log likelihood $$\\ln p(\\textbf{X} | \\pi, \\mu, \\Sigma) = \\sum_{n=1}^{N}{\\ln{ \\sum_{k=1}^{K}{\\pi_k N(\\textbf{x}_n | {\\pmb \\mu}_k, \\Sigma_k)}}}$$ 이를 maximize 하려고 하는데 문제가 생긴다. log안에 summation이 있어서 미분을 하여 closed form의 형태로 구할 수 없다. sigularity : 특정 점이 어떠한 평균값과 같은 값을 가지고 그 분포의 분산이 0으로 가면 그 점에서의 확률값이 무한으로 가고 logL도 무한으로 간다. identifiability : K! 개의 같은 solution이 생긴다. ","date":"2021-11-29","objectID":"/prml-chap09-1/:2:1","tags":["GMM","EM Algorithm"],"title":"[PRML] Chapter9 - Mixture Models and EM","uri":"/prml-chap09-1/"},{"categories":["PRML"],"content":"9.2.2 EM for Gaussian mixtures log likelihood 를 각 parameter($\\mu, \\Sigma, \\pi$)에 대해 미분하면 $$0 = - \\sum_{n=1}^{N}{\\frac{\\pi_k N(\\textbf{x} _ n | {\\pmb \\mu} _ k, \\Sigma_k)}{\\Sigma_{j}\\pi_j N(\\textbf{x} _ n | {\\pmb \\mu}_j,\\Sigma_j)} \\Sigma_k^{-1} (\\textbf{x}_n - {\\pmb \\mu}_k)}$$ $${\\pmb \\mu} _ k = \\frac{1}{N_k}\\sum_{n=1}^{N}{\\gamma(z_{nk}) \\textbf{x} _ n} \\\\ \\text{where}\\; N_k = \\sum_{n=1}^{N}{\\gamma(z_{nk})}$$ mean은 각 data에 posterior 가중치로서 곱해져 구해진다. covariance도 미분해서 구하면 아래와 같은 값을 가진다. $$\\Sigma_k = \\frac{1}{N_k}\\sum_{n=1}^{N}{\\gamma(z_{nk})(\\textbf{x}_n-{\\pmb \\mu}_k)(\\textbf{x}_n - {\\pmb \\mu}_k)^T}$$ mixing coefficient $\\pi$ 는 제약식이 있기에 Lagrange로 풀면 $$\\text{argmax} _ {\\pi} \\;\\ln p({\\bf X}|{\\bf \\pi}, {\\bf \\mu}, \\Sigma)+\\lambda\\left(\\sum _ {k=1}^K \\pi_k-1\\right)$$ $$0 = \\sum_{n=1}^{N} \\frac{N({\\bf x}_n|{\\pmb \\mu}_k, \\Sigma_k)}{\\sum_j \\pi_j N({\\bf x}_n|{\\pmb \\mu}_j, \\Sigma_j)}+\\lambda$$ $$\\pi_k = \\frac{N_k}{N}$$ $\\gamma(z_{nk})$ 값이 다른 parameter에 depend하기 때문에 iterative하게 구해야 한다. k-means보다 많은 iteration을 해야되기 때문에 초기값을 k-means를 통해 정하면 좋다. 또한 likelihood function이 여러 개의 max 봉우리를 가지면 EM을 통해 구한 값이 local maximum일 수도 있다. EM for GM 정리 parameter들$(\\mu_k, \\Sigma_k, \\pi_k)$의 초깃값을 설정한다. E-step : $\\gamma(z_{nk})$ 구하기 $$\\gamma(z_{nk})=\\frac{\\pi_k N({\\bf x}_n|{\\bf \\mu}_k, \\Sigma_k)}{\\sum_j \\pi_j N({\\bf x}_n|{\\bf \\mu}_j, \\Sigma_j)}$$ M-step : 주어진 responsibility로 $\\mu, \\Sigma, \\pi$ 구하기 $${\\bf \\mu} _ k^{new} = \\frac{1}{N_k}\\sum_{n=1}^N \\gamma(z _ {nk}){\\bf x} _ n \\\\ \\Sigma_k^{new} = \\frac{1}{N_k}\\sum_{n=1}^N \\gamma(z_{nk})({\\bf x} _ n-{\\bf \\mu}_k)({\\bf x} _ n-{\\bf \\mu} _ k)^T \\\\ \\pi_k^{new} = \\frac{N_k}{N} \\N_k = \\sum _ {n=1}^N \\gamma(z _ {nk})$$ log likelihood 구해서 converge할 때까지 반복 $$\\ln p({\\bf X}|{\\bf \\mu}, \\Sigma, {\\bf \\pi}) = \\sum_{n=1}^N \\{\\sum_{k=1}^K \\pi_k N({\\bf x}_n|{\\bf \\mu}_k, \\Sigma_k)\\}$$ ","date":"2021-11-29","objectID":"/prml-chap09-1/:2:2","tags":["GMM","EM Algorithm"],"title":"[PRML] Chapter9 - Mixture Models and EM","uri":"/prml-chap09-1/"},{"categories":["PRML"],"content":"9.3 An Alternative view of EM $$\\ln p(\\textbf{X} | \\pi, \\mu, \\Sigma)$$ 위의 식을 보면 log 안에 있는 summation(intergral) 때문에 maximum likelihood solution을 구하기 어렵다. 이를 해결하기 위해 latent variable을 추가하여 사용한다. maximization of complete-data log likelihood function은 상대적으로 쉽다고 가정하자. 하지만 latent variable 때문에 complete log likelihood를 그대로 이용하기 어렵고 대신에 Expectation을 취해서(posterior distribution for latent variable을 통해) 이를 최대로 만드는 parameter를 구하고 반복한다. E-step 현재 우리가 알고 있는 parameter $\\theta^{old}$를 이용하여 latent variable의 posterior $p(\\textbf{Z}|\\textbf{X},\\theta^{old})$를 구한다. 이를 이용하여 expectation of the complete-data log likelihood를 구한다. 원래는 $\\ln p(\\textbf{X} | \\theta)$를 maximize해야 하지만 어려우니까 $$Q({\\bf \\theta}, {\\bf \\theta}^{old}) = \\sum_{\\bf Z} p({\\bf Z}|{\\bf X}, {\\bf \\theta}^{old}) \\ln p({\\bf X}, {\\bf Z}|{\\bf \\theta})$$ M-step 이 식을 최대화하는 $\\theta^{new}$를 구한다. $${\\bf \\theta}^{new} = \\arg\\max_{\\theta} Q({\\bf \\theta}, {\\bf \\theta}^{old})$$ ","date":"2021-11-29","objectID":"/prml-chap09-1/:3:0","tags":["GMM","EM Algorithm"],"title":"[PRML] Chapter9 - Mixture Models and EM","uri":"/prml-chap09-1/"},{"categories":["PRML"],"content":"9.3.1 Gaussian mixture revisited 위에서 설명한 대로 GM을 모델링해보자. complete likelihood $$p({\\bf X}, {\\bf Z}|{\\bf \\mu}, \\Sigma, {\\bf \\pi}) = \\prod_{n=1}^N\\prod_{k=1}^K \\pi_k^{z_{nk}} N({\\bf x}_n|{\\bf \\mu} _ k, \\Sigma_k)^{z _ {nk}}$$ posterior of latent Z $$p({\\bf z})=\\prod_{k=1}^{K} \\pi^{z_k} \\ p({\\bf x}|{\\bf z}) = \\prod_{k=1}^{K} N({\\bf x}|{\\bf \\mu}_k, \\Sigma_k)^{z_k}$$ $$\\rightarrow p({\\bf Z}|{\\bf X}, {\\bf \\mu}, \\Sigma, {\\bf \\pi}) \\propto \\prod_{n=1}^{N}\\prod_{k=1}^{K}[\\pi_k N({\\bf x}_n|{\\bf \\mu} _ k, \\Sigma_k)]^{z _ {nk}}$$ 이를 이용하여 expectation of complete-data likelihood function을 구해보자. $$E_{\\bf Z}[\\ln p({\\bf X}, {\\bf Z}|\\theta)] = E_{\\bf Z}[\\sum_n\\ln p({\\bf x} _ n, {\\bf z} _ n|\\theta)] = \\sum_n E_{\\bf Z}[\\ln p({\\bf x}_n, {\\bf z}_n|\\theta)]$$ $$= \\sum_{n=1}^N E_{\\bf Z}[\\ln { p({\\bf z} _ n) p({\\bf x} _ n|{\\bf z} _ n, \\theta) } ] = \\sum_{n=1}^N E_{\\bf Z}[\\ln[\\prod_{k=1}^K (\\pi_k N({\\bf x}_n|{\\bf \\mu} _ k, \\Sigma_k))^{z _ {nk}}]]$$ $$=\\sum_{n=1}^N \\sum_{k=1}^K E_{z}[z_{nk}\\ln { \\pi_k N({\\bf x}|{\\bf \\mu} _ k, \\Sigma_k) } ] = \\sum_{n=1}^N \\sum_{k=1}^K E_{z}[z_{nk}] \\ln { \\pi_k N({\\bf x}_n|{\\bf \\mu}_k, \\Sigma_k })$$ $$=\\sum_{n=1}^N \\sum_{k=1}^K \\gamma(z_{nk}){\\ln\\pi_k+\\ln N({\\bf x}_n|{\\bf \\mu_k}, \\Sigma_k)}$$ $$E[z_{nk}] = \\frac{\\sum{z_{nk}[ \\pi_k N(\\textbf{x} _ n | \\mu_k, \\Sigma_k)]^{z_{nk} } } }{ \\sum{[ \\pi_k N(\\textbf{x} _ n | \\mu_k, \\Sigma_k)]^{z_{nj}} }} = \\frac{\\pi_k N(\\textbf{x} _ n | \\mu_k,\\Sigma_k)}{\\sum_{j=1}^{K}{\\pi_j N(\\textbf{x} _ n | \\mu_j,\\Sigma_j)}} = \\gamma(z_{nk})$$ 이제 차례대로 E-step, M-step을 진행하면 된다. ","date":"2021-11-29","objectID":"/prml-chap09-1/:3:1","tags":["GMM","EM Algorithm"],"title":"[PRML] Chapter9 - Mixture Models and EM","uri":"/prml-chap09-1/"},{"categories":["PRML"],"content":"9.3.2 Relation to K-means k-means를 GM의 특별한 케이스라고 생각할 수 있다. covariance matrices를 추정해야되는 것이 아니라 고정된 $\\epsilon I$ 라고 생각하고 이 값이 0으로 가는 경우 이는 k-means와 같은 결과를 낸다. responsibility $$\\gamma(z_{nk}) = \\frac{\\pi_k \\exp{-|{\\bf x}_n-{\\bf \\mu}_k|^2/2\\epsilon}}{\\sum_j \\pi_j \\exp{-|{\\bf x}_n-{\\bf \\mu}_j|^2/2\\epsilon}}$$ 위의 식에서 $\\epsilon$이 0으로 간다고 가정하자. $|{\\bf x}_n-{\\bf \\mu}_k|^2$ 값이 가장 작은 cluster를 k라고 하자. k 이외의 $\\exp{-|{\\bf x}_n-{\\bf \\mu}_j|^2/2\\epsilon}$ 값들은 더 빠르게 0으로 수렴한다. (exponentially) 즉, $\\gamma(z_{nk})$ 값이 k에서만 1이고 나머지는 0의 값을 가지는 것이다. (binary indicator) $\\gamma(z_{nk})$이 이전의 K-means에서 봤던 $\\gamma_{nk}$이 되는 것이다. 이제 $\\epsilon$이 0으로 간다고 가정하고 expected complete-data log likelihood 값을 보면 $$E_{\\bf Z}[\\ln p({\\bf X}, {\\bf Z}|{\\bf \\mu}, \\Sigma, {\\bf \\pi})] \\rightarrow -\\frac{1}{2}\\sum_{n=1}^N\\sum_{k=1}^K r_{nk}|{\\bf x}_n-{\\bf \\mu}_k|^2+const$$ expected complete-data log likelihood를 최대화하는 것은 결국 K-means에서 object function을 최소화하는 것과 같아졌다. wow! ","date":"2021-11-29","objectID":"/prml-chap09-1/:3:2","tags":["GMM","EM Algorithm"],"title":"[PRML] Chapter9 - Mixture Models and EM","uri":"/prml-chap09-1/"},{"categories":["PRML"],"content":"9.3.3 Mixtures of Bernoulli distribution latent class analysis의 예시이다. (구제적인 내용은 skip) ","date":"2021-11-29","objectID":"/prml-chap09-1/:3:3","tags":["GMM","EM Algorithm"],"title":"[PRML] Chapter9 - Mixture Models and EM","uri":"/prml-chap09-1/"},{"categories":["PRML"],"content":"9.3.4 EM for Bayesian linear regression $\\textbf{w}$를 marginalization했었는데 이를 latent variable로 취급하고 EM algorithm을 사용하는 예시이다. (구체적인 내용은 skip) ","date":"2021-11-29","objectID":"/prml-chap09-1/:3:4","tags":["GMM","EM Algorithm"],"title":"[PRML] Chapter9 - Mixture Models and EM","uri":"/prml-chap09-1/"},{"categories":["PRML"],"content":"9.4 The EM Algorithom in General 우리의 목표는 maximize the likelihood function that is given by $$p(X | \\theta) = \\sum_{Z}{p(X,Z | \\theta)}$$ 이다. (Z는 discrete, continuous 다 가능 intergral로 바꾸면 됨) 하지만 이를 바로 optimization하기는 힘들지만 complete likelihood function 를 optimization하는 것이 더 간단하자고 가정하자. 그러면 우리는 아래와 같은 decomposition을 생각할 수 있다. (임의의 $q(Z)$는 pdf라고 생각할 수 있다 defined over the latent variables) log likelihood는 $$\\ln p(\\textbf{X}|\\theta) = \\ln \\sum_{z}q(\\textbf{Z})\\frac{p(\\textbf{X},\\textbf{Z}|\\theta)}{q(\\textbf{Z})}$$ by Jansen’s inequality $$\\ln p(\\textbf{X}|\\theta) \\ge \\sum_{z}q(\\textbf{Z}) \\ln \\frac{p(\\textbf{X},\\textbf{Z}|\\theta)}{q(\\textbf{Z})} = L(\\theta, q)$$ 여기서 $L(\\theta, q)$는 log likelihood function의 Lower Bound (ELBO) 라고 할 수 있으며 우리는 이를 높여가면서 log likelihood를 최대화하는 $\\theta$를 찾고자 한다. (ELBO는 $\\theta,q$ 두 가지에 depend하는 식임을 기억하자) 그런데 지금 $q(Z)$에 대해 optimization를 할 수 없는 상황(임의의 q를 구할만한 정보가 없음)이고 이를 위해 추가적인 접근법이 필요하다. $$L(\\theta, q) = \\sum_{z}q(\\textbf{Z}) \\ln \\frac{p(\\textbf{X},\\textbf{Z}|\\theta)}{q(\\textbf{Z})}$$ $$= \\sum_{z}q(\\textbf{Z}) \\ln \\frac{p(\\textbf{Z} | \\textbf{X},\\theta)p(\\textbf{X}| \\theta)}{q(\\textbf{Z})} $$ $$= \\sum_{z}{ q(\\textbf{Z})\\ln \\frac{p(\\textbf{Z}|\\textbf{X},\\theta)}{q(\\textbf{Z})} + q(\\textbf{Z})\\ln p(\\textbf{X}|\\theta) }$$ $$ = \\ln p(\\textbf{X}|\\theta)+ \\sum_{z}q(\\textbf{Z})\\ln \\frac{p(\\textbf{Z}| \\textbf{X}, \\theta)}{q(\\textbf{Z})} $$ $$= \\ln p(\\textbf{X}|\\theta) - \\sum_{z}q(\\textbf{Z})\\ln \\frac{q(\\textbf{Z})}{p(\\textbf{Z}| \\textbf{X}, \\theta)}$$ 여기서 first term은 log likelihood이고 second term이 KL-divergence이다. $$KL(q||p) = -\\sum_{z}{q(\\textbf{Z}) \\ln { \\frac{p(\\textbf{Z}|\\textbf{X},\\theta)}{q(\\textbf{Z})} }}= \\sum_{z}{q(\\textbf{Z}) \\ln { \\frac{q(\\textbf{Z})}{p(\\textbf{Z}|\\textbf{X},\\theta)} }}\\ge 0$$ KL-divergence는 항상 0이상의 값을 가지기 때문에 Lower Bound를 최대화하기 위해서는 KL 을 0 의 값을 갖게 해야한다. 여기서 우리는 $q(Z)$에 대한 정보를 찾을 수 있다. 즉, t 시점에서 $$q(Z) = p(Z | X, \\theta^t)$$ 로 하면 된다. 이후 $q$를 고정시키고 우리는 다시 $\\theta^{t+1} = \\text{argmax} L(\\theta, q^t)$ 를 찾는다. 계속 iterative하게 반복하여 MLE parameter (with latent variable)의 값을 구할 수 있다. E-step lower bound L 은 $\\theta^{old}$는 고정한채로 $q(Z)$에 대해 최대화한다. 하지만 $\\ln p(X|\\theta)$는 $q(Z)$와 상관이 없기 때문에 Lower Bound의 최대값은 KL값이 0을 가져야한다. KL = 0 을 위해서는 $q(Z) = p(Z | X, \\theta^{old})$ (posterior)의 조건을 만족해야한다. 그러면 lower bound랑 log likelihood가 같아진다. (Lower Bound가 최대화되며) M-step 위의 과정에 따라 $q(Z)$는 posterior로 fixed 되고 L을 최대화하는 새로운 $\\theta^{new}$를 구한다. 이 새로운 값 때문에 KL은 non zero가 되고 log likelihood는 lower bound보다 더 큰 값을 가진다. converge할 때까지 iterative하게 반복한다. 또 다른 표현으로는 $$L(q, \\theta) = \\sum_\\textbf{Z} p(\\textbf{Z}|\\textbf{X}, \\theta^{old})\\ln p(\\textbf{X}, \\textbf{Z}|\\theta) - \\sum_\\textbf{Z} p( \\textbf{Z}|\\textbf{X}, \\theta^{old})\\ln p(\\textbf{Z} |\\textbf{X}, \\theta^{old}) $$ $$= Q(\\theta, \\theta^{old}) + const$$ 첫번째 항이 expectation of the complete-data log likelihood joint distribution이 exponential family인 경우, log를 취했을 때 쉽게 maximize할 수 있다. 두번째 항은 $\\theta$에 independent하기에 const 따라서 lower bound를 높이는 것이 expectation of the complete-data log likelihood를 최대화하는 것 이다. 한줄결론 : observed log likelihood를 최대화하는 parameter(MLE)를 구하고 싶다. latent variable에 대한 posterior distribution으로 E[complete log likelihood]를 최대로 하게 만드는 $\\theta$를 구하면 된다. ","date":"2021-11-29","objectID":"/prml-chap09-1/:4:0","tags":["GMM","EM Algorithm"],"title":"[PRML] Chapter9 - Mixture Models and EM","uri":"/prml-chap09-1/"},{"categories":["PRML"],"content":"+ EM for MAP MLE를 구하는 과정과 거의 비슷하다. 단지 prior만 추가될뿐이다! E-step $$R(\\theta, \\theta_{t-1}) = E_{\\theta_{t-1}}[\\ln p(\\textbf{X},\\textbf{Z}|\\theta)|\\textbf{X}=\\textbf{x}]+\\ln p(\\theta)$$ M-step $$\\theta_t = \\text{argmax} R(\\theta, \\theta_{t-1})$$ ","date":"2021-11-29","objectID":"/prml-chap09-1/:4:1","tags":["GMM","EM Algorithm"],"title":"[PRML] Chapter9 - Mixture Models and EM","uri":"/prml-chap09-1/"},{"categories":["PRML"],"content":"graphical model에서 inference하는 방법에 대해 정리하였다. (미완성) ","date":"2021-11-29","objectID":"/prml-chap08-2/:0:0","tags":["Grphical Model"],"title":"[PRML] Chapter8 - Graphical Models (2)","uri":"/prml-chap08-2/"},{"categories":["PRML"],"content":"8.4 Inference in Graphical Models node들에 대한 posterior를 계산하고 싶다고 하자. 이번 장에서는 exact inference에 대해 집중해서 알아보자. ","date":"2021-11-29","objectID":"/prml-chap08-2/:1:0","tags":["Grphical Model"],"title":"[PRML] Chapter8 - Graphical Models (2)","uri":"/prml-chap08-2/"},{"categories":["PRML"],"content":"8.4.1 Inference on a chain chain의 모습을 갖는 undirected의 joint distribution에 대해 살펴보자. 각 variable들은 $K$개의 states를 갖는 discrete variable이라고 가정한다. 그러면 joint disribution은 $(N-1)K^2$개의 parameter들을 갖고 있다. $$p(\\textbf{x})=\\frac{1}{Z}\\psi_{1,2}(x_1,x_2)\\psi_{2,3}(x_2,x_3)…\\psi_{N-1,N}(x_{N-1},x_N)$$ 이제 marginal distribution $p(x_n)$를 inference해보려고 한다. 가장 쉽게 보이지만 복잡하고 시간이 오래걸리는 방법은 아래처럼 다 summation하는 것이다. $$p(x_n) = \\sum_{x_1}…\\sum_{x_{n-1}}\\sum_{x_{n+1}}…\\sum_{x_{N}}p(\\textbf{x})$$ joint는 K개의 state를 갖는 N개의 variable이 있기 때문에 $K^N$개의 값이 존재하고 이를 계산하는 것은 비효율적이다. 그렇다면 chain의 특징을 이용해서 조금 더 효율적인 방법을 이용해보자. $$p(x_n)=\\frac{1}{Z}[\\sum_{x_{n-1}}\\psi_{n-1,n}(x_{n-1},x_n)…[\\sum_{x_2}\\psi_{2,3}(x_2,x_3)[\\sum_{x_1}\\psi_{1,2}(x_1,x_2)]]…] \\\\ [\\sum_{x_{n+1}}\\psi_{n,n+1}(x_n,x_{n+1})…[\\sum_{x_N}\\psi_{N-1,N}(x_{N-1},x_N)]…]$$ 위의 방법으로 구하면 total cost는 $O(NK^2)$이다. chain처럼 conditional independence를 찾아서 이용하는 것의 장점을 느낄 수 있다. 위와 같은 방법은 local messages를 보내는 것으로 해석할 수 있다. 크게 보면 marginal $p(x_n)$은 두 개의 factor로 나누어서 생각할 수 있다. $$p(x_n) = \\frac{1}{Z}\\mu_{\\alpha}(x_n)\\mu_{\\beta}(x_n)$$ 각각 $x_n$의 앞, 뒤에서 흘러오는 message로 이해할 수 있다. ","date":"2021-11-29","objectID":"/prml-chap08-2/:1:1","tags":["Grphical Model"],"title":"[PRML] Chapter8 - Graphical Models (2)","uri":"/prml-chap08-2/"},{"categories":["PRML"],"content":"8.4.2 Trees graph에서 tree는 어떤 두 개의 node를 선택했을 때 오직 하나의 path만 존재하는 것을 의미한다. 그리고 모든 node는 하나의 parent node를 갖고 가장 위에 있는 node는 root라고 부른다. local message passing을 이용한 inference를 이 tree에 이용하는 sum-product algorithm에 대해 배울 것이다. ","date":"2021-11-29","objectID":"/prml-chap08-2/:1:2","tags":["Grphical Model"],"title":"[PRML] Chapter8 - Graphical Models (2)","uri":"/prml-chap08-2/"},{"categories":["PRML"],"content":"8.4.3 Factor graphs graph에 node를 추가하여서 decomposition을 explicit하게 하는 것이다. $x_s$를 subset of the variable이라고 하면 joint를 아래와 같이 나타낼 수 있다. $$p(\\textbf{x}) = \\prod_s f_s (\\textbf{x}_s)$$ 여기서 $f_s$는 a function of a corresponding set of variables 이다. 각 factor $f_s(\\textbf{x}_s)$는 directed의 경우 local conditional distribution의 역할과 같고 undirected의 경우 potential function이라고 할 수 있다. \rundirected, directed 모두 factor graph로 일반화가 가능해지는 것으로 이해할 수 있을 것 같다. ","date":"2021-11-29","objectID":"/prml-chap08-2/:1:3","tags":["Grphical Model"],"title":"[PRML] Chapter8 - Graphical Models (2)","uri":"/prml-chap08-2/"},{"categories":["PRML"],"content":"8.4.4 The sum-product algorithm tree-structured graph에서 exact inference를 하기 위한 방법을 알아보자. variable들은 discrete이라고 가정하기에 summation으로 계산을 진행한다. (물론 continuous도 동일하게 가능) loop없는 directed graph에서 exact inference하는 알고리즘은 belief propagation이라 하고 이는 sum-product algorithm의 특별한 경우에 해당한다. original graph는 undirected tree, directed tree, polytree 이고 이에 대응되는 factor graph는 tree structure를 가진다. original graph는 factor graph로 바꾸는 과정을 통해 undirected, directed에 동일한 방법을 적용할 수 있게 된다. 우리는 이런 과정을 통해 최종적으로 얻고자 하는 바는 아래와 같다. to obtain an efficient, exact inference algorithm for finding marginals in situations where several marginals are required to allow computations to be shared efficiently 먼저 marginal을 구하는 것부터 시작해보자. $$p(x) = \\sum_{\\textbf{x}-x}p(\\textbf{x})$$ 우리는 tree structure를 다루고 있고 이를 통해 joint distribution의 factor들을 그룹으로 partition할 수 있다. $$p(\\textbf{x})=\\prod_{s\\in ne(x)}F_s(x,X_s)$$ $ne(x)$ : 이웃 variable을 의미 $X_s$ : factor node $f_x$를 통해 $x$와 연결된 subtree에 있는 set of all variables $F_s(x,X_s)$ : the product of all the factors in the group associated with factor $f_s$ 이를 통해 marginal식을 살펴보면 $$p(x) = \\sum_{\\textbf{x}-x}\\prod_{s\\in ne(x)}F_s(x,X_s)\\\\ =\\prod_{s\\in ne(x)}\\sum_{\\textbf{x}-x}F_s(x,X_s) \\\\ =\\prod_{s\\in ne(x)}\\mu_{f_s \\rightarrow x}(x)$$ 여기서 우리는 새로운 a set of functions $\\mu_{f_s \\rightarrow x}(x) = \\sum_{\\textbf{x}-x}F_s(x,X_s)$을 만나게 된다. 이는 factor nodes $f_s$에서 $x$를 향하는 messages라고 볼 수 있다. 그래서 marginal은 node $x$에 도착하는 message들의 product라고 이해할 수 있다. $F_s(x,X_s)$을 조금 더 factorize해보자. $$F_s(x,X_s) = f_s (x,x_1,…,x_M)G_1(x_1, X_{s1})…G_M(x_M, X_{sM})$$ $$\\mu_{f_s \\rightarrow x}(x) =\\sum_{x_1}…\\sum_{x_M}f_s(x,x_1,…,x_M) \\prod_{m \\in ne(f_s)-x}[\\sum_{X_{sm}}G_m(x_m, X_{sm})] \\\\ =\\sum_{x_1}…\\sum_{x_M}f_s(x,x_1,…,x_M) \\prod_{m \\in ne(f_s)-x}\\mu_{x_m \\rightarrow f_s}(x_m)$$ 이번에는 $\\mu_{x_m \\rightarrow f_s}(x_m) = \\sum_{X_{sm}}G_m(x_m,X_{sm})$ 이번에는 variable에서 factor로 가는 message를 의미한다. 이처럼 message를 보내는 flow를 이용하여 marginal distribution을 구할 수 있다. 구체적인 예시는 PRML책 409page를 보면 된다. 내용이 꽤 길어서 일부 생략하기로 한다. ","date":"2021-11-29","objectID":"/prml-chap08-2/:1:4","tags":["Grphical Model"],"title":"[PRML] Chapter8 - Graphical Models (2)","uri":"/prml-chap08-2/"},{"categories":["PRML"],"content":"8.4.5 The max-sum algorithm 이번에는 high probability를 갖는 latent variable을 구하고 싶은 경우를 생각해보자. $$\\textbf{x}^{\\text{max}} = \\arg \\max_{\\textbf{x}} p(\\textbf{x}) \\ p(\\textbf{x}^{\\text{max}}) = \\max_{\\textbf{x}}p(\\textbf{x})$$ 이를 구하기 위해 먼저 chain 예시를 한 번 살펴보자. 아래 식을 전개하는데 이용한 식 $\\max_{\\textbf{x}}p(\\textbf{x}) = \\max_{x_1}…\\max_{x_M}p(\\textbf{x})$ $\\max (ab,ac) = a \\max (b,c),;\\text{where};a\u003e0$ $$\\max_{\\textbf{x}}p(\\textbf{x}) = \\frac{1}{Z}\\max_{x_1}…\\max_{x_N}[\\psi_{1,2}(x_1, x_2)…\\psi_{N-1,N}(x_{N-1}, x_N)]\\\\ =\\frac{1}{Z} \\max_{x_1}[\\psi_{1,2}(x_1,x_2)[…\\max_{x_N}\\psi_{N-1, N}(x_{N-1},x_N)]]$$ 이는 이전의 sum-product algorithm처럼 message를 전달하는 것으로 이해할 수 있다. 이제는 tree-structured factor graph를 통해 일반적인 경우로 알아보자. sum-product algorithm과 거의 비슷하다. sum이 max로 바뀐 경우라고 이해할 수 있다. 거기에 추가로 product를 log를 씌워서 sum으로 implement한다. $$\\mu_{f \\rightarrow x}(x) = \\max_{x_1,…,x_M}[\\log f(x,x_1,…,x_M)+\\sum_{m\\in ne(f_s)-x}\\mu_{x_m\\rightarrow f}(x_m)]\\\\mu_{x \\rightarrow f}(x)=\\sum_{l \\in ne(x)-f}\\mu_{f_l\\rightarrow x}(x)$$ ","date":"2021-11-29","objectID":"/prml-chap08-2/:1:5","tags":["Grphical Model"],"title":"[PRML] Chapter8 - Graphical Models (2)","uri":"/prml-chap08-2/"},{"categories":["PRML"],"content":"8.4.6 Exact inference in general graphs ","date":"2021-11-29","objectID":"/prml-chap08-2/:1:6","tags":["Grphical Model"],"title":"[PRML] Chapter8 - Graphical Models (2)","uri":"/prml-chap08-2/"},{"categories":["PRML"],"content":"8.4.7 Loopy belief propagation ","date":"2021-11-29","objectID":"/prml-chap08-2/:1:7","tags":["Grphical Model"],"title":"[PRML] Chapter8 - Graphical Models (2)","uri":"/prml-chap08-2/"},{"categories":["PRML"],"content":"8.4.8 Learning the graph structures","date":"2021-11-29","objectID":"/prml-chap08-2/:1:8","tags":["Grphical Model"],"title":"[PRML] Chapter8 - Graphical Models (2)","uri":"/prml-chap08-2/"},{"categories":["PRML"],"content":"graphical model에 대해 정리하였다. probabilistic graphical models 의 장점 probabilistic model의 구조를 시각화하기 좋다. model에 대한 insight를 얻을 수 있다. 복잡한 modeling을 graphical적인 방법으로 다룰 수 있다. probabilistic graphical model에서 각 node는 random variable을 의미하고 link는 그들의 관계를 의미한다. joint distribution이 각 factor들의 product로 decomposed되는 모습을 주로 나타낸다. Bayesian network (directed graphical model) : link가 특정한 방향을 가르키는 경우 Markov random field (undirecte graphical model) : 방향이 없는 경우 ","date":"2021-11-29","objectID":"/prml-chap08-1/:0:0","tags":["Grphical Model"],"title":"[PRML] Chapter8 - Graphical Models (1)","uri":"/prml-chap08-1/"},{"categories":["PRML"],"content":"8.1 Bayesian Networks 먼저 간단한 예시를 보자. $$p(a,b,c) = p(c|a,b)p(b|a)p(a)$$ 위의 식처럼 우리는 joint distribution을 분해할 수 있다. 이때 node a는 node b의 parent node라고 부른다. 반대로 node b는 node a의 child node이다. 그리고 link의 방향은 given에서 출발한다. 즉, node a에서 node b로 화살표가 그려지는 것이다. 그리고 이와 같이 (특정순서대로) 모든 node에게서 link를 받으면 이 graph를 fully conneted 하다고 한다. 이를 일반화하면 $$p(\\textbf{x}) = \\prod_{k=1}^{K}{p(x_k|pa_k)}$$ 의 형태이다. $pa_k$는 parent node들을 의미한다. 우리가 다루는 directed graph는 no direted cycle 이라는 제약이 있다. 이는 directed acyclic graph라는 의미로 parent node로 다시 돌아가는 link가 없다는 의미이다. ","date":"2021-11-29","objectID":"/prml-chap08-1/:1:0","tags":["Grphical Model"],"title":"[PRML] Chapter8 - Graphical Models (1)","uri":"/prml-chap08-1/"},{"categories":["PRML"],"content":"8.1.1 Example : Polynomial regression polynomial regression에서 prediction을 graphical model로 나타내면 색이 칠해진 $t_n$ 부분은 given의 의미이다. ","date":"2021-11-29","objectID":"/prml-chap08-1/:1:1","tags":["Grphical Model"],"title":"[PRML] Chapter8 - Graphical Models (1)","uri":"/prml-chap08-1/"},{"categories":["PRML"],"content":"8.1.2 Generative models 주어진 probability distribution에서 sampling을 해야하는 경우가 있다. 다양한 방법들 중에 여기서는 graphical model과 관련있는 ancestral sampling 에 대해 알아보자. joint distribution $p(x_1,…x_k)$에 sampling을 하고자 한다. 우리는 이를 적절한 directed acyclic graph로 factorization할 것이다. 그리고 높은 숫자 node에서 낮은 숫자 node로의 link는 없다고 가정한다. 따라서 먼저 $p(x_1)$에서 sampling을 하고 $\\hat{x}_1$이 parent로 있는 conditional distribution에서 sampling을 한다. 이를 반복해서 $p(x_i|pa_i)$을 구하다보면 결국 우리가 원하는 joint distribution에서 sample을 얻는 것과 동일한 결과를 만들 수 있다. 특정 변수의 marginal distribution을 얻고 싶으면 필요한 sample만 쓰면 된다. probabilistic model에서 주로 higher-numbered node는 observation을 나타내고 lower-numbered node는 주로 latent variable에 해당한다. 이러한 구조를 이용하여 observed data가 만들어지는 과정을 해석할 수 있다. graphical model는 observed data가 만들어진 causal 과정을 잡을 수 있다. 이러한 이유로 그런 model를 generative model이라고 한다. 앞에서 본 polynomial regression같은 경우는 generative model이 아니다. input $x$과 관련한 probability distribution이 없기 때문이다. ","date":"2021-11-29","objectID":"/prml-chap08-1/:1:2","tags":["Grphical Model"],"title":"[PRML] Chapter8 - Graphical Models (1)","uri":"/prml-chap08-1/"},{"categories":["PRML"],"content":"8.1.3 Discrete variables discrete variable들의 joint distribution을 DAG로 표현해보자. probability distribution $p(\\textbf{x}|{\\pmb \\mu})$ for a single variable $\\textbf{x}$이 있다. K개의 states를 가질 수 있다고 하면 $$p(\\textbf{x} | {\\pmb \\mu}) = \\prod_{k=1}^{K}{\\mu_k^{x_k}}$$ 이번에는 2개의 discrete variable의 joint distribution을 modeling한다고 하자. $$p(\\textbf{x} _ 1, \\textbf{x} _ 2 | {\\pmb \\mu}) = \\prod_{k=1}^{K} \\prod_{l=1}^{K} \\mu_{kl}^{x_{1k} x_{2l}}$$ 여기서 $\\sum_k \\sum_l \\mu_{kl}=1$이라는 제약식이 있다. 따라서 이 distribution에서 parameter는 $K^2-1$개 이다. M개의 variable의 경우는 $K^M-1$이 될 것이고 이는 상당히 많은 양(exponentially)의 parameter를 요구하는 것이다. 만약 variable들이 서로 independent하다면 $M(K-1)$개의 parameter가 필요하다. link를 drop하여 더 간단한 model이 되는 것이다. 대신에 제한적인 distribution을 얻는다. markov chain과 같은 형태라고 가정하면 필요한 parameter는 $K-1+(M-1)K(K-1)$개 이다. parameter의 수를 줄이는 또 다른 방법은 parameter를 sharing하는 방법이다. 예를 들어 $p(x_i | x_{i-1})$의 conditional distribution이 모두 동일한 $K(K-1)$개의 parameter를 공유한다고 하면 전체 parameter는 $K-1 + K(K-1)$개가 된다. 또 다른 방법은 parameterized model을 이용하는 것이다. 예를 들어, $p(y=1|x_1,…,x_M)=\\sigma(\\textbf{w}^T\\textbf{x})$와 같은 형태를 이용하면 필요한 parameter는 $M$에 linear한 갯수가 필요하게 된다. 위의 방법들은 probabilistic modeling에서 parameter의 갯수를 줄일 수 있는 방법들이다. ","date":"2021-11-29","objectID":"/prml-chap08-1/:1:3","tags":["Grphical Model"],"title":"[PRML] Chapter8 - Graphical Models (1)","uri":"/prml-chap08-1/"},{"categories":["PRML"],"content":"8.1.4 Linear-Gaussian models 각 node i는 single continuous random variable $x_i$ (Gaussian distribution) 를 나타낸다. 해당 분포의 mean은 parent node들의 linear combination으로 이루어져있다. $$p(x_i|pa_i) = N(x_i|\\sum_{j \\in pa_i} w_{ij}x_j + b_i, v_i)$$ log of joint distribution은 log of product of all conditional node 이고 이를 전개하면 $$\\ln p(\\textbf{x}) = \\sum_{i=1}^{D} \\ln p(x_i|pa_i) \\ = - \\sum_{i}^{D} \\frac{1}{2v_i} (x_i - \\sum_{j \\in pa_i}w_{ij}x_j - b_i)^2 + \\text{const}$$ 여기서 $\\textbf{x}$의 quadratic form이라는 것을 알 수 있고 따라서 joint distribution $p(\\textbf{x})$은 multivariate gaussian이라는 것을 알 수 있다. 우리는 joint distribution의 mean과 covariance를 recursively 구할 수 있다. 각 variable $x_i$는 아래와 같은 형태를 갖고 있는데 $$x_i = \\sum_{j \\in pa_i} w_{ij}x_j + b_i + \\sqrt{v_i}\\epsilon_i$$ $$E[x_i] = \\sum_{j \\in pa_i} w_{ij} E[x_j] + b_i \\ E[\\textbf{x}] = (E[x_1], E[x_2],…,E[x_D])^T$$ 따라서 우리는 lowest numbered node에서 시작하여 recusively mean을 구할 수 있다. 이제 covariance를 구해보면 $$cov[x_i, x_j] = E[(x_i-E[x_i])(x_j-E[x_j])]$$ $$=E[(x_i-E[x_i]){ \\sum_{k \\in pa_j} w_{jk}(x_k-E[x_k])+\\sqrt{v_j}\\epsilon_j}]$$ $$=\\sum_{k \\in pa_j}w_{jk}cov[x_i,x_j]+I_{ij}v_j$$ 여기서도 똑같이 recusively 구할 수 있다. 따라서 위에서 discrete에서 공부한 것처럼 parameter의 갯수를 줄이는 방법들을 여기에서도 동일하게 적용할 수 있다. ","date":"2021-11-29","objectID":"/prml-chap08-1/:1:4","tags":["Grphical Model"],"title":"[PRML] Chapter8 - Graphical Models (1)","uri":"/prml-chap08-1/"},{"categories":["PRML"],"content":"8.2 Conditional Independence $$p(a|b,c) = p(a|c)$$ 위와 같은 경우 a is conditionally independent of b given c 라고 한다. 이는 아래와 같은 경우도 해당한다. $$p(a,b|c)=p(a|b,c)p(b|c) = p(a|c)p(b|c)$$ 두 가지 버전의 conditional independence 정의이다. 또 다른 notation으로는 $$a \\bot b | c $$ conditional independence는 probabilistic model에서 model의 structure와 computation을 단순화한다. joint distribution에서 conditional independence의 특징을 graphical한 차원에서 바로 파악할 수 있다. 이 방법을 d-seperation 이라고 한다. ","date":"2021-11-29","objectID":"/prml-chap08-1/:2:0","tags":["Grphical Model"],"title":"[PRML] Chapter8 - Graphical Models (1)","uri":"/prml-chap08-1/"},{"categories":["PRML"],"content":"8.2.1 Three example graphs 총 3가지의 경우에 대해 살펴 볼 것이다. tail-to-tail $$p(a,b,c) = p(a|c)p(b|c)p(c)$$ 여기서 모든 변수들이 observed되지 않았고 a,b의 independent를 보기 위해 c에 대해 marginalize하면 $$p(a,b) = \\sum_c p(a|c)p(b|c)p(c)$$ 이는 $p(a)p(b)$로 factorize되지 않는다. 즉 independent하지 않다는 의미이다. 그렇다면 이번에는 c가 given인 상황을 가정해보자. $$p(a,b|c) = \\frac{p(a,b,c)}{p(c)} = \\frac{p(a|c)p(b|c)p(c)}{p(c)} = p(a|c)p(b|c)\\ \\therefore a \\bot b | c $$ 여기서 node c는 tail-to-tail 이라고 한다. link가 node c에서 node a,b로 간다. 이를 통해 node a와 node b사이의 path가 생긴다. 이는 두 node가 dependent하다는 의미이다. 하지만 node c가 observed되는 순간 (conditioned on c) a와 b사이의 path를 block한다. 그래서 a와 b는 conditionally independent해진다. head-to-tail $$p(a,b,c) = p(a)p(c|a)p(b|c) \\\\ p(a,b) = p(a)\\sum_c p(c|a)p(b|c)=p(a)p(b|a)$$ 여기서도 마찬가지로 independent하지 않다. 하지만 c가 given이면 $$p(a,b|c) = \\frac{p(a,b,c)}{p(c)} = \\frac{p(a)p(c|a)p(b|c)}{p(c)}=p(a|c)p(b|c)$$ 여기서 node c는 head-to-tail 이라고 한다. node a에서 b로 가는 사이에 존재한다. 이는 두 node가 dependent하다는 것이다. 하지만 node c가 given되는 순간 두 node의 path는 block된다. 그래서 a와b는 conditionally independent해진다. heat-to-head $$p(a,b,c) = p(a)p(b)p(c|a,b) \\\\ p(a,b) = p(a)p(b)$$ 이번에는 위에 나왔던 내용들과 반대이다. c가 given이 아닌 경우, a와b가 independent하다. 오히려 c가 given이면 independent가 아닌 상태가 된다. $$p(a,b|c) = \\frac{p(a,b,c)}{p(c)} = \\frac{p(a)p(b)p(c|a,b)}{p(c)}$$ 여기서 node c는 head-to-head 이라고 한다. node a,b에서 node c로 화살표가 향하는 형태이다. node c가 unobserved되면 이는 path를 block한다. 그래서 a와 b는 independent하다. 오히려 c가 observed되면 dependent해진다. ","date":"2021-11-29","objectID":"/prml-chap08-1/:2:1","tags":["Grphical Model"],"title":"[PRML] Chapter8 - Graphical Models (1)","uri":"/prml-chap08-1/"},{"categories":["PRML"],"content":"8.2.2 D-seperation 위에서 살펴본 3가지의 종류에 따라서 joint distribution을 factorization한다. D-seperation이 특별한 방법론은 아니고 graphical적인 접근으로 conditional independent를 효율적으로 파악하고 이용한다. 책에서는 예시를 통해 이 과정을 설명한다. 책에서는 directed graph를 filter처럼 생각하라고 한다. joint distribution을 filter를 거치게 되면 d-seperation에 따라 conditional independent를 확인하고 factorization까지 한다. ","date":"2021-11-29","objectID":"/prml-chap08-1/:2:2","tags":["Grphical Model"],"title":"[PRML] Chapter8 - Graphical Models (1)","uri":"/prml-chap08-1/"},{"categories":["PRML"],"content":"8.3 Markov Random Fields Markov random fields (markov network, undirected graphical model)는 link에 방향성이 없는 것이다. 똑같이 각 node들은 a variable or group of variable을 의미하며 link에는 화살표가 없다. 마찬가지로 conditional independence와 fatorization과 관련하여 공부할 것이다. ","date":"2021-11-29","objectID":"/prml-chap08-1/:3:0","tags":["Grphical Model"],"title":"[PRML] Chapter8 - Graphical Models (1)","uri":"/prml-chap08-1/"},{"categories":["PRML"],"content":"8.3.1 Conditional independence properties 위에서 d-seperation을 통해 conditional independence에 대해 파악할 수 있었다. 그런데 head-to-head 때문에 다소 개념이 헷갈리는 부분이 분명 존재한다. 이에 대한 수요로 undirected graphical model이 나오게 되었다. A,B,C 라는 set of nodes들이 있다고 가정하자. 우리가 궁금한 conditional independence는 아래와 같다. $$A \\bot B | C $$ A에서 C를 거쳐서 B로 가는 모든 길이 block되면 conditional independence가 성립한다. 하나 이상의 길이 존재하면 이는 성립하지 않는다. 즉, 이 조건을 만족하지 않는 어떤 random variable의 분포가 하나라도 있다면 conditional independence라고 할 수 없는 것이다. 다른 시각으로는 C의 모든 node를 없애면서 이와 연결된 link도 없앤 후에 A와 B사이의 path가 존재하지 않는다면 conditional independence하고 할 수 있다. ","date":"2021-11-29","objectID":"/prml-chap08-1/:3:1","tags":["Grphical Model"],"title":"[PRML] Chapter8 - Graphical Models (1)","uri":"/prml-chap08-1/"},{"categories":["PRML"],"content":"8.3.2 Factorization properties 이제 undirected graph에서 factorization rule에 대해 알아보자. two node $x_i,x_j$가 연결되지 않았다고 가정하자. 해당 변수들은 conditionally independent given all other nodes 즉, 두 node끼리의 direct path는 없고 indirect path가 지나는 변수들은 observed된 것이다. $$p(x_i,x_j|\\textbf{x} _ {-(i,j)})=p(x_i|\\textbf{x} _ {-(i,j)})p(x_j|\\textbf{x} _ {-i,j})$$ 따라서 joint distribution을 factorization하면 두 node i, j는 같은 factor에 속하지 않을 것이다. 여기서 clique의 개념이 나온다. clique subset of the nodes in a graph 이고 모든 node들이 directly 연결되어 있다. (fully connected) 따라서 joint distribution을 decomposition할 때 각 factor들이 clique의 변수들로 이루어진 함수들이다. clique를 $C$라고 하고 $\\textbf{x}_C$를 해당 clique에 속하는 variable이라고 하자. joint distribution은 아래와 같이 decomposition할 수 있다. potential functions $\\psi_C (\\textbf{x}_C)$의 곱으로 이루어져있다. $\\psi_C(\\textbf{x}_C) \\ge 0$ $Z$ 는 normalization constant 아래식은 discrete이라 summation이고 continuous의 경우 integral $$p(\\textbf{x}) = \\frac{1}{Z} \\prod_C \\psi_C(\\textbf{x} _ C)\\\\ Z=\\sum_{\\textbf{x}} \\prod_C \\psi_C (\\textbf{x}_C)$$ directed graph에서는 각 factor들이 conditional distribution given parents의 형태였다. 하지만 여기서 potential function을 선택하는데 있어 제약이 없다. 하지만 그에 반해 normalization constant의 존재가 undirected graph의 가장 큰 한계점이라고 할 수 있다. factorization과 conditional independence의 관계를 알아보기 위해서는 potential function은 strictly positive한 값을 가진다고 가정한다. 그래서 exponential form을 이용한다. $$\\psi_C(\\textbf{x}_C) = \\exp{-E(\\textbf{x}_C)}$$ $E(\\textbf{x}_C)$ : energy function 위의 식처럼 exponential한 표현을 Boltzmann distribution이라고 한다. joint distribution은 각 potential function의 곱으로 이루어져있으므로 따라서 joint distribution은 각 clique의 energy function의 합으로 이루어지는 것을 의미한다. directed graph에서의 joint distribution과 다르게 확률적인 해석을 하기 어렵다. 하지만 potential function을 자유롭게 선택할 수 있으며 이는 domain마다 적절하게 선택해야 한다. ","date":"2021-11-29","objectID":"/prml-chap08-1/:3:2","tags":["Grphical Model"],"title":"[PRML] Chapter8 - Graphical Models (1)","uri":"/prml-chap08-1/"},{"categories":["PRML"],"content":"8.3.3 Image de-noising binary image에서 noise removal을 하는 예시를 살펴보자. noise-free image가 binary pixel $x_i \\in {-1,1}$ (unknown) pixel 일부를 random하게 반대로 바꾸면 noise image의 binary pixel $y_i \\in {-1,1}$ (known) 이를 통해 clique를 정하여 energy function을 찾아보자. energy function을 작게 만들어야 joint distribution을 커지게 할 수 있다. 각 pixel별로 clique를 만들수 있을 것이다. ${x_i, y_i}$로 만들 수 있다. $-\\eta x_i y_i$ : 두 변수가 같은 값이면 lower energy, 반대부호이면 higher energy $\\eta \u003e 0$ 이번에는 pixel의 바로 옆 neighborhood의 경우 ${x_i,x_j}$ $-\\beta x_i x_j$ : 두 변수가 같은 값이면 lower energy, 반대부호이면 higher energy $\\beta \u003e 0$ 마지막으로 biasing the model toward one particular sign 위해 $h x_i$ : pixel i in the noise-free image 이를 통해 complete energy function과 joint distribution을 구하면 $$E(\\textbf{x},\\textbf{y}) = h \\sum_i x_i - \\beta \\sum_{{i,j}} x_i x_j -\\eta \\sum_i x_i y_i$$ $$p(\\textbf{x},\\textbf{y}) = \\frac{1}{Z} \\exp{-E(\\textbf{x},\\textbf{y})}$$ $\\textbf{y}$는 observed value이고 따라서 conditional distribution $p(\\textbf{x}|\\textbf{y})$을 define할 수 있다. 여기서 우리는 확률을 높이는 $\\textbf{x}$를 구해야 할 것이다. 이를 위해 iterative한 방법을 사용할 것인데 iterated conditional modes 라는 방법이다. $x_i = y_i$로 시작한다. 각 $x_i$ 마다 (-1 or 1로) 값을 바꿔가면서 lower energy를 갖는 값을 선택한다. 하나의 $x_i$값을 계산하기 때문에 빠르게 진행할 수 있다. 특정 criterion을 만족할 때까지 반복한다. 뒤에서 high probability를 찾는 max-product algorithm에 대해 살펴볼 것이다. ","date":"2021-11-29","objectID":"/prml-chap08-1/:3:3","tags":["Grphical Model"],"title":"[PRML] Chapter8 - Graphical Models (1)","uri":"/prml-chap08-1/"},{"categories":["PRML"],"content":"8.3.4 Relation to directed graphs 예시를 통해 둘의 관계에 대해 알아보자. 먼저, MC형태의 directed graph의 joint distribution이 아래와 같다. $$p(\\textbf{x}) = p(x_1)p(x_2 | x_1)…p(x_N | x_{N-1})$$ 이를 undirected graph로 나타내보자. (maximal) clique를 고려하여 joint distribution을 나타내면 $$p(\\textbf{x}) = \\frac{1}{Z} \\psi_{1,2}(x_1, x_2)\\psi_{2,3}(x_2, x_3)…\\psi_{N-1,N}(x_{N-1}, x_N)$$ 그렇다면 어렵지 않게 $$\\psi_{1,2}(x_1, x_2)= p(x_1)p(x_2 | x_2)\\ \\psi_{2,3}(x_2, x_3)=p(x_3 | x_2) \\\\ … \\\\ \\psi_{N-1,N}(x_{N-1}, x_N) = p(x_N | x_{N-1})$$ 로 나타낼 수 있을 것이다. conditional distribution에 관련한 variable들을 같은 clique의 멤버로 하면 된다. 또 다른 예시를 보자. $$p(\\textbf{x})=p(x_1)p(x_2)p(x_3)p(x_4 | x_1,x_2,x_3)$$ 위와 같은 경우를 undirected graph로 나타내기 위해서는 마지막항으로 인해 원래는 directed graph에는 없던 link를 만들어야한다. (같은 clique에 속하게 해야하니까) 이렇게 ‘marrying parents’ 하는 과정을 moralization이라고 하며 link를 만들고 arrow를 없애는 과정으로 만들어진 graph를 moral graph라고 한다. 이처럼 directed를 undirected로 바꾸는 과정에서 conditional property를 많이 잃게 된다. 그래서 최대한 이를 지켜주면서 바꾸는게 중요한 듯 하다. 그리고 반대로 undirected에서 directed로 바꾸는 경우는 많지 않다고 한다. 그 이유중 하나는 normalization constant 때문이라고 할 수 있다. ","date":"2021-11-29","objectID":"/prml-chap08-1/:3:4","tags":["Grphical Model"],"title":"[PRML] Chapter8 - Graphical Models (1)","uri":"/prml-chap08-1/"},{"categories":["PRML"],"content":"Sparse kernel machine (SVM)에 대해 정리하였다. 이번 장에서는 SVM에 대해 공부할 것이다. SVM은 classification, regression, novelty detection에 사용한다. decision machine이기 때문에 posterior probability를 알수는 없다. model parameter를 구하는데 있어 convex optimization problem이기에 any local solution이 global optimum이 된다. high dimension에서 분류할 때 좋은 generalization 성능을 보인다 train이 quadratic programmin problem이다 train data에 대해 fit하지만 generalization의 성능이 좋다. statistical learning theory라는 탄탄한 이론에 기반하여 만들어졌다. ","date":"2021-11-29","objectID":"/prml-chap07-1/:0:0","tags":["SVM"],"title":"[PRML] Chapter7 - Sparse Kernel Machine","uri":"/prml-chap07-1/"},{"categories":["PRML"],"content":"7.1 Maximum Margin Classifiers (hard margin) 일단 몇 가지 가정을 하고 공부를 시작해보자. two class classification problem using linear model $$y(\\textbf{x}) = \\textbf{w}^T \\phi (\\textbf{x}) + b$$ train data가 linearly separable in feature space라고 가정 따라서 최소한 하나의 오류없이 100% 분류가능한 $\\textbf{w}, b$가 존재 training data $(\\textbf{x}_1,…,\\textbf{x}_n),(t_1,…,t_n), t_n \\in {-1,1}$ decision boundary : $y(\\textbf{x})=0$ $y(\\textbf{x}_n) \u003c 0 \\rightarrow t_n = -1,;y(\\textbf{x}_n) \u003e 0 \\rightarrow t_n = 1$ $\\therefore y(\\textbf{x}_n) t_n \u003e 0$ for all train data new data are classified by the sign of $y(\\textbf{x})$ train data가 lineary separable하므로 우리의 목표는 이를 나누는 hyperplane을 찾는 것이다. 그렇다면 가장 좋은 hyperplane을 어떻게 찾을까? SVM에서 hyperplane (decision boundary)는 margin 을 최대화하도록 한다. margin : smallest distance between the decision boundary and any of the samples 이에 해당하는 그림을 찾아보면 이해하기 쉬울 것이다. train set에서 margin 최대화 = generalization error 최소화 = good prediction hyperplane과 data point $\\textbf{x}$의 거리는 $$\\frac{\\left| y(\\textbf{x})\\right|}{ \\left| \\textbf{w} \\right|}$$ 인데 가정에 따라 모든 data point는 잘 분류되어 있다. (그 중에서 best hyperplane을 찾기). 따라서 $t_n y(\\textbf{x}_n)\u003e0$ 인 상황이므로 $$\\frac{t_n y(\\textbf{x}_n)}{\\left| \\textbf{w} \\right|}$$ 으로 나타낼 수 있다. 따라서 maximize margin solution은 $$\\arg\\max_{w,b}{ \\frac{1}{\\left| \\textbf{w}\\right|} \\min_{n} [t_n (\\textbf{w}^T \\phi(\\textbf{x}_n)+b)] }$$ 이를 바로 풀기는 어려움이 있어서 약간의 변화를 준다. Let $t_n(\\textbf{w}^T \\phi(x_n) + b) = 1$ for the point that is closest to the decision boundary. 따라서 $t_n(\\textbf{w}^T \\phi(x_n) + b) \\ge 1$ 의 제약이 생긴다. 대신 $\\min$ 뒷 부분을 제외하고 optimization이 가능하다. (constraint가 생기지만) 이를 통해 우리는 (convex) optimization problem을 아래와 같이 정의할 수 있다. constraint : $t_n(\\textbf{w}^T \\phi(x_n) + b) \\ge 1$ $$\\arg\\min_{w,b} \\frac{1}{2} \\left| \\textbf{w} \\right|^2_2$$ ","date":"2021-11-29","objectID":"/prml-chap07-1/:1:0","tags":["SVM"],"title":"[PRML] Chapter7 - Sparse Kernel Machine","uri":"/prml-chap07-1/"},{"categories":["PRML"],"content":"+ 위 내용을 다른 방법으로 접근 고려대학교 김성범 교수님의 유투브 참조 위의 margin을 찾는 과정에 대해 조금 다른 derivation을 소개한다. $y(\\textbf{x})=1, y(\\textbf{x})=-1$ 위의 점을 각각 $\\textbf{x}^+, \\textbf{x}^-$ 라고 하자 : support vector, 즉 decision boundary와 가장 가까운 각 class의 점들을 의미 $\\textbf{x}^-$을 움직여서 반대편 class $y(\\textbf{w})=-1$ 위의 점으로 만들 수 있다. $\\textbf{x}^+ = \\textbf{x}^- + \\alpha \\textbf{w}$ $$\\textbf{w}^T \\textbf{x}^+ + b = 1 \\ \\textbf{w}^T (\\textbf{x}^- + \\alpha \\textbf{w}) + b = 1 \\ \\textbf{w}^T \\textbf{x}^- +b + \\alpha \\textbf{w}^T \\textbf{w} = 1 \\ \\therefore \\alpha = \\frac{2}{\\textbf{w}^T \\textbf{w}}$$ margin = distance($\\textbf{x}^+, \\textbf{x}^-$) / 2 $$ = \\left| \\textbf{x}^+ - \\textbf{x}^- \\right|_ 2 /2 \\ = \\left | \\alpha \\textbf{w} \\right |_ 2 /2 \\ = \\alpha \\sqrt{\\textbf{w}^T \\textbf{w}}/2 \\ = \\frac{1}{\\sqrt{\\textbf{w}^T \\textbf{w}}} = \\frac{1}{\\left | \\textbf{w} \\right |_ 2}$$ 이렇게 약간 다른 과정을 통해 같은 결과를 얻을 수 있다. 이를 quadratic programming problem이라고 한다. quadratic programming : minimize a quadratic function subject to a set of linear inequality constraints 이를 통해 Lagrange function을 만들어 parameter를 구해보자. 제약식이 있는 maximum margin problem을 Lagrangian Primal문제로 변환 시킨 것이다. Lagrangian Primal $\\max_{a} \\min_{w,b} L(\\textbf{w},b,\\textbf{a})$ Lagrange multipliers $a_n \\ge 0$ $$L(\\textbf{w}, b, \\textbf{a}) = \\frac{1}{2} \\left| \\textbf{w} \\right|^2_2 - \\sum_{n=1}^{N}{a_n{ t_n(\\textbf{w}^T \\phi(\\textbf{x}_n)+b)-1 }}$$ 이 식을 각 parameter $\\textbf{w}, b$ 로 미분하면 $$\\textbf{w} = \\sum_{n=1}^{N}{a_n t_n \\phi (\\textbf{x}_n)}$$ $$0 = \\sum_{n=1}^{N}{a_n t_n}$$ 이를 통해 maximum margin problem을 dual representation 으로 나타낼 수 있다. 첫번째 항 $$\\frac{1}{2} \\left| \\textbf{w} \\right|^2_2 = \\frac{1}{2}\\textbf{w}^T\\textbf{w} $$ $$= \\frac{1}{2}\\textbf{w}^T \\sum_{n=1}a_n t_n \\phi(\\textbf{x} _ n)$$ $$ = \\frac{1}{2} \\sum_{n=1}a_n t_n \\textbf{w}^T \\phi(\\textbf{x} _ n) $$ $$ = \\frac{1}{2} \\sum_{n=1}a_n t_n\\sum_{m=1}a_m t_m \\phi(\\textbf{x} _ m)^T \\phi(\\textbf{x} _ n) $$ $$ =\\frac{1}{2} \\sum_{n=1}\\sum_{m=1}a_n t_na_m t_m \\phi(\\textbf{x}_m)^T \\phi(\\textbf{x}_n) $$ 두번째 항 $$- \\sum_{n=1}^{N}{a_n{ t_n(\\textbf{w}^T \\phi(\\textbf{x} _ n)+b)-1 }} $$ $$ = -\\sum_{n=1}a_n t_n \\textbf{w}^T \\phi(\\textbf{x} _ n) - b\\sum_{n=1} a_n t_n + \\sum_{n=1}a_n $$ $$ = -\\sum_{n=1}\\sum_{m=1}a_n a_m t_n t_m \\phi(\\textbf{x} _ m)^T \\phi(\\textbf{x} _ n) + \\sum_{n=1}a_n$$ 따라서 최종적으로 Lagrangian dual constraint (제약식) $a_n \\ge 0$ $\\sum_{n=1}^{N}{a_n t_n} = 0$ $$L(\\textbf{a}) = \\sum_{n=1}^{N}{a_n} - \\frac{1}{2}\\sum_{n=1}^{N} \\sum_{m=1}^{N}{a_n a_m t_n t_m \\phi(\\textbf{x}_m)^T \\phi(\\textbf{x}_n)}$$ 위 식을 maximize하면 되고 이는 다시 $a$에 관한 quadratic problem이 된다. Lagrangian Dual problem으로 바뀐 것이다. objective function is quadratic \u0026 constraint is linear 따라서 여기서 Lagrangian Dual은 quadratic programming이 된다. 또한 kernel function을 사용할 수 있는 형태을 얻었다. (inner product) 우리는 $\\textbf{a}$를 구하여 $\\textbf{w},b$ 모두 알 수 있고 prediction도 할 수 있다. 새로운 데이터를 분류하기 위해 $y(\\textbf{x})$의 sign을 알면 된다. 그리고 prediction을 위해 굳이 $\\textbf{w},b$를 구하지 않고 아래의 식으로 prediction하면 된다. $$y(\\textbf{x}) = \\sum_{n=1}^{N}{a_n t_n \\phi(\\textbf{x})^T \\phi(\\textbf{x}_n)+b}$$ 그런데 $(\\textbf{w}, b, \\textbf{a})$가 Lagrangian dual problem의 최적해가 되기 위한 조건으로 KKT condition 을 만족해야 한다. KKT( Karuch-Kuhn-Tuker) condition Stationarity $\\frac{\\partial L(\\textbf{w},b,\\textbf{a})}{\\partial \\textbf{w}}=0, \\frac{\\partial L(\\textbf{w},b,\\textbf{a})}{\\partial \\textbf{b}}=0$ Primal feasibility $t_n y(\\textbf{x}_n) - 1 \\ge 0$ Dual feasibility $a_n \\ge 0$ Complementary slackness $a_n { t_n y(\\textbf{x}_n )- 1 } = 0$ 이를 통해 SVM에서 중요한 내용을 생각할 수 있는데 모든 점은 두 가지 경우에 해당한다. $a_n \u003e 0 ; \\text{and} ; t_n y(\\textbf{x}_n)-1=0$ $a_n = 0 ; \\text{and} ; t_n y(\\textbf{x}_n)-1\\neq 0$ 근데 $a_n$이 0인 경우는 decision boundary를 만드는 것과 prediction에 아무런 영향을 주지 않는다. 영향을 주는 점들은 support vector 라고 부른다. 이들은 $t_n y(\\textbf{x}_n) = 1$ 이고 maximum margin hyperplane의 위에 있는 점들이다. (각 class별로 decision boundary와 가장 가까운 점에 관한 hyperplane) support vector만으로 optimal hyperplane(decision boundary)를 구할 수 있다. 그래서 sparse kernel machine이라고 부르는 것이다. ","date":"2021-11-29","objectID":"/prml-chap07-1/:1:1","tags":["SVM"],"title":"[PRML] Chapter7 - Sparse Kernel Machine","uri":"/prml-chap07-1/"},{"categories":["PRML"],"content":"7.1.1 Overlapping class distributions (soft margin) 이전까지 우리는 완전히 separable이 가능한 경우에서 모델링하였다. 하지만 이런 경우는 드물다. overlap되는 경우에 우리는 penalty를 주고 misclassification이 된 경우가 존재하는 모델을 만드는 것이다. 이를 soft margin 이라고 부른다. 이 penalty를 위해 각 data point마다 slack variable을 생각한다. slack variable (penalty) $\\xi_n = 0$ : 데이터가 잘 분류되고 margin 밖에 위치 이외의 경우 : $\\xi_n = | t_n - y(x_n) |$ (틀린 거리만큼 penalty) $0 \u003c \\xi_n \u003c 1$ : 잘 분류되었지만 margin 범위 안에 위치 $\\xi_n = 1$ : data가 +, - boundary 위에 위치 $\\xi_n \u003e 1$ : 잘못 분류 이에 따라 $t_n y(\\textbf{x}_n) \\ge 1- \\xi_n$ 으로 constraint가 바뀐다(error를 허용하는). 따라서 우리는 minimize constraint : $t_n(\\textbf{w}^T \\phi(\\textbf{x}_n) + b) \\ge 1- \\xi_n$ $$C\\sum_{n=1}^{N}{\\xi_n + \\frac{1}{2}|\\textbf{w}|^2_2}$$ 하게 된다. 여기서 C는 trade-off 관계를 컨트롤하는 파라미터이다. C가 커지면 error를 많이 허용하지 않으므로 overfit C가 작으면 error를 많이 허용하므로 underfit 이 식을 위에서 했던 대로 Lagrange로 계산하면 위의 dual representation과 같은 결과가 나온다. 이번에는 Lagrange multiplyer가 두 개가 필요하다. 다른 점은 constraint, KKT 가 달라진다. Lagrangian Primal $\\max_{a,\\gamma} \\min_{w,b,\\xi} L(\\textbf{w},b,\\textbf{a}, \\xi, \\gamma)$ Lagrange multipliers $a_n \\gamma_n \\ge 0$ $$L(\\textbf{w},b,\\textbf{a}, \\xi, \\gamma)$$ $$ = \\frac{1}{2} \\| \\textbf{w} \\|^2_2 + C\\sum_{n=1}\\xi_n - \\sum_{n=1}{a_n{ t_n(\\textbf{w}^T \\phi(\\textbf{x} _ n)+b) - 1 + \\xi_n }} - \\sum_{n=1}\\gamma_n \\xi_n$$ 이 식을 각 parameter $\\textbf{w}, b, \\xi$ 로 미분하면 $$\\textbf{w} = \\sum_{n=1}^{N}{a_n t_n \\phi (\\textbf{x}_n)}$$ $$0 = \\sum_{n=1}^{N}{a_n t_n}$$ $$C - a_n - \\gamma_n = 0$$ Lagrange dual constraint (제약식) $a_n \\ge 0$ $\\sum_{n=1}^{N}{a_n t_n} = 0$ $$L(\\textbf{a}) = \\sum_{n=1}^{N}{a_n} - \\frac{1}{2}\\sum_{n=1}^{N} \\sum_{m=1}^{N}{a_n a_m t_n t_m k(\\textbf{x}_n,\\textbf{x}_m)}$$ KKT( Karuch-Kuhn-Tuker) condition $\\frac{\\partial L(\\textbf{w},b,\\textbf{a})}{\\partial \\textbf{w}}=0, \\frac{\\partial L(\\textbf{w},b,\\textbf{a})}{\\partial \\textbf{b}}=0$ $C - a_n- \\gamma_n = 0$ $a_n { t_n y(\\textbf{x}_n )- 1 + \\xi } = 0, \\gamma_n \\xi_n = 0$ 이번에도 마찬가지로 solution의 특징을 보면 $a_n { t_n y(\\textbf{x}_n )- 1 + \\xi } = 0,; \\gamma_n \\xi_n = 0,; a_n = C-\\gamma_n$ $a_n = 0 \\Rightarrow \\gamma_n = C \\Rightarrow \\xi_n=0 \\Rightarrow t_n y(\\textbf{x}_n )- 1\\neq 0$ $\\textbf{x}_n$ 이 +,- boundary 보다 멀리 잘 분류되었다. $0 \u003c a_n \u003c C \\Rightarrow \\gamma_n \u003e 0 \\Rightarrow \\xi_n=0, \\gamma_n\\xi_n=0 \\Rightarrow t_n y(\\textbf{x}_n )- 1=0$ $\\textbf{x}_n$ 이 +,- boundary 위에 있다. (support vector) $a_n = C \\Rightarrow \\gamma_n = 0 \\Rightarrow \\xi_n\u003e0 \\Rightarrow t_n y(\\textbf{x}_n )- 1 = -a_n \\xi_n \\neq 0$ $\\textbf{x}_n$ 이 +,- boundary 과 decision boundary 사이에 존재한다. (margin의 범위에 존재, 이들도 support vector라고 함) 이제 kernel method for nonlinear classification에 대해 살펴보자. 우리의 위에서 dual problem을 통해 kernel function의 사용가능성을 파악할 수 있었다. kernel을 사용함으로서 nonlinear decision boundary를 만드는데 있어서 inner product $\\phi(\\textbf{x}_n)^T \\phi(\\textbf{x}_m)$이 아니라 $k(\\textbf{x}_n, \\textbf{x}_m)$으로 계산할 수 있다. 예시를 통해 kernel의 유용성을 알아보자. $\\textbf{x},\\textbf{z}$는 2차원 vector kernel function : $k(\\textbf{x},\\textbf{z}) = (1+\\textbf{x}^T\\textbf {z})$ 라고 하자. $$\\phi(\\textbf{x})^T \\phi(\\textbf{z}) = (1\\;\\sqrt{2}x_1\\;\\sqrt{2}x_2\\;x_1^2\\;\\sqrt{2}x_1x_2;x_2^2)(1\\;\\sqrt{2}z_1\\;\\sqrt{2}z_2\\;z_1^2\\;\\sqrt{2}z_1 z_2\\;z_2^2)^T $$ $$ = (1+x_1z_1+x_2z_2)^2 = (1 + \\textbf{x}^T \\textbf{z})^2$$ 이처럼 kernel을 통해 기존의 $\\textbf{x}$을 nonlinear하게 만들어서 decision boundary를 만들 수 있어서 classification을 더 잘 할 수 있는 것이다. (여기서는 처음부터 $\\phi(\\textbf{x})$를 사용하였지만 지금까지의 모든 과정을 $\\textbf{x}$ 라고 생각하면 kernel을 통해 nonlinear하게 만들었다고 이해할 수 있다.) 기존의 data를 explicit하게 $\\phi(\\textbf{x})$ (nonlinear하게) 으로 만든 뒤에 inner product로 계산하는 것이 아니라 kernel function을 통해 같은 결과를 만들 수 있기에 explicit하게 몰라도 되고 상당히 computationally 좋다. 가장 많이 쓰이는 kernel은 Gaussian Kernel (Radial basis function Kernel) $$k(\\textbf{x}, \\textbf{z}) = \\exp(\\frac{- \\left| \\textbf{x} - \\textbf{z} \\right|^2_2}{2 \\sigma^2})$$ ","date":"2021-11-29","objectID":"/prml-chap07-1/:1:2","tags":["SVM"],"title":"[PRML] Chapter7 - Sparse Kernel Machine","uri":"/prml-chap07-1/"},{"categories":["PRML"],"content":"7.1.2 Comparison to logistic regression 그림을 찾아보는 것을 추천한다. SVM loss function : Hinge loss $\\xi_j = (1-(wx_j + b)y_j)_ {+}$ logistic loss function : Log loss $\\xi_j = -\\log (1+\\exp(wx_j+b)y_j)$ $$\\because \\theta_{MLE} = \\arg\\max {\\sum{log(P(T_i \\ X_i;\\theta))}} $$ $$ = \\arg\\max {\\sum { Y_i X_i \\theta - \\log (1+\\exp(X_i \\theta) ) }}$$ Hinge loss는 correct한 경우 penalty가 0이 되지만 log loss는 corret한 경우에도 0이 되지 않는다. log loss가 좀 덜 극단적인 것 같다. ","date":"2021-11-29","objectID":"/prml-chap07-1/:1:3","tags":["SVM"],"title":"[PRML] Chapter7 - Sparse Kernel Machine","uri":"/prml-chap07-1/"},{"categories":["PRML"],"content":"7.1.3 Multiclass SVM 다양한 방법이 있다. 하지만 다들 한계점이 있는 것으로 보인다. ","date":"2021-11-29","objectID":"/prml-chap07-1/:1:4","tags":["SVM"],"title":"[PRML] Chapter7 - Sparse Kernel Machine","uri":"/prml-chap07-1/"},{"categories":["PRML"],"content":"7.1.4 SVMs for regression 어렵지 않다. 정리는 생략하고자 한다. $\\epsilon$-insensitive error function $$E_\\epsilon((y(\\textbf{x})-t)) = \\begin{Bmatrix} 0 ,\\; if\\;|y(\\textbf{x})-t|\u003c\\epsilon \\\\ |y(\\textbf{x})-t|-\\epsilon,\\; \\text{otherwise} \\end{Bmatrix}$$ 아래의 식을 최소화한다. $$C\\sum_{n=1}^{N}{E_\\epsilon((y(x)-t)) + \\frac{1}{2}|\\textbf{w}|^2}$$ ","date":"2021-11-29","objectID":"/prml-chap07-1/:1:5","tags":["SVM"],"title":"[PRML] Chapter7 - Sparse Kernel Machine","uri":"/prml-chap07-1/"},{"categories":["PRML"],"content":"7.2 Relevance vector machines SVM은 확률적인 요소가 없다. 이를 위해 Bayesian SVM이라고 할 수 있는 RVM이 있다. 하지만 나중에 필요하면 다시 공부하고자 한다. ","date":"2021-11-29","objectID":"/prml-chap07-1/:2:0","tags":["SVM"],"title":"[PRML] Chapter7 - Sparse Kernel Machine","uri":"/prml-chap07-1/"},{"categories":["PRML"],"content":"khan academy의 강의를 듣고 간략하게 정리해보았다. ","date":"2021-11-29","objectID":"/prml-chap07-0/:0:0","tags":["Optimization"],"title":"[PRML] Chapter7 - Constrained Optimization","uri":"/prml-chap07-0/"},{"categories":["PRML"],"content":"gradient store all partial derivative information of a multivariate function vector-valued function $$\\nabla f = [\\frac{\\partial f}{\\partial x};\\frac{\\partial f}{\\partial y};\\frac{\\partial f}{\\partial z}…]^T$$ 특징 gradient vector $\\nabla f (x_0, y_0,…)$는 함수식 $f$ 위의 점 $(x_0, y_0,…)$에서 $f$ 에 perpendicular 하다. $\\nabla f (x_0, y_0,…)$는 해당 점에서 $f$ 가 가장 빠르게 커지게하는 방향을 의미한다. ","date":"2021-11-29","objectID":"/prml-chap07-0/:1:0","tags":["Optimization"],"title":"[PRML] Chapter7 - Constrained Optimization","uri":"/prml-chap07-0/"},{"categories":["PRML"],"content":"문제상황 maximize $f(x,y) = x^2 y$ constraint : $x^2 + y^2 = 1$ 두 함수가 만나는 지점에서 $f$를 최대로 하는 점을 찾아야한다. 여기서 우리는 gradient를 이용한다. 해당 점을 $x_m, y_m$ 라고 하자. $g(x,y) = x^2 + y^2$ 라고 하자. $\\lambda$ : Lagrange multiplier $$\\nabla f(x_m, y_m) = \\lambda \\nabla g(x_m, y_m)$$ 해당 점에서 각 함수의 gradient는 어떤 상수배($\\lambda$)를 통해 같아질 수 있다. 해당함수(targent)에 perpendicular하기 때문이다. 그래프를 머리속으로 그려서 생각해보자! $$\\nabla f = [2xy; x^2]^T, \\nabla g = [2x;2y]^T$$ 이므로 우리는 식 3개와 변수 3개 $2xy = \\lambda 2x$ $x^2 = \\lambda 2y$ $x^2 + y^2 = 1$ (제약식) 를 얻을 수 있고 이를 통해 $x_m, y_m$ 을 구할 수 있다. ","date":"2021-11-29","objectID":"/prml-chap07-0/:2:0","tags":["Optimization"],"title":"[PRML] Chapter7 - Constrained Optimization","uri":"/prml-chap07-0/"},{"categories":["PRML"],"content":"Lagrange method Lagrangian optimize $f$ constraint $g = C$ $$L(x,y,\\lambda) = f(x,y) - \\lambda (g(x,y) - C)$$ 이를 미분해서 0이 되는 $x^* ,y^* ,\\lambda^*$ 를 구하면 된다. Lagrange multiplier의 의미 $M^* = f(x^* , y^* )$라고 하자. 그런데 이 식은 $C$에 따라 달라지기에 $$M^* (C) = f(x^* (C) , y^* (C) )$$ 이를 이용하여 $\\lambda^*$에 대해 정리하면 (증명 생략) $$\\lambda^* = \\frac{d M^* }{d C }$$ ","date":"2021-11-29","objectID":"/prml-chap07-0/:3:0","tags":["Optimization"],"title":"[PRML] Chapter7 - Constrained Optimization","uri":"/prml-chap07-0/"},{"categories":["PRML"],"content":"Bayesian Optimization으로 모델의 성능을 올려보자. ","date":"2021-11-29","objectID":"/prml-chap06-3/:0:0","tags":["Bayesian Optimization"],"title":"[PRML] Bayesian Optimization","uri":"/prml-chap06-3/"},{"categories":["PRML"],"content":"Bayesian Optimization with Gaussian Process 어떤 sequence of experiments를 한다고 생각해보자. 다음은 몇 가지 가정사항이다. Interested in finding a global maximizer(minimizer) of $f(\\bf{x})$ 우리는 experiments result를 만드는 underlying function $f(\\bf{x})$를 모른다. input은 우리가 다 알고 조절할 수 있다. result have a stochastic element $y_t \\sim N(f,\\sigma^2_{noise})$ results and input are continuous 일반적인 경우는 continous를 고려하지만 discrete, hybrid의 경우도 존재한다. 다양한 task에서 사용할 수 있지만 우리는 주로 hyperparameter tuning을 할 때 사용하게 된다. Grid search no learning of underlying function Binary search learning of constraints, not the function 위와 같은 방법들이 많이 사용되었다. 이와 다르게 BOP는 learning underlying function with surrogate model selecting the next sampling input 같은 task를 통해서 최적의 결과를 얻어내고자 하는 것이다. 그렇다면 어떤 과정으로 최적의 결과를 얻어낼까? GPR은 모든 data point에서 predicted mean, predicted std를 알려준다. input을 넣고 underlying function을 만든다 (GPR을 fitting하는 것). 그 후에 mean과 variance를 통해 exploitation or exploration를 결정하여 next sampling input을 결정한다. (그리고 다시 underlying function을 만든다. 이를 반복한다.) Exploitation : result값이 높은 곳(underlying function mean이 큰) 탐색 Exploration : 관측지가 적은 곳(variance가 큰) 탐색 이떄, 이에 대한 판단 기준이 필요하다. acquisition function을 이용한다. 이에 대해 한번 더 정리하자면 Surrogate model : Compute $p(f|D_{1})$, yielding $\\mu_{1}({\\bf x})$ and $\\sigma_{1}({\\bf x})$. Acquisition function: Choose ${\\bf{x}} _ {2}$ such that ${\\bf x} _ {2}=argmax_{ {\\bf x} \\in \\mathcal{X} } a ({\\bf x}|\\mathcal{M}_{1})$ Augment data, $D_2 = D_1 \\cup \\{ ({\\bf x}_{2}, y _ {2}) \\}$ Surrogate model : Compute $p(f|D_2)$, yielding $\\mu_{2}({\\bf x})$ and $\\sigma_{2}({\\bf x})$. Acquisition function: Choose ${\\bf x} _ 3$ such that ${\\bf x} _ {3}=argmax_{ {\\bf x} \\in \\mathcal{X} }a({\\bf x}|\\mathcal{M}_{3})$ Augment data, $D_ 3 = D_2 \\cup \\{ ({\\bf x} _ {3},y _ {3}) \\}$ Repeat theses till the final round T, to compute $\\mu_{T}({\\bf x})$ ${\\bf x}^{*} = argmax_{ {\\bf x} \\in {\\bf x}_1,…,{\\bf x} _ T } \\mu _ {T}({\\bf x})$ ","date":"2021-11-29","objectID":"/prml-chap06-3/:1:0","tags":["Bayesian Optimization"],"title":"[PRML] Bayesian Optimization","uri":"/prml-chap06-3/"},{"categories":["PRML"],"content":"surrogate model 다양한 모델을 사용할 수 있다. 하지만 해당 point의 mean, variance를 알 수 있는 stochastic한 모델이여야 할 것이다. Random Forest Empirical하게 mena, variance를 구할 수 있다. scable, faster continuous, discrete 변수 모두 handle 가능하다. (GP는 kernel을 따로 design해야 한다고 함) extrapolation을 잘 못한다. GP regression Nonparameteric Bayesian Regression Not scalable 10dim이 넘어가면 standard GP로는 힘들다. sample dsata의 수가 많아져도 힘들다. ","date":"2021-11-29","objectID":"/prml-chap06-3/:1:1","tags":["Bayesian Optimization"],"title":"[PRML] Bayesian Optimization","uri":"/prml-chap06-3/"},{"categories":["PRML"],"content":"Acquisition Function Acquisition Function은 다양하다. 몇 가지만 간단히 알아보고 코드를 통해 실습을 진행해보자. Maximum Probability of Improvement (PI) 현재 optimized value $y_{max}$를 어떤 margin m 이상으로 올려줄 확률이 가장 높은 input을 sampling한다. grid search처럼 value를 계산하는 것이 아니라 확률만 계산하여 진행한다. $D$는 기존 data, 이를 통해 GPR을 만들수 있겠다. $y \\sim N(\\mu, \\sigma^2)$ 이는 GPR로 만들어진 것이다. $$MPI(x|D) = \\argmax_x P(y \\ge (1+m)y_{max} | x, D)$$ $$y\\sim N(\\mu, \\sigma^2) = \\argmax_x P(\\frac{y-\\mu}{\\sigma} \\ge \\frac{(1+m)y_{max}-\\mu}{\\sigma})$$ $$= \\argmax_x \\Phi (\\frac{\\mu - (1+m)y_{max}}{\\sigma})$$ 그런데 PI는 잘 안쓴다고 한다. Maximum Expected Improvement (EI) MPI를 조금 더 디벨롭시킨 것이다. MPI에서는 m을 고려해야했다. 그렇게 하지 말고 0부터 infinite으로 고려하면 되지 않을까? 라는 접근을 한다. 구체적으로 식을 구하는 과정은 생략한다. expected improvement w.r.t. the best observed objective value $y_{b}$ so far is defined as $$EI = E _ y [ \\max (y - y_{b} ,0) ]$$ $$=\\int \\max (y-y_{b}) N (y | \\bar{y}, \\sigma^{2})dy$$ $$=(\\bar{y} - y_b) \\Phi ( \\frac{\\bar{y}-y_b}{\\sigma} ) + \\sigma \\phi ( \\frac{\\bar{y} - y_b}{\\sigma} )$$ Gaussian Process-Upper Confidence Bound (GP-UCB) posterior mean과 variance의 적절한 trade-off를 고려하여 data point를 선택한다. 아래의 수식에 따라서 point를 선택한다. $\\beta_t$ : appropriate constants $\\nu$ : hyperparameter involving the degree of exploration $$\\bf{x} _ t = \\argmax_{\\bf{x}} ( \\mu_{t-1}(\\bf{x}) + \\sqrt{\\nu \\beta_t} \\sigma_{t-1}(\\bf{x}))$$ Thompson Sampling posterior에서 function을 sampling하는 방법이다. ","date":"2021-11-29","objectID":"/prml-chap06-3/:1:2","tags":["Bayesian Optimization"],"title":"[PRML] Bayesian Optimization","uri":"/prml-chap06-3/"},{"categories":["PRML"],"content":"이해를 위한 코드 # NHN cloud # https://www.youtube.com/watch?v=PTxqPfG_lXY import numpy as np from scipy.stats import norm from sklearn.gaussian_process import GaussianProcessRegressor from sklearn.gaussian_process.kernels import RBF # Acquisition function def expected_improvement(mean, std, max): z = (mean - max) / std return (mean - max) * norm.cdf(z) + std * norm.pdf(z) # Objective function def f(x): return x * np.sin(x) # hyperparameter space min_x, max_x = -2, 10 # Observation data X = np.random.uniform(min_x, max_x, 3).reshape(-1, 1) y = f(X).ravel() # GP model gp_model = GaussianProcessRegressor(kernel=RBF(1.0)) for i in np.arange(10): # surrogate model fit gp_model.fit(X, y) # predict -\u003e mean, std 계산 xs = np.random.uniform(min_x, max_x, 10000) mean, std = gp_model.predict(xs.reshape(-1, 1), return_std=True) # acq 계산 acq = expected_improvement(mean, std, y.max()) # acq가 가장 큰 값 선택 x_new = xs[acq.argmax()] y_new = f(x_new) # 데이터에 추가 X = np.append(X, np.array([x_new])).reshape(-1, 1) y = np.append(y, np.array([y_new])) ","date":"2021-11-29","objectID":"/prml-chap06-3/:1:3","tags":["Bayesian Optimization"],"title":"[PRML] Bayesian Optimization","uri":"/prml-chap06-3/"},{"categories":["PRML"],"content":"Reference 문일철 교수님 강의 NHN cloud 발표 paper Taking the Human Out of the Loop: A Review of Bayesian Optimization (2016) A tutorial on Bayesian optimization (2018) ","date":"2021-11-29","objectID":"/prml-chap06-3/:2:0","tags":["Bayesian Optimization"],"title":"[PRML] Bayesian Optimization","uri":"/prml-chap06-3/"},{"categories":["PRML"],"content":"Gaussian Process에 대해 정리하였다. ","date":"2021-11-29","objectID":"/prml-chap06-2/:0:0","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"6.4 Gaussian Processes 이 부분은 카이스트 문일철 교수님의 유투브영상을 보고 정리하였습니다. ","date":"2021-11-29","objectID":"/prml-chap06-2/:1:0","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Continuous Domain Data GP는 continuous domain data 분석에 유용하다. Time, Space, Spatio-Temporal… 어떻게 분석, 모델링? Estimating on the underlying function (ex. Autoregression) Prediction on the unexpected point (ex. extrapolation with autoregression) ","date":"2021-11-29","objectID":"/prml-chap06-2/:1:1","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Underlying Function and Observations $Y = sinc(x)$ 라는 함수를 underlying function이라고 하자. 여기서 gaussian noise를 추가하여 observation들을 생성했다. 지금 그림은 없지만 그림1은 x에 따라 분산이 동일하고 그림2는 x에 따라 분산이 변화(x가 클수록 분산이 커짐)한다. underlying function을 구해야하므로 mean function을 찾는 것은 당연하고 추가로 variance(or precision) function도 중요하다. $$\\mu(t), \\sigma(t)^2$$ ","date":"2021-11-29","objectID":"/prml-chap06-2/:1:2","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Simple Analyses without Domain Correlation mean function을 domain correlation없이 estimate한다고 하자. 즉, 특정 1개의 point에서 mean과 variance를 계산하는 것이다. 그런데 continuous domain에서 사실 같은 $x(t)$에 대해 multiple obsevation이 나올 수 없다. 약간의 discretize라고 할 수 있다. 해당 domain point에서 observation이 많으면 어느 정도 smooth하게 mean function을 구할 수 있다. 하지만 반대의 경우 좋은 estimation이 어렵다. 그래서 우리는 주위의 다른 domain data point도 사용하는게 좋지 않을까 라는 생각을 할 수 있다. ","date":"2021-11-29","objectID":"/prml-chap06-2/:1:3","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Simple Analyses with Domain Correlation Moving average time window(특정 구간)를 설정하고 평균 급격하게 변화하는 구간은 잘 안 맞을 수도 있다. time window에 따라 변화 window가 커질수록 smooth해진다. $$MA(x) = \\frac{1}{N} \\sum_{x \\in W} y_i$$ 그런데 모든 data point에 동일한 가중치를 주는게 다르게 주면 어떨까? 예를 들면, Squared Exponential $L$이 커지면 window가 커지는 역할 위에서 window 크기처럼 $L$을 적절히 선택해야한다. $$k(x,x_i;L) = exp(-\\frac{|x-x_i|^2}{L^2})$$ 위처럼 domain correlation을 다르게 생각하고 거리에 따라 가중치를 다르게 주는 것이다. 가까울수록 큰 가중치! $$MA(x) = \\frac{1}{\\sum_{x_i \\in D} k(x,x_i)}\\sum_{x_i \\in D} k(x,x_i) y_i$$ ","date":"2021-11-29","objectID":"/prml-chap06-2/:1:4","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Random Process Random process(=Stochastic process) An infinite indexed collection of random variables ${ X(w,t) , t \\in T }$ index paramter : $t$ (time, space…) A function $X(t,\\omega), t \\in T ;\\text{and}; \\omega \\in \\Omega$ outcome : $\\omega$ Fixed $t \\rightarrow X(t,\\omega)$ is a random variable over $\\Omega$ Fixed $\\omega \\rightarrow X(t,\\omega)$ is a deterministic function of $t$ ; sample function ","date":"2021-11-29","objectID":"/prml-chap06-2/:2:0","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Gaussian Process GP는 Random Process의 한 종류 For any set S, a GP on S is a set of random variable ($z_t : t \\in S$) such that vector $[z_{t_1}, z_{t_2},…,z_{t_n}]$ is multivariate gaussian $$P(T) = N(0, (\\beta I_N)^{-1} + K) \\ K_{nm} = k(x_n, x_m) = \\theta_0 \\exp(-\\frac{\\theta_1}{2}||x_n - x_m||^2) + \\theta_2 + \\theta_3 x_n^T x_m$$ ","date":"2021-11-29","objectID":"/prml-chap06-2/:3:0","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Derivation of Gaussian Process 일단 linear regression으로 접근하고 GP에 대해 알아본다. gaussian process regression : a nonparametric bayesian regression method using the properties of Gaussian processes ","date":"2021-11-29","objectID":"/prml-chap06-2/:4:0","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Mapping Functions non-linearly separable data set이 있다고 가정하자. 이를 위해 basis space를 증가시키면 될 것이다. mapping function $\\phi$를 통해 확장시킨다. ","date":"2021-11-29","objectID":"/prml-chap06-2/:4:1","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Linear regression with basis function $$y(x) = w^T \\phi (x)$$ 여기서 $w$를 deterministic value가 아니라 probabilistically distributed value라고 생각하자. (Bayesian linear regression의 방법론) $$P(w) = N(0, \\alpha^{-1} I)$$ Y의 확률분포(joint distribution)에 대해 생각해보자. ($w$가 확률분포가 있으니까) $Y$도 normal 이겠구나 (multivariate gaussian) $$Y = (y_1, y_2,…,y_n)$$ $K$ : Gram matrix $$E[Y] = E[\\Phi w] = \\Phi E[w] = 0$$ $$cov(Y) = E[YY^T] = E[\\Phi w w^T \\Phi^T]$$ $$= \\Phi E[ww^T]\\Phi^T = \\frac{1}{\\alpha} \\Phi \\Phi^T$$ $$K_{nm} = k(x_n,x_m) = \\frac{1}{\\alpha} \\phi (x_n)^T \\phi (x_m)$$ $$\\therefore P(Y) = N(0,K)$$ 분산이 kernel function을 이용한다는 점을 기억하자 이제 $Y$에 대한 분포를 파악했으니 이를 통해 prediction을 해보자. ","date":"2021-11-29","objectID":"/prml-chap06-2/:4:2","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Modeling Noise with Gaussian distribution $t_n$ : observed value with noise $y_n$ : Latent, error-free value $e_n$ : Error term distributed by following the gaussian distribution $$t_n = y_n + e_n \\ (t_n = f(x_n)+e_n)$$ $$P(T|Y) = N(Y, \\beta^{-1} I)$$ $\\beta$ : hyperparameter of the error precision error term들이 independent라고 가정하기에 variance 부분에 $I$이 된다. $$P(T) = \\int P(T|Y)P(Y) dY = \\int N(Y,\\beta^{-1} I) N(0,K) dY$$ 위의 곱해지는 두 분포 모두 multivariate gaussian distribution 이므로 이를 이용하여 구할 것이다. $$P(T|Y)P(Y) = P(T,Y) = P(Z)$$ $$\\ln P(Z) = \\ln P(T|Y) + \\ln P(Y) \\ = - \\frac{1}{2} Y^TK^{-1}Y - \\frac{1}{2}(T-Y)^T \\beta I (T-Y) + const$$ 여기서 변수는 $T,Y$이다. 여기서 second order term을 보면 (second order term을 찾으면 covariance를 찾을 수 있기에) $$ = \\frac{1}{2} \\begin{pmatrix} Y \\\\ T \\end{pmatrix}^T \\begin{pmatrix} K^{-1} + \\beta I \u0026 -\\beta I \\\\ - \\beta I \u0026 \\beta I \\end{pmatrix} \\begin{pmatrix} Y \\\\ T \\end{pmatrix} = \\frac{1}{2}Z^T R Z$$ $R$은 precision matrix가 된다. 이를 inverse 하면 (공식이용) $$R^{-1} = \\begin{pmatrix} K \u0026 K \\\\ K \u0026 (\\beta I)^{-1} + K \\end{pmatrix}$$ $\\ln (Z)$의 first order term은 없다. mean이 0라는 것을 알 수 있다. 따라서 최종 결과는 $$P(Z) = N(0, R^{-1})$$ 이제 PRML chapter 2에서 봤었던 공식을 이용하면 marginal distribution을 구할 수 있다. $$P(T) = N(0, (\\beta I)^{-1} + K)$$ 이제 우리가 관찰한 N개의 data를 통해 $P(T)$를 알게 되었다. 그렇다면 이제 prediction해보자. $t_{N+1}$을 알아내야 한다. $$P(t_{N+1}|T_N)$$ 이를 구하기 위해 N+1의 joint를 구하고 conditional disribution을 만들면 된다. ","date":"2021-11-29","objectID":"/prml-chap06-2/:4:3","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Sampling of $P(T)$ Sampling T of 101 dimension when points $x_n = [-1,-0.98,…,1]$ : 101개의 data point mean $0$ : 101 dim zero vector cov $(\\beta I_N)^{-1} + K$ : 101 * 101 dim cov $$P(T) = N(0, (\\beta I_N)^{-1} + K)$$ kernel의 parameter와 $\\beta$값에 따라서 sampling data들이 이루는 모습이 달라진다. ","date":"2021-11-29","objectID":"/prml-chap06-2/:4:4","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Mean and Covariance of $P(t_{N+1} | T_N)$ $$P(t_{N+1}|T_N) = P(T_{N+1}) / P(T_N)$$ $$P(T_{N+1}) = N(0, cov_{N+1})$$ mean은 1차원이 늘어난 zero vector이고 cov는 행과 열이 하나씩 들어간 형태일 것이다. 이는 kernel function과 $\\beta$를 통해 어렵지 않게 구할 수 있다. $$cov_{N+1} = \\begin{pmatrix} cov_N \u0026 k \\\\ k^T \u0026 K_{(N+1)(N+1)}+\\beta^{-1} \\end{pmatrix}$$ 이제 joint distribution을 구했으니 conditional distribution을 구할 수 있다. (공식 PRML chap2에 나온다) $$P(t_{N+1}|T_N) = N(0+k^T cov_N^{-1}(T_N-0),K_{(N+1)(N+1)}+\\beta^{-1} -k^Tcov_N^{-1} k )$$ 이는 결국 regression을 한 것이다. predictive distribution을 구한 것이다. 평균과 분산 모두 new data $x_{N+1}$에 depend하다. 분산에서 inverse가 computationally 오래걸려서 approximation하는 방법들이 있다고 한다. $$\\mu_{t_{N+1}} = k^T cov_N^{-1} T_N \\ \\sigma^2_{t_{N+1}} = K_{(N+1)(N+1)}+\\beta^{-1} -k^Tcov_N^{-1} k$$ 우리가 알고 있는 일반적인 regression과는 조금 다른 형태이다. 각 feature들의 weight들이 어디있는지 궁금할 수 있는데 kernel function안의 parameter로 들어갔다. ","date":"2021-11-29","objectID":"/prml-chap06-2/:4:5","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Hyperparameter of Gaussian Process Regression 위에서 linear regression에서 parameter optimization을 하는 방법을 알아보자. 아래의 kernel hyperparameter를 추정해야 하는 것이다. $$ K_{nm} = k(x_n, x_m) = \\theta_0 \\exp(-\\frac{\\theta_1}{2}||x_n - x_m||^2) + \\theta_2 + \\theta_3 x_n^T x_m$$ $$P(T;\\theta) = N(0, (\\beta I_N)^{-1} + K)$$ $\\theta$를 추정하기 위해 likelihood를 최대한 높이는 방법을 택한다. $\\theta$에 대해 미분하여 구하면 된다. $$\\frac{\\partial}{\\partial \\theta_i} \\log P(T;\\theta) \\overset{let}{=}0$$ 그런데 closed form은 존재하지 않는다. 그래서 approximation해야 한다. (너무 복잡해서 derivation 생략) 우리는 pytorch와 같은 framework의 도움을 받아서 구한다. ","date":"2021-11-29","objectID":"/prml-chap06-2/:4:6","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Gaussian Process Classifier 아래와 같이 일반적인 logistic regression과 거의 동일하다. Gaussian process classifier : sigmoid function + Gaussian process Gaussian process : $f(x;\\theta)$ Gaussian process classifier : $y=\\sigma (f(x;\\theta))$ if $t \\in {0,1}$, objective function to optimize : $$P(t | \\theta) = \\sigma (f(x;\\theta))^t (1-\\sigma (f(x;\\theta)))^{1-t}$$ ","date":"2021-11-29","objectID":"/prml-chap06-2/:5:0","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"PRML에서 Naive bayes 와 Logistic regression에 대해 공부하였는데 이 둘의 관계에 대해 간단히 정리해보고자 한다. (문일철 교수님의 강의에 대해 정리하였습니다.) 몇 가지 가정(constraint)가 더해지면 Naive bayes와 Logistic regression이 같아진다. ","date":"2021-11-26","objectID":"/prml-chap04-3/:0:0","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (3)","uri":"/prml-chap04-3/"},{"categories":["PRML"],"content":"Gaussian Naive Bayes Naive Bayes에 대해서는 이전에 공부하였다. 이번에는 거기에 조금 더 추가하여 각 conditional distribution들이 Gaussian distribution이라고 가정해보자. $$f_{NB} = \\arg\\max_{Y=y}P(Y=y)\\prod_{i=1}^{D}P(X_i=x_i|Y=y)$$ $$P(Y=k) = \\pi_k$$ $$P(X_i=x_i|Y=y) = \\frac{1}{c \\sigma_k^i } \\exp(- \\frac{1}{2}(\\frac{x_i - \\mu_k^i}{\\sigma_k^i})^2)$$ 이제 Naive bayes classifier이 Logistic regression의 형태가 되는 과정을 살펴볼 것이다. Logistic regression : $P(Y=k | X)$ Naive Bayes : $\\frac{P(X|Y=k)P(Y=k)}{P(X)}$ generative 방법의 Naive bayes로 부터 Discriminative한 Logistic regression으로 가보자 $$ = \\frac{p(Y=k)\\prod_{i=1}^D P(X_i|Y=y)}{p(Y=k)\\prod_{i=1}^D P(X_i|Y=k) + p(Y=k^C)\\prod_{i=1}^D P(X_i|Y=k^C)}$$ $$= 1/[1 + \\frac{\\pi_2 \\prod \\frac{1}{c \\sigma_{not;k}^i } \\exp(- \\frac{1}{2}(\\frac{x_i - \\mu_{\\text{not};k}^i}{\\sigma_{\\text{not};k}^i})^2) }{\\pi_1 \\prod \\frac{1}{c \\sigma_{k}^i } \\exp(- \\frac{1}{2}(\\frac{x_i - \\mu_{k}^i}{\\sigma_{k}^i})^2) }]$$ 여기서 $\\sigma_{not ; k} = \\sigma_{k}= \\sigma$라고 가정하면 $$=1/[1+\\frac{\\pi_2 \\prod \\exp(- \\frac{1}{2}(\\frac{x_i - \\mu_{not;k}^i}{\\sigma^i})^2) }{\\pi_1 \\prod \\exp(- \\frac{1}{2}(\\frac{x_i - \\mu_{k}^i}{\\sigma^i})^2) }] $$ $$ = 1/[1+exp(-\\frac{1}{2 {\\sigma^i}^2} \\sum { 2(\\mu_{not;k}^i-\\mu_k^i)x_i + {\\mu_{not; k}^i}^2 - {\\mu_k^i}^2 + \\log\\pi_2 - \\log\\pi_1 }] $$ 최종식을 보면 sigmoid function에 $w^T x$가 들어가있는 형태이다. 즉, Logistic regression이 되는 것이다. Naive Bayes의 conditional independent 가정 conditional한 상황에서 각 feature들이 Gaussian이고 분산이 같다는 가정 ","date":"2021-11-26","objectID":"/prml-chap04-3/:1:0","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (3)","uri":"/prml-chap04-3/"},{"categories":["PRML"],"content":"Classification에 대해 알아보자. ","date":"2021-11-26","objectID":"/prml-chap04-2/:0:0","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (2)","uri":"/prml-chap04-2/"},{"categories":["PRML"],"content":"4.3 Probabilistic Discriminative Models 이전과 다르게 parameter 추정을 $p(C_k|x)$에서 Maximum likelihood 를 이용하여 directly 하고자 한다. 이전에 본 generative한 방법에 비해 parameter가 더 적다 class-conditional density 가정이 잘못되면 성능이 좋지 않을 수 있다 ","date":"2021-11-26","objectID":"/prml-chap04-2/:1:0","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (2)","uri":"/prml-chap04-2/"},{"categories":["PRML"],"content":"4.3.1 Fixed basis functions 이제부터는 basis function $\\phi ({\\bf x})$을 사용할 것이다. basis function이 비선형이라 decision boudary는 original space에 linear하지 않을 것이다. basis function에는 $\\phi ({\\bf x})=1$ bias를 기본적으로 넣는다. original이 아닌 basis function을 사용했다고 항상 결과가 좋은 것은 아니다. ","date":"2021-11-26","objectID":"/prml-chap04-2/:1:1","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (2)","uri":"/prml-chap04-2/"},{"categories":["PRML"],"content":"4.3.2 Logistic regression 2-class의 경우로 시작해보자. 이전에 공부했듯이 일반적인 가정하에서 posterior는 sigmoid에 linear function of $\\phi$ (feature vector) 가 들어간 형태이다. $$p(C_1 | \\phi) = y(\\phi) = \\sigma ({\\bf w}^T \\phi)$$ logistic regression 의 장점 (2 class) M 차원이라고 가정하면 M개의 parameter가 있을 것이다. 반면에 generative한 상황을 생각하면 Gaussian class conditional density 의 경우 2M개의 평균, M(M+1) / 2개의 covariance matrix, prior 까지 총 M(M+5)/2+1 개의 parameter가 필요하다. interpretable하다. parameter estimation에 있어 computationally efficient 하다. multiclass도 가능하다. 단점 prediction performance가 좋은 편은 아니다. basis가 fixed되어 있다. likelihood로 parameter를 추정하는 과정을 살펴보자. Given : $D = [({\\bf x}_1,y_1),({\\bf x}_2,y_2),..,({\\bf x}_n,y_n)]$ model : $t_i \\sim^{iid} \\text{Bern}[\\sigma({\\bf w}^T \\phi({\\bf x}_i))]$ $$y_n = p(C_1 | \\phi_n)=\\sigma({\\bf w}^T \\phi({\\bf x}_n))$$ $$p(\\textbf{t}|{\\bf w}) = \\prod_{n=1}^{N}{y_n^{t_n}(1-y_n)^{1-t_n}}$$ $\\textbf{t} = (t_1,…t_N)^T$ : true target cross-entropy error function : $$E({\\bf w}) = - \\ln p(\\textbf{t} | {\\bf w}) = - \\sum{ { t_n \\log y_n + (1-t_n)\\log(1-y_n) } }$$ ${\\bf w}$에 대해 미분하면 $$\\bigtriangledown E({\\bf w}) = \\sum_{n=1}^{N}{(y_n - t_n)\\phi_n}$$ 이를 구하는 방법은 chain rule을 사용한다. 아래의 값들을 곱하면 위의 식이 나온다. $$\\frac{\\partial E}{\\partial y_n} = \\frac{1-t_n}{1-y_n} - \\frac{t_n}{y_n} = \\frac{y_n-t_n}{y_n(1-y_n)}$$ $$\\frac{\\partial y_n}{\\partial a_n} = \\frac{\\partial \\sigma(a_n)}{\\partial a_n} = \\sigma(a_n)(1-\\sigma(a_n)) = y_n(1-y_n)$$ $$ \\frac{\\partial a_n}{\\partial {\\bf w}} = \\phi_n$$ 이전에 linear regression과는 다르게 MLE가 closed form으로 존재하지 않는다. 따라서 approximation하는 방법이 필요하다. 이를 Gradient descent 방법을 통해 답을 구할 수도 있다. 하지만 뒤에서는 약간 다른 방법으로 해결해본다. (전통적인 통계방법) ","date":"2021-11-26","objectID":"/prml-chap04-2/:1:2","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (2)","uri":"/prml-chap04-2/"},{"categories":["PRML"],"content":"4.3.3 Iterative reweighted least squares +일단은 교재의 내용을 보기 전에 이해를 돕기 위해 추가 설명을 한다. 우리는 logL를 미분했을 때, 이를 0으로 만드는 MLE를 찾고싶다. $g'(x)$ 는 미분가능 $g''(x) \\neq 0$ 위의 조건을 만족하는 경우 taylor expansion을 이용하여 (1차 근사) $$0 = g'(x) \\approx g'(x^{t}) + (x-x^t)g''(x^t)$$ 이를 정리하면 $$x = x^t - \\frac{g'(x^t)}{g''(x^t)}$$ 이제 교재의 내용을 살펴보자. logisitc regression은 sigmoid function의 non-linearlity 때문에 closed-form의 해를 구할 수 없다. 그래서 우리는 error function의 최소화하는 방법으로 Newton-Raphson iterative opimization algorithm을 사용한다. $${\\bf w}^{new} = {\\bf w}^{old} - {\\bf H}^{-1} \\bigtriangledown E({\\bf w})$$ ${\\bf H}$ : hessian matrix whose elements comprise the second derivatives of $E({\\bf w})$ with respect to the component of ${\\bf w}$ $$\\bigtriangledown E({\\bf w}) = \\sum_{n=1}^{N}{(y_n - t_n)\\phi_n} = \\Phi ^T (\\textbf{y}-\\textbf{t})$$ $${\\bf H} = \\bigtriangledown \\bigtriangledown E({\\bf w}) = \\sum_{n=1}^{N}{y_n(1-y_n)\\phi_n \\phi_n^T} = \\Phi^T\\textbf{R}\\Phi$$ $\\Phi^T\\textbf{R}^{1/2} \\textbf{R}^{1/2} \\Phi =(\\textbf{R}^{1/2} \\Phi)^T (\\textbf{R}^{1/2} \\Phi)$ 이기에 positive semi definite이고 이를 통해 $E({\\bf w})$가 convex하다는 것을 알 수 있다. $\\textbf{R}$ : N*N diagonal matrix with elements $R_{nn} = y_n(1-y_n)$ $y_n$의 식이므로 parameter ${\\bf w}$에 dependent하다. 따라서 ${\\bf R}$에 대해서도 iterative하게 업데이트가 필요하다. 아래처럼 iterative하게 parameter를 업데이트 한다. $${\\bf w}^{(new)} = {\\bf w}^{(old)} - (\\Phi^T{\\bf R}\\Phi)^{-1}\\Phi^T({\\bf y}-{\\bf t})$$ $$= (\\Phi^T{\\bf R}\\Phi)^{-1}\\{\\Phi^T{\\bf R}\\Phi{\\bf w}^{(old)}-\\Phi^T({\\bf y}-{\\bf t})\\}$$ $$= (\\Phi^T{\\bf R}\\Phi)^{-1}\\Phi^T{\\bf R}{\\bf z}$$ $${\\bf z} = \\Phi{\\bf w}^{(old)} - {\\bf R}^{-1}({\\bf y}-{\\bf t})$$ 마지막 줄을 보면 이 형태는 weighted least-square 문제에서의 normal equation의 형태이다. 하지만 ${\\bf R}$이 상수가 아니기에 iterative하게 답을 구해야 하고 이러한 이유로 iterative reweighted least square 라고 부른다. ${\\bf R}$의 대각성분을 variance라고 해석할 수도 있다. 대각성분이 $y_n(1-y_n)$ 인데 이는 $t_n$의 variance이기 때문이다. ","date":"2021-11-26","objectID":"/prml-chap04-2/:1:3","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (2)","uri":"/prml-chap04-2/"},{"categories":["PRML"],"content":"4.3.4 Multiclass logistic regression 위에서 본 binary와 똑같이 할 수 있다. multiclass에서는 softmax function을 이용한다. $$p(C_k|\\phi) = y_k(\\phi) = \\frac{\\exp(a_k)}{\\sum_j \\exp(a_j)}$$ likelihood function을 구하면 $$p({\\bf T}|{\\bf w} _ 1,…{\\bf w} _ K) = \\prod_{n=1}^{N}\\prod_{k=1}^{K} p(C_k|\\phi_n)^{t_{nk}} = \\prod_{n=1}^{N}\\prod_{k=1}^{K}y_{nk}^{t_{nk}}$$ negative log를 취하면 $$E({\\bf w} _ 1, …, {\\bf w} _ K) = -\\ln p({\\bf T}|{\\bf w} _ 1, …,{\\bf w} _ K) = - \\sum_{n=1}^{N} \\sum_{k=1}^{K} t_{nk} \\ln(y_{nk})$$ 똑같이 미분을 취하고 Gradient descent나 IRLS 방법을 통해 parameter를 추정한다. $$\\nabla_{ {\\bf w} _ j } E({\\bf w} _ 1, …, {\\bf w} _ K) = \\sum_{n=1}^{N} (y _ {nj} - t _ {nj}) \\phi_n $$ ","date":"2021-11-26","objectID":"/prml-chap04-2/:1:4","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (2)","uri":"/prml-chap04-2/"},{"categories":["PRML"],"content":"4.3.5 Probit regression 이전과 마찬가지로 generalized linear model의 형태 $$p(t=1|a)=f(a)=f({\\bf w}^T \\phi)$$ 를 유지하지만 조금 다른 activation function을 알아보자. link function으로 noisy threshold model을 생각해보면 $t_n = 1 \\text{ if } a_n\\ge \\theta $ $t_n=0 \\text{ otherwise}$ $\\theta$는 random variable이고 probability density가 $p(\\theta)$라고 하자. 이에 따라 activation function을 CDF형태 $$f(a) = \\int_{-\\infty}^{a}p(\\theta)d\\theta$$ 로 표현할 수 있다. probability density를 $N(0,1)$로 가정하면 $$\\Phi(a) = \\int_{-\\infty}^{a}N(0, 1)d\\theta $$ 이고 이를 probit function이라고 한다. 모양은 sigmoid function과 거의 유사하다. 이를 모델에서 사용할 때는 약간 다른 모습을 이용한다. (계산의 편리함 때문인듯) erf function 은 $$erf(a) = \\frac{2}{\\sqrt{\\pi}} \\int_{0}^{a} \\exp(-\\theta^2) d\\theta$$ 이를 통해 탄생한 generalized linear model을 probit regression 이라고 한다. $$\\Phi(a) = \\frac{1}{2} \\{1+erf\\left(\\frac{a}{\\sqrt{2}}\\right)\\}$$ probit은 뒤에 나올 Bayesian logistic regression에서 사용된다. logistic, probit regression 모두 outlier에 취약한 편이다. 근데 probit은 $exp(-x^2)$이 있어서 더 취약하다. data가 mislabelling된 경우, 새로운 probability $\\epsilon$을 추가하여 사용할 수 있다. $$p(t|{\\bf x}) = (1-\\epsilon)\\sigma({\\bf x}) + \\epsilon(1-\\sigma({\\bf x})) = \\epsilon + (1-2\\epsilon)\\sigma({\\bf x})$$ ","date":"2021-11-26","objectID":"/prml-chap04-2/:1:5","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (2)","uri":"/prml-chap04-2/"},{"categories":["PRML"],"content":"4.4 The Laplace Approximation 4.5장에서 logistic regression에 Bayesian 방법을 사용하고자 한다. 근데 ${\\bf w}$의 posterior가 더 이상 Gaussian이 아니기 때문에 integrate하기가 어렵다. 따라서 특정 범위에 있는 함수를 Gaussian으로 approximation하는 방법을 이용하고자 한다. 먼저 single variable의 경우부터 살펴보자. Suppose the distribution $p(z)$ is defined by $$p(z) = \\frac{1}{Z}f(z),;; Z = \\int f(z)dz$$ 우리의 목표는 $p(z)$의 mode를 중앙(평균)으로 갖는 Gaussian distribution을 approximation하는 것이다. 먼저, mode를 찾아야한다. $$p'(z_0) = 0$$ Taylor expansion $$\\ln f(z) \\simeq \\ln f(z_0) - \\frac{1}{2}A(z-z_0)^2$$ $$A=-\\left.\\dfrac{d^2}{dz^2}\\ln f(z)\\right|_ {z=z_0} $$ 따라서 $$f(z) \\simeq f(z_0) \\exp { - \\frac{A}{2}(z-z_0)^2}$$ $$q(z) = (\\frac{A}{2\\pi})^{1/2} \\exp { -\\frac{A}{2}(z-z_0)^2 }$$ 우리는 $p(z)$를 approximate한 Gaussian $q(z)$를 찾을 수 있다! 이 과정이 Laplace approximation 이다. Gaussian approximation에서 ($f(z)$를 두 번 미분하여 $z_0$를 대입) precision $A$는 양수이다. 따라서 $z_0$는 local maximum이다. 이제 다차원의 형태로 살펴보자. Hessian Matrix $\\textbf{A} = - \\bigtriangledown \\bigtriangledown \\ln f(\\textbf{z}_0)$ $f(\\textbf{z}) \\simeq f(\\textbf{z}_0) \\exp { -\\frac{1}{2} (\\textbf{z} - \\textbf{z}_0)^T \\textbf{A} (\\textbf{z}-\\textbf{z}_0) }$ $$q({\\bf z}) = \\dfrac{|{\\bf A}|^{1/2}}{(2\\pi)^{M/2}}\\exp\\{-\\dfrac{1}{2}({\\bf z}-{\\bf z}_0)^T{\\bf A}({\\bf z}-{\\bf z}_0)\\} = N( {\\bf z}_0, {\\bf A}^{-1})$$ Laplace approximation 특징 Mutimodal인 distribution은 다양한 Laplace approximation이 생길 수 있다. CLT에 의해 Laplace approximation은 data가 많을수록 좋다. 위에서 알 수 있는이 $Z$에 대해 알 필요가 없다. Gaussian에 기반하므로 실수 변수에만 사용이 가능하다. global한 특징을 잡기 어렵다. ","date":"2021-11-26","objectID":"/prml-chap04-2/:2:0","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (2)","uri":"/prml-chap04-2/"},{"categories":["PRML"],"content":"4.4.1 Model comparison and BIC normalization constraint $Z$에 대해 approximation해보자. $$Z = \\int f({\\bf z})d{\\bf z} \\simeq f({\\bf z}_0)\\int\\exp\\{\\dfrac{1}{2}({\\bf z}-{\\bf z}_0)^T{\\bf A}({\\bf z}-{\\bf z}_0)\\}d{\\bf z}=f({\\bf z}_0)\\dfrac{(2\\pi)^{M/2}}{|{\\bf A}|^{1/2}}$$ 우리는 이 결과를 통해 이전에 공부했던 Bayesian model comparison에서 model evidence를 approximation해볼 것이다. model evidence $p(D|M_i)$ $M_i$ 생략 $$p(D)=\\int p(D|{\\pmb \\theta})p({\\pmb \\theta})d{\\pmb \\theta}$$ 아래와 같이 정의하고 우리는 model evidence를 approximation하면 $f({\\pmb \\theta}) = p(D|{\\pmb \\theta})p({\\pmb \\theta})$ $Z = p(D)$ $$\\ln p(D)\\simeq \\ln p(D|{\\pmb \\theta} _ {MAP}) + \\ln p({\\pmb \\theta} _ {MAP}) + \\dfrac{M}{2}\\ln(2\\pi) - \\dfrac{1}{2}\\ln|{\\bf A}| $$ 첫번째 term은 log likelihood evaluated using the optimized parameters 두번째 term부터 마지막 term까지 Occam factor 라고 부른다. penalizes model complexity ${\\pmb \\theta}_{MAP}$ : mode of posterior distribution ${\\bf A}$ : Hessian matrix $${\\bf A} = - \\nabla\\nabla p(D|{\\pmb \\theta} _ {MAP})p({\\pmb \\theta} _ {MAP}) = -\\nabla\\nabla\\ln p({\\pmb \\theta} _ {MAP}|D)$$ model evidence를 approximation한 식에서 Gaussian prior가 broad하고 Hessian이 full rank이면 우리는 해당 식을 더 간단하게 (의미없는 상수 생략) $$\\ln p(D) \\simeq \\ln p(D|{\\bf \\theta}_{MAP}) - \\frac{1}{2}M\\ln N$$ 이는 BIC(Baysian Information Criterion) 이다. $M$은 parameter의 갯수, $N$은 data의 수를 의미한다. AIC보다 더 간단한 모델을 추구한다. BIC를 쉽게 계산할 수 있지만 full rank라는 가정이 만족하기 쉽지 않아서 한계가 존재한다. ","date":"2021-11-26","objectID":"/prml-chap04-2/:2:1","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (2)","uri":"/prml-chap04-2/"},{"categories":["PRML"],"content":"4.5 Bayesian Logistic Regression Logistic regression에 Bayesian적으로 접근해보자. ","date":"2021-11-26","objectID":"/prml-chap04-2/:3:0","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (2)","uri":"/prml-chap04-2/"},{"categories":["PRML"],"content":"4.5.1 Laplace approximation 일단 prior는 Gaussian으로 가정한다. $$p({\\bf w}) = N( \\textbf{m}_0 , \\textbf{S}_0)$$ 이제 posterior를 구해보자. $$p(\\textbf{w}| \\textbf{t}) \\propto p(\\textbf{w})p(\\textbf{t}|\\textbf{w})$$ 양변에 log를 취하면 $$\\ln p(\\textbf{w} | \\textbf{t}) = - \\frac{1}{2}(\\textbf{w}-\\textbf{m} _ 0)^T \\textbf{S} _ 0^{-1} (\\textbf{w} - \\textbf{m} _ 0 )$$ $$+ \\sum_{n=1}^{N}{\\{ t_n \\ln y_n + (1-t_n)\\ln (1-y_n) \\}+ const}$$ posterior에 대한 Gaussian approximation하였다고 가정하자. maximize하는 parameter를 ${\\bf w}_{MAP}$라고 하고 covariance는 $${\\bf S}_N^{-1} = -\\nabla\\nabla \\ln p({\\bf w}|{\\bf t}) = {\\bf S} _ 0^{-1} + \\sum _ {n=1}^{N} y_n(1-y_n)\\phi_n\\phi_n^T$$ 따라서 Gaussian approximation한 posterior distribution의 form은 $$q(\\textbf{w}) = N(\\textbf{w}_{MAP} , \\textbf{S}_N)$$ 이제 approximation하여 구한 posterior로 Predictive를 구해보자. ","date":"2021-11-26","objectID":"/prml-chap04-2/:3:1","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (2)","uri":"/prml-chap04-2/"},{"categories":["PRML"],"content":"4.5.2 Predictive distribution 2-class의 경우라고 가정하자. predictive distribution은 $$p(C_1 | \\phi, \\textbf{t} ) = \\int p(C_1 | \\phi, \\textbf{w})p(\\textbf{w} | \\textbf{t}) \\simeq \\int \\sigma (\\textbf{w}^T\\phi) q(\\textbf{w})d\\textbf{w}$$ Funtion $\\sigma ({\\bf w}^T \\phi)$ depends on w only through tis projection onto $\\phi$ (교재에 설명이 다소 빈약) 그냥 아래처럼 변형 $$\\sigma({\\bf w}^T\\phi) = \\int \\delta(a-{\\bf w}^T\\phi)\\sigma(a)da$$ 이를 predictive distribution에 대입하면 $$\\int \\sigma({\\bf w}^T\\phi)q({\\bf w})d{\\bf w} = \\int \\sigma(a)p(a)da$$ $$p(a) = \\int \\delta(a-{\\bf w}^T\\phi)q({\\bf w})d{\\bf w}$$ $p(a)$는 Gaussian distribution이 되는데 delta function ($\\delta$) imposes a linear constraint on ${\\bf w}$이고 $q({\\bf w})$ 는 정의에 의해 Gaussian distribution Gaussian의 marginal도 Gaussian $$\\mu_a = E[a] = \\int p(a)a da = \\int q({\\bf w}){\\bf w}^T \\phi d{\\bf w} = {\\bf w}_{MAP}^T\\phi$$ $$\\sigma_a^2 = var[a] = \\int p(a){ a^2 - E[a]^2 }da $$ $$= \\int q({\\bf w}) {({\\bf w}^T\\phi)^2 - ({\\bf m}_N^T\\phi)^2 }d{\\bf w} = \\phi^T{\\bf S}_N\\phi$$ 따라서 predictive distribution은 $$p(C_1|{\\bf t}) = \\int \\sigma(a)p(a)da = \\int \\sigma(a)N(\\mu_a, \\sigma_a^2)da$$ sigmoid-gaussian을 analytically 구할 수 없기 때문에 이 또한 approximation을 해야한다. sigmoid와 비슷한 모양을 가지는 Probit function을 이용한다. ($\\sigma(a) \\approx \\Phi(\\lambda a) ,\\lambda^2 = \\pi / 8$) probit function을 이용한 approximation의 장점은 Gaussian과 만나서 analytically 또 probit function으로 아래와 같은 결과가 나온다. $$\\int \\Phi (\\lambda a )N ( \\mu, \\sigma^2)da = \\Phi (\\frac{\\mu}{( \\lambda^{-2}+\\sigma^2 ) ^{1/2}})$$ $$\\int \\sigma(a) N(\\mu,\\sigma^2)da \\simeq \\sigma (k(\\sigma^2)\\mu)$$ $k(\\sigma^2) = (1+\\pi \\sigma^2 / 8)^{-1/2}$ 최종 결과 approximate predictive distribution은 $$p(C_1 | \\phi, \\textbf{t}) = \\sigma (k(\\sigma^2_a)\\mu_a)$$ ","date":"2021-11-26","objectID":"/prml-chap04-2/:3:2","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (2)","uri":"/prml-chap04-2/"},{"categories":["PRML"],"content":"Classification에 대해 알아보자. input space는 decision regions 로 나눠지는데 이는 decision boundaries(decision surfaces) 에 의해 나눠진다. 이번 챕터에서는 분류 선형모델에 대해 공부하는데 이는 decision surfaces가 input x의 linear function 이라는 것을 의미한다. D차원의 input space가 D-1 차원의 hyperplane으로 나눠지는 것이다. 크게 3가지로 나누어서 공부한다. Discriminant function generative Discriminative classification에서는 discrete class labels 이나 각 class가 될 probability를 target으로 예측한다. 후자의 경우 (0,1) 사이의 값을 가질 것이다. 따라서 우리는 linear function of ${\\bf w}$를 nonlinear function을 이용하여 transform한다. $$y({\\bf x}) = f({\\bf w}^T {\\bf x} + w_0)$$ machine learning에서는 $f$를 activation function 이라고 부른다. 통계학에서는 inverse of link function 으로 부른다. 따라서 이전에 봤던 regression model과는 다르게 더이상 parameter에 linear하지 않는 성질을 가진다. ","date":"2021-11-26","objectID":"/prml-chap04-1/:0:0","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (1)","uri":"/prml-chap04-1/"},{"categories":["PRML"],"content":"4.1 Discriminant Functions discriminant : a function that takes an input vector ${\\bf x}$ and assigns it to one of $K$ class 이번 chapter에서는 linear discriminant ( : decision surfaces are hyperplane) 로 한정지어 공부할 것이다. ","date":"2021-11-26","objectID":"/prml-chap04-1/:1:0","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (1)","uri":"/prml-chap04-1/"},{"categories":["PRML"],"content":"4.1.1 two classes 가장 간단한 linear discriminant function을 보면 $$y({\\bf x}) = {\\bf w}^T {\\bf x} + w_0$$ $y({\\bf x}) \\ge 0$ 이면 class 1이고 반대면 class 2 이다. 따라서 decision boundary는 $y({\\bf x}) = 0$ 이고 $(D-1)$차원의 hyperplane이다. decision surface 위에 두 점 ${\\bf x}_A , {\\bf x}_B$ 이 있다고 가정하면 ${\\bf w}^T({\\bf x}_A - {\\bf x}_B)=0$ 이므로 vector ${\\bf w}$는 decision surface에 있는 모든 점들과 orthogonal하다. 이는 ${\\bf w}$가 decision surface의 orientation을 결정한다는 의미이다. 똑같이 ${\\bf x}$가 decision surface 위의 점이라고 하고 원점과 decision surface의 거리를 계산하면 아래와 같다. 여기서 ${\\bf w}_0$는 decision surface의 위치를 결정한다. $$\\frac{\\textbf{w}^T \\textbf{x}}{\\left|| \\textbf{w} \\right||} = - \\frac{ \\textbf{w}_0}{\\left|| \\textbf{w} \\right||}$$ ","date":"2021-11-26","objectID":"/prml-chap04-1/:1:1","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (1)","uri":"/prml-chap04-1/"},{"categories":["PRML"],"content":"4.1.2 Multiple classes $K$ 가 2보다 큰 multiple class를 분류하는 상황을 생각해보자. linear discriminant로 분류하는 방법은 크게 두 가지로 나눌 수 있다. one vs the rest one vs one 두 방법 모두 class를 결정하는데 있어 애매한 상황이 발생한다. hyperplane이라는 제약때문에 그 어떤 class에도 속하지 못하는 지역이 발생한다. (PRML figure 4.2 에 잘 보여줌) 이를 해결하기 위해 아래와 같은 $K$개의 linear function을 $K$-class discriminant로 사용한다. $$y_k(x) = w^T_kx + w_{k0}$$ $y_k({\\bf x}) \\ge y_j ({\\bf x})$ 인 경우, ${\\bf x}$는 $k$로 분류한다. 즉, 큰 값을 가지는 쪽으로! 여기서 만들어지는 decision region은 항상 singly connected and convex하다. decision region $R_k$에 들어있는 두 점 ${\\bf x}_A, {\\bf x}_B$ 이 두 점을 연결한 선 위에 점 $\\hat{ {\\bf x} }$이 있다고 가정하자. 이를 표현하면 ($0 \\le \\lambda \\le 1$) $$\\hat{\\bf x}=\\lambda{\\bf x}_A + (1-\\lambda){\\bf x}_B$$ 따라서 discriminant function은 다음을 만족한다. $$y_k(\\hat{ {\\bf x} })={\\lambda}y_k({\\bf x}_A) + (1-\\lambda)y_k({\\bf x}_B) $$ $y_k({\\bf x}_A) \u003e y_j({\\bf x}_A) , y_k({\\bf x}_B) \u003e y_j({\\bf x}_B)$ 을 만족하기에 $y_k({\\hat {\\bf x}}) \u003e y_j({\\hat {\\bf x}})$ 도 성립한다. 따라서, ${\\hat {\\bf x}}$은 항상 $R_k$에 속한다. 이제 linear discriminant function의 parameter를 학습하는 방법에 대해 배울 것이다. least square Fisher’s linear discriminant perceptron algorithm ","date":"2021-11-26","objectID":"/prml-chap04-1/:1:2","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (1)","uri":"/prml-chap04-1/"},{"categories":["PRML"],"content":"4.1.3 Least squares for classification 이전의 sum of squares error function을 그대로 이용한다. target은 1-of-K binary coding하여 vector ${\\bf t}$ 이다. (해당하는 class는 1 나머지 class는 0으로 표현) 각 class 마다 $y_k({\\bf x}) = {\\bf w}_k^T {\\bf x} + w _ {k0}$ , 이를 합쳐서 표현하면 $$\\textbf{y} (\\textbf{x}) = \\widetilde{ \\textbf{W} }^T \\widetilde{ {\\bf x} }$$ $\\widetilde{\\textbf{W}}$ : 각 컬럼이 $\\widetilde{\\textbf{w}}_k = ({\\bf w} _ {k0}, {\\bf w}_k^T)$ $\\widetilde{\\textbf{W}}_k^T \\widetilde{ {\\bf x}}$가 가장 큰 값(class)에 input ${\\bf x}$를 할당한다. normal equation으로 parameter를 구하면 $$\\widetilde{\\textbf{W}}=(\\widetilde{\\textbf{W}}^T \\widetilde{\\textbf{W}})^{-1}\\widetilde{\\textbf{W}}^T\\widetilde{\\textbf{T}}=\\widetilde{\\textbf{W}}^{\\dagger}\\widetilde{\\textbf{T}}$$ 특징 exact closed-form의 solution이 나온다. output이 확률의 범위 (0,1) 을 넘어가는 경우가 존재한다. (우리는 output이 확률값이길 원한다) least square의 단점인 outlier에 취약하다. input data에 따라서 decision이 급변하다. ","date":"2021-11-26","objectID":"/prml-chap04-1/:1:3","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (1)","uri":"/prml-chap04-1/"},{"categories":["PRML"],"content":"4.1.4 Fisher’s linear discriminant 차원 축소의 역할로 많이 쓰이는데 classification으로도 사용가능하다. 일단은 2-class의 경우만 고려해보자. $D$ 차원의 input vector $\\textbf{W}$를 1차원에 project한다고 생각하자. $$y = \\textbf{w}^T \\textbf{x}$$ 이렇게 할 수 있다. 하지만 overlapping되니까 class seperation을 최대화하는 projection을 하는 것이다. 각 class의 평균을 $\\textbf{m}_1, \\textbf{m}_2$이라고 하면 아래의 값을 최대로 하는 ${\\bf w}$를 찾아야 한다. ${\\bf m_1}=1 / N_1\\sum_{n \\in C_1}\\textbf{x}_n$ ${\\bf m_2}=1 / N_2\\sum_{n \\in C_2}\\textbf{x}_n$ $$m_2 - m_1 = \\textbf{w}^T (\\textbf{m}_1 - \\textbf{m}_2),\\quad where; m_k = \\textbf{w}^T \\textbf{m}_k$$ ${\\bf w}$를 계속 키우면 커지기 때문에 제약식 $\\sum {\\bf w}_i^2 = 1$을 두고 라그랑지로 풀면 $${\\bf w} \\propto (\\textbf{m}_2 - \\textbf{m}_1)$$ 의 결론을 얻는다. 이에 추가적으로 Fisher는 within class의 varinace를 최소화 하고자 했다. 반면에 between class의 variance는 최대화 한다. class $C_k$의 within variance는 $y_n = {\\bf w}^T {\\bf x}_n$ $m_k = {\\bf w}^T {\\bf m}_k$ $$s_k^2=\\sum_{n \\in C_k}(y_n-m_k)^2$$ 전체 class의 within variance는 $s_1^2+s_2^2$ 이를 통해 Fisher criterion (ratio of the between-class variance to the within-class variance)은 $$J(\\textbf{w}) = \\frac{(m_2 - m_1)^2}{s_1^2+s_2^2}$$ Fisher criterion을 다시 쓰면 $$J(\\textbf{w}) = \\frac{\\textbf{w}^T {\\bf S}_B \\textbf{w}}{\\textbf{w}^T {\\bf S}_W \\textbf{w}}$$ $${\\bf S}_B = (\\textbf{m}_2 - \\textbf{m}_1)(\\textbf{m}_2 - \\textbf{m}_1)^T$$ 이 값은 between-class covariance matrix이다. $$\\textbf{S} _ W = \\sum_{n \\in C_1} (\\textbf{x} _ n - \\textbf{m} _ 1)(\\textbf{x} _ n - \\textbf{m} _ 1)^T + \\sum_{n \\in C_2} ({\\bf x}_n - \\textbf{m}_2)({\\bf x}_n-\\textbf{m}_2)^T$$ 이 값은 total within-class covariance matrix이다. w에 대해 미분하고 위의 값을 최대화하는 값을 찾으면 $\\textbf{w} \\propto {\\bf S}_W^{-1} (\\textbf{m}_2 - \\textbf{m}_1)$ . 이 결과를 Fisher’s linear discriminant 라고 한다. 1차원에 projection한 뒤에 특정 threshold값을 정해 classification할 수 있다. ","date":"2021-11-26","objectID":"/prml-chap04-1/:1:4","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (1)","uri":"/prml-chap04-1/"},{"categories":["PRML"],"content":"4.1.5 Relation to least squares Fisher criterion은 least square의 특별한 경우이다. target을 1-of-K encoding의 방법이 아닌 class 1은 $N / N_1$ class 2는 $-N / N_2$ 으로 encoding 하면 된다. 이렇게 한 뒤에 least square의 방법대로 parameter를 구하면 Fisher criterion이 나온다. (과정은 생략) ","date":"2021-11-26","objectID":"/prml-chap04-1/:1:5","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (1)","uri":"/prml-chap04-1/"},{"categories":["PRML"],"content":"4.1.6 Fisher’s discriminant for multiple classes skip ","date":"2021-11-26","objectID":"/prml-chap04-1/:1:6","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (1)","uri":"/prml-chap04-1/"},{"categories":["PRML"],"content":"4.1.7 The perceptron algorithm perceptron 특징 2 class에서만 사용가능하다. based on linear combination of fixed basis function target을 이전에는 주로 1,0 으로 했는데 여기서는 -1, 1 로 코딩한다. perceptron criterion (error function) $$E_p ({\\bf w}) = -\\sum_{n \\in M}{\\textbf{w}^T \\phi_n t_n}$$ $M$은 잘못분류한 케이스를 의미한다. 우리는 이 criterion을 최소화 하고자 한다. $\\textbf{w}^T \\phi_n \u003e 0$ 이면 1로 분류 $\\textbf{w}^T \\phi_n \u003c 0$ 이면 -1로 분류 따라서 분류를 잘못하면 ${\\textbf{w}^T \\phi_n t_n} \u003c 0$ 이고 error가 커지는 것이다. 위 perceptron criterion을 SGD로 iterative하게 계산하면 $${\\bf w}^{(\\tau+1)}={\\bf w}^{(\\tau)}-\\eta\\triangledown E_p({\\bf w})={\\bf w}^{(\\tau)}+\\eta\\phi_n{t_n}$$ ($\\eta$는 learning rate) 이다. 이를 쉽게 해석하면 분류가 맞으면 놔두고 틀리면 그 $\\phi_n$ 만큼 더하고 빼고 하는 것이다. 양변에 $-\\phi_n t_n$을 곱하면 에러가 줄어듬(parameter가 converge)을 알 수 있다. $$-{\\bf w}^{(\\tau+1)T}{\\phi}_n{t_n} = -{\\bf w}^{(\\tau)T}{\\phi_n}{t_n}-(\\phi_n{t_n})^T\\phi_n{t_n} \u003c -{\\bf w}^{(\\tau)T}\\phi_n{t_n}$$ perceptron convergence theorem training data set is linearly separable 하면 perceptron algorithm수렴한다 (반드시 해당하는 decision boundary를 찾을 수 있다) . 아니면 수렴이 안된다. 수렴하기 전까지 이게 non separable 문제인지 아니면 수렴이 천천히 되는 건지 파악하기 어렵다. ","date":"2021-11-26","objectID":"/prml-chap04-1/:1:7","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (1)","uri":"/prml-chap04-1/"},{"categories":["PRML"],"content":"4.2 Probabilistic Generative Models data의 분포에 대한 가정을 갖는 decision boundary에 대해 공부해보자. $p(x|C_k), p(C_k)$로 베이즈정리를 이용하여 posterior를 계산한다. (일단 binary classification의 경우) posterior probability for class 1 : $$p(C_1 | {\\bf x}) = \\frac{p({\\bf x}|C_1)p(C_1)}{p({\\bf x}|C_1)p(C_1)+p({\\bf x}|C_2)p(C_2)}$$ $$ = \\frac{1}{1+\\frac{p({\\bf x}|C_2)p(C_2)}{p({\\bf x}|C_1)p(C_1)}} = \\frac{1}{1+exp(-a) } = \\sigma (a)$$ $$\\text{where}\\; a = \\ln \\frac{p(x|C_1)p(C_1)}{p(x|C_2)p(C_2)}$$ $\\sigma (x) = \\frac{1}{1+exp(-x) }$ 이 식은 logistic sigmoid function 이다. 이의 inverse는 $x=\\ln (\\frac{\\sigma}{1-\\sigma})$ 이고 logit function이라고 한다. 이번에는 일반적인 경우에 대해 살펴보자. multi class의 경우 $$p(C_k | {\\bf x}) = \\frac{p({\\bf x}|C_k)p(C_k)}{\\sum p({\\bf x}|C_j)p(C_j)} = \\frac{exp(a_k)}{\\sum_j exp(a_j)}$$ $$\\text{where}\\; a_k = \\ln p({\\bf x}|C_k)p(C_k)$$ 이를 normalized exponential or softmax function 이라고 한다. ","date":"2021-11-26","objectID":"/prml-chap04-1/:2:0","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (1)","uri":"/prml-chap04-1/"},{"categories":["PRML"],"content":"4.2.1 Continuous inputs class-conditional density를 Gaussian이라고 가정하고 posterior를 살펴보자. 단 모든 class는 같은 covariance matrix를 가진다. (2-class) $$p({\\bf x}|C_k) = \\dfrac{1}{(2\\pi)^{D/2}|\\Sigma|^{1/2}}\\exp \\{-\\dfrac{1}{2}({\\bf x} - {\\pmb \\mu}_k)^T\\Sigma^{-1}({\\bf x} - {\\pmb \\mu}_k)\\} $$ 이므로 이를 이용해 위에서 구한 posterior를 계산하면 $a = \\ln \\frac{p(x|C_1)p(C_1)}{p(x|C_2)p(C_2)}$ $$p(C_1 | {\\bf x}) =\\sigma (a) = \\sigma ({\\bf w}^T {\\bf x} + w_0)$$ $${\\bf w} = \\Sigma^{-1}({\\pmb \\mu_1}-{\\pmb \\mu_2})$$ $$w_0 = -\\frac{1}{2}{\\pmb \\mu_1}^T\\Sigma^{-1}{\\pmb \\mu_1} + \\frac{1}{2}{\\pmb \\mu_2}^T\\Sigma^{-1}{\\pmb\\mu_2} + \\ln{\\frac{p(C_1)}{p(C_2)}}$$ 의 형태가 나온다. class-conditional density를 Gaussian이라고 가정하였기 때문에 logistic sigmoid안에서 ${\\bf x}$ 의 linear function의 형태가 나온다. K-class의 경우 $$a_k({\\bf x})=\\ln(p({\\bf x}|C_k)p(C_k)) = {\\bf w}^T_k {\\bf x}+w_0$$ $${\\bf w}_k = \\Sigma^{-1}{\\pmb \\mu}_k$$ $$w_{k0} = -\\frac{1}{2}{\\pmb \\mu}_{k}^{T} \\Sigma^{-1}{\\pmb \\mu}_k + \\ln p(C_k)$$ posterior의 decision boundary는 input space에 linear하다. (공분산이 동일하다는 가정하에서) 공분산을 각 class마다 다르다고 가정하면 우리는 quadratic function of ${\\bf x}$를 얻게 되고 이는 quadratic discriminant 이다. 이처럼 posterior probability는 $$p({\\bf x}|C_k) = f(\\text{linear of}\\;{\\bf x})$$ 의 형태가 된다. ","date":"2021-11-26","objectID":"/prml-chap04-1/:2:1","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (1)","uri":"/prml-chap04-1/"},{"categories":["PRML"],"content":"4.2.2 Maximum likelihood solution MLE를 통해 prameter들을 추정해보자. class-conditional에서 Gaussian을 가정하였는데 그에 해당하는 parameter들 이다. prior : $p(C_1) = \\pi , p(C_2) = 1- \\pi$ $p(x_n,C_1) = p(C_1)p({\\bf x}_n|C_1) = \\pi N({\\bf x}_n | {\\pmb \\mu}_1,{\\pmb \\Sigma})$ $p(x_n,C_2) = p(C_2)p({\\bf x}_n|C_2) =(1- \\pi) N({\\bf x}_n | {\\pmb \\mu}_2,{\\pmb \\Sigma})$ Class 1은 1, Class 2는 0 으로 target coding likelihood function : $$p(\\textbf{t} | \\pi, {\\pmb \\mu}_1,{ \\pmb \\mu}_2, {\\pmb \\Sigma} ) = \\prod [\\pi N({\\bf x}_n | {\\pmb \\mu}_1, {\\pmb \\Sigma})]^{t_n}[(1-\\pi)N({\\bf x}_n | {\\pmb \\mu}_2, {\\pmb \\Sigma})]^{1-t_n}$$ 이를 log 취하고 미분하여 MLE를 구하면 (K-class도 동일한 방법으로 구할 수 있다) $$\\pi = \\frac{1}{N} \\sum_{n=1}^{N}{t_n} = \\frac{N_1}{N_1 + N_2}$$ $${\\pmb \\mu} _ 1 = \\frac{1}{N_1} \\sum_{n=1}^{N}t_n {\\bf x} _ n, {\\pmb \\mu} _ 2 = \\frac{1}{N_2}\\sum_{n=1}^{N}(1-t_n){\\bf x}_n$$ $${\\pmb \\Sigma} = {\\bf S} = \\frac{N_1}{N}{\\bf S}_1 + \\frac{N_2}{N}{\\bf S}_2$$ ","date":"2021-11-26","objectID":"/prml-chap04-1/:2:2","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (1)","uri":"/prml-chap04-1/"},{"categories":["PRML"],"content":"4.2.3 Discrete features 각 input data feature가 2가지의 값을 갖는 discrete feature들이라고 가정해보자. 그러면 총 $2^D$의 경우 수가 생긴다. 이를 추정하기에는 너무 복잡하다. 따라서 naive bayes의 가정을 이용하면 $$p({\\bf x}|C_k) = \\prod_{i=1}^{D}\\mu_{ki}^{x_i}(1-\\mu_{ki})^{1-x_i} $$ $$a_k({\\bf x})=\\ln(p({\\bf x}|C_k)p(C_k))$$ $$a_k({\\bf x})=\\sum_{i=1}^{D}\\{x_i\\ln \\mu_{ki}+(1-x_i)\\ln(1-\\mu_{ki})\\}+\\ln p(C_k)$$ 이 또한 linear한 형태이다. ","date":"2021-11-26","objectID":"/prml-chap04-1/:2:3","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (1)","uri":"/prml-chap04-1/"},{"categories":["PRML"],"content":"4.2.4 Exponential Family 위에서 알 수 있듯이 input이 Gaussian이던 discrete이던지 우리에게 가장 중요한 posterior class probability는 generalized linear model과 sigmoid, softmax activation function에 의해 결정된다. 이러한 특징은 class-conditional density가 exponential family의 경우 해당한다. $$p({\\bf x};|\\lambda_k) = h({\\bf x})g(\\lambda_k)\\exp(\\lambda_k^T u({\\bf x})) $$ 여기서 제약을 위한 parameter $s$를 추가하고 (잘 이해못함) $$p({\\bf x};|\\lambda_k, s) = \\dfrac{1}{s}h\\left(\\dfrac{1}{s}{\\bf x}\\right)g\\left(\\lambda_k\\right)\\exp \\left(\\dfrac{1}{s}\\lambda_k^T u({\\bf x})\\right)$$ linear function을 구할 수 있다. $$a({\\bf x})=\\dfrac{1}{s}(\\lambda_1-\\lambda_2)^T{\\bf x}+\\ln g(\\lambda_1) - \\ln g(\\lambda_2) + \\ln p(C_1) - \\ln p(C_2)$$ $$a_k({\\bf x}) = \\dfrac{1}{s}\\lambda_k^T{\\bf x}+\\ln g(\\lambda_k) + \\ln p(C_k)$$ link function과 exp fam의 관계 EX) Bernoulli dist $$L(\\theta) = \\prod \\theta^{x_i}(1-\\theta)^{1-x_i}= \\exp {\\sum{x_i \\log \\theta}+ \\sum{(1-x_i)\\log (1-\\theta)} } $$ $$=\\exp { \\sum{x_i} \\log(\\frac{\\theta}{1-\\theta}) }(1-\\theta)^n$$ 위의 식에서 $\\log (\\frac{\\theta}{1-\\theta})$ 가 link function이다. $\\log (\\frac{\\theta}{1-\\theta}) = \\beta_0 + \\beta_1 x_1+…+\\beta_n x_n$ 이 이제 배울 logistic regression 이다. ","date":"2021-11-26","objectID":"/prml-chap04-1/:2:4","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (1)","uri":"/prml-chap04-1/"},{"categories":["PRML"],"content":"Regression에 대해 알아보자. ","date":"2021-11-26","objectID":"/prml-chap03-2/:0:0","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (2)","uri":"/prml-chap03-2/"},{"categories":["PRML"],"content":"3.3 Bayesian Linear Regression 이전에 우리는 maximum likelihood 방법을 통해 linear regression 의 parameter를 구하는 방법을 공부했다. 이는 몇 가지 특징(단점)이 있는데 MLE 는 overfitting의 위험이 있다. 적절한 model complexity를 정해야 한다. by basis function의 수 regularization coefficient 우리는 한정적인 dataset을 갖고 있기에 적절한 model complexity를 정하기 위해서는 cross validation과 같은 computationally expensive한 방법을 사용해야한다. 위와 같은 단점들을 해결하기 위해 우리는 Bayesian 방법론을 사용할 것이다. MAP는 uncertainty를 표현할 수 없기 때문에 distribution을 이용한다. ","date":"2021-11-26","objectID":"/prml-chap03-2/:1:0","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (2)","uri":"/prml-chap03-2/"},{"categories":["PRML"],"content":"3.3.1 Parameter distribution 이전에 likelihood function $p(t|{\\bf w})$ 이 Gaussian 이었다. 이에 대한 conjugate prior로 Gaussian을 가정한다. prior distribution은 $$p({\\bf w}) = N({\\bf m}_0, {\\bf S}_0) $$ likelihood function과 prior를 곱해 posterior를 계산하면 (계산과정은 생략, monk영상을 보면 된다) $$p({\\bf w}|{\\bf t}) = N({\\bf m}_N, {\\bf S}_N)$$ ${\\bf m}_N = {\\bf S}_N({\\bf S}_0^{-1} {\\bf m}_0 + \\beta { \\bf \\Phi}^T {\\bf t})$ ${\\bf S}_N^{-1} = {\\bf S}_0^{-1}+\\beta {\\bf \\Phi}^T {\\bf \\Phi}$ $\\beta$ : (target error term) noise precision parameter (assume known) Gaussian은 mean과 mode(최빈값)가 같은 값을 갖기 때문에 ${\\bf w}_{MAP} = {\\bf m}_N$ 이다. 만약 infinite broad prior인 경우 (${\\bf S}_0 = \\alpha^{-1}{\\bf I},\\alpha \\rightarrow 0$) 수식을 전개해보면 ${\\bf m}_N \\rightarrow {\\bf m} _ {ML}$ 반대로 $N \\rightarrow 0$ 이면 posterior 는 prior로 가까워진다. 복잡해 보이는 prior를 다소 간단한 형태로 정하면 $p({\\bf w}|\\alpha) = N(0, \\alpha^{-1}I)$ 으로 생각할 수 있다. 이 prior에서 posterior의 mean, precision은 $${\\bf m}_N = \\beta {\\bf S}_N {\\bf \\Phi}^T {\\bf t}$$ $${\\bf S}_N^{-1} = \\alpha {\\bf I} + \\beta {\\bf \\Phi}^T {\\bf \\Phi}$$ log of posterior distribution (log of likelihood function과 log of prior의 합) 은 $$\\ln p({\\bf w}|{\\bf t}) = -\\frac{\\beta}{2}\\sum_{n=1}^{N}{t_n-{\\bf w}^T\\phi({\\bf x}_n)}^2 - \\frac{\\alpha}{2}{\\bf w}^T{\\bf w}+const$$ 이는 결국 minimization of the sum of square with quadratic regulrarization($\\lambda = \\frac{\\alpha}{\\beta}$) 과 같은 수식이다. ","date":"2021-11-26","objectID":"/prml-chap03-2/:1:1","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (2)","uri":"/prml-chap03-2/"},{"categories":["PRML"],"content":"3.3.2 Predictive distribution 우리의 최종 목표는 predictive distribution 이다. $$p(t|{\\bf t}, \\alpha, \\beta) = \\int p(t|{\\bf w}, \\beta)p({\\bf w}|{\\bf t}, \\alpha, \\beta)d{\\bf w} $$ predictive distribution을 보면 target의 conditional distribution $p(t | w,\\beta)=N(t | y(w,x), \\beta^{-1})$ 와 weight parameter ${\\bf w}$의 posterior distribution으로 만들어졌다. 이를 토대로 정리하면 $$p(t|{\\bf t}, \\alpha, \\beta) = N({\\bf m}_N^T\\phi({\\bf x}), \\sigma_N^2({\\bf x})) $$ variance : $\\sigma_N^2({\\bf x}) = \\frac{1}{\\beta} + \\bf \\phi({\\bf x})^T {\\bf S}_N\\phi({\\bf x})$ 이 variance에서 첫번째 항은 data의 noise이고 (앞부분을 찾아보자) 뒷부분이 ${\\bf w}$의 uncertainty를 나타낸다. noise와 ${\\bf w}$ distribution은 independent하기에 두 값을 더한게 variance가 된것이다. N이 커질수록 posterior는 narrow해지므로 뒷부분은 0으로 간다. ","date":"2021-11-26","objectID":"/prml-chap03-2/:1:2","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (2)","uri":"/prml-chap03-2/"},{"categories":["PRML"],"content":"3.3.3 Equivalent kernel 위에 $w$에 대해 구한 값을 토대로 mean of predictive distribution은 $$y({\\bf x}, {\\bf m} _ N) = {\\bf m} _ N^T\\phi({\\bf x}) = \\beta \\phi({\\bf x})^T {\\bf S} _ N \\Phi^T {\\bf t} \\\\ = \\sum_{n=1}^N \\beta \\phi({\\bf x})^T {\\bf S}_N \\phi({\\bf x}_n)t_n $$ 특정 ${\\bf x}$에 대한 mean of predictive dist 은 결국 training set target t의 linear combination 이다. 이를 다르게 표현하면 $$y({\\bf x}, {\\bf m} _ N) = \\sum_{n=1}^N k({\\bf x}, {\\bf x}_n)t_n$$ $k({\\bf x}, {\\bf x}') = \\beta \\phi({\\bf x})^T {\\bf S}_N \\phi({\\bf x}')$ : 이 식을 smoother matrix or equvalent kernel 라고 부른다. 따라서 mean of predictive distribution at $x$ 은 $x$와 (비슷한)가까운 data에 해당하는 $t$에 높은 가중치를 준다. equvalent kernel에 대해서 covariance의 측면으로 살펴보자. $$cov[y({\\bf x}), y({\\bf x}')] = cov[\\phi({\\bf x})^T{\\bf w}, {\\bf w}^T\\phi({\\bf x}')] = \\phi({\\bf x})^T{\\bf S}_N\\phi({\\bf x}')=\\beta^{-1}k({\\bf x}, {\\bf x}') $$ equvalent kernel의 형태에서 근처의 points들의 predictive mean는 상관관계가 높다는 것을 알 수 있다. ","date":"2021-11-26","objectID":"/prml-chap03-2/:1:3","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (2)","uri":"/prml-chap03-2/"},{"categories":["PRML"],"content":"3.4 Bayesian Model Comparison Bayesian의 입장에서 model selection을 바라보고자 한다. 모델을 선택하는 과정에 있어서 확률적인 내용을 많이 사용한다. maximum likelihood와 관련한 overfitting 문제는 marginalizing over the model parameters instead of making point estimates of their values 로 해결 할 수 있다. 모델은 training data를 통해 바로 정할 수 있으므로 validation set이 필요없다. 따라서 모든 데이터를 학습시킬 수 있고 불필요한 검증과정을 없앨 수 있다. 이제 L개의 ${M_i}$ model이 있다고 하자. 이제 이 model들을 random variable으로 생각하고 model에 대한 uncertainty는 확률로 표현한다. $$p(M_i | D) \\propto p(M_i)p(D | M_i) $$ 일단 model에 대한 prior는 다 같다고 가정하자. 따라서 우리의 주 관심은 model evidence(=marginal likelihood) : $p(D/M_i)$ model을 이루는 parameter들이 marginalized out 되었기에 marginal likelihood라고도 부름 (뒷 부분에 나옴) Bayes factor ratio of model evidence s $p(D|M_i)p(D|M_j)$ model의 posterior를 알고 이를 이용하여 predictive distribution을 구하면 $$p(t|{\\bf x}, D) = \\sum_{i=1}^{L} p(t|{\\bf x}, M_i, D)p(M_i|D)$$ 이다. (mixture distribution의 모습) 이는 model posterior를 가중치로 하여 평균을 낸 것으로 볼 수 있다. 위와 같은 model averaging의 값과 가장 근사하는 좋은 model 하나를 찾고자 한다. 이를 model selection 이라고 한다. model evidence (${\\bf w}$는 model에 관한 parameter) 이를 sampling 측면에서 바라보면, marginal likelihood는 data set D를 생성하는 probability로 볼 수 있는데 여기서 D는 prior로 부터 random하게 뽑힌 parameter들로 이루어진 model에서 만들어진 것이다. 또한, evidence는 Bayes' Them에서 분모에 해당하는 normalizing term을 의미하기도 한다 : $p({\\bf w}| D, M_i) = \\frac{p(D | {\\bf w}, M_i) p({\\bf w} | M_i)}{p(D | M_i)}$ $$p(D|M_i) = \\int p(D|{\\bf w}, M_i)p({\\bf w}|M_i)d{\\bf w}$$ 이제 model evidence에 대해 더 알아보자. model이 single parameter $w$ 를 갖고 있다고 가정 notation $M_i$는 생략 $w$의 posterior는 $p(D|w)p(w)$에 비례 posterior는 $w_{MAP}$ 에서 peaked 된 상태이고 그 때 width는 $\\vartriangle w_{posterior}$ 라고 가정 prior는 flat with width $\\vartriangle w_{prior}$, 따라서 $p(w) = 1/\\vartriangle w_{prior}$ $$p(D) = \\int p(D | w)p(w)dw \\simeq p(D | w_{MAP}) \\frac{1}{\\vartriangle w_{prior}} \\vartriangle w_{posterior}$$ log를 씌우면 $$\\ln p(D) \\simeq \\ln p(D|w_{MAP}) + \\ln (\\frac{\\vartriangle w_{posterior}}{\\vartriangle w_{prior}})$$ 첫번째 항 : 이 data를 가장 잘 표현하는 파라미터에 대한 확률값으로 log likelihood 의미 두번째 항 : model complexity에 대한 penalty 항 우리는 $\\ln p(D|M_i)$ 가 가장 큰 model($M_i$)을 찾는 것이 목표이다. complex가 높은 model를 구하면 첫번째 항이 커질 것이지만 두번째 항은 $\\vartriangle w_{posterior}$ 이 narrow 해지면서 음수가 되고 점점 작아진다. trade-off 관계인 것이다. 따라서 적절한 complexity가 있는 model을 선택하게 된다. $\\ln p(D | M_i) = accuracy(M_i) - complexity(M_i)$ 느낌 AIC, BIC를 예시로 생각할 수 있다. M 개의 parameter가 있을 경우 위에서 설명한 부분과 같다. 뒷 부분에 M이 추가되어 M이 커지면서 더 penalty를 준다. $$\\ln p(D | \\textbf{w} _ {MAP}) + M \\ln (\\frac{\\vartriangle w_{posterior}}{\\vartriangle w_{prior}})$$ optimal model complexity (model selection) 는 maximum evidence 으로 정해진다는 것 을 기억하자. ","date":"2021-11-26","objectID":"/prml-chap03-2/:2:0","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (2)","uri":"/prml-chap03-2/"},{"categories":["PRML"],"content":"3.5 The Evidence Approximation linear basis model에서 완전한 Bayesian 접근법을 위해서 ${\\bf w}$에 대한 hyperparameter $\\alpha, \\beta$의 prior를 고려해보자. predictive distribution은 아래와 같이 구할 수 있다. (${\\bf x}$ 표시는 생략) $p(t|{\\bf w})$ : distribution of target ($=N(y(x,{\\bf w}), \\beta^{-1})$) $p({\\bf w}|{\\bf t}, \\alpha, \\beta)$ : posterior of ${\\bf w}$ $p(\\alpha, \\beta | {\\bf t})$ : posterior of $\\alpha, \\beta$ $$p(t|{\\bf t}) = \\iiint p(t|{\\bf w}, \\beta) p({\\bf w}|{\\bf t}, \\alpha, \\beta) p(\\alpha, \\beta | {\\bf t}) d{\\bf w}d\\alpha d\\beta $$ 하지만 여기서 문제가 발생한다. 위처럼 모든 변수에 대해 marginalize하는 것은 항상 가능한 것이 아니다 (analytically intractable). 그래서 우리는 hyperparameter를 특정한 값으로 approximation한다. 그 방법은 maximizing marginal likelihood function이다. 이러한 방법론을 evidence approximation (통계에서는 emprical Bayes, type 2 maximum likelihood, generalized maximum likelihood) 라고 부른다. 만약에 posterior distribution $p(\\alpha, \\beta | {\\bf t})$ 가 특정한 값 $\\hat{\\alpha}, \\hat{\\beta}$에서 가장 높은 값(peaked)을 가진다면 predictive distribution은 ${\\bf w}$에 대해서만 marginalize해서 구할 수 있을 것이다. $$p(t|{\\bf t}) \\simeq p(t|{\\bf t}, \\hat{\\alpha}, \\hat{\\beta}) = \\int p(t|{\\bf w}, \\hat{\\beta})p({\\bf w}|{\\bf t}, \\hat{\\alpha}, \\hat{\\beta})d{\\bf w}$$ posterior distribution for $\\alpha, \\beta$ 는 $$p(\\alpha, \\beta | {\\bf t}) \\propto p({\\bf t}|\\alpha, \\beta) p(\\alpha, \\beta) $$ prior는 flat 하다고 가정하자. 따라서 우리는 $\\hat{\\alpha}, \\hat{\\beta}$를 구하기 위해서 marginal likelihood function $p({\\bf t} | \\alpha, \\beta)$ 을 최대로 만드는 찾으면 된다. 이를 통해 우리는 cross validation과 같은 방법이 아니라 한 번에 hyperparameter를 찾을 수 있다. 찾는 방법은 미분을 이용하는 방법, EM 알고리즘을 이용하는 방법이 있다. 전자는 이제 살펴볼 것이고 후자는 9장에서 배운다. ","date":"2021-11-26","objectID":"/prml-chap03-2/:3:0","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (2)","uri":"/prml-chap03-2/"},{"categories":["PRML"],"content":"3.5.1 Evaluation of the evidence function marginal likelihood function은 parameter ${\\bf w}$를 marginalize해서 얻을 수 있다. $p({\\bf t}|{\\bf w}, \\beta)$ : likelihood function $p({\\bf w}|\\alpha)$ : prior of w $$p({\\bf t}|\\alpha, \\beta) = \\int p({\\bf t}|{\\bf w}, \\beta) p({\\bf w}|\\alpha) d{\\bf w}$$ 위의 식을 Gaussian의 형태를 이용하여 정리해보자. (과정은 생략, PRML 연습문제에 있다) $$p({\\bf t}|\\alpha, \\beta) = \\left(\\frac{\\beta}{2\\pi}\\right)^{N/2}\\left(\\frac{\\alpha}{2\\pi}\\right)^{M/2} \\int \\exp{-E({\\bf w})}d{\\bf w}$$ $$E({\\bf w}) = \\beta E_D({\\bf w}) + \\alpha E_w({\\bf w}) = \\frac{\\beta}{2}|{\\bf t} - \\Phi{\\bf w}|^2 + \\frac{\\alpha}{2}{\\bf w}^T{\\bf w} $$ $$E({\\bf w}) = E({\\bf m}_N)+\\frac{1}{2}({\\bf w}-{\\bf m}_N)^T {\\bf A} ({\\bf w} - {\\bf m}_N) $$ ${\\bf A} = \\alpha {\\bf I} + \\beta \\Phi^T\\Phi$ ${\\bf m}_N = \\beta {\\bf A}^{-1}\\Phi^T{\\bf t}$ 이제 이를 이용하면 $$\\int \\exp\\left(-E({\\bf w})\\right) d{\\bf w} = \\exp(-E({\\bf m}_N))\\int \\exp \\{ -\\frac{1}{2}({\\bf w}-{\\bf m}_N)^T {\\bf A} ({\\bf w}-{\\bf m}_N) \\} d { \\bf w} \\\\ = \\exp\\{-E({\\bf m}_N)\\}(2\\pi)^{M/2}|{\\bf A}|^{-1/2}$$ 이를 이용하여 최종적으로 log marginal likelihood function을 구하면 $$\\ln p({\\bf t}|\\alpha, \\beta) = \\frac{M}{2}\\ln \\alpha + \\frac{N}{2}\\ln \\beta - E({\\bf m}_n) - \\frac{1}{2}\\ln |{\\bf A}| - \\frac{N}{2}\\ln(2\\pi)$$ ","date":"2021-11-26","objectID":"/prml-chap03-2/:3:1","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (2)","uri":"/prml-chap03-2/"},{"categories":["PRML"],"content":"3.5.2 Maximizing the evidence function $\\ln p({\\bf t} | \\alpha, \\beta)$을 최대화하는 $\\alpha, \\beta$를 구하기 위해 미분을 이용해보자. $(\\beta \\Phi^T \\Phi) {\\bf \\mu}_i = \\lambda_i{\\bf \\mu}_i$ 라고 하면 ${\\bf A}$의 eigenvalue는 $\\alpha + \\lambda_i$ 이다. 따라서 $$\\frac{d}{d\\alpha}\\ln |{\\bf A}| = \\frac{d}{d\\alpha}\\ln \\prod_{i}(\\lambda_i+\\alpha) = \\frac{d}{d\\alpha}\\sum_i \\ln(\\lambda_i+\\alpha) = \\sum_i \\frac{1}{\\lambda_i + \\alpha}$$ $\\alpha$에 대해 미분 $$0 = \\frac{M}{2\\alpha} - \\frac{1}{2}{\\bf m}_N^T{\\bf m}_N - \\frac{1}{2}\\sum_i \\frac{1}{\\lambda_i+\\alpha}$$ $$\\alpha {\\bf m} _ N^T {\\bf m} _ N = M - \\alpha \\sum_{i=1}^{M} \\frac{1}{\\lambda_i+\\alpha} = \\gamma$$ 이를 다시 정리하면 $$\\gamma = \\sum_{i=1}^{M} \\frac{\\lambda_i}{\\alpha + \\lambda_i}$$ 최종적으로 $\\alpha$에 대해 정리하면 $$\\alpha = \\frac{\\gamma}{ {\\bf m}_N^T{\\bf m}_N} $$ 그런데 $\\gamma, {\\bf m}_N$ 모두 $\\alpha$에 depend한다. 따라서 이를 위해서 iterative한 방법을 사용한다. 임의의 수로 $\\alpha$를 시작하고 $\\gamma, {\\bf m}_N$을 구한다. 다시 이 두 값으로 $\\alpha$를 구한다. 이렇게 수렴할 때까지 반복하는 것이다. $\\beta$에 대해 미분 $$\\frac{d}{d\\beta} \\ln |{\\bf A}| = \\frac{d}{d\\beta}\\sum_i \\ln(\\lambda_i+\\alpha) = \\frac{1}{\\beta}\\sum_i\\frac{\\lambda_i}{\\lambda_i+\\alpha} = \\frac{\\gamma}{\\beta}$$ $$0 = \\frac{N}{2\\beta} - \\frac{1}{2}\\sum_{n=1}^N{t_n-{\\bf m}_N^T\\phi({\\bf x}_n)}^2 - \\frac{\\gamma}{2\\beta} $$ $$\\frac{1}{\\beta} = \\frac{1}{N-\\gamma}\\sum_{n=1}^N {t_n-{\\bf m}_N^T\\phi({\\bf x}_N)}^2 $$ 이도 마찬가지도 iterative하게 구한다. cross validation과 같은 추가적인 computation이 없이 한 번에 train data set을 모두 이용하여 model complexity를 정할 수 있다 는 점을 기억하자. ","date":"2021-11-26","objectID":"/prml-chap03-2/:3:2","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (2)","uri":"/prml-chap03-2/"},{"categories":["PRML"],"content":"3.5.3 Effective number of parameters 이 부분은 ridge regression의 내용 (data의 고윳값이 작은 방향의 parameter가 0에 가까워진다) 과 같다. ESL 책의 linear regression부분을 보면 알 수 있다. $\\alpha$에 대한 Bayesian의 접근에 대해 조금 더 살펴보자. $\\beta \\Phi^T \\Phi$는 positive definite matrix이므로 eigenvalue가 모두 0이상의 값을 갖는다. 따라서 $0 \\le \\lambda_i /(\\lambda_i + \\alpha) \\le 1$ $0 \\le \\gamma \\le 1$ 임을 알 수 있다. $\\lambda_i » \\alpha$ 인 경우는 이에 해당하는 parameter $w_i$가 maximum likelihood의 값과 가까워지고 $\\lambda_i /(\\lambda_i + \\alpha)$ 이 1에 가까워진다. 반대의 경우는 $w_i, \\lambda_i /(\\lambda_i + \\alpha)$ 모두 0에 가까워진다. 따라서 $\\gamma$는 measures the effective total number of well determined parameters 다음은 $\\beta$에 대해 알아보자. 위에서 보았듯이 effective number of parameter는 $\\gamma$이고 나머지 $M-\\gamma$개의 parameters 들이 prior에 의해 작은 값을 갖는다. 이것이 variance에서 $\\frac{1}{N-\\gamma}$로 나타나고 bias of maximum likelihood result를 바로 잡아준다. 만약에 $N » M$의 상황인 경우, 대부분의 parameter들이 well determined될 것이고 data size에 따라 eigenvalue도 커지게 된다. 그러면 $\\gamma = M$이 되고 evidence approximation도 아래 값을 이용해 간단해진다. (data 많은게 짱이다) $$\\alpha = \\frac{M}{2E_W({\\bf m}_N)}$$ $$\\beta = \\frac{N}{2E_D({\\bf m}_N)}$$ ","date":"2021-11-26","objectID":"/prml-chap03-2/:3:3","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (2)","uri":"/prml-chap03-2/"},{"categories":["PRML"],"content":"3.6 Limitations of Fixed Basis Functions 장점 nonlinear basis functions의 linear combination이니까 해석이 쉽다. closed form의 해가 존재한다. 단점 basis function이 training data를 보기 전에 이미 fixed되서 시작한다. 차원의 저주 input간의 correlation 때문에 보다 작은 차원에 nonlinear manifold에 데이터가 분포할 수 있다. ","date":"2021-11-26","objectID":"/prml-chap03-2/:4:0","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (2)","uri":"/prml-chap03-2/"},{"categories":["PRML"],"content":"Regression에 대해 알아보자. 목표는 predictive distribution $p(t|x)$를 찾는 것 주로 loss funciton은 squared loss를 사용하며 이 때 optimal solution은 conditional expectation of t : $E[t|x]$ ","date":"2021-11-26","objectID":"/prml-chap03-1/:0:0","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (1)","uri":"/prml-chap03-1/"},{"categories":["PRML"],"content":"3.1 Linear Basis Function Models 가장 기본적인 linear model for regression은 $$y(x,w) = w_0+w_1x_1+…+w_D x_D$$ 의 형태일 것이다. 하지만 basis function $\\phi_ j(\\textbf{x})$을 이용하여 nonlinear의 성질을 추가할 수 있다. basis function은 다양하다. gaussian distribution의 형태 polynomial의 형태 원래의 input data를 마음대로 변화가능 $$y(\\textbf{w},\\textbf{x}) = w_0 + \\sum_{j=1}^{M-1}{w_j \\phi_j(\\textbf{x})} = \\textbf{w}^T {\\pmb \\phi}( \\textbf{x})$$ 하지만 여전히 linear model이다. 여기서 linear의 의미는 계수 w에 linear하다는 의미이기 때문이다. 그렇기에 여전히 interpretation에 대한 장점은 갖고 있다. 단점은 너무 단순하다는 것이다. ","date":"2021-11-26","objectID":"/prml-chap03-1/:1:0","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (1)","uri":"/prml-chap03-1/"},{"categories":["PRML"],"content":"3.1.1 Maximum likelihood and least sqaures $t$ : target variable $y(\\textbf{x}, \\textbf{w})$ : deterministic funciton $\\epsilon \\sim N(0, \\beta^{-1})$ : noise $$t = y(\\textbf{x}, \\textbf{w})+ \\epsilon$$ $$p(t | \\textbf{x},\\textbf{w},\\beta) = N(y(\\textbf{x}, \\textbf{w}), \\beta^{-1})$$ 위의 gaussian 가정에서는 parameter $w$를 추정할 때, likelihood를 이용하는 것과 least square의 방법을 이용하는 것이 똑같다. (그 과정은 직접 해보면 쉽게 파악가능, chapter1에도 있다) optimal prediction은 conditional mean of the target variable 이므로 unimodal이라는 한계가 존재 $$E[t | {\\bf x}] = \\int tp(t | {\\bf x})dt = y({\\bf x}, {\\bf w}) $$ 이제 likelihood function을 통해 MLE를 구하는 과정을 간단히 살펴보자. $$\\ln{p({\\bf t}|{\\bf w}, \\beta)} = \\sum_{n=1}^{N}\\ln{N( {\\bf w}^T{\\pmb \\phi}(x_n), \\beta^{-1})}\\\\ =\\dfrac{1}{2}\\ln{\\beta}-\\dfrac{1}{2}\\ln{2\\pi}-\\beta{E_D({\\bf w})}$$ $$E_D({\\bf w})=\\dfrac{1}{2}\\sum_{n=1}^{N}{t_n-{\\bf w}^T {\\pmb \\phi}(x_n)}^2$$ 위의 식을 미분하고 정리하면 ($\\Phi$ : N*M design matrix) normal equation을 얻는다. $${\\bf w}_{ML} = (\\Phi^T\\Phi)^{-1}\\Phi^T{\\bf t} $$ bias : $w_0 = \\bar{t} - \\sum_{j=1}^{M-1}{w_j \\bar{\\phi}_j}$ 실제 얻어지는 샘플들의 타겟 값들의 평균과, 이 때 basis function에 parameter를 곱하여 얻어진 결과의 평균값의 차이를 보정하는 역할 noise precision : $\\frac{1}{\\beta_{ML}} = \\frac{1}{N}\\sum_{n=1}^{N}{{ t_n - w_{ML}^T \\phi(x_n)}^2}$ ","date":"2021-11-26","objectID":"/prml-chap03-1/:1:1","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (1)","uri":"/prml-chap03-1/"},{"categories":["PRML"],"content":"3.1.2 Geometry of least squares least square의 방법에서 우리가 prediction한 값의 의미를 기하학적으로 살펴보자. 증명의 과정은 ESL에 잘 나와있다. 물론 봐도 이해하기는 어렵다. 결론만 언급하자면 “input vector가 span하는 space에 true t의 값을 orthorgonal하게 projection한 값이 우리가 예측한 t의 값이다” 추가적으로 multicolinearity에 대한 해결책으로는 PCA, SVD와 같은 방법으로 input들을 orthorgonal하게 만들어주는 것과 ridge regression과 같이 regulrarization 항이 있는 모델을 쓰는 것이다. ","date":"2021-11-26","objectID":"/prml-chap03-1/:1:2","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (1)","uri":"/prml-chap03-1/"},{"categories":["PRML"],"content":"3.1.3 Sequential learning 이 부분에서는 parameter를 최적화하는 과정에 있어서 gradient descent의 방법을 말하고 있다. 그게 Sequential하게 update하는 것이라 그런 것 같다. 데이터의 크기가 크면 normal equation의 방법이 오래걸리는 단점을 보완할 수도 있다. $$\\textbf{w}^{\\tau+1}=\\textbf{w}^{(\\tau)}+{\\eta}(t_n-{\\bf w}^{(\\tau)T}{\\pmb \\phi}_n) {\\pmb \\phi}_n$$ ","date":"2021-11-26","objectID":"/prml-chap03-1/:1:3","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (1)","uri":"/prml-chap03-1/"},{"categories":["PRML"],"content":"3.1.4 Regularized least squares 기존의 error function에 regularization term을 추가하여서 parameter shrinkage를 하고자 한다. 이를 통해 overfitting을 완화시킨다. lasso 같은 경우 sparse한 model을 만들어서 feature selection의 역할도 한다. regularized error takes the form 아래 식에서 q가 1이면 lasso, 2이면 ridge regression이다. $\\lambda$가 커질수록 model complexity가 낮아진다. $$\\frac{1}{2}\\sum_{n=1}^{N}{{t_n - \\textbf{w}^T{\\pmb \\phi}(x_n)}^2}+ \\frac{\\lambda}{2}\\sum_{j=1}^{M}{ \\left| \\textbf{w}_j\\right|^q }$$ ridge의 경우 error function이 $\\textbf{w}$에 대해 quadratic form이라서 closed form으로 solution이 존재한다. $$w_{ridge} = (\\Phi^T \\Phi + \\lambda I)^{-1}\\Phi^T t$$ ","date":"2021-11-26","objectID":"/prml-chap03-1/:1:4","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (1)","uri":"/prml-chap03-1/"},{"categories":["PRML"],"content":"3.2 The Bias-Variance Decomposition 모델링을 할 때 overfitting을 피하기 위해 제약을 두면 complexity를 못 잡을 수도 있다. 너무 모델을 복잡하게 하면 overfitting이 될 수도 있다. 이는 상당히 어려운 문제이다. 이 부분에 있어서 frequentist의 입장에서 바라보는 bias-variance trade off 관계를 공부하고자 한다. 이해를 위해 square loss (regression)의 경우의 예시를 살펴보자. square loss function 에서 optimal solution : $$E[t | \\textbf{x}] = \\int t p(t | \\textbf{x})dt = h(\\textbf{x})$$ expected squared loss : $$E[L] = \\int { y(\\textbf{x}) - h(\\textbf{x})}^2 p(\\textbf{x})d\\textbf{x} + \\int {h(\\textbf{x}) - t}^2 p(\\textbf{x},t)d\\textbf{x}dt$$ 우리는 우항의 첫번째를 최대한 작게하는 $y(\\textbf{x})$을 만들고자 한다. 위의 식에서 우항의 두번째는 우리가 줄일 수 없는 intrinsic noise이다. 첫 번째 항을 decompose 해보자. 일단 ${ y(\\textbf{x};D) - h(\\textbf{x})}^2$ 값은 특정한 dataset $D$에 대한 값이다. 이제 dataset이 여러개가 있다고 가정하고 이에 대해 average한 경우를 생각해보자. $E_D[y(\\textbf{x};D)]$ 을 더하고 빼서 $$E_D[{ y(\\textbf{x};D)-h(\\textbf{x}) }^2] =\\ {E_D[y(\\textbf{x};D)] -h(\\textbf{x})}^2+ E_D[{ y(\\textbf{x};D) - E_D[y(\\textbf{x};D)]}^2]$$ 이렇게 나타낼 수 있다. 즉, expected loss = (bias)^2 + variance +noise 인 것이다. bias 의미 : average prediction over all datasets 이 우리가 알고 싶은 true (regression) function과 차이나는 정도 variance 의미 : 해당 하나의 dataset이 average 와 차이나는 정도, function $y(\\textbf{x};D)$이 특정한 dataset에 얼마나 민감한지 이 둘은 trade-off 관계 : 한쪽이 커지면 한쪽이 작아진다. 하지만 이런 bias-variance의 관계는 average에 기반을 한 개념이기 때문에(bias, variance의 계산하는 과정이 D에 대해 평균) 한계점이 분명 존재 한다. 우리가 가지고 있는 데이터는 한정적이기 때문이다. 독립적인 데이터가 여러 개이면 각 데이터로 복잡한 모델을 만들어서 평균을 내면 좋은 결과를 얻을 수 있지만 우리는 데이터가 부족하다. 그래서 저자는 Bayesian 접근법을 소개한다. ","date":"2021-11-26","objectID":"/prml-chap03-1/:2:0","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (1)","uri":"/prml-chap03-1/"},{"categories":["PRML"],"content":"+ monk의 설명 정의 MSE of an estimate $\\hat{\\theta} = f(D)$ for $\\theta$ is $$MSE(\\hat{\\theta}) = E[(\\hat{\\theta} - \\theta)^2 | \\theta]$$ $bias(\\hat{\\theta}) = E[\\hat{\\theta}] - \\theta$ $var(\\hat{\\theta}) = E[(\\hat{\\theta}-E[\\hat{\\theta}])^2]$ $$MSE(\\hat{\\theta}) = bias^2(\\hat{\\theta}) + var(\\hat{\\theta})$$ (proof) let $\\mu = E[\\hat{\\theta}]$ $$E[(\\hat{\\theta} - \\theta)^2] = E[(\\hat{\\theta} - \\mu + \\mu -\\theta)^2] \\\\ = E[(\\hat{\\theta} - \\mu)^2 + 2(\\hat{\\theta} - \\mu)(\\mu - \\theta) + (\\mu - \\theta)^2] \\\\ = (\\mu - \\theta)^2 + E[(\\hat{\\theta}-\\mu)^2] \\quad \\because E[(\\hat{\\theta} - \\mu)(\\mu - \\theta)] = 0 $$ 쉬운 예시 $X \\sim N(\\theta,1)$ $\\theta$는 non random, unknown $\\hat{\\theta}_1 = X \\rightarrow bias^2 = 0, var = 1, MSE = 1$ $\\hat{\\theta}_2 = 0 \\rightarrow bias^2 = \\theta^2, var = 0, MSE = \\theta^2$ ","date":"2021-11-26","objectID":"/prml-chap03-1/:2:1","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (1)","uri":"/prml-chap03-1/"},{"categories":["PRML"],"content":"+ 문일철 교수님의 설명 Sources of Error in ML 크게 두 가지로 나눌 수 있다 : Approximation and generalization $E_{out} \\le E_{in} + \\Omega$ $E_{out}$ : estimation error $E_{in}$ : error from approximation by the learning algorithm $\\Omega$ : error caused by the variance of the observations 뒤에서 사용할 notation에 대해 알아보자. $f$ : the target function to learn (true function) $g$ : the learning function of ML $g^{(D)}$ : the learned function by using a dataset $\\bar{g}$ : the average hypothesis of a given infinite numbers of D ( $\\bar{g}(x) = E_D [g^{(D) } (x)]$ ) 하나의 dataset D에 대한 Error는 $$E_{out}[g^{(D)}(x)] = E_x[(g^{(D)}(x) - f(x))^2]$$ 그렇다면 expected error of the infinite dataset은 $$E_D [E_{out}[g^{(D)}(x)] ] = E_D [E_x[(g^{(D)}(x) - f(x))^2]] = E_x [E_D[(g^{(D)}(x) - f(x))^2]]$$ 일단 안쪽에 있는 term부터 확인해보자. $$E_D[(g^{(D)}(x) - f(x))^2] = E_D [( g^{(D)}(x) - \\bar{g}(x) + \\bar{g}(x) - f(x) )^2]$$ $$= E_D [(g^{(D)}(x) - \\bar{g}(x) )^2] + (\\bar{g}(x) - f(x))^2$$ $$\\therefore E_D [E_{out}[g^{(D)}(x)] ] = E_D [(g^{(D)}(x) - \\bar{g}(x) )^2] + (\\bar{g}(x) - f(x))^2 $$ 여기서 우리는 variance와 bias를 정의할 수 있는데 $Var = E_D [(g^{(D)}(x) - \\bar{g}(x) )^2]$ $Bias^2 = (\\bar{g}(x) - f(x))^2$ 이들이 의미하는 바는 var는 제한적인 dataset 때문에 model을 average hypothesis로 훈련시킬 수 없는 부분을 의미 bias는 average hypothesis조차도 (true) real world hypothesis를 맞출수 없는 부분을 의미 그렇다면 var과 bias를 줄이기 위해서는? var를 줄이기 위해서는 data를 더 모은다. bias를 줄이기 위해서는 더 복잡한 model을 사용한다. 하지만 문제는 var와 bias는 trade-off 관계를 가진다. 예를 들어, 우리가 갖고 있는 dataset에 잘 맞는 복잡한 모델을 사용하면 평균적인 모델과는 차이가 커질 것이다. 간단한 model은 낮은 variance, 높은 bias를 갖는다. 복잡한 model은 높은 variance, 낮은 bias를 갖는다. 따라서 적잘한 model을 만드는 것이 관건이다. Occam’s Razor 같은 error를 갖는 모델이라면 둘 중 더 간단한 모델을 선택하라! ","date":"2021-11-26","objectID":"/prml-chap03-1/:2:2","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (1)","uri":"/prml-chap03-1/"},{"categories":["PRML"],"content":"Exponential Family와 Nonparametric 방법론에 대해 알아보자. ","date":"2021-11-26","objectID":"/prml-chap02-4/:0:0","tags":["Exponential Family","Non parametric"],"title":"[PRML] Chapter2 - Probability Distribution (4)","uri":"/prml-chap02-4/"},{"categories":["PRML"],"content":"2.4 The Exponential Family 우리가 이전에 공부했던 대부분의 distribution은 Exponential Family에 속한다. The exponential family of distribution over $x$, given parameters $\\eta$, is defined to be the set of distributions of the form $$p({\\pmb x} | {\\pmb \\eta}) = h({\\pmb x})g({\\pmb \\eta}) \\exp ({\\pmb \\eta}^T u({\\pmb x}))$$ pdf(pmf) $p({\\pmb x} | {\\pmb \\eta})$ 을 우항과 같이 표현할 수 있다면 exponential family에 속한다. ${\\pmb x}$는 스칼라, 벡터 둘 다 가능하고 discrete, continous 모두 가능하다. ${\\pmb \\eta}$ 는 natural parameter of the distribution 이라고 한다. $g(\\pmb \\eta)$는 distribution의 normalize coefficient (적분해서 1이 되도록 만들어주는) 라고 할 수 있다. $$g({\\pmb \\eta}) \\int h({\\pmb x})\\exp{ {\\pmb \\eta}^T{\\pmb u} ({\\pmb x}) } d {\\pmb x}=1 $$ Bernoulli distribution 예시 $p(x | \\mu) = Bern(x | \\mu)=\\mu^x(1-\\mu)^{1-x}$ 이를 exponential form으로 표현해보자. $f(x)=\\exp(\\ln{f(x)})$ 을 이용하여 $$p(x | \\mu) = \\exp {x \\ln \\mu + (1-x) \\ln (1-\\mu) } \\\\ = (1-\\mu) \\exp \\{ \\ln \\left( \\frac{\\mu}{1-\\mu} \\right) x \\} \\\\ \\therefore \\eta = \\ln\\left(\\frac{\\mu}{1-\\mu}\\right) $$ 위의 형태를 $\\mu$에 대한 식으로 바꿔보면 $$\\mu=\\sigma(\\eta)=\\dfrac{1}{1+\\exp(-\\eta)} $$ 위의 식과 같은 형태의 함수를 logistic sigmoid function이라고 부른다. Multinomial distribution 예시 $p({\\pmb x} | {\\pmb \\mu}) = \\prod_{k=1}^{M}\\mu_k^{x_k}= \\exp [\\sum_{k=1}^{M}x_k \\ln \\mu_k]$ $p({\\pmb x}|{\\pmb \\eta})=\\exp({\\pmb \\eta}^T{\\pmb x})$ $\\eta_k = \\ln \\mu_k$ ${\\pmb \\eta} = (\\eta_1, \\eta_2,…,\\eta_k)^T$ M개의 parameter가 있지만 $\\sum_{k=1}^{M}{\\mu_k}=1$ 이라는 제약때문에 M-1개의 값이 정해지면 마지막 M개는 저절로 정해진다. 이를 이용할 것이다. $$\\exp \\{\\sum_{k=1}^{M}x_k\\ln\\mu_k \\} = \\exp \\{\\sum_{k=1}^{M-1}x_k\\ln\\mu_k + \\left(1-\\sum_{k=1}^{M-1}x_k\\right)\\ln\\left(1-\\sum_{k=1}^{M-1}\\mu_k\\right) \\}\\\\ = \\exp\\{\\sum_{k=1}^{M-1}x_k\\ln\\left(\\frac{\\mu_k}{1-\\sum_{j=1}^{M-1}\\mu_j}\\right)+\\ln\\left(1-\\sum_{k=1}^{M-1}\\mu_k\\right)\\}$$ $$\\therefore \\eta_k = \\ln\\left(\\frac{\\mu_k}{1-\\sum_{j \\neq k} \\mu_j}\\right)$$ 똑같이 $$\\mu_k=\\dfrac{\\exp(\\eta_k)}{1+\\sum_{j \\neq k}\\exp(\\eta_j)}$$ 위의 식과 같은 형태의 함수를 softmax function (normalized exponential) 이라고 부른다. ","date":"2021-11-26","objectID":"/prml-chap02-4/:1:0","tags":["Exponential Family","Non parametric"],"title":"[PRML] Chapter2 - Probability Distribution (4)","uri":"/prml-chap02-4/"},{"categories":["PRML"],"content":"2.4.1 Maximum likelihood and sufficient statistics $\\eta$가 어떤 것인지 알았으니 이제 이를 MLE로 estimate해보자. exponential form을 $\\eta$에 대해 미분하면 $$\\nabla g({\\pmb \\eta})\\int h({\\pmb x})\\exp{ {\\pmb \\eta}^T {\\pmb u}({\\pmb x})}d{\\pmb x} + g({\\pmb \\eta})\\int h({\\pmb x})\\exp{ {\\pmb \\eta}^T{\\pmb u}({\\pmb x})}{\\pmb u}({\\pmb x})d{\\pmb x} = 0$$ $g({\\pmb \\eta}) \\int h({\\pmb x})\\exp{ {\\pmb \\eta}^T{\\pmb u} ({\\pmb x}) } d {\\pmb x}=1$ 을 이용하여 $$-\\frac{1}{g({\\pmb \\eta})} \\nabla g({\\pmb \\eta}) = g({\\pmb \\eta})\\int h({\\pmb x})\\exp{ {\\pmb \\eta}^T{\\pmb u}({\\pmb x})}{\\pmb u}({\\pmb x})d{\\pmb x}=E[{\\pmb u}({\\pmb x})]$$ 최종적으로는 $$-\\nabla \\ln g({\\pmb \\eta}) = E[{\\pmb u}({\\pmb x})] $$ 이제 iid인 data를 통해 likelihood function을 만들면 $$p({\\pmb X}|{\\pmb \\eta}) = \\left(\\prod_{n=1}^{N}h({\\pmb x} _ n)\\right) g({\\pmb \\eta})^N \\exp\\{ {\\pmb \\eta}^T\\sum_{n=1}^{N}{\\pmb u}({\\pmb x}_n)\\} $$ log를 취한 뒤에 $\\eta$에 대해 미분하여 0을 갖도록 하면 아래와 같은 식을 얻을 수 있다. $$-\\nabla \\ln g({\\pmb \\eta} _ {ML}) = \\frac{1}{N}\\sum_{n=1}^{N}{\\pmb u}({\\pmb x}_n)$$ 이를 통해 우리는 MLE solution이 오직 $\\sum_{n=1}^{N} \\textbf{u}(\\textbf{x}_n)$에 달려 있다는 것을 알 수 있다. 이는 sufficient statistics of the distribution 이라고 부른다. parameter에 대한 정보가 여기 다 들어 있어서 충분하다! 라고 이해할 수 있다. 따라서 우리는 MLE를 구하는 과정에 있어서 각 data를 모두 알고 있을 필요가 없이 충분통계량만 알면 된다. $N \\rightarrow \\infty$이면 우항은 $E[\\textbf{u}(\\textbf{x})]$이 되고 ${\\pmb \\eta}_{ML}$은 true값으로 수렴한다는 것을 알 수 있다. ","date":"2021-11-26","objectID":"/prml-chap02-4/:1:1","tags":["Exponential Family","Non parametric"],"title":"[PRML] Chapter2 - Probability Distribution (4)","uri":"/prml-chap02-4/"},{"categories":["PRML"],"content":"2.4.2 Conjugate priors exponential family인 prior distribution은 $$p({\\pmb \\eta} | {\\pmb \\chi}, v) = f({\\pmb \\chi}, v)g({\\pmb \\eta})^v \\exp\\{v{\\pmb \\eta}^T{\\pmb \\chi}\\}$$ 여기에 위에서 보았던 likelihood function을 곱하여 posterior distribution을 구하면 $$p({\\pmb \\eta}|{\\pmb X}, {\\pmb \\chi}, v) \\propto g({\\pmb \\eta})^{v+N}\\exp\\{ {\\pmb \\eta}^T\\left(\\sum_{n=1}^{N}{\\pmb u}({\\pmb x})+v{\\pmb \\chi}\\right)\\}$$ conjugacy를 확인할 수 있다. 또한 parameter $v$는 effective nunber of pseudo-observation 이라고 이해할 수 있다. ","date":"2021-11-26","objectID":"/prml-chap02-4/:1:2","tags":["Exponential Family","Non parametric"],"title":"[PRML] Chapter2 - Probability Distribution (4)","uri":"/prml-chap02-4/"},{"categories":["PRML"],"content":"2.4.3 Noninformative priors posterior를 만들기 위해 사전의 정보가 충분하면 상관없지만 그렇지 않은 경우, 우리는 prior의 영향을 최소화하고 싶을 것이다. 이런 prior를 Noninformative prior 라고 부른다. $p(x|\\lambda)$ distribution이 있을 때, prior distribution $p(\\lambda)=\\text{const}$ 가 적절한 prior가 될 것이다. 만약에 $\\lambda$가 $K$ states를 갖는 discrete이면 prior 는 $1/K$로 하면 된다. 하지만 continous하고 domain이 unbounded하면 prior distribution은 합이 1이 되지 않는다 (integral diverge, not correctly normalized). 이런 prior를 improper prior 라고 한다. 적분값이 1이 아닌 diverge하는 모든 분포에 해당하는 것은 아니다. prior는 improper해도 posterior는 적절한 pdf가 되어야 한다. ","date":"2021-11-26","objectID":"/prml-chap02-4/:1:3","tags":["Exponential Family","Non parametric"],"title":"[PRML] Chapter2 - Probability Distribution (4)","uri":"/prml-chap02-4/"},{"categories":["PRML"],"content":"2.5 Nonparametric Methods 말 그대로 비모수적인 방법들이다. 이전까지는 parameter를 추정하여 density를 추정하였다면 아래의 방법들은 parameter를 추정할 필요가 없는 data oriented한 방법이라고 생각할 수 있다. ","date":"2021-11-26","objectID":"/prml-chap02-4/:2:0","tags":["Exponential Family","Non parametric"],"title":"[PRML] Chapter2 - Probability Distribution (4)","uri":"/prml-chap02-4/"},{"categories":["PRML"],"content":"Histogram 주로 같은 크기의 bin으로 해당 data를 나눈 뒤에 해당 bin에 들어가는 data의 수를 통해 density를 파악한다. 기본적인 것으로 저차원에서 시각화용으로만 사용해야 할 것 같다. (Probability 식) : x를 크기 $\\Delta$로 나누고 각 bin i에 들어가는 data의 수를 $n_i$라고 하면 각 bin i의 확률값은 (각 bin의 넓이는 $\\frac{n_i}{N} * \\Delta$ 이고 histogram 전체 넓이는 1이라) $$p_i = \\frac{n_i}{N \\Delta}$$ density는 bin의 크기가 커질수록 smooth해지고 작아질수록 복잡해진다. ","date":"2021-11-26","objectID":"/prml-chap02-4/:2:1","tags":["Exponential Family","Non parametric"],"title":"[PRML] Chapter2 - Probability Distribution (4)","uri":"/prml-chap02-4/"},{"categories":["PRML"],"content":"Kernel density estimators D-dimension의 probability density $p({\\pmb x})$ 있고 우리는 이 값을 추정하려고 한다. data set은 이 분포에서 나온 $N$개의 observation $R$은 data가 들어있는 어떤 지역 이 지역의 probability mass는 $$P=\\int_R p({\\pmb x})d{\\pmb x}$$ 여기서 이 지역에 들어가는 data의 수는 $K$라고 하면 이는 binomial distribution을 따를 것이다. $$Bin(K/N, P) = \\dfrac{N!}{K!(N-K)!}P^K(1-P)^{1-K}$$ data의 수 $N$이 커지면 $K \\approx NP$일 것이다. $R$이 충분히 작아서 density $p({\\pmb x})$는 해당 지역에서 거의 constant하면 $P \\approx p({\\pmb x}) V$ 임을 알 수 있다. ($V$는 volume of $R$) 따라서 density estimate하면 $$p({\\pmb X}) = \\frac{K}{NV}$$ $V$를 fix : Kernel approach $K$를 fix : K-nearest-neighbour 조금 더 자세히 살펴보자. $R$을 우리가 구하고 싶은 probability density의 point ${\\pmb x}$가 가운데에 있는 작은 hypercube라고 하자. 해당 지역에 들어있는 data 수 $K$를 위해 다음과 같은 함수를 생각해보자. 이 함수는 kernel function 의 한 예시이다. 따라서 $$K = \\sum_{n=1}^{N}k\\left(\\frac{ {\\pmb x}-{\\pmb x}_n}{h}\\right) $$ 이를 이용하여 density at ${\\pmb x}$를 구하면 $$p({\\pmb x}) = \\frac{1}{N}\\sum_{n=1}^{N}\\frac{1}{h^D}k\\left(\\frac{ {\\pmb x}-{\\pmb x}_n}{h}\\right)$$ $v = h^D$ 위 식은 함수 $k({\\pmb u})$의 대칭성을 생각하여, single cube centered on ${\\pmb x}$가 아니라 N cubes centered on the N data point ${\\pmb x_n}$ 이라고 이해할 수 있다. 하지만 이는 여전히 불연속적인 단점이 있기에 좀 더 업그레이드해보자. kernel function을 Gaussian으로 정하면 $$p({\\pmb x}) = \\frac{1}{N}\\sum_{n=1}^N\\frac{1}{(2\\pi h^2)^{D/2}}\\exp\\{-\\frac{|{\\pmb x}-{\\pmb x}_n|^2}{2h^2}\\}$$ kernel function은 다양하게 정할 수 있다. 단, 조건은 $k(x) \\ge 0$ $\\int k(x)dx = 1$ density는 h가 커지면 smooth해지고 h가 작아지면 더 복잡해진다. 우리는 적절하나 h를 잘 찾아야 하는데 이미 최선의 h는 밝혀져 있다. 아울러 가장 좋은 kernel function도 이미 밝혀져있다. ","date":"2021-11-26","objectID":"/prml-chap02-4/:2:2","tags":["Exponential Family","Non parametric"],"title":"[PRML] Chapter2 - Probability Distribution (4)","uri":"/prml-chap02-4/"},{"categories":["PRML"],"content":"Nearest-neighbour methods 이번에는 $K$를 미리 정한 뒤에 이에 적절한 $V$를 찾는 것이다. density는 $K$가 커지면 smooth해지고 작아지면 복잡해진다. KNN classification이 잘 알려져있다. 지금까지 Nonparametric 방법론을 살펴보았다. 전체 data를 저장하고 있어야 하는 단점이 존재한다. data가 너무 많으면 계산에 어려움이 생기고 너무 적으면 다소 부정확한 근사치를 만들 수 있다. ","date":"2021-11-26","objectID":"/prml-chap02-4/:2:3","tags":["Exponential Family","Non parametric"],"title":"[PRML] Chapter2 - Probability Distribution (4)","uri":"/prml-chap02-4/"},{"categories":["PRML"],"content":"Gaussian Distribution과 관련한 내용을 알아보자. ","date":"2021-11-26","objectID":"/prml-chap02-3/:0:0","tags":["Gaussian Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (3)","uri":"/prml-chap02-3/"},{"categories":["PRML"],"content":"2.3.6 Bayesian inference for the Gaussian 이번에는 Bayesian의 방법으로 접근해보자. $\\sigma^2$ is known, inferring the mean $\\mu$ likelihood function은 $$p({\\bf x} | \\mu) = \\prod_{n=1}^{N}p(x_n | \\mu) = \\dfrac{1}{(2\\pi\\sigma^2)^{N/2}}\\exp \\{-\\frac{1}{2\\sigma^2}\\sum_{n=1}^{N}(x_n-\\mu)^2 \\}$$ Gaussian의 conjugate prior는 Gaussian이다. 따라서 prior distribution은 $$p(\\mu) = N(\\mu | \\mu_0, \\sigma_0^2)$$ posterior distribution은 $$p(\\mu |{\\bf x}) \\propto p({\\bf x}|\\mu)p(\\mu) = N(\\mu | \\mu_N, \\sigma_N^2)$$ $\\mu_N = \\frac{\\sigma^2}{N\\sigma_0^2+\\sigma^2}\\mu_0 + \\frac{N\\sigma_0^2}{N\\sigma_0^2+\\sigma^2}\\mu_{ML}$ $\\frac{1}{\\sigma_N^2}=\\frac{1}{\\sigma_0^2}+\\frac{N}{\\sigma^2}$ 위의 결론을 통해 평균과 분산에 대해 좀 더 살펴보자. posterior mean prior mean $\\mu_0$ 와 MLE solution $\\mu_{ML}$ 사이의 값을 갖는다. $N=0$이면 prior mean쪽으로 $N \\rightarrow \\infty$이면 MLE solution쪽을 가까워 진다. posterior variance 해석의 편의를 위해 precision으로 표현하였다. data의 수가 늘어날수록 precision이 커지고 따라서 posterior variance는 작아진다. $N=0$이면 prior variance의 값과 같다. $N \\rightarrow \\infty$이면 variance가 0으로 가까워진다. 이번에는 $\\mu$ is known, inferring the variance $\\sigma^2$ $$p({\\bf x} | \\lambda) = \\prod_{n=1}^{N} N(x_n | \\mu, \\lambda^{-1}) \\propto \\lambda^{N/2} \\exp \\{ -\\frac{\\lambda}{2} \\sum_{n=1}^{N}(x_n-\\mu)^2 \\}$$ precision의 posterior의 conjugate prior는 gamma distribution이다. $$Gam(\\lambda | a,b)=\\frac{1}{\\Gamma(a)}b^a\\lambda^{a-1}\\exp(-b\\lambda) $$ 이를 이용하여 posterior를 구하면 $$p({\\bf x} | \\lambda) \\propto \\lambda^{a_0-1}\\lambda^{N/2} \\exp \\{-b_0\\lambda-\\frac{\\lambda}{2}\\sum_{n=1}^{N}(x_n-\\mu)^2\\}$$ $a_N = a_0 + \\frac{N}{2}$ $b_N = b_0 + \\frac{1}{2}\\sum_{n=1}^{N}(x_n-\\mu)^2 = b_0 + \\frac{N}{2}\\sigma_{ML}^2$ precision이 아닌 covariance를 바로 이용하는 경우 gamma distribution이 아니라 inverse gamma distribution을 이용한다. 이번에는 $\\mu, \\sigma^2$ 둘 다 모른다고 하자 $$p({\\bf x} | \\mu, \\lambda) = \\prod_{n=1}^{N} (\\frac{\\lambda}{2\\pi} )^{1/2} \\exp \\{-\\frac{\\lambda}{2}(x_n-\\mu)^2\\} \\\\ \\propto [\\lambda^{1/2}\\exp (-\\frac{\\lambda\\mu^2}{2})]^N\\exp\\{\\lambda\\mu\\sum_{n=1}^{N}x_n-\\frac{\\lambda}{2}\\sum_{n=1}^{N}x_n^2\\} $$ parameter가 2개이기에 prior가 $p(\\mu, \\lambda)$일 것이다. likelihood function의 모양과 $p(\\mu, \\lambda) = p(\\mu |\\lambda)p(\\lambda)$를 이용하면 Normal-Gamma distribution $$p(\\mu, \\lambda) = N(\\mu|\\mu_0, (\\beta\\lambda)^{-1})Gam(\\lambda|a,b) $$ 을 구할 수 있다. independent한 두 식을 곱한게 아니다. Normal의 precision이 $\\lambda$에 dependent하다. D-dimension인 경우, Wishart distribution을 이용한다. ","date":"2021-11-26","objectID":"/prml-chap02-3/:0:1","tags":["Gaussian Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (3)","uri":"/prml-chap02-3/"},{"categories":["PRML"],"content":"2.3.7 Student’s t-distribution 위에서 gaussian precision과 관련하여 gamma prior을 이용했다. 이때 $x$에 대한 marginal distribution을 구해보자. $$p(x/\\mu,a,b) = \\int_{0}^{\\infty}N(x/\\mu, \\tau^{-1})Gam(\\tau/a,b)d\\tau \\\\ =\\int_{0}^{\\infty}\\frac{b^a e^{(-b\\tau)}\\tau^{(a-1)}}{\\Gamma(a)}(\\frac{\\tau}{2\\pi})^{1/2}\\exp \\{-\\frac{\\tau}{2}(x-\\mu)^2 \\}d\\tau \\\\ = \\frac{b^a}{\\Gamma(a)}(\\frac{1}{2\\pi})^{1/2}[b+\\frac{(x-\\mu)^2}{2}]^{-a-1/2}\\Gamma(a+1/2) $$ $z = \\tau[b+(x-\\mu)^2/2]$로 놓고 식을 전개하면 $$St(x/\\mu,\\lambda,v) = \\frac{\\Gamma(v/2+1/2)}{\\Gamma(v/2)}\\left(\\frac{\\lambda}{\\pi v}\\right)^{1/2}\\left[1+\\frac{\\lambda(x-\\mu)^2}{v}\\right]^{-v/2-1/2} $$ 이를 Student’s t-distribution 이라고 한다. $v$는 자유도이며 이 값이 무한대로 갈수록 gaussian distribution에 가까워진다. 이 분포의 특징 중 하나는 robustness 라는 것이다. 분포모양이 gaussian distribution과 비슷하지만 (좌우대칭) 더 긴 꼬리를 갖고 있다. 이 때문에 outlier(이상치)에 대해 덜 민감하다. ","date":"2021-11-26","objectID":"/prml-chap02-3/:0:2","tags":["Gaussian Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (3)","uri":"/prml-chap02-3/"},{"categories":["PRML"],"content":"2.3.8 Periodic variables skip ","date":"2021-11-26","objectID":"/prml-chap02-3/:0:3","tags":["Gaussian Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (3)","uri":"/prml-chap02-3/"},{"categories":["PRML"],"content":"2.3.9 Mixtures of Gaussians mixture distribution : linear combination of basic distribution K개의 gaussian distribution을 중첩하면 $$p({\\bf x}) = \\sum_{k=1}^{K}\\pi_k N({\\bf x} | {\\bf \\mu}_k, \\Sigma_k) $$ 이를 Mixture of Gaussian 이라고 부른다. 이 때 각 $N({\\bf x} | {\\bf \\mu}_k, \\Sigma_k)$ 는 component, $\\pi_k$는 mixing coefficients 라고 부른다. $\\pi_k$은 0과 1 사이의 값을 갖고 합이 1이다. 따라사 이를 확률로 이해할 수 있다. 이를 통해 다시 marginal distribution을 전개하면 $$p({\\bf x}) = \\sum_{k=1}^{K}p(k)p({\\bf x}|k)$$ 그렇다면 이제 parameter 추정을 해보자. prameter는 $\\pi, \\mu,\\Sigma$ $$\\ln p({\\bf X}|{\\bf \\pi}, {\\bf \\mu}, \\Sigma) = \\sum_{n=1}^{N}\\ln \\{\\sum_{k=1}^{K} \\pi_k N({\\bf x}_n|{\\bf \\mu}_k, \\Sigma_k) \\}$$ 위의 식에서 MLE를 구하기는 쉽지 않다. log 안에 summation이 있기 때문이다. (미분이 어려움) 이를 구하는 방법은 EM algorithm이다. 나중에 배운다. ","date":"2021-11-26","objectID":"/prml-chap02-3/:0:4","tags":["Gaussian Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (3)","uri":"/prml-chap02-3/"},{"categories":["PRML"],"content":"Gausisan distribution의 성질을 알아보자. ","date":"2021-11-26","objectID":"/prml-chap02-2/:0:0","tags":["Gaussian Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (2)","uri":"/prml-chap02-2/"},{"categories":["PRML"],"content":"2.3 Gaussian distribution Multivariate Gaussian distribution D 차원의 vector $\\textbf{x}$에 대한 distribution entropy가 가장 큰 분포가 gaussian이고 multivariate gaussian도 해당한다. ${\\Sigma}$ : D*D의 covariance matrix $$N(\\pmb{x} | \\pmb{\\mu}, \\pmb{\\Sigma}) = \\frac{1}{(2\\pi)^{D/2}} \\frac{1}{ | \\pmb{\\Sigma} |^{1/2} } \\exp{ -\\frac{1}{2}(\\pmb{x} - \\pmb{\\mu})^T \\pmb{\\Sigma}^{-1}(\\pmb{x} - \\pmb{ \\mu})}$$ Gaussian distribution은 상당히 중요한 특징들을 갖고 있다 하나씩 살펴보자. $$\\Delta^2 = ({\\bf x}-{\\pmb \\mu})^T{\\bf \\Sigma}^{-1}({\\bf x}-{\\pmb \\mu}) $$ $\\Delta$ : Mahalanobis distance from $\\pmb{\\mu}$ to $\\textbf{x}$ $\\pmb{\\Sigma}$가 identity이면 Euclidean distance $\\pmb{\\Sigma}$는 (실수)대칭행렬이므로 고윳값이 실수 고유벡터들은 orthonomal하게 가능 고유대각화가 가능하고 아울어 직교대각화가 가능하다. $${\\bf \\Sigma}=\\sum_{i=1}^{D}{\\pmb \\Lambda}_i{\\bf u}_i{\\bf u}_i^T = U{\\pmb \\Lambda} U^{-1}$$ $${\\bf \\Sigma}^{-1}=\\sum_{i=1}^{D}\\dfrac{1}{\\pmb \\Lambda}_i{\\bf u}_i{\\bf u}_i^T = U {\\pmb \\Lambda}^{-1} U^{-1}$$ 이를 위에 대입하면 $$\\Delta^2 = \\sum_{i=1}^{D}\\frac{y_i^2}{\\pmb \\Lambda}_i $$ $y_i={\\bf u}_i^T({\\bf x}-{\\pmb \\mu})$ 우리는 ${y_i}$를 orthonomal vector $\\textbf{u}_i$에 의해 새롭게 정의된 coordinate system이라고 이해할 수 있다. multivariate gaussian의 평균과 분산은 $E[\\textbf{x}] = {\\pmb \\mu}$ $cov[\\textbf{x}] = {\\pmb \\Sigma}$ : 공분산행렬 (covariance matrix) multivariate gaussian은 유용한 분포지만 한계점도 있다. 공분산행렬의 parameter 개수 공분산행렬의 parameter는 $D(D+3)/2$ 개 이다. 차원이 커짐에 따라 parameter가 quadratic하게 커진다. 이를 위한 해결책은 2가지가 있는데 공분산행렬은 대각행렬로 생각한다. 즉, ${\\pmb \\Sigma} = diag(\\sigma_i^2)$ 공분산행렬을 isotropic covariance로 만든다. 즉, ${\\pmb \\Sigma} = \\sigma^2{\\pmb I}$ 물론 이런 제약이 생기면 data간의 correlation을 못 잡는 경우가 발생한다. gaussian은 unimodal 하기에 multimodal distribution을 잘 approximation하기 어렵다. 이에 대해 해결책은 나중에 뒤에서 배운다. (Mixture 등등) ","date":"2021-11-26","objectID":"/prml-chap02-2/:1:0","tags":["Gaussian Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (2)","uri":"/prml-chap02-2/"},{"categories":["PRML"],"content":"2.3.1 Conditional Gaussian distributions conditional distribution의 경우를 살펴보자. $\\textbf{x}$는 Gaussian distribution $N(\\textbf{x} | {\\pmb \\mu, \\Sigma})$의 D-차원 vector이다. 이를 두 부분으로 나누어 $\\textbf{x}_a, \\textbf{x}_b$ 라고 하자. D*D covariance matrix는 대칭행렬이다. $$\\textbf{x} = \\begin{pmatrix} \\textbf{x}_a \\\\ \\textbf{x}_b \\end{pmatrix}, {\\pmb \\mu} = \\begin{pmatrix} {\\pmb \\mu}_a \\\\ {\\pmb \\mu}_b \\end{pmatrix}$$ $${\\pmb \\Sigma} = \\begin{pmatrix} \\Sigma_{aa} \u0026 \\Sigma_{ab} \\\\ \\Sigma_{ba} \u0026 \\Sigma_{bb} \\end{pmatrix}$$ precision matrix $${\\pmb \\Lambda} \\equiv {\\pmb \\Sigma}^{-1} = \\begin{pmatrix} {\\pmb \\Lambda} _ {aa} \u0026 {\\pmb \\Lambda} _ {ab} \\\\ {\\pmb \\Lambda} _ {ba} \u0026 {\\pmb \\Lambda}_{bb} \\end{pmatrix}$$ 이제 우리는 conditional distribution $p(\\textbf{x}_a | \\textbf{x}_b)$ 을 살펴보자. (gaussian은 quadratic form in the exponent를 주의깊게 살펴보자) $\\textbf{x}_b$는 fixed 되었으며 exp 안의 부분을 나눠서보면 $$-\\frac{1}{2}({\\bf x}-{\\pmb \\mu})^T\\Sigma^{-1}({\\bf x}-{\\pmb \\mu})=$$ $$ -\\frac{1}{2}({\\bf x}_a - {\\pmb \\mu}_a)^T{\\pmb \\Lambda} _ {aa}({\\bf x}_a-{\\pmb \\mu}_a) - \\frac{1}{2}({\\bf x}_a - {\\pmb \\mu}_a)^T {\\pmb \\Lambda} _ {ab}({\\bf x}_b-{\\pmb \\mu}_b)$$ $$-\\frac{1}{2}({\\bf x}_b-{\\pmb \\mu}_b)^T{\\pmb \\Lambda} _ {ba}({\\bf x}_a-{\\pmb \\mu}_a) - \\frac{1}{2}({\\bf x}_b - {\\pmb \\mu}_b)^T{\\pmb \\Lambda} _ {bb}({\\bf x}_b-{\\pmb \\mu}_b) $$ 위 식을 보면 $\\textbf{x}_a$ 에 대한 함수이고 quadratic form 임을 알 수 있다. 즉 conditional dist는 Gaussian인 것이다. 이제 평균과 분산을 구하는 과정을 살펴보자. 먼저, $\\textbf{x}_a$의 second order인 부분을 먼저보면 $$-\\frac{1}{2}\\textbf{x}^T_a {\\pmb \\Lambda}_{aa} \\textbf{x}_a$$ 따라서 우리는 conditional distribution $p(\\textbf{x}_a | \\textbf{x}_b)$의 covariance 가 $${\\pmb \\Sigma_{a|b} = {\\pmb \\Lambda}_{aa}^{-1}}$$ 임을 알 수 있다. 다음은 $\\textbf{x}_a$에 linear한 부분을 보면 $$\\textbf{x}_a^T { {\\pmb \\Lambda} _ {aa} {\\pmb \\mu}_a - {\\pmb \\Lambda} _ {ab}(\\textbf{x}_a - {\\pmb \\mu}_b)}$$ 이를 이용하여 우리는 평균을 구할 수 있다. $${\\pmb \\mu} _ {a|b} = {\\pmb \\Sigma}_{a|b} [ {\\pmb \\Lambda} _ {aa}{\\pmb \\mu}_a - {\\pmb \\Lambda} _ {ab}({\\bf x}_b-{\\pmb \\mu}_b) ] = {\\pmb \\mu}_a -{\\pmb \\Lambda} _ {aa}^{-1}{\\pmb \\Lambda} _ {ab}({\\bf x}_b-{\\pmb \\mu}_b) $$ 다음으로 공분산행렬을 구하면 $${\\pmb \\Sigma}_{a|b} = {\\pmb \\Sigma} _ {aa} - {\\pmb \\Sigma} _ {ab}{\\pmb \\Sigma} _ {bb}^{-1}{\\pmb \\Sigma} _ {ba} $$ [참고] 아래의 공식을 이용하여 구한다. $$$$ $$M = (A-BD^{-1}C)^{-1} $$ 결론 : conditional distribution도 Gaussian distribution이다 mean은 linear function of $\\textbf{x}_b$ covariance은 independent of $\\textbf{x}_b$ ","date":"2021-11-26","objectID":"/prml-chap02-2/:1:1","tags":["Gaussian Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (2)","uri":"/prml-chap02-2/"},{"categories":["PRML"],"content":"2.3.2 Mariginal Gaussian distributions $$p({\\bf x}_a) = \\int p({\\bf x}_a, {\\bf x}_b)d{\\bf x}_b $$ joint distribution에서 integrate out $x_b$하면 된다. 이번에도 마찬가지로 quadratic form을 이용하여 문제를 해결한다. 위에서 봤던 joint distribution의 exp부분을 이번에는 $\\textbf{x}_b$에 대해 전개하면 $$-\\dfrac{1}{2}{\\bf x}_b^{T}{\\pmb \\Lambda} _ {bb}{\\bf x}_b + {\\bf x}_b^T{\\bf m} = -\\dfrac{1}{2}({\\bf x}_b- {\\pmb \\Lambda} _ {bb}^{-1}{\\bf m})^T {\\pmb \\Lambda} _ {bb}({\\bf x}_b- {\\pmb \\Lambda} _ {bb}^{-1}{\\bf m}) + \\dfrac{1}{2}{\\bf m}^T {\\pmb \\Lambda} _ {bb}^{-1}{\\bf m}$$ $$\\text{where}\\;{\\bf m} = {\\pmb \\Lambda}_{bb}{\\pmb \\mu} _ b - {\\pmb \\Lambda} _ {ba}({\\bf x}_a-{\\pmb \\mu}_a)$$ 위의 식 우항에서 첫번째 부분은 quadratic form으로 만들었다. integrate하면 exp부분을 제외한 Gaussian distribution의 normalization constant가 나온다. 이는 첫번째항의 covariance determinant만 관련이 있고 $\\textbf{x}_a$와 independent하다. 결국 중요한건 $\\textbf{x}_a$와 dependent한 뒷부분인데 이를 정리하면 ${\\bf x}_a$에 대한 marginal gaussian distribution가 된다. $$\\dfrac{1}{2}[{\\pmb \\Lambda} _ {bb}{\\pmb \\mu}_b-{\\pmb \\Lambda} _ {ba}({\\bf x}_a-{\\pmb \\mu}_a)]^T {\\pmb \\Lambda} _ {bb}^{-1}[{\\pmb \\Lambda} _ {bb}{\\pmb \\mu}_b-{\\pmb \\Lambda} _ {ba}({\\bf x}_a-{\\pmb \\mu}_a)]$$ $$- \\dfrac{1}{2}{\\bf x}_a^T{\\pmb \\Lambda} _ {aa}{\\bf x}_a + {\\bf x}_a^T({\\pmb \\Lambda} _ {aa}{\\pmb \\mu}_a+{\\pmb \\Lambda} _ {ab}{\\pmb \\mu}_b) + const$$ $$= - \\dfrac{1}{2}{\\bf x}_a^T({\\pmb \\Lambda} _ {aa}-{\\pmb \\Lambda} _ {ab}{\\pmb \\Lambda} _ {bb}^{-1}{\\pmb \\Lambda} _ {ba}){\\bf x}_a + {\\bf x}_a^T({\\pmb \\Lambda} _ {aa}-{\\pmb \\Lambda} _ {ab}{\\pmb \\Lambda} _ {bb}^{-1}{\\pmb \\Lambda} _ {ba}){\\pmb \\mu}_a+const $$ 이를 이용하여 marginal distribution을 구하면 된다. 먼저, covariance는 $${\\pmb \\Sigma}_a = ({\\pmb \\Lambda} _ {aa}-{\\pmb \\Lambda} _ {ab}{\\pmb \\Lambda} _ {bb}^{-1}{\\pmb \\Lambda} _ {ba})^{-1} = {\\pmb \\Sigma} _ {aa}$$ mean은 아래와 같다. $${\\pmb \\Sigma}_a({\\pmb \\Lambda} _ {aa}-{\\pmb \\Lambda} _ {ab}{\\pmb \\Lambda} _ {bb}^{-1}{\\pmb \\Lambda} _ {ba}){\\pmb \\mu}_a = {\\pmb \\mu}_a$$ 결론 : Marginal distribution도 Gaussian distribution이다. $E[\\textbf{x}_a] = {\\pmb \\mu}_a$ $cov[\\textbf{x}_a] = \\Sigma _{aa}$ 직관과 거의 일치한다. (partitioned한 부분) ","date":"2021-11-26","objectID":"/prml-chap02-2/:1:2","tags":["Gaussian Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (2)","uri":"/prml-chap02-2/"},{"categories":["PRML"],"content":"2.3.3 Bayes' theorem for Gaussian variables Gaussian marginal distribution $p(\\textbf{x})$ , Gaussian conditional distribution $p(\\textbf{y} | \\textbf{x})$가 주어진 상태이다. (2.3.1과 2.3.2에서 알게된 사실을 토대로) $$p({\\bf x}) = N({\\bf x}|{\\pmb \\mu}, {\\pmb \\Lambda}^{-1}) $$ $$p({\\bf y}|{\\bf x}) = N({\\bf y}|{\\bf A} {\\bf x}+{\\bf b} , \\textbf{L}^{-1}) $$ 우리는 Gaussian marginal distribution $p(\\textbf{y})$ , Gaussian conditional distribution $p(\\textbf{x} | \\textbf{y})$를 구하고자 한다. 먼저 joint distribution을 구한 뒤에 구해보자. $${\\bf z} = \\dbinom{ {\\bf x} }{ {\\bf y} }$$ $$\\ln p({\\bf z}) = \\ln p({\\bf x}) + \\ln p({\\bf y}) \\\\ = -\\frac{1}{2}({\\bf x}-{\\pmb \\mu})^T{\\pmb \\Lambda}({\\bf x}-{\\pmb \\mu}) -\\frac{1}{2}({\\bf y}-{\\bf A}{\\bf x}-{\\bf b})^T {\\bf L}({\\bf y}-{\\bf A}{\\bf x}-{\\bf b})+const $$ 위의 식은 quadratic 형태의 함수라는 것을 알수 있고 따라서 Gaussian distribution의 함수일 것이다. 위의 식을 전개하여 이차항을 살펴보면 (for covariance) $$-\\frac{1}{2} {\\bf x}^T ({\\pmb \\Lambda} + {\\bf A}^T {\\pmb \\Lambda} {\\bf A}) {\\bf x} - \\frac{1}{2} {\\bf y}^T {\\bf L}{\\bf y} + \\frac{1}{2} {\\bf x}^T {\\bf A}{\\bf L}{\\bf y}$$ $$ = -\\frac{1}{2} \\dbinom{ {\\bf x} }{ {\\bf y} }^T \\left(\\begin{array}{cc}{\\pmb \\Lambda}+{\\bf A}^T{\\bf L}{\\bf A} \u0026 -{\\bf A}^T{\\bf L} \\\\ - {\\bf L}{\\bf A} \u0026 {\\bf L}\\end{array} \\right) \\dbinom{ {\\bf x} }{ {\\bf y} } = -\\frac{1}{2}{\\bf z}^T{\\bf R}{\\bf z}$$ 따라서 precision matrix는 $${\\bf R} = \\left(\\begin{array}{cc}{\\pmb \\Lambda}+{\\bf A}^T{\\bf L}{\\bf A} \u0026 -{\\bf A}^T{\\bf L}\\-{\\bf L}{\\bf A} \u0026 {\\bf L}\\end{array}\\right)$$ 임을 알 수 있다. 이를 inverse하여 covariance matrix를 구하면 $$cov[{\\bf z}]={\\bf R}^{-1} = \\left(\\begin{array}{cc}{\\pmb \\Lambda}^{-1} \u0026 {\\pmb \\Lambda}^{-1}{\\bf A}^T \\ {\\bf A}{\\pmb \\Lambda}^{-1} \u0026 {\\bf L}^{-1}+{\\bf A}{\\pmb \\Lambda}^{-1}{\\bf A}^T \\end{array}\\right)$$ 이전의 방법을 이용하여 mean을 구할 수 있다. $${\\bf x}^T{\\pmb \\Lambda}{\\pmb \\mu} - {\\bf x}^T{\\bf A}^T{\\bf L}{\\bf b} + {\\bf y}^T{\\bf L}{\\bf b} = \\dbinom{ {\\bf x} }{ {\\bf y} }^T \\dbinom {\\pmb \\Lambda}{\\pmb \\mu}-{\\bf A}^T{\\bf L}{\\bf b} {\\bf L}{\\bf b} $$ $$E[{\\bf z}] = {\\bf R}^{-1}\\dbinom{ {\\bf x} }{ {\\bf y} }^T\\dbinom {\\pmb \\Lambda}{\\pmb \\mu}-{\\bf A}^T{\\bf L}{\\bf b} {\\bf L}{\\bf b}$$ 전개하면 최종적으로 mean은 $$E[{\\bf z}] = \\dbinom{ {\\pmb \\mu} }{ {\\bf A} {\\pmb \\mu} - {\\bf b}}$$ 결과 $$E[{\\bf y}] = {\\bf A}{\\pmb \\mu} + {\\bf b}$$ $$cov[{\\bf y}] = {\\bf L}^T + {\\bf A}{\\pmb \\Lambda}^{-1}{\\bf A}^T $$ 다음은 conditional distribution $p(\\textbf{x}| \\textbf{y})$ 의 mean, covariance를 구하면 $$\\Sigma_{a|b}={\\pmb \\Lambda} _ {aa}^{-1} \\ {\\pmb \\mu}_{a|b}={\\pmb \\mu}_a - {\\pmb \\Lambda} _ {aa}^{-1}{\\pmb \\Lambda} _ {ab}({\\bf x}_b-{\\pmb \\mu}_b)$$ $$E[{\\bf x}|{\\bf y}] = ({\\pmb \\Lambda}+{\\bf A}^T{\\bf L}{\\bf A})^{-1}{ {\\bf A}^T{\\bf L}({\\bf y}-{\\bf b})+{\\pmb \\Lambda}{\\pmb \\mu}} $$ $$cov[{\\bf x}|{\\bf y}] = ({\\pmb \\Lambda}+{\\bf A}^T{\\bf L}{\\bf A})^{-1} $$ ","date":"2021-11-26","objectID":"/prml-chap02-2/:1:3","tags":["Gaussian Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (2)","uri":"/prml-chap02-2/"},{"categories":["PRML"],"content":"2.3.4 Maximum likelihood for the Gaussian Log likelihood $$\\ln p({\\bf X}|{\\pmb \\mu}, \\Sigma) = -\\frac{ND}{2}\\ln(2\\pi) - \\frac{N}{2}\\ln|\\Sigma|-\\frac{1}{2}\\sum_{n=1}^{N}({\\bf x}_n-{\\pmb \\mu})^T\\Sigma^{-1}({\\bf x}_n-{\\pmb \\mu})$$ (과정 생략) $${\\pmb \\mu} _ {ML} = \\frac{1}{N}\\sum_{i=1}^{N}{\\bf x}_i = \\bar{\\bf x}$$ $${ \\pmb \\Sigma} _ {ML} = \\frac{1}{N}\\sum_{i=1}^{N}({\\bf x}_i-\\mu)({\\bf x}_i-\\mu)^T$$ ","date":"2021-11-26","objectID":"/prml-chap02-2/:1:4","tags":["Gaussian Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (2)","uri":"/prml-chap02-2/"},{"categories":["PRML"],"content":"2.3.5 Sequential estimation data sample이 하나 들어오면 바로 계산하고 버린다. MLE를 구하는 예시를 살펴보자. $${\\pmb \\mu} _ {ML}^{(N)} = \\frac{1}{N} \\sum_{n=1}^{N}{\\bf x}_n = \\frac{1}{N}{\\bf x} _ N + \\frac{1}{N} \\sum _ {n=1}^{N-1}{\\bf x}_n$$ $$= \\frac{1}{N}{\\bf x}_N + \\frac{N-1}{N}{\\pmb \\mu} _ {ML}^{(N-1)}={\\pmb \\mu} _ {ML}^{(N-1)}+\\frac{1}{N}({\\bf x}_N-{\\pmb \\mu} _ {ML}^{(N-1)}) $$ 이전에 구한 parameter를 ‘error signal’ $(\\textbf{x} _N - {\\pmb \\mu} _{ML}^{(N-1)})$ 쪽으로 1/N에 비례하도록 수정하여 parameter를 업데이트한다. $N$이 커질수록 새로운 data의 영향은 작아진다. 이번에는 이런 Sequential estimation에서 사용되는 일반적인 방법에 대해 살펴보자. 바로 Robbins-Monro algorithm이다. random variables $\\theta, z$가 있다. conditional expectation은 $$f(\\theta)\\equiv E[z|\\theta] = \\int zp(z|\\theta)dz $$ 이고 이러한 형태를 regression function이라고 부른다. 우리의 목표는 $f(\\theta^{ * }) = 0$을 만족하는 root $\\theta^{ * }$를 찾는 것이다. 몇가지 가정을 살펴보면 data가 많으면 한번에 regression function을 만들고 root를 estimation할 수 있겠지만 지금은 Sequential하게 data가 하나씩 구해진다고 가정한다. $E[(z-f)^2 | \\theta]\u003c\\infty$ : conditional variance는 finite하다고 가정한다. $\\theta \u003e \\theta^{ * } \\rightarrow f(\\theta) \u003e 0$ $\\theta \u003c \\theta^{ * } \\rightarrow f(\\theta) \u003c 0$ Robbins-Monro의 방법은 $$\\theta^{(N)} = \\theta^{(N-1)} - a_{N-1} z(\\theta^{N-1}) $$ 여기서 $z(\\theta^{(N)})$은 N번째의 $\\theta$가 들어왔을 때, $z$의 값을 의미한다. $a_N$은 양의 실수이며 다음과 같은 조건을 갖는다. $\\lim_{N\\rightarrow\\infty}a_N=0 $ : $\\theta$가 특정값에 수렴 $\\sum_{N=1}^{\\infty}a_N=\\infty $ : root를 찾기도 전에 다른 값에 수렵하지 않도록 $% $ : 축적되는 noise가 finite하여 수렴을 방해하지 않는다. 이제 이 방법을 통해 이전에 구했던 MLE의 예시에 적용해보자. $$\\frac{\\partial}{\\partial\\theta}{-\\frac{1}{N}\\sum_{n=1}^{N}\\ln p(x_n|\\theta)}_ {\\theta_{MLE}}=0$$ MLE는 위처럼 log likelihood function을 미분하여 0으로 만드는 값니다. as $N \\rightarrow \\infty$ $$-\\lim_{n\\rightarrow\\infty}\\frac{1}{N}\\sum_{n=1}^{N}\\frac{\\partial}{\\partial\\theta}\\ln p(x_n|\\theta) = E_x\\left[-\\frac{\\partial}{\\partial\\theta}\\ln p(x|\\theta)\\right] $$ 이제 Robbins-Monro의 방법을 적용하면 $$\\theta^{(N)} = \\theta^{(N-1)} - a_{N-1}\\frac{\\partial}{\\partial\\theta^{(N-1)}}\\left[-\\ln p(x_N/\\theta^{(N-1)})\\right] $$ $$z=\\frac{\\partial}{\\partial\\mu_{ML}}[-\\ln p(x|\\mu_{ML}, \\sigma^2)]=-\\frac{1}{\\sigma^2}(x-\\mu_{ML}) $$ 따라서 $\\textbf{x}_N$을 대입하고 $a_N = \\sigma^1 / N$을 대입하면 처음에 구한 결과와 같다. ","date":"2021-11-26","objectID":"/prml-chap02-2/:1:5","tags":["Gaussian Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (2)","uri":"/prml-chap02-2/"},{"categories":["PRML"],"content":"이번 장은 주어진 데이터를 이용하여 Distribution을 만드는 것을 배울 것이다. density estimation을 하는 것이다. 이에 대한 방법으로 크게 parametric, nonparmetric 방법으로 나눌 수 있다. 추가로 몇가지 중요한 분포들에 대해 살펴볼 것이다. ","date":"2021-11-26","objectID":"/prml-chap02-1/:0:0","tags":["Bayesian","Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (1)","uri":"/prml-chap02-1/"},{"categories":["PRML"],"content":"2.1 Binary Variables 동전던지기와 같이 random variable이 딱 두가지의 값을 가지는 경우 ($x \\in {0,1}$) 에 대해 살펴보자. Bernoulli distribution $x=1$의 확률을 $p(x=1 | \\mu) = \\mu$ 라고 하자. ($0\\le \\mu \\le 1$) $E[x] = \\mu, Var[x] = \\mu(1-\\mu)$ parameter를 MLE로 추정하면 $\\mu_{ML} = \\frac{1}{N}\\sum_{n=1}^{N}{x_n}$ $$Bern(x | \\mu) = \\mu^x (1- \\mu)^{1-x}$$ MLE의 문제점을 여기서 볼 수 있다. 만약에 동전을 3번 던져서 모두 앞면이 나왔다고 하자. 이 data를 기반으로 동전이 앞면이 나올 확률을 MLE로 추정한다면 1일 것이다. 이처럼 극단적으로 overfitting이 되는 경우가 생길 수 있다. 이에 대한 해결책으로는 더 많은 data를 수집하거나 bayesian의 관점으로 접근해야 한다. Binomial distribution N번 중 $\\mu$의 확률로 사건이 $x$개 발생한 경우 (Bernoulli trial이 N번 발생) $$Bin(x | sN,\\mu) = \\begin{pmatrix} N \\ x \\end{pmatrix}\\mu^x (1-\\mu)^{N-x}$$ $$E[x] =N \\mu, Var[x] =N \\mu(1-\\mu)$$ ","date":"2021-11-26","objectID":"/prml-chap02-1/:1:0","tags":["Bayesian","Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (1)","uri":"/prml-chap02-1/"},{"categories":["PRML"],"content":"2.1.1 The beta distribution 위의 분포를 보고 bayesian의 접근방식을 생각해보자. parameter $\\mu$에 대한 prior를 만들어보자. conjugacy (prior와 posterior가 같은 분포를 갖는) 의 성질을 이용하면 Beta distribution을 생각할 수 있다. prior도 Beta이고 posterior도 Beta distribution의 모습을 보이도록 만들어준다. conjugacy를 이용하면 계산, 해석적인 측면에서 상당히 유용하다. $$Beta(\\mu | a,b) = \\frac{\\Gamma(a+b)}{\\Gamma (a) \\Gamma (b)}\\mu^{a-1}(1-\\mu)^{b-1}$$ $$E[\\mu] = \\frac{a}{a+b}, Var[\\mu] = \\frac{ab}{(a+b)^2(a+b+1)}$$ Binomial likelihood function과 Beta prior를 곱하여 posterior dist of $\\mu$ 를 만들면 $$p(\\mu | x,l,a,b) \\propto \\mu^{x+a-1} (1-\\mu)^{N-x+b-1}$$ 합이 1이 되게 constant를 만들지 않아도 posterior가 beta distribution임을 파악할 수 있다. posterior에서 $a$와 $b$는 각각 $x=1$, $x=0$ 인 data의 수와 같은 의미(역할)임을 알 수 있다. 우리는 prior를 beta로 이용했고 posterior가 beta로 나왔다. 그렇다면 나온 posterior를 다시 prior로 이용할 수 있을 것이다. 이처럼 sequential한 접근이 가능해진다. 우리의 목표는 predict이므로 predictive distribution을 구해보자. $$p(x=1 | D) = \\int_{0}^{1} p(x=1,\\mu | D)d\\mu$$ $$= \\int_{0}^{1} p(x=1 | \\mu)p(\\mu | D)d\\mu = \\int_{0}^{1}\\mu p(\\mu | D)d\\mu = E[\\mu | D]$$ 여기서 posterior dist의 평균을 구하면 $$p(x=1|D) = \\frac{x+a}{x+a+N-x+b}$$ 이고 데이터의 수가 많아지면 posterior mean은 MLE와 같아진다. 또한, uncertainty도 줄어들며 likelihood function의 모양과 가까워진다. 물론, 반대로 prior의 정보가 강하다면 prior와 비슷해진다. prior가 강하거나 data수가 많아 likelihood가 강해지면 uncertainty가 줄면서 posterior distribution의 모양이 뾰족해진다. 수리통계학에서 배웠던 공식을 이용하여 살펴보면 $E_{\\theta}[\\theta] = E_{D}[E_{\\theta}[\\theta|D]]$ D에 대해 averaged over된 posterior mean of $\\theta$ = prior mean of $\\theta$ $V_{\\theta}[\\theta] = E_{D}[V_{\\theta}[\\theta|D]]+V_{D}[E_{\\theta}[\\theta|D]]$ 평균적으로 posterior variance of $\\theta$가 prior variance보다 더 작다. ","date":"2021-11-26","objectID":"/prml-chap02-1/:1:1","tags":["Bayesian","Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (1)","uri":"/prml-chap02-1/"},{"categories":["PRML"],"content":"2.2 Multinomial Variables 이번에는 확률변수가 2가지의 값을 갖는게 아닌 K개의 값을 갖는 경우를 살펴보자. 이를 위해 우리는 vector로 확률변수를 표현한다. 예를 들어, 주사위를 던졌더니 3이란 수가 나왔다. $\\textbf{x} = (0,0,1,0,0,0)^T$ 이렇게 표현한다. 각 원소 $x_k$들의 합은 1이다. $x_k=1$인 확률을 parameter $\\mu_k$로 표현하면, $\\textbf{x}$의 distribution은 $$p(\\textbf{x} | {\\pmb \\mu}) = \\prod_{k=1}^{K}\\mu_{k}^{x_k}$$ $\\sum \\mu_k = 1, 0\\le\\mu_k\\le 1$ 이다. expectation은 $$E[{\\bf x}|{\\pmb \\mu}] = \\sum_{\\bf x}p({\\bf x}|{\\pmb \\mu}){\\bf x} = (\\mu_1, …, \\mu_K)^T = {\\pmb \\mu}$$ 으로 구할 수 있다. 그렇다면 이제 likelihood function을 구해보자. $$p(D|{\\pmb \\mu}) = \\prod_{n=1}^{N}\\prod_{k=1}^{K}\\mu_k^{x_{nk}} = \\prod_{k=1}^{K}\\mu_k^{\\sum_n x_{nk}}=\\prod_{k=1}^{K}\\mu_k^{m_k}$$ $m_k = \\sum_{n} x_{nk}$ : 전체 data에서 k값을 가지는 data 갯수 이 likelihood function을 이용하여 parameter ${\\pmb \\mu}$를 구해보자. constraint $\\sum_{k=1}^{K}{\\mu_k} = 1$ 에서 log likelihood 를 최대화 해야 한다. Lagrange multiplier $\\lambda$를 이용하여 아래 식을 최대화하면 된다. (Lagrange method) $$\\sum_{k=1}^{K}{m_k \\ln \\mu_k} + \\lambda (\\sum_{k=1}^{K}{\\mu_k}-1) $$ $\\mu_k$에 대해 미분하면 $\\mu_k = - m_k / \\lambda$ 이고 constraint때문에 $\\lambda = - N$ 이라는 것을 파악할 수 있다. 따라서 MLE는 $$\\mu_k = \\frac{m_k}{N}$$ Multinomial distribution $\\sum \\mu_k = 1, 0\\le\\mu_k\\le 1$ $\\sum m = N$ $$\\text{Multi}(m_1,m_2, … , m_K | \\mu, N) = \\frac{N!}{m_1! m_2! … m_K!}\\prod_{k=1}^{K}{\\mu_k^{m_k}}$$ ","date":"2021-11-26","objectID":"/prml-chap02-1/:2:0","tags":["Bayesian","Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (1)","uri":"/prml-chap02-1/"},{"categories":["PRML"],"content":"2.2.1 The Dirichlet distribution $$Dir(\\boldsymbol{\\mu} | \\boldsymbol{\\alpha}) = \\frac{\\Gamma (\\alpha_0)}{\\Gamma (\\alpha_1) \\Gamma(\\alpha_2)…\\Gamma(\\alpha_K)}\\prod_{k=1}^{K}{\\mu_k^{\\alpha_k - 1}}$$ $\\sum \\mu_k = 1, 0\\le\\mu_k\\le 1$ Multinomial의 conjugate prior K = 2이면 beta 분포이다. Binomial의 일반화된 분포가 Multinomial이듯 Beta의 일반화된 분포가 Dirichlet 분포라고 할 수 있다. posterior $$p({\\pmb \\mu}|D, {\\pmb \\alpha}) \\propto p(D|{\\pmb \\mu})p({\\pmb \\mu}|{\\pmb \\alpha}) \\propto \\prod_{k=1}^{K} \\mu_k^{\\alpha_k+m_k-1}$$ 이전에 봤듯이 prior의 $a_k$는 data에서 ‘observation of $x_k=1$’ 의 갯수와 같은 의미(역할)이라고 할 수 있다. ","date":"2021-11-26","objectID":"/prml-chap02-1/:2:1","tags":["Bayesian","Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (1)","uri":"/prml-chap02-1/"},{"categories":["PRML"],"content":"Information Theory에 대해 알아봅시다. ","date":"2021-11-26","objectID":"/prml-chap01-3/:0:0","tags":["Information Theory"],"title":"[PRML] Chapter1 - Introduction (3)","uri":"/prml-chap01-3/"},{"categories":["PRML"],"content":"1.6 Information Theory 일단 entropy에 대해 두 가지의 시선으로 살펴볼 예정이다. 일단 discrete random variable $x$와 이 variable의 specific value를 알아내면서 얻는 정보의 양이 얼마나 되는지로부터 시작한다. 어떤 사건이 일어날 확률이 큰 경우보다 일어날 확률이 작은 사건이 더 정보가 많다고 한다. 이에 따라 우리는 information content ($h(x)$ 라고 하자) 를 측정하는 방법이 필요하다. 그 방법의 조건은 확률 $p(x)$에 대해 monotonic function 두 개의 사건이 독립적이면 information gain은 두 information의 합으로 표현 이런 조건을 만족시키기 위해 우리는 logarithm을 이용한다. ($\\log_2$인 이유는 2진수 bit단위의 정보전달의 측면에서 접근하기 위해) $$h(x) = - \\log_2 p(x)$$ information은 0이상의 값을 갖기에 음수부호를 붙여서 사용한다. 이제 sender가 receiver에게 random variable의 값을 전달해야하는 상황이라고 가정하자. 그들이 전달하는 정보의 평균적인 양은 $$H[x] = - \\sum_{x}{p(x)\\log_2 p(x)}$$ 이를 우리는 entropy of the random variable x 라고 부른다. (예시는 생략) nonuniform distribution은 uniform distribution보다 더 작은 entropy값을 갖는다. entropy의 값을 정보전달의 측면 (bit단위라고 생각) 에서 생각해보자. 예를 들면, A집단의 entropy가 2, B집단의 entropy가 3의 값을 가진다. A의 내용을 전달하기 위해서는 최소 2bit, B는 최소 3bit가 필요한 것을 의미하고 이처럼 entropy는 the state of a random variable을 전달하기 위해 필요한 bits 수의 lower bound이다. 이번에는 entropy에 대해 다른 시각으로 살펴보자. N개의 물체를 bin에 나누어 담아야 한다. $i^{th}$ bin 에는 $n_i$개의 물체가 들어간다. 물체를 나누어 담는 경우의 수 $W$ 를 생각해보면 $$W = \\frac{N!}{\\prod_i n_i !}$$ 이를 multiplicity 라고 부른다. entropy를 만들기 위해 logarithm과 적절한 scaled 취하면 $$H = \\frac{1}{N}\\ln w = \\frac{1}{N} \\ln N! - \\frac{1}{N}\\sum_{i} \\ln n_i !$$ N이 무한대로 가고 $n_i / N$은 fixed 된다. 그리고 Stirling’s approximation을 이용하면 $\\ln N ! \\approx N \\ln N - N$ $\\ln n_i ! \\approx n_i \\ln n_i - n_i$ 이를 대입하면 $$H = - \\lim_{N \\rightarrow \\infty} \\sum_{i} \\frac{n_i}{N} \\ln \\frac{n_i}{N} = - \\sum_{i}{p_i \\ln p_i}$$ $\\sum_i n_i = N$ $p_i = \\lim_{N \\rightarrow \\infty} (n_i / N)$ : 물체가 i bin에 들어갈 확률 우리는 bin을 random variable X의 state $x_i$ 라고 할 수 있다. 따라서 random variable X의 entropy는 $$H[p] = - \\sum_{i}{p(x_i)\\ln p(x_i)}$$ 우리는 Lagrange를 이용하여 위의 식의 최댓값을 구할수 있고 최댓값은 Uniform distribution 일 때이다. 이제 continuos variable에서도 생각해보자. (과정 생략) continuos variable의 entropy는 아래 값을 가진다. $$H[x] = - \\int p(x) \\ln p(x) dx$$ 이를 differential entropy 라고 부른다. discrete의 경우에서와 마찬가지로 continuos에서는 어떤 distribution이 가장 큰 entropy를 가질까? (과정 생략, 똑같이 Lagrange 사용) 정답은 Gaussian distribution 인 경우이다. ","date":"2021-11-26","objectID":"/prml-chap01-3/:1:0","tags":["Information Theory"],"title":"[PRML] Chapter1 - Introduction (3)","uri":"/prml-chap01-3/"},{"categories":["PRML"],"content":"1.6.1 Relative entropy and mutual information 우리가 모르는 distribution $p(x)$가 있다고 가정해보자. 이를 approximation하는 $q(x)$를 모델링하였다. 이전에 정보전달에서의 측면에서 생각해보면 우리는 approximation 했기에 random variable 의 value 전달을 위해 추가적으로 리소스 bit가 더 필요하다. 더 필요한 정도는 $$KL(p| q) = - \\int p(\\textbf{x}) \\ln q(\\textbf{x})d\\textbf{x} - (- \\int p(\\textbf{x}) \\ln p(\\textbf{x})d\\textbf{x}) \\ = - \\int p(\\textbf{x})\\ln \\frac{p(\\textbf{x})}{q(\\textbf{x})}d\\textbf{x}$$ 이를 Kullbak-Leibler divergence (Relative entropy) between $p(\\textbf{x})$ and $q(\\textbf{x})$ 라고 부른다. 그리고 아래와 같은 특징을 갖는다. (이러한 특징을 통해 Kullbak-Leibler divergence는 measure of the dissimilarity of the two distributions $p(\\textbf{x}), q(\\textbf{x})$ 라고 할 수 있다.) $KL(p| q) \\ge 0$ $KL(p| q) = 0$, if and only if, $p(\\textbf{x}) = q(\\textbf{x})$ 증명은 Jensen’s inequality로 쉽게 할 수 있다. convex function $f(x)$는 $$f(\\sum_{i=1}^{M}{\\lambda_i x_i}) \\le \\sum_{i=1}^{M}{\\lambda_i f(x_i)}$$ $\\lambda \\ge 0$ $\\sum_i \\lambda_i = 1$ 의 특징을 갖는다. 위에서 $\\lambda_i$를 x의 확률분포라고 생각하면 $f(E[x]) \\le E[f(x)]$ 이다. 따라서 ($f$ 를 -log라고 생각하면 된다) $$KL[p|q] = - \\int p(\\textbf{x}) \\ln \\frac{q(\\textbf{x})}{p(\\textbf{x})}d\\textbf{x} \\ge - \\ln \\int q(\\textbf{x}) d\\textbf{x} = 0 $$ KL divergence를 최소화하는 것은 결국 likelihood function을 최대화하는 것과 같은데 이에 대해 살펴보자. 우리가 모르는 (approximation해야하는) 분포 $p(\\textbf{x})$에서 data가 generate되었다고 하자. 우리는 어떤 parametric distribution $q(\\textbf{x} | \\theta)$ 를 통해 approximation하고자 한다. $\\theta$를 정하는 방법은 $\\theta$에 대해 KL divergence를 최소화하는 것을 찾는 것이다. 그런데 우리는 $p(\\textbf{x})$를 모르는 상황이기에 directly할 수 없다. 대신 N개의 train data가 존재하므로 이를 이용하면 $$KL(p|q) \\approx \\sum_{n=1}^{N}{{ - \\ln q (\\textbf{x}_n | {\\bf \\theta}) + \\ln p(\\textbf{x}_n)} }$$ 우변의 두번째항은 parameter와 independent하다. 첫번째항은 negative log likelihood function for $\\theta$ of under the distribution $q(\\textbf{x} | \\theta)$ (train data를 통해 만들어진 분포) 이므로 KL divergence를 최소화하는 것은 likelihood function을 최대화하는 것이다. 이번에는 joint distribution을 생각해보자. 두 변수가 independent이면 $p(\\textbf{x}\\textbf{y}) = p(\\textbf{x})p(\\textbf{y})$ 이다. 하지만 independent가 아닌 경우, 우리는 KL divergence를 통해 얼마나 independent와 가까운지 생각해볼수 있다. $$I[\\textbf{x}, \\textbf{y}] \\equiv KL(p(\\textbf{x}, \\textbf{y}) | p(\\textbf{x})p(\\textbf{y})) = - \\int \\int p(\\textbf{x}, \\textbf{y}) \\ln \\frac{p(\\textbf{x})p(\\textbf{y})}{p(\\textbf{x}, \\textbf{y})}d\\textbf{x} d\\textbf{y}$$ 이를 mutual information between the variable x and y 라고 부른다. conditional entropy의 측면에서 $I[\\textbf{x}, \\textbf{y}] = H[\\textbf{x}] - H[\\textbf{x}|\\textbf{y}] = H[\\textbf{y}] - H[\\textbf{y}/\\textbf{x}]$ 따라서 MI는 y를 알고 난 뒤에 x의 uncertainty가 줄어든 정도 (반대도 성립) 라고 할 수 있다. Bayesian의 입장에서는 $p(\\textbf{x})$가 pior이고 $p(\\textbf{x} | \\textbf{y})$는 y data를 얻은 후의 posterior이다. 따라서 MI는 새로운 observation y의 등장으로 줄어든 x의 uncertainty라고 할 수 있다. ","date":"2021-11-26","objectID":"/prml-chap01-3/:1:1","tags":["Information Theory"],"title":"[PRML] Chapter1 - Introduction (3)","uri":"/prml-chap01-3/"},{"categories":["PRML"],"content":"Decision Theory에 대해 알아봅시다. ","date":"2021-11-26","objectID":"/prml-chap01-2/:0:0","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"1.5 Decision Theory Decision Theory는 크게 두 가지의 과정으로 이루어져 있다. Determining $p(x,t)$ from a training data set : inference 이를 통하여 새로운 데이터에 대해 결정(분류,회귀) : decision Decision Theory의 목표는 적절한 Probability들을 이용하여 optimal한 decision을 내리는 것이다. 2-class classification의 상황을 예시로 뒤의 내용을 진행한다. 우리는 input data를 통해 해당 data의 class를 구분하고 싶기에 $p(C_k / \\textbf{x})$를 구해야 한다. Bayes' theorem을 생각해보면 posterior를 구해야 하는 것이다. $$p(C_k | \\textbf{x}) = \\frac{p(\\textbf{x} | C_k)p(C_k)}{p(\\textbf{x})}$$ 우리는 misclassfication을 최소화하기 위해서 둘 중 더 큰 posterior probability갖는 class에 input data를 분류한다. ","date":"2021-11-26","objectID":"/prml-chap01-2/:1:0","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"1.5.1 Minimizing the misclassfication rate 우리의 목표가 misclassfication을 최소화하는게 목표라고 하자. 각 $\\textbf{x}$를 class에 분류해야하고 이를 위해 rule이 필요하다. 그 rule에 따라 input space를 region $R_k$로 나눠야 한다. 이 region을 decision regions 라고 한다. ($R_k$에 속한 data는 class k라고 분류) decision region간의 경계선을 decision boundary, decision surface 라고 부른다. misclassfication의 확률은 $$P(mistake) = P(\\textbf{x} \\in R_1, C_2) + P(\\textbf{x} \\in R_2, C_1) = \\int_{R_1} p(\\textbf{x}, C_2)d\\textbf{x}+ \\int_{R_2} p(\\textbf{x}, C_1)d\\textbf{x}$$ mistake의 확률을 최소화하기 위해서는 각 integral의 값을 최소화해야 한다. 따라서 만약 $p(\\textbf{x}, C_1) \u003e p(\\textbf{x}, C_2)$의 경우, data를 class1으로 분류해야한다. $p(\\textbf{x}, C_k) = p(\\textbf{x}) p(C_k | \\textbf{x})$ 이고 우변의 $p(\\textbf{x})$는 공통된 부분이므로 우리는 $p(C_k | \\textbf{x})$만 고려하면 된다. ","date":"2021-11-26","objectID":"/prml-chap01-2/:1:1","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"1.5.2 Minimizing the expected loss 위에서 misclassfication rate를 줄이는 부분에 대해서 살펴봤다. 하지만 실제로 분류를 할 때는 이 접근으로는 부족하다. 예를 들어, 암환자를 분류하는 문제라고 생각해보자. 암이 걸리지 않은 환자를 걸렸다고 잘못 판단하는 것과 암이 걸렸는데 걸리지 않았다고 판단하는 것. 둘 중 후자가 훨씬 심각한 문제이다. 이런 경우 후자에 대해 더 가중치가 있어야 하지 않을까? loss function (cost function) : overall measure of loss incurred in taking any of the available decisions or actions $L_{kj}$ : (k인데 j로 분류한 경우) loss matrix의 element를 의미한다. misclassfication에 대한 loss라고 이해하면 된다. 예를 들면 암환자의 loss matrix는 아래와 같은 모양이다. $$\\begin{bmatrix} 0 \u0026 100 \\\\ 1 \u0026 0 \\end{bmatrix}$$ (inference가 끝난 뒤에 decision하는 과정에 해당) optimal solution은 loss function을 최소화하는 것이다. 하지만 loss function은 true class을 알아야 계산할 수 있다. 우리는 true class를 모른다. (예를 들어, 환자의 신상데이터가 있고 이를 통해 암환자인지 아닌지 찾아야하는 상황) 따라서 우리는 expected (average) loss를 최소화하는 방법을 선택한다. $$E[L] = \\sum_{k} \\sum_{j} \\int_{R_j} L_{kj} p(\\textbf{x}, C_k) d\\textbf{x}$$ 우리의 목표는 expected loss를 최소로 만드는 적절한 $R_j$를 찾는 것이고 이는 각 데이터 $\\textbf{x}$가 $\\sum_{k} L_{kj}p(\\textbf{x}, C_k)$를 최소화 한다는 것을 의미한다. 최종적으로 expected loss를 최소화 하기 위해서는 $\\textbf{x}$를 값 $$\\sum_{k}{L_{kj} p(C_k|\\textbf{x})}= E[L(C_k, \\hat{C}_k) | X=\\textbf{x}]$$ 이 최소가 되는 class $j$로 분류하는 것이다. ","date":"2021-11-26","objectID":"/prml-chap01-2/:1:2","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"1.5.3 The reject option class에 따라 posterior의 비교를 통해 결정하기 애매한 상황이 생긴다. 이런 경우에는 probability에 따라 결정하기 보다는 다른 방법을 사용하는 것이 적절할 수도 있다. (예를 들면, 해당 데이터를 model이 아니라 전문가가 판단하는 방법) 이런 경우 regect option 이 있다고 할 수 있는 것이다. ","date":"2021-11-26","objectID":"/prml-chap01-2/:1:3","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"1.5.4 Inference and decision decision 문제를 해결하는 방법을 3가지로 분류할 수 있다. 앞쪽의 방법일수록 복잡한 방법이다. generative model 아래 식에서 posterior를 구하기 위해서는 분자, 분모를 다 구해야 한다. 한마디로 approachs that explicitly or implicitly model the distribution of inputs as well as outputs. 다른 표현으로는, joint distribution $p(\\textbf{x}, C_k)$을 구해서 marginalize하여 분모도 구하여 posterior를 구한다. $$p(C_k | x) = \\frac{p(x | C_k)p(C_k)}{p(x)}$$ discriminative model approachs that model the posterior probabilities directly 예를 들면 SVM, Tree models, KNN 등등 discriminative function maps each input x directly onto a class label 따라서 확률을 고려하지 않는다. inference와 decision stage를 하나로 묶은 것이다. 각각 장단점이 존재한다. 예를 들면, 1번에서 prior $p(\\textbf{x})$를 구했으므로 해당 값이 너무 작은 새로운 data는 무시하는 판단을 할 수 있다. (outlier detection하는 것처럼) 그렇다면 이제 (1,2번 선호) posterior를 구하면 어떤 장점이 있는지 알아보자. Minimizing risk 이전에 봤던 loss matrix를 수정하여 decision criterion을 수정하기 쉽다. 확률의 threshold를 조정하여 decision criterion을 수정하기 쉽다. Reject option expected loss뿐만 아니라 misclassfication rate를 최소화하는 rejection criterion을 정할 수 있게 해준다. Compensating for class priors posterior는 prior에 비례하므로 prior를 적절하게 바꿔줌으로서 posterior를 보완할 수 있다. Combing models 특정 문제를 subproblem으로 나누어서 생각할 수 있다. 예를 들면, naive bayes model과 같이 independent를 이용하여 posterior를 나누어서 생각할 수 있는 장점이 생긴다. ","date":"2021-11-26","objectID":"/prml-chap01-2/:1:4","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"1.5.5 Loss functions for regression 이전까지 classification에 대해 살펴봤으므로 이번에는 regression에 대해 살펴보자. expected (average) loss는 $$E[L] = \\int \\int L(t, y(\\textbf{x})) p(\\textbf{x}, t) d\\textbf{x}dt$$ 이다. regression에서 주로 사용하는 loss function은 squared loss이고 이를 통해 다시 쓰면 $$E[L] = \\int \\int {y(\\textbf{x}) - t}^2 p(\\textbf{x}, t) d\\textbf{x} dt$$ 이다. 우리는 이를 최소화하는 $y(\\textbf{x})$를 찾는 것이 목표이므로 미분하여 구할 수 있다. $$\\frac{dE[L]}{dy(\\textbf{x})} = 2\\int { y(\\textbf{x}) - t}p(\\textbf{x}, t) dt = 0$$ $$y(\\textbf{x}) = \\frac{\\int t p(\\textbf{x}, t)dt}{p(\\textbf{x})} = \\int t p(t | \\textbf{x})dt = E_t [t | \\textbf{x}]$$ 이는 우리가 알고 있는 regression function의 모양이다. (conditional average of t conditioned on x) 이를 이용하여 추가적인 접근을 해보자면 $${y(\\textbf{x}) - t}^2 = {y(\\textbf{x}) - E[t | \\textbf{x}] + E[t | \\textbf{x}] - t }^2$$ $$E[L] = \\int {y(\\textbf{x}) - E[t | \\textbf{x}]}^2 p(\\textbf{x})d\\textbf{x} + \\int {E[t | \\textbf{x}] - t}^2 p (\\textbf{x}) d\\textbf{x} $$ 두번째 항은 variance of the distribution of t, averaged over x 이다. 따라서 이는 irreducible minumum value of the loss function을 의미한다. ","date":"2021-11-26","objectID":"/prml-chap01-2/:1:5","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"+ Decision Theory 추가 monk의 강의에서 decision theory를 다루는데 해당 내용을 추가하고자 한다. 일단, loss function은 “0-1 loss” 으로 생각하자. true = prediction : 0 true != prediction : 1 두 가지 상황으로 나누어서 살펴보자. 하지만 두 경우 모두의 공통적인 결론은 $p(y/x)$ 가 핵심이라는 것이다. ","date":"2021-11-26","objectID":"/prml-chap01-2/:2:0","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"1. Minimizing conditional expected loss : Given $x$, minimize $L(y, \\hat{y})$ … but don’t know true class $y$ $(X, Y) \\sim P$ : discrete $$E[L(Y, \\hat{y}) | X = x] = \\sum_{y} L(y, \\hat{y}) P(y | x) = \\sum_{y \\neq \\hat{y} } 1*P(y | x) = 1 - P(\\hat{y} | x)$$ $$\\therefore \\hat{y} = argmin_y E[L(Y,\\hat{y}) | x] = argmax_y P(y | x)$$ ","date":"2021-11-26","objectID":"/prml-chap01-2/:2:1","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"2. Choosing f to minimize expected loss : Choose $f(f(x) = y)$ to minimize $L(y, f(x))$ but don’t know $x$ or $y$ $$E[L(Y, \\hat{Y})] = E[L(Y, f(X))] = \\sum_{x,y}L(y, f(x))P(x,y)$$ $$ = \\sum_{x}{\\sum_y L(y, f(x))P(y | x)}P(x) = \\sum_{x}g(x,f(x))p(x) = E_x[g(x,f(x))]$$ suppose for some $x', t$ $g(x', f(x')) \\ge g(x', t)$ $f_0(x) =$ if $x \\neq x', f(x)$ if $x = x', t$ 모든 $x,; g(x,f(x)) \\ge g(x, f_0(x))$ $$\\therefore E_x [g(x, f(x))] \\ge E_x[g(x,f_0(x))]$$ Choose f to min $g(x,f(x))$ $$f(x) = argmin_t g(x,t)$$ ","date":"2021-11-26","objectID":"/prml-chap01-2/:2:2","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"Big picture ","date":"2021-11-26","objectID":"/prml-chap01-2/:2:3","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"Generative model estimate $p(x,y)$ using data and then $p(y|x) = \\frac{p(x,y)}{p(x)}$ parameter / latent : $\\theta$ 라고 하자 $\\theta$는 distribution에 관한 parameter / latent $D$는 random (new data) $$p(y|x,D) = \\int p(y|x,D,\\theta) p(\\theta | x,D) d\\theta$$ $p(y|x,D)$ : predictive distribution $p(\\theta |x,D)$ : posterior distribution $p(y|x,D,\\theta)$ 이 부분은 주로 closed form(eg. regression y=wx)으로 구해지며 어렵지 않다. 하지만 posterior 부분은 closed form으로 못 구하는 경우가 많다. 또한 integral 부분도 계산이 어려운 경우가 많다. 그렇다면 이를 어떻게 해결할까? 크게 4가지의 방법을 살펴보자. exact inference Multivariate Gaussian, Conjugate prior, Graphical model point estimate MLE, MAP (1.2.5를 보면 integral 없이 계산) optimization, EM deteministic approximation Laplace approximation, Variational method, Expectation propagation stochastic approximation Sampling 기법들 (eg. MCMC) ","date":"2021-11-26","objectID":"/prml-chap01-2/:2:4","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"Probability Theory에 대해 알아봅시다. ","date":"2021-11-26","objectID":"/prml-chap01-1/:0:0","tags":null,"title":"[PRML] Chapter1 - Introduction (1)","uri":"/prml-chap01-1/"},{"categories":["PRML"],"content":"1.1 Example : polynomial curve fitting 예를 들어, 회귀에서 error function이 quadratic function of w이면 w에 대한 미분은 w에 linear하고 unique한 closed form의 해를 구할 수 있다. 모델의 overfitting을 항상 조심하고 데이터의 수가 늘어날수록 그 정도는 약해진다. MLE 방법은 overfitting에 취약하며 Bayesian 모델링으로 보완할 수 있다. ridge와 같이 error function에 패널티항을 추가하여 overfitting을 막는 방법도 있다. 이를 shrinkage 방법이라 부른다. (딥러닝에서는 weight decay) 이런 모델의 복잡한 정도를 정하는 데에 validation data set을 만들기도 하는데 이는 다소 낭비이므로 다른 방법을 공부할 것이다. (아마 Bayesian approach일듯) ","date":"2021-11-26","objectID":"/prml-chap01-1/:1:0","tags":null,"title":"[PRML] Chapter1 - Introduction (1)","uri":"/prml-chap01-1/"},{"categories":["PRML"],"content":"1.2 Probability Theory 패턴인식에서 가장 중요한 컨셉은 uncertainty이다. Probability Theory는 이런 uncertainty을 quantification하고 manipulation하는 방법을 제시한다. (확률을 이용하여) The rules of Probability sum rule : $p(X) = \\sum_{Y}{p(X,Y)}$ product rule : $p(X,Y) = p(Y|X)p(X)$ Bayes' Throrem (rule) $p(Y|X) = \\frac{p(X|Y)p(Y)}{p(X)}$ $p(Y)$ : prior probability $p(Y|X)$ : posterior probability ","date":"2021-11-26","objectID":"/prml-chap01-1/:2:0","tags":null,"title":"[PRML] Chapter1 - Introduction (1)","uri":"/prml-chap01-1/"},{"categories":["PRML"],"content":"1.2.1 Probability densities probability density : if the probability of a real-valued variable $x $ falling in the interval $(x, x+\\delta x )$ is given by $p(x)\\delta x$ for $\\delta x \\rightarrow 0$, then $p(x)$ is called the probability density 값은 항상 0 이상, 합하면 1을 가진다. ","date":"2021-11-26","objectID":"/prml-chap01-1/:2:1","tags":null,"title":"[PRML] Chapter1 - Introduction (1)","uri":"/prml-chap01-1/"},{"categories":["PRML"],"content":"1.2.2 Expectations and covariances expection of $f(x)$ : $E[f(x)] = \\int{p(x)f(x)dx}$ it can be approximated as $$E[f] \\approx \\frac{1}{N}\\sum_{n=1}^{N}{f(x_n)}$$ $E_x [f(x,y)]$는 y에 대한 함수이다. x에 대해 averaged over 된 것이다. conditional expection : $E[f(x)|y] = \\int{p(x|y)f(x)dx}$ variance of $f(x)$ : $var[f] = E[(f(x) - E[f(x)])^2]$ $f(x)$가 mean 주위에서 얼마나 variability가 있는지 보여준다. ","date":"2021-11-26","objectID":"/prml-chap01-1/:2:2","tags":null,"title":"[PRML] Chapter1 - Introduction (1)","uri":"/prml-chap01-1/"},{"categories":["PRML"],"content":"1.2.3 Bayesian probabilities 우리가 일반적으로 알고 있는 확률(probability)은 frequentist의 견해이다. bayesian은 frequentist와는 아예 다른 접근법을 갖는다. Frequentist 분모가 되는 전체 사건이 무한대로 일어나고 우리가 궁금한 사건이 그 중 몇번 일어나는지를 확률로 생각한다. parameter 추정이 목표이며 parameter는 fixed 되어 있다고 생각한다. 주로 estimator로서 likelihood function을 최대화하는 MLE로 사용한다. Bayesian 확률 : uncertainty를 quantification한 것으로 생각한다. parameter는 fixed 된 것이 아니라 (probability) distribution을 갖는 것이라고 생각한다. posterior distribution을 찾는 것이 목표이다. Bayes' theorem $$p(\\textbf{w} | D) = \\frac{p(D | \\textbf{w})p(\\textbf{w})}{p(D)}$$ parameter에 대해 원래 갖고 있던 믿음을 data D에 대한 정보를 얻은 뒤에 posterior probability로 업데이트 한다. (분모는 posterior가 합이 1이 되기 위한 normalization constant) prior probability : $p(w)$ likelihood function : $p(D/w)$ posterior probability : $p(w/D)$ posterior $\\propto$ likelihood * prior ","date":"2021-11-26","objectID":"/prml-chap01-1/:2:3","tags":null,"title":"[PRML] Chapter1 - Introduction (1)","uri":"/prml-chap01-1/"},{"categories":["PRML"],"content":"1.2.4 The Gaussian distribution $$N(x | \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi \\sigma^2}}exp{ - \\frac{(x-\\mu)^2}{2 \\sigma^2} }$$ mean : $\\mu$ variance : $\\sigma^2$ standard deviation : $\\sigma$ precision : $\\beta = 1/ \\sigma^2$ normal (gaussian) 분포는 mode와 mean이 같다. i.i.d (independent and identically distributed : data point가 독립적이고 같은 분포에서 나왔다) 인 경우, likelihood function은 $$p(\\textbf{x} | \\mu, \\sigma^2) = \\prod_{n=1}^{N}{N(x_n | \\mu, \\sigma^2)}$$ 이고 이를 최대화하는 mean과 variance의 MLE는 sample mean, sample variance이다. MLE를 구하는 방법은 likelihood function에 log를 취한 후 미분하여 0을 만족하는 parameter를 찾으면 된다. 이때 단점은 maximum likelihood 접근법이 분포의 variance를 underestimate한다(bias 발생)는 점이다. N이 커지면 문제가 없지만 복잡한 모델에서는 이런 bias때문에 문제가 발생할 수 있다. (나중에 공부한다) ","date":"2021-11-26","objectID":"/prml-chap01-1/:2:4","tags":null,"title":"[PRML] Chapter1 - Introduction (1)","uri":"/prml-chap01-1/"},{"categories":["PRML"],"content":"1.2.5 Curve fitting re-visted data를 통해 polynomial curve를 fitting해보자. target t에 대한 uncertainty를 probability를 통해 표현하면 (under gaussian noise distribution) $$p(t | x, \\textbf{w}, \\beta) = N(t | y(x,\\textbf{w}), \\beta^{-1})$$ 위의 식을 이용하여 우리는 parameter $\\textbf{w}$ 추정한다. likelihood를 최대로 하는 MLE를 찾으면 되는 것이다. log likelihood function은 아래와 같은 모양을 갖는다. $$\\ln p(\\textbf{t} | \\textbf{x}, \\textbf{w}, \\beta) = - \\frac{\\beta}{2}\\sum_{n=1}^{N}{{ y(x_n, \\textbf{w}) - t_n }^2} + \\frac{N}{2}\\ln \\beta - \\frac{N}{2}\\ln (2 \\pi)$$ 위 값을 최대화 하는 $\\textbf{w}_{ML}$을 찾으면 된다. 이는 결국 least square 방법과 동일한 의미를 갖는다. (추정선과 target의 차이를 최소화해야되므로) parameter를 추정한 뒤에 이제 prediction을 해야한다. 우리는 확률모델을 갖고 있기에 t에 대한 point estimate만이 아니라 predictive distribution을 만들 수 있다. $$p(t | x, \\textbf{w} _ {ML}, \\beta _ {ML}) = N(y(x,\\textbf{w} _ {ML}), \\beta _ {ML}^{-1})$$ 지금까지는 frequentist의 영역이였다면 Bayesian들은 어떤 접근을 하는지 살펴보자. 일단 우리가 추정해야하는 parameter에 대한 prior를 갖고 있다. prior distribution를 gaussian 분포로 가정하면 아래와 같이 나타낼 수 있다. (Mth order의 polynomial) $$p(\\textbf{w} | \\alpha) = N(\\textbf{0}, \\alpha^{-1}\\textbf{I}) = (\\frac{\\alpha}{2\\pi})^{(M+1)/2} \\exp { -\\frac{\\alpha}{2} \\textbf{w}^T \\textbf{w}}$$ 이를 통해 우리는 posterior distribution를 구할 수 있다. posterior는 likelihood와 prior의 곱에 비례하므로 $$p(\\textbf{w} | \\textbf{x}, \\textbf{t}, \\alpha, \\beta) \\propto p(\\textbf{t} | \\textbf{x}, \\textbf{w}, \\beta)p(\\textbf{w} | \\alpha)$$ 위의 posterior distribution을 최대화로 만드는 parameter를 MAP (MLE에 대응되는 point estimate)라고 부른다. posterior distribution에 negative log를 취한다. posterior를 최대로 만드는 것은 아래를 최소화 하는 것과 같다. $$\\frac{\\beta}{2}\\sum_{n=1}^{N}{{ y(x_n, \\textbf{w}) - t_n }^2} + \\frac{\\alpha}{2}\\textbf{w}^T\\textbf{w}$$ 위 결과를 통해 posterior distribution를 maximizing하는 것은 regularized sum-of-squares error function을 minimizing하는 것과 동일하다는 것을 알 수 있다.. (L2 regularization, Ridge regression) ","date":"2021-11-26","objectID":"/prml-chap01-1/:2:5","tags":null,"title":"[PRML] Chapter1 - Introduction (1)","uri":"/prml-chap01-1/"},{"categories":["PRML"],"content":"1.2.6 Bayesian curve fitting 위의 Bayesian 접근법은 point estimate를 구했기 때문에 살짝 아쉽다. 좀 더 Bayesian적인 방법은 $\\textbf{w}$의 모든 값에 대해 integral over하는 것이다. $\\textbf{w}$에 대해 marginalize하면 되는데 이는 뒤에 자주 나오는 방법이므로 잘 기억하자. 이제 predictive distribution을 구해보자. training data : $\\textbf{x},\\textbf{t}$ new data : $x$ hyperparameter (assume we know) : $\\alpha, \\beta$ (아래식에서는 생략) $$p(t | x, \\textbf{x}, \\textbf{t}) = \\int p(t | x, \\textbf{w})p(\\textbf{w} | \\textbf{x}, \\textbf{t}) d\\textbf{w} = N(t| \\mu(x), s^2(x))$$ $$\\mu (x) = \\beta \\phi (x)^T \\textbf{S} \\sum_{n=1}^{N}{\\phi (x_n)} t_n $$ $$s^2 (x) = \\beta^{-1} + \\phi (x)^T \\textbf{S} \\phi (x)$$ $$\\textbf{S}^{-1} = \\alpha \\textbf{I} + \\beta \\sum_{n=1}^{N}{\\phi (x_n) \\phi (x)^T}$$ vector $\\phi (x)$ : element $\\phi_i (x) = x^i$ for $i = 0, … M$ ","date":"2021-11-26","objectID":"/prml-chap01-1/:2:6","tags":null,"title":"[PRML] Chapter1 - Introduction (1)","uri":"/prml-chap01-1/"},{"categories":["PRML"],"content":"1.3 Model Selection 여러 가지 모델을 선택할 때, train score로 model을 선택하는 것은 적절하지 않다. 그래서 validation set을 이용한다. 하지만 validation set에 overfitting하는 경우도 있기에 test set으로 최종 점검까지 하는 것이다. data가 제한적인 경우 cross validation의 방법을 사용한다. 하지만 이는 상당히 computationally expensive하다. ","date":"2021-11-26","objectID":"/prml-chap01-1/:3:0","tags":null,"title":"[PRML] Chapter1 - Introduction (1)","uri":"/prml-chap01-1/"},{"categories":["PRML"],"content":"1.4 The Curse of Dimensionalty 차원의 저주를 보여주는 몇가지 예시들 nearest neighborhood 알고리즘에 해당하는 부분 : sample space를 cubic형태로 나눈다고 생각했을 때, 차원이 커짐에 따라 지수적으로 cubic의 갯수가 많아진다. 따라서 cubic에 data가 텅 비지 않으려면 많은 양의 데이터가 필요하다. polynomial 의 경우 : Mth order의 polynomial 모델을 사용한다고 하면 $D^M$ 으로 parameter의 수가 증가한다. data를 sphere하게 생각해보자. 차원이 높아질수록 sphere의 표면쪽에 data가 몰려있다. 즉, 중심쪽이 sparse해지는 것이다. ","date":"2021-11-26","objectID":"/prml-chap01-1/:4:0","tags":null,"title":"[PRML] Chapter1 - Introduction (1)","uri":"/prml-chap01-1/"}]