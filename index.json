[{"categories":["Docker"],"content":"Docker의 가장 기본적인 개념 (Image, Container) ","date":"2022-06-03","objectID":"/01_udemy_docker/:0:0","tags":["Docker"],"title":"[Docker] Image와 Container","uri":"/01_udemy_docker/"},{"categories":["Docker"],"content":"Image templates for containers, Read-Only 이미지를 기반으로 컨테이너 띄워서 사용한다. docker run imageName run 명령어를 치면 이미지가 없는 경우 도커허브에서 다운받고 컨테이너를 띄운다' docker run -it node 바로 컨테이너안에서 명령어를 칠 수 있게 된다 (컨테이너가 대화형 셀을 제공하는 경우) docker ps 지금 돌아가고 있는 컨테이너를 알려준다. docker ps -a로 -a를 붙이면 모든 컨테이너를 보여준다 (정지된 컨테이너도 포함하여) ","date":"2022-06-03","objectID":"/01_udemy_docker/:0:1","tags":["Docker"],"title":"[Docker] Image와 Container","uri":"/01_udemy_docker/"},{"categories":["Docker"],"content":"Image layer 이미지는 layer 기반이라고 할 수 있다. (각 명령어는 layer라고 할 수 있다) 한번 build한 이미지는 다시 build하면 엄청 빠르게 진행된다. 이는 캐시되었기 때문이다. 특정 명령어 부분의 코드가 바뀌면 그 뒤의 모든 명령어(layer)들도 전부 캐시를 이용하지 않고 처음 build하듯이 살펴본다. 그래서 명령어의 순서도 적절하기 배치하는 것이 build를 최적화하는 방법중 하나이다. ","date":"2022-06-03","objectID":"/01_udemy_docker/:0:2","tags":["Docker"],"title":"[Docker] Image와 Container","uri":"/01_udemy_docker/"},{"categories":["Docker"],"content":"Dockerfile Dockerfile을 통해서 이미지를 빌드할 수 있다. 우리가 원하는대로 커스텀 이미지를 만들 수 있는 것이다. Dockerfile 예시 FROM node: 기본 이미지 다운로드 WORKDIR /app: 이미지에서 명령어가 실행될 기본 디렉토리 설정 COPY . ./: 첫번째가 지금 위치, 두번째가 이미지 내부 위치를 의미, 지금 위치의 파일을 복사해서 이미지 내부의 위치에 복사 RUN npm install: 이미지 내부에서 명령어 실행 EXPOSE 80: 호스트와 연결할 포트 번호를 설정, 하지만 document같은 역할일 뿐 실제로 포트를 연결하기 위해서는 컨테이너를 띄울때 명령어를 통해 진행해야 한다 CMD [\"node\", \"server.js\"]: 이미지를 기반으로 컨테이너가 시작될 때 실행된다, 배열형식으로 명령어를 작성 FROM node WORKDIR /app COPY . /app RUN npm install EXPOSE 80 CMD [\"node\", \"server.js\"] 위의 Dockerfile이 있는 위치에서 docker build . 명령어를 통해서 이미지를 빌드할 수 있다. 포트를 연결하기 위해서는 docker run -p 3000:80 imageID 같은 명령어가 필요하다: -p 로컬포트:container포트 docker stop containerName으로 컨테이너를 멈출 수 있다. ","date":"2022-06-03","objectID":"/01_udemy_docker/:0:3","tags":["Docker"],"title":"[Docker] Image와 Container","uri":"/01_udemy_docker/"},{"categories":["Docker"],"content":"image, container 관리 ","date":"2022-06-03","objectID":"/01_udemy_docker/:1:0","tags":["Docker"],"title":"[Docker] Image와 Container","uri":"/01_udemy_docker/"},{"categories":["Docker"],"content":"컨테이너 재시작 docker start containerID: 기존의 containerID 컨테이너 재시작 (container 이름으로도 당연히 가능하다) ","date":"2022-06-03","objectID":"/01_udemy_docker/:1:1","tags":["Docker"],"title":"[Docker] Image와 Container","uri":"/01_udemy_docker/"},{"categories":["Docker"],"content":"attached, detached docker run은 attached 모드가 default, docker start는 detached 모드가 default이다. detached 모드는 컨테이너를 백그라운드에서 동작하게 한다. detached 모드를 하고 싶으면 docker run -d imageID하면 된다. attaced모드로 꺼져있는 컨테이너를 시작하고 싶으면 docker start -a containerID하면 된다. 실행중인 컨테이너에 attach하고 싶으면 docker attach containerID하면 된다. ","date":"2022-06-03","objectID":"/01_udemy_docker/:1:2","tags":["Docker"],"title":"[Docker] Image와 Container","uri":"/01_udemy_docker/"},{"categories":["Docker"],"content":"interactive 모드 -i 옵션을 통해서 입력이 가능하게하고 -t 옵션을 통해서 컨테이너의 터미널을 사용할 수 있게 된다. 그래서 이미지로 컨테이너를 띄울 때, 두 가지 옵션 -it을 자주 같이 사용한다. 컨테이너 재시작에서도 docker start -a -i containerID로 사용하기도 한다. ","date":"2022-06-03","objectID":"/01_udemy_docker/:1:3","tags":["Docker"],"title":"[Docker] Image와 Container","uri":"/01_udemy_docker/"},{"categories":["Docker"],"content":"컨테이너에서 나오기 exit, Ctrl + D 입력하면 컨테이너 빠져나오면서 동시에 컨테이너를 정지시킨다. 컨테이너를 정지시키지 않고 나오고 싶으면 Ctrl + P, Q를 이용하자. ","date":"2022-06-03","objectID":"/01_udemy_docker/:1:4","tags":["Docker"],"title":"[Docker] Image와 Container","uri":"/01_udemy_docker/"},{"categories":["Docker"],"content":"삭제 docker rm containerID는 컨테이너를 삭제할 수 있다 한번에 여러개도 할 수 있다. 그냥 주르륵 쓰면 된다. docker images는 image들을 보여준다. docker rmi imageID는 이미지를 삭제할 수 있다. 모든 이미지를 항상 삭제할 수 있는 것은 아니고 중지된 컨테이너들만 존재할 때 삭제할 수 있다. docker image prune는 현재 실행되지 않는 컨테이너의 이미지들을 모두 삭제한다. (사용하지 말자 ㅎㅎ) docker rum --rm containerID에서 --rm은 컨테이너가 중지되면 자동으로 삭제되는 옵션이다. ","date":"2022-06-03","objectID":"/01_udemy_docker/:1:5","tags":["Docker"],"title":"[Docker] Image와 Container","uri":"/01_udemy_docker/"},{"categories":["Docker"],"content":"이미지, 컨테이너 살펴보기 docker image inspect imageID를 통해 이미지에 대한 정보를 알 수 있다. (컨테이너도 가능) OS, 만들어진 날짜 등등 생각보다 많은 정보를 알 수 있다. ","date":"2022-06-03","objectID":"/01_udemy_docker/:1:6","tags":["Docker"],"title":"[Docker] Image와 Container","uri":"/01_udemy_docker/"},{"categories":["Docker"],"content":"컨테이너 파일 복사 컨테이너로 파일을 복사할 수 있고 반대로 컨테이너에서 파일을 복사할 수도 있다. (실행중인 컨테이너도 가능) docker cp folder/test.txt containerName:/test/test.txt는 로컬 파일경로 folder/test.txt를 containerName이라는 컨테이너의 /test/test.txt위치에 복사한다. (:도 꼭 해줘야한다) docker cp containerName:/test/test.txt folder/test.txt는 위와 반대의 과정을 진행한다. ","date":"2022-06-03","objectID":"/01_udemy_docker/:1:7","tags":["Docker"],"title":"[Docker] Image와 Container","uri":"/01_udemy_docker/"},{"categories":["Docker"],"content":"컨테이너의 이름, 이미지의 태그 지정 docker run --name 원하는컨테이너이름 imageID처럼 --name으로 원하는 컨테이너의 이름을 지정할 수 있다. 이미지의 이름은 아래처럼 두 가지로 이루어져있다. repository:tag repository는 이미지들을 그룹핑 할 수 있는 것 또는 이름으로 이해할 수 있고 tag는 버전같이 더 해당그룹의 작은 단위의 특징을 나타낼 수 있다. docker build -t repository:tag . 이런식으로 image의 만들면 된다. docker tag 이전이름 새이름 repository:tag를 바꿀 수도 있다. ","date":"2022-06-03","objectID":"/01_udemy_docker/:1:8","tags":["Docker"],"title":"[Docker] Image와 Container","uri":"/01_udemy_docker/"},{"categories":["Docker"],"content":"Dockerhub에 이미지 푸시하기 Docker Hub를 이용할 수도 있고 Private Registry에 이미지를 푸시할 수 있다. Docker Hub Docker Hub에서 repository를 먼저 만들어준다. 그리고 push 를 이용해서 올릴 수 있다. docker push hubID/repositoryName:tagName 따라서 로컬에 있는 이미지의 이름도 위와 같아야한다. 그리고 권한 제한이 뜰 수도 있는데 이 때는 docker login을 해서 인증을 해야한다. ","date":"2022-06-03","objectID":"/01_udemy_docker/:1:9","tags":["Docker"],"title":"[Docker] Image와 Container","uri":"/01_udemy_docker/"},{"categories":["Docker"],"content":"Reference Docker \u0026 Kubernetes: 실전 가이드 -2022년판 (udemy 강의) 시작하세요 도커/쿠버네티스 , 용찬호 지음 ","date":"2022-06-03","objectID":"/01_udemy_docker/:2:0","tags":["Docker"],"title":"[Docker] Image와 Container","uri":"/01_udemy_docker/"},{"categories":["CatchMinor"],"content":"label이 있는 경우인 Supervised Outlier Analysis (Outlier Analysis, Charu C. Aggarwal) 이상치를 찾을 때, label이 있다면 무조건 이를 이용해야한다. 실제로 모델의 성능이 비교할 수 없을 정도로 차이가 난다. 그렇다면 label이 있다면 classification을 위한 모델을 만드는 것인데 supervised outlier detection은 일반적인 classification과 어떤 차이가 있을까? ","date":"2022-05-09","objectID":"/outlieranalysis02/:0:0","tags":["Outlier Analysis"],"title":"[OutlierAnalysis] Supervised Outlier Analysis","uri":"/outlieranalysis02/"},{"categories":["CatchMinor"],"content":"supervised outlier detection vs classification ","date":"2022-05-09","objectID":"/outlieranalysis02/:1:0","tags":["Outlier Analysis"],"title":"[OutlierAnalysis] Supervised Outlier Analysis","uri":"/outlieranalysis02/"},{"categories":["CatchMinor"],"content":"Class imbalance 가장 큰 차이라고 할 수 있을 것이다. 데이터를 이루고 있는 class의 비율이 차이가 나는 것이다. imbalance가 커질수록 모델을 major class로 biased된다. rare한 class를 major class로 예측하는 경우가 많아질 것이다. ","date":"2022-05-09","objectID":"/outlieranalysis02/:1:1","tags":["Outlier Analysis"],"title":"[OutlierAnalysis] Supervised Outlier Analysis","uri":"/outlieranalysis02/"},{"categories":["CatchMinor"],"content":"Contaminated normal class 이상치의 수가 워낙 적기 때문에 normal이라고 하지만 사실은 이상치이 경우가 존재할 수 있다. 또는 사실은 이상치이지만 새로운 형태의 이상치이기 때문에 normal이라고 잘못된 라벨링이 발생할 수도 있다. ","date":"2022-05-09","objectID":"/outlieranalysis02/:1:2","tags":["Outlier Analysis"],"title":"[OutlierAnalysis] Supervised Outlier Analysis","uri":"/outlieranalysis02/"},{"categories":["CatchMinor"],"content":"Partial training information 이상치의 수가 적어서 대부분 normal에 대한 정보만 많다. 그래서 거의 semi-supervised 같은 경우가 될 수도 있는 것이다. ","date":"2022-05-09","objectID":"/outlieranalysis02/:1:3","tags":["Outlier Analysis"],"title":"[OutlierAnalysis] Supervised Outlier Analysis","uri":"/outlieranalysis02/"},{"categories":["CatchMinor"],"content":"방법론 ","date":"2022-05-09","objectID":"/outlieranalysis02/:2:0","tags":["Outlier Analysis"],"title":"[OutlierAnalysis] Supervised Outlier Analysis","uri":"/outlieranalysis02/"},{"categories":["CatchMinor"],"content":"Cost-Sensitive 예를 들어서 positive label이 1%라고 하자. 그렇다면 모델이 모든 instance를 negative라고 예측하면 accuracy가 99%나 되는 좋은 모델이 만들어진다. 하지만 우리는 1%의 positive label을 잘 찾아내기를 원한다. 따라서 label을 동일한 weight가 아닌 중요한 정도에 따라 weighted된 loss function을 최적화하기를 원할 수 있다. 이러한 관점이 cost-sensitive 라고 할 수 있다. 대표적인 방법으로는 아래와 같은 방법들이 있다. Relabeling (MetaCost…) model-agnostic한 방법으로 weight(cost)를 고려하여 확률값을 이용하여 label을 다시하여 학습하는 방법이다. 다만 확률값에 따라서 결과가 천차만별이기에 조심해야 한다. 예를 들어, minor label을 major로 예측하는 경향을 가진 모델이 만들어지면 이미 부족한 label을 잃어버리는 결과가 발생할 수도 있다. Weighting model model fitting 과정에서 weight를 주는 방법 ","date":"2022-05-09","objectID":"/outlieranalysis02/:2:1","tags":["Outlier Analysis"],"title":"[OutlierAnalysis] Supervised Outlier Analysis","uri":"/outlieranalysis02/"},{"categories":["CatchMinor"],"content":"Adaptive Re-Sampling 책에서는 re-sampling 방법을 indirect form of cost-sensitive learning이라고 했다. weight를 주는 것은 결국 imbalanced한 데이터를 평등하게 맞추는 과정이므로 re-sampling(under, over sampling)도 그 의도와 결과가 비슷하다고 할 수 있다.이와 관련한 연구도 상당히 많다. 대표적인 방법론은 SMOTE가 있다. ","date":"2022-05-09","objectID":"/outlieranalysis02/:2:2","tags":["Outlier Analysis"],"title":"[OutlierAnalysis] Supervised Outlier Analysis","uri":"/outlieranalysis02/"},{"categories":["CatchMinor"],"content":"Ensemble Ensemble 모델이 만들어지는 과정에서 cost-sensitive(or re-sampling)의 방법을 같이 접목시킨다. 예를 들어, Adaboost의 경우 예측이 틀린 데이터에 더 가중치를 둬서 모델이 학습하도록 한다. 이 때, minor한 label에 더 가중치를 줘서 학습을 하도록 하는 AdaCost같은 모델이 있다. 또한 모델링 과정에서 SMOTE방법론을 이용하는 SMOTEBoost도 이러한 방법론이다. 다양한 방법론들이 있지만 위 방법론들이 항상 효과적인 것은 아니다. 결국 데이터와 비즈니스상황에 따라 결과가 많이 달라진다. 하지만 방법론들에 대한 전반적인 이해를 갖고 있다면 문제를 해결해 나가는 과정이 좀 더 수월하지 않을까. ","date":"2022-05-09","objectID":"/outlieranalysis02/:2:3","tags":["Outlier Analysis"],"title":"[OutlierAnalysis] Supervised Outlier Analysis","uri":"/outlieranalysis02/"},{"categories":["Algorithmic Marketing"],"content":"타겟팅을 할 때, 주로 사용하는 uplift 모형에 대한 기본개념을 알아보자. 예를 들어, 앱 사용자들에게 푸시알람을 보내서 전환율(물건구매라고 생각해도 됨)을 높이고 싶은 상황이라고 생각해보자. 모든 유저에게 푸시알람을 보낼 수 없거나 푸시알람이 비용이 발생하는 경우, 전환율이 높을 것 같은 유저에게 푸시를 보내는 것이 맞을 것이다. 이를 모델링으로 해결하고자 한다면 어떻게 해야 할까? 일단 크게 두 가지를 생각할 수 있다. response model (classification), uplift model 이 있다. response model의 경우 이전에 푸시알람을 보낸 데이터를 이용하여 전환여부를 target값으로 놓고 classification model을 만들고 predict하여 확률값으로 sort하여 상위 %에서 보내는 방법이다. 우리가 살펴볼 uplift model의 경우는 조금 다르다. 실험데이터가 필요하기 때문이다. 두 model 모두 공통적으로 covariates와 target은 있지만 uplift model은 RCT를 이용해 구한 treatment여부가 있는 데이터가 필요하다. 예시에서는 푸시알람이 treatment이다. 그래서 각 고객들 중에서 treatment effect가 큰 고객들에게 먼저 보내려고 하는 것이다. 이에 대해 아래 그림을 참고하자. 아래 그림에서 uplift model이 찾고자하는 그룹은 persuadables이다. 즉, 푸시알람을 보내야만 구매를 하는 사람에게 푸시알람을 보내고 싶은 것이다. 푸시알람을 보내지 않더라도 어차피 물건을 구매하는 사람에게는 보낼 필요가 없고 푸시알람에 상관없이 구매하지 않을 사람, 푸시알람을 받으면 오히려 역효과가 나는 사람들에게도 보낼 필요가 없기 때문이다. 하지만 멀티버스가 존재하지 않는 한 우리는 특정 고객이 푸시알람을 받아야 구매할지 아닐지 알 수가 없다. 둘 중 하나의 결과만 알 수 있기 때문이다. 따라서 uplift model은 이러한 문제를 해결하기 위한 접근이라고 할 수 있다. 마케팅쪽에서는 uplift model이라고 하고 causality쪽에서는 Heterogeneous treatment effect estimation 이라고 불리는 분야이다. 당연히 이와 관련하여 다양한 모델들이 존재한다. Uber나 Microsoft의 오픈소스들을 참고하면 이해하기 더 좋다. 여기서는 다양한 모델중에서 T-Learner에 대해 간단히 정리해보고자 한다. 실제 데이터를 통해 구한 모델링 과정의 코드는 여기서 확인하면 된다. 모델링 과정은 다음과 같다. 데이터는 train, valid로 나눈다. train data에서 treat, control 그룹을 각각 나누어서 모델을 각자 만든다. 이 때 모델의 X에는 treatment여부는 빠지고 target은 전환여부(binary)이고 이를 예측하는 위한 covariate들로 이루어져 있다. 모델은 classification 모델 아무거나 상관없다. 그리고 각 모델에 valid data를 넣어서 prediction한다. 이 때, 우리는 확률을 이용할 것이다. 이 valid data에는 treat, control 그룹 모두 들어있다. 즉, 2번에서 만든 모델을 통해 valid data에 있는 유저들이 treatment를 받았을 때와 그렇지 않았을 때 target이 어떨지 각각 구할 수 있는 것이다. 위의 확률값을 통해서 uplift score를 구한다. treatment 받았을 때의 전환확률 - treatment 받지 않았을 때의 전환확률 uplift score에 따라 sort하여서 10%씩 실제 전환율을 살펴보자. 위의 과정을 통해 구한 결과는 아래 사진과 같다. uplift가 0보다 큰 상위 60%정도까지는 실제 treat 그룹의 response rate가 더 높다. 우리는 uplift score가 높은 고객들, 즉 푸시알람을 받았을 때 effect가 큰 유저들에게 보내도 되겠다는 증거가 되는 것이다. ","date":"2022-05-08","objectID":"/05_uplift/:0:0","tags":["Uplift Model","Targeting"],"title":"[Algorithmic Marketing] Uplift Model","uri":"/05_uplift/"},{"categories":["Algorithmic Marketing"],"content":"Reference https://matheusfacure.github.io/python-causality-handbook/21-Meta-Learners.html https://partrita.github.io/posts/python-uplift/ ","date":"2022-05-08","objectID":"/05_uplift/:1:0","tags":["Uplift Model","Targeting"],"title":"[Algorithmic Marketing] Uplift Model","uri":"/05_uplift/"},{"categories":["Airflow"],"content":"Airflow에 대한 좀 더 advanced한 내용을 공부해보자. ","date":"2022-05-02","objectID":"/airflow05/:0:0","tags":["Airflow"],"title":"[Airflow] Advanced Concepts in Airflow","uri":"/airflow05/"},{"categories":["Airflow"],"content":"Remove repetive patterns with SubDags 반복적인 task의 경우 좀 더 깔끔한 패턴을 만들기 위해 subdags라는 개념을 이용할 수 있다. 이전에 봤던 예시인 task_1 \u003e\u003e [task_2, task_3] \u003e\u003e task_4 에서 task_2, task_3를 묶어보자. SubDagOperator는 인자로 subdag을 return하는 함수가 필요하다. 이를 위해 일단 dags 폴더에 subdags라는 폴더를 만든다. 그리고 그 폴더에 subdag_parallel_dag.py 파일을 만들고 함수를 만들어보자. 해당함수는 dag을 return하는 함수여야 한다. from airflow import DAG def subdag_parallel_dag(parent_dag_id, child_dag_id, default_args): with DAG(dag_id=f'{parent_dag_id}.{child_dag_id}', default_args=default_args) as dag: task_2 = BashOperator( task_id='task_2', bash_command='sleep 3' ) task_3 = BashOperator( task_ud='task_3', bash_command='sleep 3' ) return dag 그리고 이 함수를 import해서 아래와 같이 DAG를 만들어준다. from airflow import DAG from airflow.operators.bash import BashOperator from airflow.operators.subdag import SubDagOperator from subdags.subdag_parallel_dag import subdag_parallel_dag from datetime import datetime default_args = { 'start_date': datetime(2022, 4, 23) } with DAG( 'parallel_subdag', schedule_interval='@daily', default_args=default_args, catchup=False ) as dag: task_1 = BashOperator( task_id='task_1', bash_command='sleep 3' ) processing = SubDagOperator( task_id='processing_tasks', subdag=subdag_parallel_dag('parallel_subdag', 'processing_tasks', default_args) ) task_4 = BashOperator( task_id='task_4', bash_command='sleep 3' ) task_1 \u003e\u003e processing \u003e\u003e task_4 이렇게 subdag으로 task를 묶을 수 있다. 하지만 subdag을 사용하는 것을 추천하지는 않는다고 한다. 이유는 Deadlock, complexity, subdag은 sequential excutor를 default로 사용 이라고 한다. ","date":"2022-05-02","objectID":"/airflow05/:1:0","tags":["Airflow"],"title":"[Airflow] Advanced Concepts in Airflow","uri":"/airflow05/"},{"categories":["Airflow"],"content":"SubDags가 아닌 TaskGroup를 사용해보자 from airflow import DAG from airflow.operators.bash import BashOperator from airflow.utils.task_group import TaskGroup from subdags.subdag_parallel_dag import subdag_parallel_dag from datetime import datetime default_args = { 'start_date': datetime(2022, 4, 23) } with DAG( 'parallel_subdag', schedule_interval='@daily', default_args=default_args, catchup=False ) as dag: task_1 = BashOperator( task_id='task_1', bash_command='sleep 3' ) with TaskGroup('processing_tasks') as processing_tasks: task_2 = BashOperator( task_id='task_2', bash_command='sleep 3' ) task_3 = BashOperator( task_id='task_3', bash_command='sleep 3' ) task_4 = BashOperator( task_id='task_4', bash_command='sleep 3' ) task_1 \u003e\u003e processing_tasks \u003e\u003e task_4 TaskGroup을 사용하면 따로 함수를 만들 필요도 없어서 편하다. ","date":"2022-05-02","objectID":"/airflow05/:2:0","tags":["Airflow"],"title":"[Airflow] Advanced Concepts in Airflow","uri":"/airflow05/"},{"categories":["Airflow"],"content":"Share data with XCom XCom을 이용하여 task끼리 data를 주고받을 수 있다. Airflow에서 어떤 database를 쓰냐에 따라 data의 크기도 정해져 있다. 다만, 작은 양의 data를 사용하기를 추천한다. task를 통해 생성된 값은 key, value 형태로 보존된다. 예시를 통해 이해해보자. 머신러닝 모델을 3개 만들어보고 가장 성능이 좋은 모델을 선택하는 pipeline을 만들고 싶다. 아래 코드에서는 processing_tasks에서 모델을 훈련시키고 성능점수를 choose_model에서 확인하고 있다. from airflow import DAG from airflow.operators.bash import BashOperator from airflow.operators.python import PythonOperator from airflow.operators.task_group import TaskGroup from random import uniform from datetime import datetime default_args = { 'start_date': datetime(2022, 5, 1) } def _training_model(ti): acc = uniform(0.1, 10.0) print(f'model\\'s acc = {acc}') # database에 push ti.xcom_push(key='model_acc', value=acc) def _choose_best_model(ti): print('choose best model') # database에서 pull accs = ti.xcom_pull(key='model_acc', task_ids=[ 'processing_tasks.training_model_a', 'processing_tasks.training_model_b', 'processing_tasks.training_model_c', ]) # webserver나 terminal에서 확인 할 수 있다 print(accs) with DAG( 'xcom_dag', schedule_interval='@daily', default_args=default_args, catchup=False ) as dag: downloading_data = BashOperator( task_id='downloading_data', bash_command='sleep 3' ) with TaskGroup('processing_tasks') as processing_tasks: training_model_a = PythonOperator( task_id='training_model_a', python_callable=_training_model ) training_model_b = PythonOperator( task_id='training_model_b', python_callable=_training_model ) training_model_c = PythonOperator( task_id='training_model_c', python_callable=_training_model ) choose_model = PythonOperator( task_id='task_4', python_callable=_choose_best_model ) downloading_data \u003e\u003e processing_tasks \u003e\u003e choose_model webserver에서 Admin -\u003e xcom 에서 결과를 확인할 수 있다. 로그를 보면 accs가 print된 것을 확인할 수 있다. ","date":"2022-05-02","objectID":"/airflow05/:3:0","tags":["Airflow"],"title":"[Airflow] Advanced Concepts in Airflow","uri":"/airflow05/"},{"categories":["Airflow"],"content":"특정 condition에 따라 실행할 task 선택하기 아래 코드예시처럼 return 값에 다음에 진행할 task_id를 넣어주면 된다. from airflow import DAG from airflow.operators.bash import BashOperator from airflow.operators.python import PythonOperator, BranchPythonOperator from airflow.operators.dummy import DummyOperator from airflow.utils.task_group import TaskGroup from random import uniform from datetime import datetime default_args = { 'start_date': datetime(2022, 5, 1) } def _training_model(ti): acc = uniform(0.1, 10.0) print(f'model\\'s acc = {acc}') # database에 push ti.xcom_push(key='model_acc', value=acc) def _choose_best_model(ti): print('choose best model') # database에서 pull accs = ti.xcom_pull(key='model_acc', task_ids=[ 'processing_tasks.training_model_a', 'processing_tasks.training_model_b', 'processing_tasks.training_model_c', ]) # 조건에 맞는 task를 return하게 한다 for acc in accs: if acc \u003e 5: return 'accurate' # ['accurate', 'inaccurate'] 이런식으로 여러개도 가능 return 'inaccurate' with DAG( 'xcom_dag', schedule_interval='@daily', default_args=default_args, catchup=False ) as dag: downloading_data = BashOperator( task_id='downloading_data', bash_command='sleep 3', # default로 push를 하기 때문에 이런식으로 못하게 할 수 있다 # False안하고 xcom을 보면 key, value에 아무것도 없음을 알 수 있다 do_xcom_push=False ) with TaskGroup('processing_tasks') as processing_tasks: training_model_a = PythonOperator( task_id='training_model_a', python_callable=_training_model ) training_model_b = PythonOperator( task_id='training_model_b', python_callable=_training_model ) training_model_c = PythonOperator( task_id='training_model_c', python_callable=_training_model ) choose_model = BranchPythonOperator( task_id='task_4', python_callable=_choose_best_model ) accurate = DummyOperator( task_id='accurate' ) inaccurate = DummyOperator( task_id='inaccurate' ) downloading_data \u003e\u003e processing_tasks \u003e\u003e choose_model choose_model \u003e\u003e [accurate, inaccurate] ","date":"2022-05-02","objectID":"/airflow05/:4:0","tags":["Airflow"],"title":"[Airflow] Advanced Concepts in Airflow","uri":"/airflow05/"},{"categories":["Airflow"],"content":"Trigger Rules task가 trigger되는 default값을 바꿔서 특정 조건이 되면 trigger되도록 (사용자가 원하는대로) 할 수 있다. task마다 trigger_rule을 통해서 규칙을 정해주면 된다. from airflow import DAG from airflow.operators.bash import BashOperator from datetime import datetime default_args = { 'start_date': datetime(2022, 5, 1) } with DAG( 'trigger_rule', schedule_interval='@daily', default_args=default_args, catchup=False ) as dag: task_1 = BashOperator( task_id='task_1', bash_command='exit 1', do_xcom_push=False ) task_2 = BashOperator( task_id='task_2', bash_command='exit 0', do_xcom_push=False ) task_3 = BashOperator( task_id='task_3', bash_command='exit 0', do_xcom_push=False, # 이렇게 지정가능 trigger_rule='one_failed' ) [task_1, task_2] \u003e\u003e task_3 ","date":"2022-05-02","objectID":"/airflow05/:5:0","tags":["Airflow"],"title":"[Airflow] Advanced Concepts in Airflow","uri":"/airflow05/"},{"categories":["Airflow"],"content":"Reference udemy: the complete hands on course to master apache airflow ","date":"2022-05-02","objectID":"/airflow05/:6:0","tags":["Airflow"],"title":"[Airflow] Advanced Concepts in Airflow","uri":"/airflow05/"},{"categories":["Airflow"],"content":"Airflow에서 plugin을 이용하여 사용반경을 넓혀보자. 먼저 Elasticsearch를 설치해보자. curl -fsSL https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add - # 그리고 비밀번호 친다 echo \"deb https://artifacts.elastic.co/packages/7.x/apt stable main\" | sudo tee -a /etc/apt/sources.list.d/elastic-7.x.list sudo apt update \u0026\u0026 sudo apt install elasticsearch # 설치 pip install elasticsearch==7.10.1 # 시작 sudo systemctl start elasticsearch # 잘 되는지 확인 curl -X GET 'http://localhost:9200' ","date":"2022-05-02","objectID":"/airflow06/:0:0","tags":["Airflow"],"title":"[Airflow] Use plugin in Airflow","uri":"/airflow06/"},{"categories":["Airflow"],"content":"Plugin 사용자만의 own operators를 커스텀 views를 통해서 원하는 ui 만들기 hooks을 통해서 서드파티를 이용가능 직접 원하는대로 python module을 만들어서 사용할 수 있다. 이제 Elasticsearch와 interact할 수 있는 plugin을 만들어보자. postgreSQL에서 Elasticsearch로 data를 보내는 hook과 operator를 아래와 같이 만들 수 있다. 먼저, plugins(이름을 잘 지켜야함)라는 폴더를 만들고 그 안에 elasticsearch_plugin이라는 폴더를 만든다. 그리고 그 폴더안에 hooks, operators라는 폴더를 만든다. 그리고 각 폴더에 elastic_hook.py, postgres_to_elastic.py라는 파일을 만든다. 두 파일 모두 Airflow에 있는 Base hook, operator를 상속받아서 class를 만들어 사용하는 코드를 담고 있다. from airflow.hooks.base import BaseHook from elasticsearch import Elasticsearch class ElasticHook(BaseHook): def __init__( self, conn_id='elasticsearch_default', *args, **kwargs ): super().__init__(*args, **kwargs) # BaseHook에 있는 함수 conn = self.get_conntetion(conn_id) conn_config = {} hosts = [] if conn.host: hosts = conn.host.split(',') if conn.port: conn_config['port'] = int(conn.port) if conn.login: conn_config['http_auth'] = (conn.login, conn.password) self.es = Elasticsearch(hosts, **conn_config) self.index = conn.schema def info(self): return self.es.info() def set_index(self, index): self.index = index def add_doc(self, index, doc_type, doc): self.set_index(index) res = self.es.index(index=index, doc_type=doc_type, body=doc) return res from airflow.models import BaseOperator from airflow.providers.postgres.hooks.postgres import PostgresHook from elasticsearch_plugin.hooks.elastic_hook import ElasticHook from contextlib import closing import json class PostgresToElasticOperator(BaseOperator): def __init__( self, sql, index, postgres_conn_id='postgres_default', elastic_conn_id='elasticsearch_default', *args, **kwargs ): super(PostgresToElasticOperator, self).__init__(*args, **kwargs) self.sql = sql self.index = index self.postgres_conn_id = postgres_conn_id self.elastic_conn_id = elastic_conn_id def execute(self, context): es = ElasticHook(conn_id=self.elastic_conn_id) pg = PostgreHook(postgres_conn_id=self.postgres_conn_id) with closing(pg.get_conn()) as conn: with closing(conn.cursor()) as cur: cur.itersize = 1000 cur.execute(self.sql) for row in cur: doc = json.dumps(row, indent=2) es.add_doc(index=self.index, doc_type='external', doc=doc) 그리고 dag을 만들어준다. from airflow import DAG from elasticsearch_plugin.hooks.elastic_hook import ElasticHook from elasticsearch_plugin.operators.postgres_to_elastic import PostgresToElasticOperator from airflow.operators.python import PythonOperator from datetime import datetime default_args = { 'start_date': datetime(2022, 5, 5) } def _print_es_info(): hook = ElasticHook() print(hook.info()) with DAG( 'elastcisearch_dag', schedule_interval='@daily', default_args=default_args, catchup=False ) as dag: print_es_info = PythonOperator( task_id=-'print_es_info', python_callable=_print_es_info ) connections_to_es = PostgresToElasticOperator( task_id='connections_to_es', sql='SELECT * FROM connection', index='connections' ) print_es_info \u003e\u003e connections_to_es web에서 connection을 추가해준다. 그리고 postgresql에 들어가서 user를 추가해준다. sudo -u postgres psql ALTER USER postgres PASSWORD 'postgres'; 이제 dag을 실행시키고 아래 명령어를 통해 postgreSQL에서 Elasticsearch로 데이터를 보낸 것을 확인할 수 있다. curl -X GET \"http://localhost:9200/connections/_search\" -H \"Content -type: application/json\" -d '{\"query\":{\"match_all\":{}}}' ","date":"2022-05-02","objectID":"/airflow06/:1:0","tags":["Airflow"],"title":"[Airflow] Use plugin in Airflow","uri":"/airflow06/"},{"categories":["Airflow"],"content":"Reference udemy: the complete hands on course to master apache airflow ","date":"2022-05-02","objectID":"/airflow06/:2:0","tags":["Airflow"],"title":"[Airflow] Use plugin in Airflow","uri":"/airflow06/"},{"categories":["Airflow"],"content":"multiple task를 execute하는 방법과 관련한 내용을 공부해보자. airflow.cfg를 바꿔서 적용하려면 webserver, scheduler를 재시작해야한다 ","date":"2022-04-23","objectID":"/airflow04/:0:0","tags":["Airflow"],"title":"[Airflow] Database and Executor","uri":"/airflow04/"},{"categories":["Airflow"],"content":"default configuration airflow config get-value core sql_alchemy_conn 위의 명령어를 치면 sqlite:////home/airflow/airflow/airflow.db 라고 나온다. 이는 현재 airflow에서 SQLite가 default db라고 이해할 수 있다. airflow config get-value core executor 위의 명령어를 치면 SequentialExecutor 라고 나온다. 이러한 default의 상황에서 아래 예시는 sequential하게 task1을 하고 task2, 3를 하고 task4를 하는 과정이다. task2, 3 중에서 누가 먼저 진행될지는 알 수 없다. 순차적으로 진행된다. from airflow import DAG from airflow.operators.bash import BashOperator from datetime import datetime default_args = { 'start_date': datetime(2022, 4, 23) } with DAG( 'parallel_dag', schedule_interval='@daily', default_args=default_args, catchup=False ) as dag: task_1 = BashOperator( task_id='task_1', bash_command='sleep 3' ) task_2 = BashOperator( task_id='task_2', bash_command='sleep 3' ) task_3 = BashOperator( task_id='task_3', bash_command='sleep 3' ) task_4 = BashOperator( task_id='task_4', bash_command='sleep 3' ) task_1 \u003e\u003e [task_2, task_3] \u003e\u003e task_4 위의 내용들이 현재 airflow의 default configuration이라고 할 수 있다. 이제 목적에 맞게 이를 조금씩 수정하는 과정을 알아보자. ","date":"2022-04-23","objectID":"/airflow04/:0:1","tags":["Airflow"],"title":"[Airflow] Database and Executor","uri":"/airflow04/"},{"categories":["Airflow"],"content":"Scaling with the Local Executor local executor sequential executor와 다르게 multiple tasks를 parallel하게 execute할 수 있다 위의 예시에서 task2, 3를 parallel하게 진행해보자. 또한, 이번에는 sqlite가 아니라 PostgreSQL을 사용해보자. 이는 SQLite는 한번에 하나의 writer만이 가능하기에 동시에 task를 해야하는 local, celery executor를 사용하기에 적절하지 않기 때문이다. sudo apt update # 설치 sudo apt install postgresql # 비밀번호 지정 sudo -u postgres psql ALTER USER postgres PASSWORD 'postgres'; # 추가 패키지 설치 pip install 'apache-airflow[postgres]' 그리고 default configure를 바꾸기 위해 airflow.cfg에 들어가서 sql_alchemy_conn의 값을 바꿔준다. sql_alchemy_conn = postgresql+psycopg2://postgres:postgres@localhost/postgres # 원래는 아래값이 default # sql_alchemy_conn = sqlite:////home/airflow/airflow/airflow.db 그리고 잘됐는지 확인하기 위해 airflow db check해서 확인해보자. 이제 metastore db가 postgres로 바뀌었다. 추가로 executor도 바꿔주고 websever, scheduler 모두 끄고 다시 db init 부터 시작한다. executor = LocalExecutor # executor = SequentialExecutor airflow db init airflow users create -u admin -p admin -r Admin -f admin -l admin -e admin@airflow.com 그리고 다시 webserver, scheduler를 키고 dag를 실행시키면 task2, 3가 정말 동시에 parallel하게 진행됨을 확인할 수 있다. ","date":"2022-04-23","objectID":"/airflow04/:0:2","tags":["Airflow"],"title":"[Airflow] Database and Executor","uri":"/airflow04/"},{"categories":["Airflow"],"content":"Scale to the infinity with the Celery Executor celery executor allows distributing the execution of task instances to multiple worker nodes task는 queue(redis를 이용할 예정)에 있다가 실행될 때, node(worker)로 보내져서 실행된다. node(worker)의 수를 늘리면 더 많은 task를 할 수 있다. 또한 각 node(worker)마다 또한 여러 개의 task를 진행할 수 있고 이는 worker_concurruency를 통해서 조절 할 수 있다. # celery 설치 pip install 'apache-airflow[celery]' # redis server 설치 sudo install redis-server # 설정 바꾸기 sudo vi /etc/redis/redis.conf # 여기서 supervised no 를 찾아서 no를 systemd로 바꾼다 # redis restart하고 잘되는지 확인 sudo systemctl restart redis.service sudo systemctl status redis.service redis가 잘 돌아가면 이제 airflow.cfg헤서 몇 가지 수정한다. executor를 CeleryExecutor로 바꾼다. broker_url = redis://redis:6379/0를 broker_url = redis://localhost:6379/0로 바꾼다. result_backend = db+postgresql://postgres:airflow@postgres/airflow를 result_backend = postgresql+psycopg2://postgres:postgres@localhost/postgres로 바꾼다. result_backend는 task가 완료되면 관련한 metadata를 저장하는 곳을 의미 다음으로 redis와 airflow의 연결을 위해 pip install 'apache-airflow[redis]'으로 관련 패키지를 설치한다. 그리고 다른 bash창에서 airflow celery flower를 통해 worker들을 웹으로 확인해볼 수 있다. 그러면 지금은 worker가 없는 것을 확인할 수 있다. airflow celery worker로 worker를 추가하면 Flower웹에서 확인할 수 있다. 그리고 dag를 돌려서 확인해볼 수도 있다. ","date":"2022-04-23","objectID":"/airflow04/:0:3","tags":["Airflow"],"title":"[Airflow] Database and Executor","uri":"/airflow04/"},{"categories":["Airflow"],"content":"Concurrency airflow.cfg에서 parallelism을 찾아보면 airflow instance 전체에서 parallel하게 task가 동시에 최대 몇 개 까지 진행될 수 있는지 나와있다. executor = LocalExecutor였을 때 원래 task2, 3가 동시에 진행되었는데 parallelism=1로 지정하면 동시에 진행되지 않는다. dag_concurrency를 통해서 하나의 DAG에서 parallel하게 동시에 돌아갈 수 있는 task 수를 제한 할 수 있다. 이 값은 default이고 당연히 각 DAG에 각각 다르게 지정할 수 있다. max_active_runs_per_dag은 maximum number of active DAG runs per DAG을 의미한다. 이 값도 DAG에 따라 다르게 지정할 수 있다. 이들을 통해 동시에 진행되는 DAG, Task를 조절할 수 있다. ","date":"2022-04-23","objectID":"/airflow04/:0:4","tags":["Airflow"],"title":"[Airflow] Database and Executor","uri":"/airflow04/"},{"categories":["Airflow"],"content":"Reference udemy: the complete hands on course to master apache airflow ","date":"2022-04-23","objectID":"/airflow04/:1:0","tags":["Airflow"],"title":"[Airflow] Database and Executor","uri":"/airflow04/"},{"categories":["Airflow"],"content":"Airflow pipeline을 만들어보자 ","date":"2022-04-17","objectID":"/airflow03/:0:0","tags":["Airflow"],"title":"[Airflow] Pipeline","uri":"/airflow03/"},{"categories":["Airflow"],"content":"DAG DAG node들이 task이고 edge가 각 task의 dependency를 의미한다 ","date":"2022-04-17","objectID":"/airflow03/:0:1","tags":["Airflow"],"title":"[Airflow] Pipeline","uri":"/airflow03/"},{"categories":["Airflow"],"content":"Operator operator one task in data pipeline 하나의 operator에는 하나의 task만 넣어라 특히 dependency가 있는 task의 경우는 더 그래야한다 3 types of operator Action operators: Execute an action Transfer operators: Transfer data Sensors: Wait for a condition to be met ","date":"2022-04-17","objectID":"/airflow03/:0:2","tags":["Airflow"],"title":"[Airflow] Pipeline","uri":"/airflow03/"},{"categories":["Airflow"],"content":"pipeline 만들기 만들고자 하는 pipeline은 다음과 같다. creating_table \u003e\u003e is_api_available \u003e\u003e extracting_user \u003e\u003e processing_user \u003e\u003e storing_user 먼저 webserver와 scheduler를 활성화한다. airflow webserver airflow scheduler ","date":"2022-04-17","objectID":"/airflow03/:1:0","tags":["Airflow"],"title":"[Airflow] Pipeline","uri":"/airflow03/"},{"categories":["Airflow"],"content":"creating_table airflow를 설치하면 최소한의 패키지만 설치되기 때문에 추가적으로 패키지가 필요하면 설치해야 한다. 지금 만드려고 하는 db의 경우 sqlite를 이용할 것이기 때문에 sqlite operator가 필요하다. 링크에 가면 third-party와의 연결을 위한 package들이 있다. pip install apache-airflow-providers-sqlite으로 설치를 해준다. 파이썬 가상환경을 활성화해주면 그리고 아래와 같이 user_processing.py 파일을 만들어준다. from airflow.models import DAG from airflow.providers.sqlite.operators.sqlite import SqliteOperator from datetime import datetime # default로 넣고 싶은 인자들 default_args = { 'start_date': datetime(2022, 4, 20) } with DAG( 'user_processing', # dag id는 unique 해야한다: 'user_processing' schedule_interval='@daily', # start_date이후로 얼마나 자주 DAG가 run되야하는지 default_args=default_args, catchup=False ) as dag: # define the task/operator creating_table = SqliteOperator( task_id='creating_table', # 하나의 pipeline에서 unique 해야함 sqlite_conn_id='db_sqlite', sql=''' CREATE TABLE users ( firstname TEXT NOT NULL, lastname TEXT NOT NULL, country TEXT NOT NULL, username TEXT NOT NULL, password TEXT NOT NULL, email TEXT NOT NULL PRIMARY KEY ); ''' ) 그리고 Admin -\u003e Connections 에 가서 connection을 아래와 같이 추가해줘야 한다. conn_id는 위에서 정한 db_sqlite로 해줘야하고 Host는 아래와 같이 airflow.db가 있는 path를 해주면 된다. test airflow tasks test user_processing creating_table 2022-04-23 ","date":"2022-04-17","objectID":"/airflow03/:1:1","tags":["Airflow"],"title":"[Airflow] Pipeline","uri":"/airflow03/"},{"categories":["Airflow"],"content":"is_api_available task이름 그래도 api가 작동하는지 확인하는 것이다. 기존 airflow의 example 데이터를 이용한다. from airflow.models import DAG from airflow.providers.sqlite.operators.sqlite import SqliteOperator from airflow.providers.http.sensors.http import HttpSensor from datetime import datetime # default로 넣고 싶은 인자들 default_args = { 'start_date': datetime(2022, 4, 20) } with DAG( 'user_processing', # dag_id는 unique 해야한다: 'user_processing' schedule_interval='@daily', default_args=default_args, catchup=False ) as dag: # define the task/operator creating_table = SqliteOperator( task_id='creating_table', # 하나의 pipeline에서 unique 해야함 sqlite_conn_id='db_sqlite', sql=''' CREATE TABLE users ( firstname TEXT NOT NULL, lastname TEXT NOT NULL, country TEXT NOT NULL, username TEXT NOT NULL, password TEXT NOT NULL, email TEXT NOT NULL PRIMARY KEY ); ''' ) is_api_available = HttpSensor( task_id='is_api_available', http_conn_id='user_api', endpoint='api/' ) test airflow tasks test user_processing is_api_available 2022-04-23 ","date":"2022-04-17","objectID":"/airflow03/:1:2","tags":["Airflow"],"title":"[Airflow] Pipeline","uri":"/airflow03/"},{"categories":["Airflow"],"content":"extracting_user airflow example 데이터를 extract하는 task를 생성한다. from airflow.models import DAG from airflow.providers.sqlite.operators.sqlite import SqliteOperator from airflow.providers.http.sensors.http import HttpSensor from airflow.providers.http.operators.http import SimpleHttpOperator from datetime import datetime import json # default로 넣고 싶은 인자들 default_args = { 'start_date': datetime(2022, 4, 20) } with DAG( 'user_processing', # dag_id는 unique 해야한다: 'user_processing' schedule_interval='@daily', default_args=default_args, catchup=False ) as dag: # define the task/operator creating_table = SqliteOperator( task_id='creating_table', # 하나의 pipeline에서 unique 해야함 sqlite_conn_id='db_sqlite', sql=''' CREATE TABLE users ( firstname TEXT NOT NULL, lastname TEXT NOT NULL, country TEXT NOT NULL, username TEXT NOT NULL, password TEXT NOT NULL, email TEXT NOT NULL PRIMARY KEY ); ''' ) is_api_available = HttpSensor( task_id='is_api_available', http_conn_id='user_api', endpoint='api/' ) extracting_user = SimpleHttpOperator( task_id='extracting_user', http_conn_id='user_api', endpoint='api/', method='GET', response_filter=lambda response: json.loads(response.text), log_response=True ) test airflow tasks test user_processing is_api_available 2022-04-23 test를 진행하면 그 결과가 나온다. 아래는 GET을 통해 가져온 데이터를 의미한다. [2022-04-23 06:35:15,589] {http.py:140} INFO - Sending 'GET' to url: https://randomuser.me/api/ [2022-04-23 06:35:16,104] {http.py:115} INFO - {\"results\":[{\"gender\":\"female\",\"name\":{\"title\":\"Mrs\",\"first\":\"Lonne\",\"last\":\"Schilstra\"},\"location\":{\"street\":{\"number\":4722,\"name\":\"Jaspis\"},\"city\":\"Zutphen\",\"state\":\"Flevoland\",\"country\":\"Netherlands\",\"postcode\":64338,\"coordinates\":{\"latitude\":\"40.3466\",\"longitude\":\"58.3229\"},\"timezone\":{\"offset\":\"+4:30\",\"description\":\"Kabul\"}},\"email\":\"lonne.schilstra@example.com\",\"login\":{\"uuid\":\"897a7df1-9964-4baf-9b3c-001f9cc815ef\",\"username\":\"smallbear142\",\"password\":\"chrysler\",\"salt\":\"LysRP72T\",\"md5\":\"92f39f731719df04767870a0cdcfb43d\",\"sha1\":\"2cedb9b8ae797b56ddf40e8425db36df1f4866ee\",\"sha256\":\"a1fd36358cf8d94e243ccfba37d9478b4b129bff367aa2ff218a4c975851ef11\"},\"dob\":{\"date\":\"1949-10-26T18:21:22.653Z\",\"age\":73},\"registered\":{\"date\":\"2019-06-05T08:17:56.847Z\",\"age\":3},\"phone\":\"(875)-139-9718\",\"cell\":\"(524)-611-0968\",\"id\":{\"name\":\"BSN\",\"value\":\"47403055\"},\"picture\":{\"large\":\"https://randomuser.me/api/portraits/women/55.jpg\",\"medium\":\"https://randomuser.me/api/portraits/med/women/55.jpg\",\"thumbnail\":\"https://randomuser.me/api/portraits/thumb/women/55.jpg\"},\"nat\":\"NL\"}],\"info\":{\"seed\":\"ff9863d9e80ca539\",\"results\":1,\"page\":1,\"version\":\"1.3\"}} [2022-04-23 06:35:16,123] {taskinstance.py:1184} INFO - Marking task as SUCCESS. dag_id=user_processing, task_id=extracting_user, execution_date=20220423T000000, start_date=20220423T060222, end_date=20220423T063516 ","date":"2022-04-17","objectID":"/airflow03/:1:3","tags":["Airflow"],"title":"[Airflow] Pipeline","uri":"/airflow03/"},{"categories":["Airflow"],"content":"processing_user from airflow.models import DAG from airflow.providers.sqlite.operators.sqlite import SqliteOperator from airflow.providers.http.sensors.http import HttpSensor from airflow.providers.http.operators.http import SimpleHttpOperator from airflow.operators.python import PythonOperator from datetime import datetime import json from pandas import json_normalize # default로 넣고 싶은 인자들 default_args = { 'start_date': datetime(2022, 4, 20) } # extracting_user 를 통해 얻은 결과를 이용 # airflow tasks test user_processing extracting_user 2022-04-23 def _processing_user(ti): # extracting_user task의 결과가 metastore에 저장이 되고 이 결과를 pull 한다 users = ti.xcom_pull(task_ids=['extracting_user']) if not len(users) or 'results' not in users[0]: raise ValueError('User is empty') user = users[0]['results'][0] # json_normalize로 dict를 pd.DataFrame으로 변환 processed_user = json_normalize({ 'first_name': user['name']['first'], 'lastname': user['name']['last'], 'country': user['location']['country'], 'username': user['login']['username'], 'password': user['login']['password'], 'email': user['email'] }) processed_user.to_csv('/tmp/processed_user.csv', index=None, header=False) with DAG( 'user_processing', # dag_id는 unique 해야한다: 'user_processing' schedule_interval='@daily', default_args=default_args, catchup=False ) as dag: # define the task/operator creating_table = SqliteOperator( task_id='creating_table', # 하나의 pipeline에서 unique 해야함 sqlite_conn_id='db_sqlite', sql=''' CREATE TABLE users ( firstname TEXT NOT NULL, lastname TEXT NOT NULL, country TEXT NOT NULL, username TEXT NOT NULL, password TEXT NOT NULL, email TEXT NOT NULL PRIMARY KEY ); ''' ) is_api_available = HttpSensor( task_id='is_api_available', http_conn_id='user_api', endpoint='api/' ) extracting_user = SimpleHttpOperator( task_id='extracting_user', http_conn_id='user_api', endpoint='api/', method='GET', response_filter=lambda response: json.loads(response.text), log_response=True ) processing_user = PythonOperator( task_id='processing_user', python_callable=_processing_user ) test airflow tasks test user_processing is_api_available 2022-04-23 test를 진행하면 processed_user.csv가 생성된다. cat /tmp/processed_user.csv를 하면 아래와 같은 결과가 나온다. Mercedes,Jimenez,Spain,goldenbutterfly721,darius,mercedes.jimenez@example.com ","date":"2022-04-17","objectID":"/airflow03/:1:4","tags":["Airflow"],"title":"[Airflow] Pipeline","uri":"/airflow03/"},{"categories":["Airflow"],"content":"storing_user 이제 /home/airflow/airflow/airflow.db에 user를 저장해보자. 처음에 sqlite3 airflow.db로 sqlite에 접속하고 SELECT * FROM users;하면 아무것도 없다가 나중에 storing_user task를 실행하면 그 유저가 들어간 것을 확인 할 수 있다. ","date":"2022-04-17","objectID":"/airflow03/:1:5","tags":["Airflow"],"title":"[Airflow] Pipeline","uri":"/airflow03/"},{"categories":["Airflow"],"content":"task 순서(dependency)정하기 \u003e\u003e 를 통해서 dependency를 알려준다. from airflow.models import DAG from airflow.providers.sqlite.operators.sqlite import SqliteOperator from airflow.providers.http.sensors.http import HttpSensor from airflow.providers.http.operators.http import SimpleHttpOperator from airflow.operators.python import PythonOperator from airflow.operators.bash import BashOperator from datetime import datetime import json from pandas import json_normalize # default로 넣고 싶은 인자들 default_args = { 'start_date': datetime(2022, 4, 20) } # extracting_user 를 통해 얻은 결과를 이용 # airflow tasks test user_processing extracting_user 2022-04-23 def _processing_user(ti): # extracting_user task의 결과가 metastore에 저장이 되고 이 결과를 pull 한다 users = ti.xcom_pull(task_ids=['extracting_user']) if not len(users) or 'results' not in users[0]: raise ValueError('User is empty') user = users[0]['results'][0] # json_normalize로 dict를 pd.DataFrame으로 변환 processed_user = json_normalize({ 'first_name': user['name']['first'], 'lastname': user['name']['last'], 'country': user['location']['country'], 'username': user['login']['username'], 'password': user['login']['password'], 'email': user['email'] }) processed_user.to_csv('/tmp/processed_user.csv', index=None, header=False) with DAG( 'user_processing', # dag_id는 unique 해야한다: 'user_processing' schedule_interval='@daily', default_args=default_args, catchup=False ) as dag: # define the task/operator creating_table = SqliteOperator( task_id='creating_table', # 하나의 pipeline에서 unique 해야함 sqlite_conn_id='db_sqlite', sql=''' CREATE TABLE IF NOT EXISTS users ( firstname TEXT NOT NULL, lastname TEXT NOT NULL, country TEXT NOT NULL, username TEXT NOT NULL, password TEXT NOT NULL, email TEXT NOT NULL PRIMARY KEY ); ''' ) is_api_available = HttpSensor( task_id='is_api_available', http_conn_id='user_api', endpoint='api/' ) extracting_user = SimpleHttpOperator( task_id='extracting_user', http_conn_id='user_api', endpoint='api/', method='GET', response_filter=lambda response: json.loads(response.text), log_response=True ) processing_user = PythonOperator( task_id='processing_user', python_callable=_processing_user ) storing_user = BashOperator( task_id='storing_user', bash_command='echo -e \".separator \",\"\\n.import /tmp/processed_user.csv\" | sqlite3 /home/airflow/airflow/airflow.db' ) creating_table \u003e\u003e is_api_available \u003e\u003e extracting_user \u003e\u003e processing_user \u003e\u003e storing_user ","date":"2022-04-17","objectID":"/airflow03/:1:6","tags":["Airflow"],"title":"[Airflow] Pipeline","uri":"/airflow03/"},{"categories":["Airflow"],"content":"Reference udemy: the complete hands on course to master apache airflow ","date":"2022-04-17","objectID":"/airflow03/:2:0","tags":["Airflow"],"title":"[Airflow] Pipeline","uri":"/airflow03/"},{"categories":["Airflow"],"content":"Airflow의 기본적인 구조와 CLI 명령어를 정리 ","date":"2022-04-17","objectID":"/airflow02/:0:0","tags":["Airflow"],"title":"[Airflow] 기본 구조, CLI 명령어","uri":"/airflow02/"},{"categories":["Airflow"],"content":"구조 webserver scheduler 설정한 시간에 맞춰 DAG를 실행할 수 있게 해줌 worker(excecutor) 실제 작업을 실행하는 주체 metaDB 작업관련 데이터들이 저장됨 ","date":"2022-04-17","objectID":"/airflow02/:1:0","tags":["Airflow"],"title":"[Airflow] 기본 구조, CLI 명령어","uri":"/airflow02/"},{"categories":["Airflow"],"content":"명령어 ","date":"2022-04-17","objectID":"/airflow02/:2:0","tags":["Airflow"],"title":"[Airflow] 기본 구조, CLI 명령어","uri":"/airflow02/"},{"categories":["Airflow"],"content":"db airflow db init 처음 시작할 때만 사용해야함 airflow에 필요한 file, data들을 생성 airflow db upgrade airflow db reset ","date":"2022-04-17","objectID":"/airflow02/:2:1","tags":["Airflow"],"title":"[Airflow] 기본 구조, CLI 명령어","uri":"/airflow02/"},{"categories":["Airflow"],"content":"webserver airflow webserver webserver를 실행 ","date":"2022-04-17","objectID":"/airflow02/:2:2","tags":["Airflow"],"title":"[Airflow] 기본 구조, CLI 명령어","uri":"/airflow02/"},{"categories":["Airflow"],"content":"dag airflow dags list 아래처럼 dag에 대한 정보를 보여준다' dag_id | filepath | owner | paused ===================================+===================================+=========+======= example_bash_operator | /home/airflow/sandbox/lib/python3 | airflow | True | .8/site-packages/airflow/example_ | | | dags/example_bash_operator.py | | ","date":"2022-04-17","objectID":"/airflow02/:2:3","tags":["Airflow"],"title":"[Airflow] 기본 구조, CLI 명령어","uri":"/airflow02/"},{"categories":["Airflow"],"content":"task airflow tasks list dag이름 해당 dag의 task의 이름을 보여준다 ","date":"2022-04-17","objectID":"/airflow02/:2:4","tags":["Airflow"],"title":"[Airflow] 기본 구조, CLI 명령어","uri":"/airflow02/"},{"categories":["Airflow"],"content":"Reference udemy: the complete hands on course to master apache airflow ","date":"2022-04-17","objectID":"/airflow02/:3:0","tags":["Airflow"],"title":"[Airflow] 기본 구조, CLI 명령어","uri":"/airflow02/"},{"categories":["Airflow"],"content":"Airflow를 공부하기 위해 vitualBox를 이용하여 세팅해보자. ","date":"2022-04-16","objectID":"/airflow01/:0:0","tags":["Airflow"],"title":"[Airflow] 설치","uri":"/airflow01/"},{"categories":["Airflow"],"content":"설치 vitualBox를 이용해서 진행한다. vitualBox를 설치하고 강의자가 제공하는 file을 이용하여 가상환경을 세팅한다. 그리고 vscode에서 ssh로 접근한다. ","date":"2022-04-16","objectID":"/airflow01/:1:0","tags":["Airflow"],"title":"[Airflow] 설치","uri":"/airflow01/"},{"categories":["Airflow"],"content":"ssh 연결 vscode extension에서 remote-ssh를 설치한다. cmd+p를 치고 \u003eremote-ssh라고 치고 Add New SSH Host...를 클릭한다. ssh -p 2222 airflow@localhost라고 친다. 그리고 첫번째 ssh config file을 클릭한다. 연결이 잘 되었다면 cmd+p를 치면 localhost가 뜰 것이고 이를 클릭한다. 그러면 접속이 될 것이다. ","date":"2022-04-16","objectID":"/airflow01/:1:1","tags":["Airflow"],"title":"[Airflow] 설치","uri":"/airflow01/"},{"categories":["Airflow"],"content":"airflow 설치 python virtual environment를 이용하여 airflow를 설치한다. 이미 강의자가 잘 세팅을 했고 이를 이용하기만 하면 된다. python3 -m venv sandbox source sandbox/bin/activate # 이러면 sandbox가 활성화된다 pip install wheel pip3 install apache-airflow==2.1.0 --constraint https://gist.githubusercontent.com/marclamberti/742efaef5b2d94f44666b0aec020be7c/raw/21c88601337250b6fd93f1adceb55282fb07b7ed/constraint.txt airflow db init # 필요한 파일들 생성 그러면 airflow 폴더가 만들어져있을 것이다. 그리고 airflow webserver라고 치면 localhost:8080에 들어가면 web이 띄워져 있다. 지금은 사용자를 생성하지 않은 상태이므로 사용자를 생성해보자. airflow users create -u admin -p admin -f minsoo -l song -r Admin -e admin@airflow.com 이제 web에 로그인할 수 있다. 처음에는 디폴트 예시 DAG들이 있을 것이다. ","date":"2022-04-16","objectID":"/airflow01/:1:2","tags":["Airflow"],"title":"[Airflow] 설치","uri":"/airflow01/"},{"categories":["Airflow"],"content":"Reference udemy: the complete hands on course to master apache airflow ","date":"2022-04-16","objectID":"/airflow01/:2:0","tags":["Airflow"],"title":"[Airflow] 설치","uri":"/airflow01/"},{"categories":["Computer Science"],"content":"입출력 시스템과 디스크 관리에 대해 알아보자. ","date":"2022-04-12","objectID":"/os_lec12_iosystemanddiskmanagement/:0:0","tags":["I/O system","Disk Management"],"title":"[OS] I/O system and Disk Management","uri":"/os_lec12_iosystemanddiskmanagement/"},{"categories":["Computer Science"],"content":"I/O Mechanism I/O 에서는 크게 두 가지 방식이 있다. Processor controlled memory access pooling interrupt direct memory access ","date":"2022-04-12","objectID":"/os_lec12_iosystemanddiskmanagement/:1:0","tags":["I/O system","Disk Management"],"title":"[OS] I/O system and Disk Management","uri":"/os_lec12_iosystemanddiskmanagement/"},{"categories":["Computer Science"],"content":"Pooling processor가 주기적으로 I/O 장치들을 순환하면서 상태를 확인 장점 simple I/O 장치가 빠르고 데이터 전송이 잦은 경우 효율적 단점 processor의 부담이 큼 (특히 I/O device가 느린 경우) ","date":"2022-04-12","objectID":"/os_lec12_iosystemanddiskmanagement/:1:1","tags":["I/O system","Disk Management"],"title":"[OS] I/O system and Disk Management","uri":"/os_lec12_iosystemanddiskmanagement/"},{"categories":["Computer Science"],"content":"Interrupt I/O 장치가 작업을 완료한 후, 자신의 상태를 processor에게 전달 interrupt 발생 시, processor는 데이터 전송 수행 장점 pooling 대비 low overhead 불규칙적인 요청 처리에 적합 단점 interrupt handling overhead Processor controlled memory access 방법은 processor가 모든 데이터 전송을 처리해야하는 단점이 존재한다. 전송하는 모든 과정에 참여해야 하기에 overhead가 있다. ","date":"2022-04-12","objectID":"/os_lec12_iosystemanddiskmanagement/:1:2","tags":["I/O system","Disk Management"],"title":"[OS] I/O system and Disk Management","uri":"/os_lec12_iosystemanddiskmanagement/"},{"categories":["Computer Science"],"content":"Direct memory access (DMA) processor는 I/O 장치와 memory 사이의 데이터 전송을 시작/종료에만 관여 processor가 명령 \u0026 관련정보 들을 DMA 제어기에 보내고 DMA가 I/O 작업을 진행하고 끝나면 processor에게 알린다 ","date":"2022-04-12","objectID":"/os_lec12_iosystemanddiskmanagement/:1:3","tags":["I/O system","Disk Management"],"title":"[OS] I/O system and Disk Management","uri":"/os_lec12_iosystemanddiskmanagement/"},{"categories":["Computer Science"],"content":"I/O services of OS I/O performance를 올리기 위해 OS가 제공하는 방법들을 알아보자. ","date":"2022-04-12","objectID":"/os_lec12_iosystemanddiskmanagement/:2:0","tags":["I/O system","Disk Management"],"title":"[OS] I/O system and Disk Management","uri":"/os_lec12_iosystemanddiskmanagement/"},{"categories":["Computer Science"],"content":"I/O scheduling 입출력 요청에 대한 처리 순서 결정 ","date":"2022-04-12","objectID":"/os_lec12_iosystemanddiskmanagement/:2:1","tags":["I/O system","Disk Management"],"title":"[OS] I/O system and Disk Management","uri":"/os_lec12_iosystemanddiskmanagement/"},{"categories":["Computer Science"],"content":"Error handling 입출력 중 발생하는 오류 처리 ","date":"2022-04-12","objectID":"/os_lec12_iosystemanddiskmanagement/:2:2","tags":["I/O system","Disk Management"],"title":"[OS] I/O system and Disk Management","uri":"/os_lec12_iosystemanddiskmanagement/"},{"categories":["Computer Science"],"content":"Buffering I/O 장치와 program 사이에 전송되는 데이터를 buffer에 임시저장 전송속도(or 처리단위) 차이 문제를 해결 ","date":"2022-04-12","objectID":"/os_lec12_iosystemanddiskmanagement/:2:3","tags":["I/O system","Disk Management"],"title":"[OS] I/O system and Disk Management","uri":"/os_lec12_iosystemanddiskmanagement/"},{"categories":["Computer Science"],"content":"Caching 자주 사용하는 데이터를 미리 복사해 둠 cache hit 시 I/O를 생략 할 수 있음 ","date":"2022-04-12","objectID":"/os_lec12_iosystemanddiskmanagement/:2:4","tags":["I/O system","Disk Management"],"title":"[OS] I/O system and Disk Management","uri":"/os_lec12_iosystemanddiskmanagement/"},{"categories":["Computer Science"],"content":"Spooling 한 I/O 장치에 여러 program이 요청을 보낼 시, 출력이 섞이지 않도록 하는 기법 각 program에 대응하는 disk file에 기록 (spooling) 예를 들어, 프린트에 여러 개의 요청이 쌓이면 섞이지 않도록 해야함 ","date":"2022-04-12","objectID":"/os_lec12_iosystemanddiskmanagement/:2:5","tags":["I/O system","Disk Management"],"title":"[OS] I/O system and Disk Management","uri":"/os_lec12_iosystemanddiskmanagement/"},{"categories":["Computer Science"],"content":"Disk Scheduling Disk access 요청들의 처리 순서를 결정하고 disk system의 성능을 향상시키기 위해서 스케쥴링을 잘해야 한다. 이 과정에 있어서 고려해야하는 주요 기준은 Throughput (단위 시간당 처리량), mean response time (평균 응답 시간), predictability (응답 시간의 예측성, 요청이 무기한 연기되지 않도록 방지) 이라고 할 수 있다. 아래는 방법론들이다. Optimizing seek time (head 이동) FCFS SSTF Scan scheduling C-Scan scheduling Look scheduling Optimizing rotational delay (돌아서 필요한 sector가 head로) SLTF SPTF (Shortest Positioning Time First) ","date":"2022-04-12","objectID":"/os_lec12_iosystemanddiskmanagement/:3:0","tags":["I/O system","Disk Management"],"title":"[OS] I/O system and Disk Management","uri":"/os_lec12_iosystemanddiskmanagement/"},{"categories":["Computer Science"],"content":"First Come First Service (FCFS) 요청이 도착한 순서에 따라 처리 simple, 공평한 처리 최적 성능 달성에 대한 고려가 없음 disk access 부하가 적은 경우에 적합 ","date":"2022-04-12","objectID":"/os_lec12_iosystemanddiskmanagement/:3:1","tags":["I/O system","Disk Management"],"title":"[OS] I/O system and Disk Management","uri":"/os_lec12_iosystemanddiskmanagement/"},{"categories":["Computer Science"],"content":"Shortest Seek Time First (SSTF) 현재 head 위치에서 가장 까까운 요청 먼저 처리 throughput은 mean response time은 낮은 장점 하지만 predictability가 낮고 starvation 현상이 발생가능 따라서 일괄처리 시스템에 적합하다 ","date":"2022-04-12","objectID":"/os_lec12_iosystemanddiskmanagement/:3:2","tags":["I/O system","Disk Management"],"title":"[OS] I/O system and Disk Management","uri":"/os_lec12_iosystemanddiskmanagement/"},{"categories":["Computer Science"],"content":"Scan scheduling 현재 head의 진행방향에서 head와 가장 가까운 요청 먼저 처리 진행방향 기준 마지막 cylinder 도착 후, 반대 방향으로 진행 SSTF의 starcation 문제 해결 Throughput 및 mean response time 우수 진행 방향 반대쪽 끝의 요청들의 응답시간이 길어진다 ","date":"2022-04-12","objectID":"/os_lec12_iosystemanddiskmanagement/:3:3","tags":["I/O system","Disk Management"],"title":"[OS] I/O system and Disk Management","uri":"/os_lec12_iosystemanddiskmanagement/"},{"categories":["Computer Science"],"content":"C-Scan scheduling scan과 유사하지만 head가 미리 정해진 방향으로만 이동 즉, 진행방향으로 가다가 끝 cylinder에 도착하면 그 반대 cylinder로 이동하여 같은 진행방향으로 진행 scan에 비해 균등한 기회제공 ","date":"2022-04-12","objectID":"/os_lec12_iosystemanddiskmanagement/:3:4","tags":["I/O system","Disk Management"],"title":"[OS] I/O system and Disk Management","uri":"/os_lec12_iosystemanddiskmanagement/"},{"categories":["Computer Science"],"content":"Look scheduling scan(C-scan)에서 현재 진행 방향에 요청이 없으면 방향 전환 ","date":"2022-04-12","objectID":"/os_lec12_iosystemanddiskmanagement/:3:5","tags":["I/O system","Disk Management"],"title":"[OS] I/O system and Disk Management","uri":"/os_lec12_iosystemanddiskmanagement/"},{"categories":["Computer Science"],"content":"Shortest latency time first (SLTF) fixed head dist 시스템에 사용 각 track마다 head가 있는 disk, head의 이동이 없음 sector queuing algorithm head 아래 도착한 sector의 queue에 있는 요청을 먼저 처리함 moving head disk의 경우는 같은 cylinder에 도착하면 queue에 있는 여러 개의 요청을 모두 처리 ","date":"2022-04-12","objectID":"/os_lec12_iosystemanddiskmanagement/:3:6","tags":["I/O system","Disk Management"],"title":"[OS] I/O system and Disk Management","uri":"/os_lec12_iosystemanddiskmanagement/"},{"categories":["Computer Science"],"content":"Shortest Positioning Time First (SPTF) positioning time = seek time + rotational delay positioning time이 가장 작은 요청 먼저 처리 throughput 높고, mean response time은 낮다는 장점 가장 안쪽과 바깥쪽 cylinder의 요청에 대해 starvation 발생 가능 ","date":"2022-04-12","objectID":"/os_lec12_iosystemanddiskmanagement/:3:7","tags":["I/O system","Disk Management"],"title":"[OS] I/O system and Disk Management","uri":"/os_lec12_iosystemanddiskmanagement/"},{"categories":["Computer Science"],"content":"RAID Architecture RAID (Redundant Array of Inexpensive Disks) 여러 개의 물리 disk를 하나의 논리 disk로 사용 disk system의 성능 향상을 위해 사용 ","date":"2022-04-12","objectID":"/os_lec12_iosystemanddiskmanagement/:4:0","tags":["I/O system","Disk Management"],"title":"[OS] I/O system and Disk Management","uri":"/os_lec12_iosystemanddiskmanagement/"},{"categories":["Computer Science"],"content":"RAID 0 disk striping block을 일정한 크기로 나누어 각 disk에 나누어 저장 모든 disk에 입출력 부하 균등 분배, parallel access, performance 향상 한 disk에서 장애시 데이터 손실 발생 (low reliability) ","date":"2022-04-12","objectID":"/os_lec12_iosystemanddiskmanagement/:4:1","tags":["I/O system","Disk Management"],"title":"[OS] I/O system and Disk Management","uri":"/os_lec12_iosystemanddiskmanagement/"},{"categories":["Computer Science"],"content":"RAID 1 Disk mirroring 동일한 데이터를 mirroring disk에 중복 저장 최소 2개의 disk로 구성되어야 함 (입출력은 둘 중 어느 disk에서 가능) 한 disk에서 장애가 생겨도 데이터를 중복 저장해서 괜찮다 (high reliability) 가용 disk 용량 = (전체 disk 용량 / 2) ","date":"2022-04-12","objectID":"/os_lec12_iosystemanddiskmanagement/:4:2","tags":["I/O system","Disk Management"],"title":"[OS] I/O system and Disk Management","uri":"/os_lec12_iosystemanddiskmanagement/"},{"categories":["Computer Science"],"content":"RAID 3 RAID 0 + parity disk byte 단위 분할 저장 모든 disk에 입출력 부하 균등 분배 parity라는 disk를 통해 나머지는 관리하는 느낌 (hadoop master node처럼) 한 disk에 장애 발생 시, parity 정보를 이용하여 복구 write 시 parity 계산 필요 ","date":"2022-04-12","objectID":"/os_lec12_iosystemanddiskmanagement/:4:3","tags":["I/O system","Disk Management"],"title":"[OS] I/O system and Disk Management","uri":"/os_lec12_iosystemanddiskmanagement/"},{"categories":["Computer Science"],"content":"RAID 4 RAID 3와 유사, 단 block 단위로 분산저장 ","date":"2022-04-12","objectID":"/os_lec12_iosystemanddiskmanagement/:4:4","tags":["I/O system","Disk Management"],"title":"[OS] I/O system and Disk Management","uri":"/os_lec12_iosystemanddiskmanagement/"},{"categories":["Computer Science"],"content":"Reference HPC Lab. KOREATECH 운영체제 강의 ","date":"2022-04-12","objectID":"/os_lec12_iosystemanddiskmanagement/:5:0","tags":["I/O system","Disk Management"],"title":"[OS] I/O system and Disk Management","uri":"/os_lec12_iosystemanddiskmanagement/"},{"categories":["Computer Science"],"content":"File System에 대해 알아보자 ","date":"2022-04-10","objectID":"/os_lec11_filesystem/:0:0","tags":["File System"],"title":"[OS] File System","uri":"/os_lec11_filesystem/"},{"categories":["Computer Science"],"content":"Disk System ","date":"2022-04-10","objectID":"/os_lec11_filesystem/:1:0","tags":["File System"],"title":"[OS] File System","uri":"/os_lec11_filesystem/"},{"categories":["Computer Science"],"content":"Disk Pack 먼저 Disk Pack에 대해 알아보자. Disk Pack은 데이터를 영구적으로 저장할 수 있는 비휘발성 장치를 의미한다. 그렇다면 Disk Pack의 구성요소에 대해 알아보자. Platter 양면에 자성물질을 입힌 원형 금속판 데이터의 기록/판독이 가능한 기록매체 Sector 데이터 기록/핀독의 물리적 단위 Track Platter 한 면에서 중심으로 같은 거리에 있는 sector들의 집합 Cylinder 같은 반지름을 갖는 track들의 집합 여러 개의 platter를 관통하는 집합 Surface platter의 윗면과 아랫면 ","date":"2022-04-10","objectID":"/os_lec11_filesystem/:1:1","tags":["File System"],"title":"[OS] File System","uri":"/os_lec11_filesystem/"},{"categories":["Computer Science"],"content":"Disk drive Disk drive는 Disk Pack에 데이터를 기록/판독할 수 있도록 구정된 장치이다. 구성요소를 알아보자. Head 디스크 표면에 데이터를 기록/판독 Arm Head를 고정/지탱 Positioner (boom) Arm을 지탱 Head를 원하는 track으로 이동 Spindle Disk pack을 고정 (회전축) RPM (Revolutions Per Minute): 분당 회전 수 ","date":"2022-04-10","objectID":"/os_lec11_filesystem/:1:2","tags":["File System"],"title":"[OS] File System","uri":"/os_lec11_filesystem/"},{"categories":["Computer Science"],"content":"Disk address Disk Pack에 있는 데이터를 기록/판독하기 위해서는 Disk address를 알아야한다. 먼저 Physical disk address는 cylinder number, surface number, sector number 이 3가지를 통해 해당하는 sector로 이동할 수 있다. 하지만 OS는 Logical disk address만 알고 사용한다. Disk system 데이터 전체를 block들의 나열로 취급한다. 따라서 os는 block number만 다루고 이를 disk driver가 physical address로 변환하여 disk에 접근하게 된다. Disk system에서 Data에 Access하는 시간은 아래와 같이 크게 3가지로 구분한다. (실행순서도) Seek time 디스크 head를 필요한 cylinder로 이동하는 시간 Rotational delay 필요한 sector가 head 위치로 도착하는 시간 Data transmission time 해당 sector를 읽어서 기록/전송하는 시간 ","date":"2022-04-10","objectID":"/os_lec11_filesystem/:1:3","tags":["File System"],"title":"[OS] File System","uri":"/os_lec11_filesystem/"},{"categories":["Computer Science"],"content":"File System File system의 구성 File: 보조 기억 장치에 저장된 연관된 정보들의 집합 Directory structure: 시스템 내 파일들의 정보를 구성 및 제공 Partitions: Directory들의 집합을 논리적/물리적으로 구분 ","date":"2022-04-10","objectID":"/os_lec11_filesystem/:2:0","tags":["File System"],"title":"[OS] File System","uri":"/os_lec11_filesystem/"},{"categories":["Computer Science"],"content":"Directory Structure ","date":"2022-04-10","objectID":"/os_lec11_filesystem/:3:0","tags":["File System"],"title":"[OS] File System","uri":"/os_lec11_filesystem/"},{"categories":["Computer Science"],"content":"Flat Directory Structure File system에 directory가 하나만 존재하는 경우이다. 옛날 mp3 생각하면 될 것 같다. 문제 file naming file protection file management 다중 사용자 환경에서 문제가 더욱 커진다 ","date":"2022-04-10","objectID":"/os_lec11_filesystem/:3:1","tags":["File System"],"title":"[OS] File System","uri":"/os_lec11_filesystem/"},{"categories":["Computer Science"],"content":"2-Level Directory Structure 사용자마다 하나의 directory 배정 문제 flat과 거의 유사 ","date":"2022-04-10","objectID":"/os_lec11_filesystem/:3:2","tags":["File System"],"title":"[OS] File System","uri":"/os_lec11_filesystem/"},{"categories":["Computer Science"],"content":"Hierarchinal Directory Structure tree 형태의 계층적 directory 사용 가능 사용자가 하부 directory 생성/관리 가능 대부분의 OS가 사용 ","date":"2022-04-10","objectID":"/os_lec11_filesystem/:3:3","tags":["File System"],"title":"[OS] File System","uri":"/os_lec11_filesystem/"},{"categories":["Computer Science"],"content":"Acyclic Graph Directory Structure Hierachinal directory structure의 확장 directory안에 shared directory, shared file를 담을 수 있다. 이는 link의 개념을 사용했다고 할 수 있다. ","date":"2022-04-10","objectID":"/os_lec11_filesystem/:3:4","tags":["File System"],"title":"[OS] File System","uri":"/os_lec11_filesystem/"},{"categories":["Computer Science"],"content":"General Graph Directory Structure cycle을 허용 하지만 infinite loop 가 생성되지 않도록 조심해야 한다 ","date":"2022-04-10","objectID":"/os_lec11_filesystem/:3:5","tags":["File System"],"title":"[OS] File System","uri":"/os_lec11_filesystem/"},{"categories":["Computer Science"],"content":"File Protection File에 대한 부적절한 접근을 방지하는 것은 특히 다중 사용자 시스템에서 더 필요하다. 접근 제어가 필요한 연산들은 주로 read, write, execute, append이다. 그렇다면 파일을 보호하는 방법들은 어떤게 있을까? File Protection mechanism password 기법 모든 file과 접근제어연산 마다 pw를 부여하기 현실적으로 어렵다 따라서 몇 가지 중요한 file에만 사용 access matrix 기법 ","date":"2022-04-10","objectID":"/os_lec11_filesystem/:4:0","tags":["File System"],"title":"[OS] File System","uri":"/os_lec11_filesystem/"},{"categories":["Computer Science"],"content":"Access matrix 범위(domain)와 개체(object) 사이의 접근 권한을 명시한 것이다. object: 접근 대상 (file , device…) domain: 접근 권한의 집합 access right: \u003cobject-name, right\u003e 그렇다면 이런 access matrix를 실제로 어떻게 구현하는지에 대해 알아보자. Access List Access matrix의 열을 list로 표현 object 생성 시, 각 domain에 대한 권한 부여 object 접근 시, 권한을 검사 실제 os에서 많이 사용됨 ls- l 명령어 치면 나오는 것처럼 Capability List Access matrix의 행을 list로 표현 각 domain별로 obejct와 관련 접근권한을 나열 프로세스가 권한을 제시하고 시스템이 검증을 승인 Access list의 경우 object별 권한 관리가 용이하다. 하지만 모든 접근마다 권한을 검사해야하는 하기 때문에 느려질 수도 있다. 반면에 Capability list는 list내 object들에 대한 접근에 유리하지만 object별 권한관리가 어렵다. 그래서 많은 OS에서 이를 모두 이용한다. object에 대한 첫 접근 $\\rightarrow$ access list 탐색 접근이 허용된다면 capability를 생성하여 프로세스에게 전달 따라서 이후 접근시에는 권한검사가 필요없이 프로세스가 capability를 제시하고 접근 마지막 접근 후에 capability를 삭제 ","date":"2022-04-10","objectID":"/os_lec11_filesystem/:4:1","tags":["File System"],"title":"[OS] File System","uri":"/os_lec11_filesystem/"},{"categories":["Computer Science"],"content":"File system implementation 이번에는 file 저장을 위한 디스크 공간 할당 방법을 알아보자. Allocation Continuous Discontinuous (linked, indexed) ","date":"2022-04-10","objectID":"/os_lec11_filesystem/:5:0","tags":["File System"],"title":"[OS] File System","uri":"/os_lec11_filesystem/"},{"categories":["Computer Science"],"content":"Continuous Allocation 한 file을 디스크의 연속된 block에 저장 장점 효율적인 file 접근 단점 새로운 file을 위한 공간 확보가 어려움 external fragmentation file 공간 크기 결정이 어려움, 나중에 파일이 커지게 된다면? ","date":"2022-04-10","objectID":"/os_lec11_filesystem/:5:1","tags":["File System"],"title":"[OS] File System","uri":"/os_lec11_filesystem/"},{"categories":["Computer Science"],"content":"Linked Allocation file이 저장된 block들을 linked list로 연결 directory는 각 file에 대한 첫번째 block에 대한 포인터를 가짐 장점 순처적 접근에는 효율적 no external fragmentation 단점 직접 접근에 비효율적 포인터 저장을 위한 공간이 필요, 포인터를 사용자가 건드릴수도 있음 ","date":"2022-04-10","objectID":"/os_lec11_filesystem/:5:2","tags":["File System"],"title":"[OS] File System","uri":"/os_lec11_filesystem/"},{"categories":["Computer Science"],"content":"Indexed Allocation file이 저장된 block의 정보(pointer)를 index block에 모아둔다 장점 직접 접근에는 효율적 단점 순차적 접근에는 비효율적 file당 index block을 유지해야 되서 space overhead가 발생할 수 있다 ","date":"2022-04-10","objectID":"/os_lec11_filesystem/:5:3","tags":["File System"],"title":"[OS] File System","uri":"/os_lec11_filesystem/"},{"categories":["Computer Science"],"content":"Free space management 빈 공간을 다루는 방법을 알아보자. Bit vector Linked list Grouping Counting ","date":"2022-04-10","objectID":"/os_lec11_filesystem/:6:0","tags":["File System"],"title":"[OS] File System","uri":"/os_lec11_filesystem/"},{"categories":["Computer Science"],"content":"Bit vector 시스템 내 모든 block들에 대한 사용여부를 1 bit flag로 표시 bit vector 전체를 메모리에 보관해야 한다 ","date":"2022-04-10","objectID":"/os_lec11_filesystem/:6:1","tags":["File System"],"title":"[OS] File System","uri":"/os_lec11_filesystem/"},{"categories":["Computer Science"],"content":"Linked list 빈 block을 linked list로 연결 비효율적 (공간, 직접접근) ","date":"2022-04-10","objectID":"/os_lec11_filesystem/:6:2","tags":["File System"],"title":"[OS] File System","uri":"/os_lec11_filesystem/"},{"categories":["Computer Science"],"content":"Grouping n개의 빈 block을 그룹으로 묶고, 그룹 단위로 linked list로 연결 연속된 빈 block을 쉽게 찾을 수 있음 ","date":"2022-04-10","objectID":"/os_lec11_filesystem/:6:3","tags":["File System"],"title":"[OS] File System","uri":"/os_lec11_filesystem/"},{"categories":["Computer Science"],"content":"Counting 연속된 빈 block들 중에서 첫번째 block의 주소와 연속된 block의 수를 table로 유지 continuous allocation 시스템에 유리한 기법 예시: (0번위치, 6개), (13번위치,10개) ","date":"2022-04-10","objectID":"/os_lec11_filesystem/:6:4","tags":["File System"],"title":"[OS] File System","uri":"/os_lec11_filesystem/"},{"categories":["Computer Science"],"content":"Reference HPC Lab. KOREATECH 운영체제 강의 ","date":"2022-04-10","objectID":"/os_lec11_filesystem/:7:0","tags":["File System"],"title":"[OS] File System","uri":"/os_lec11_filesystem/"},{"categories":["Computer Science"],"content":"virtual memory를 다루는 방법들을 알아보자 새로운 page를 어떤 page와 교체할 것인가? (빈 page frame이 없는 경우) 에 대한 전략들을 알아보자. Fixed allocation을 위한 기법 MIN, Random, FIFO, LRU, LFU, NUR, Clock, Second chance algorithm Variable allocation을 위한 기법 VMIN, WS, PFF algorithm ","date":"2022-04-09","objectID":"/os_lec10_virtualmemorymanagement2/:0:0","tags":["virtual memory management"],"title":"[OS] Virtual Memory Management (2)","uri":"/os_lec10_virtualmemorymanagement2/"},{"categories":["Computer Science"],"content":"Fixed allocation ","date":"2022-04-09","objectID":"/os_lec10_virtualmemorymanagement2/:1:0","tags":["virtual memory management"],"title":"[OS] Virtual Memory Management (2)","uri":"/os_lec10_virtualmemorymanagement2/"},{"categories":["Computer Science"],"content":"MIN Algorithm 앞으로 가장 오랫동안 참조되지 않을 page를 교체하는 방법 minimize page fault frequency (optimal solution) 할 수 있는 것이 증명되었다 하지만 page reference string (참조되는 순서) 을 미리 알고 있어야 한다 따라서 실현 불가능한 기법 ","date":"2022-04-09","objectID":"/os_lec10_virtualmemorymanagement2/:1:1","tags":["virtual memory management"],"title":"[OS] Virtual Memory Management (2)","uri":"/os_lec10_virtualmemorymanagement2/"},{"categories":["Computer Science"],"content":"Random Alogorithm 무작위로 교체할 page 선택 ","date":"2022-04-09","objectID":"/os_lec10_virtualmemorymanagement2/:1:2","tags":["virtual memory management"],"title":"[OS] Virtual Memory Management (2)","uri":"/os_lec10_virtualmemorymanagement2/"},{"categories":["Computer Science"],"content":"FIFO Algorithm page가 적재된지 가장 오래된 page를 교체 적재된 시간을 기억하고 있어야 한다 locality에 대한 고려가 없어서 자주 사용되는 page도 교체될 수도 있다 FIFO anomaly 더 많은 page frame을 할당받았음에도 page fault의 수가 증가하는 경우가 있다 ","date":"2022-04-09","objectID":"/os_lec10_virtualmemorymanagement2/:1:3","tags":["virtual memory management"],"title":"[OS] Virtual Memory Management (2)","uri":"/os_lec10_virtualmemorymanagement2/"},{"categories":["Computer Science"],"content":"LRU (Least Recently Used) Algorithm 가장 오랫동안 참조되지 않은 page를 교체 page 참조할때 마다 시간을 기록해야 한다 locality에 기반을 둔 방법으로 min algorithm에 근접한 성능을 보여줘서 실제로 가장 많이 활용된다고 한다 단점 참조할때 마다 시간을 기록해야한다 (overhead), 다만 정확한 시간대신 순서를 기록하는 등의 방법을 이용할 수도 있다 Loop 실행에 필요한 크기보다 작은 수의 page frame이 할당된 경우, page fault 수가 급격히 증가한다 예를 들어, loop 실행으로 page 1,2,3,4가 있고 할당된 page frame이 3개이면 계속 page fault가 발생 이는 Allocation 기법에서 해결해야 한다 아래의 표에서 Time=6에서 이제 page5가 메모리에 적재되어야 한다. 따라서 LRU의 정책에 따라 가장 오랫동안 참조되지 않는 page2와 바꾸면서 page fault가 일어난다. ","date":"2022-04-09","objectID":"/os_lec10_virtualmemorymanagement2/:1:4","tags":["virtual memory management"],"title":"[OS] Virtual Memory Management (2)","uri":"/os_lec10_virtualmemorymanagement2/"},{"categories":["Computer Science"],"content":"LFU (Least Frequently Used) Algorithm 가장 참조 횟수가 적은 page를 교체 따라서 page 참조할때 마다 참조 횟수를 누적시켜야함 locality 활용하고 LRU 대비 적은 overhead (시간이 아니라 횟수누적만 하면 되니까) 단점 최근 적재되어서 참조횟수는 적지만 곧 다시 참조될 가능성이 높은 page가 교체될 가능성이 있다 참조누적횟수도 overhead가 없는 것은 아니다 ","date":"2022-04-09","objectID":"/os_lec10_virtualmemorymanagement2/:1:5","tags":["virtual memory management"],"title":"[OS] Virtual Memory Management (2)","uri":"/os_lec10_virtualmemorymanagement2/"},{"categories":["Computer Science"],"content":"Clock Algorithm reference bit 를 사용한다, 다만 주기적인 초기화는 없다 page frame들을 순차적으로 가리키는 pointer(시계바늘같은 것)를 사용하여 교체될 page를 결정한다 pointer를 돌리면서 교체 page를 결정한다 현재 가리키고 있는 page의 reference bit 를 확인한다 $r=0$인 경우, 교체 page로 결정 $r=1$인 경우, reference bit 초기화 후 pointer를 이동한다 위와 같은 방법으로 진행하면 먼저 적재된 page가 교체될 가능성이 높아진다 (FIFO처럼) 아래 표에서 time=5가 되면 e가 들어와야하므로 pointer가 돌기 시작한다. 지금 모두 ref가 1이므로 0으로 초기화하면서 pointer가 이동한다. 한 바퀴 다 돌고 다시 frame0으로 왔더니 ref가 0이므로 a를 내리고 e를 적재한다. 그리고 ref를 1로 바꾼다. ","date":"2022-04-09","objectID":"/os_lec10_virtualmemorymanagement2/:1:6","tags":["virtual memory management"],"title":"[OS] Virtual Memory Management (2)","uri":"/os_lec10_virtualmemorymanagement2/"},{"categories":["Computer Science"],"content":"Second Change Algorith Clock algorithm과 유사하나 update bit 도 함께 고려한다. (ref bit, update bit) 를 확인 (0,0): 교체 page로 결정 (0,1): (0,0)으로 바꿈 \u0026 write-back list 에 추가 후 이동 (1,0): (0,0)으로 바꾸고 이동 (1,1): (0,1)으로 바꾸고 이동 ","date":"2022-04-09","objectID":"/os_lec10_virtualmemorymanagement2/:1:7","tags":["virtual memory management"],"title":"[OS] Virtual Memory Management (2)","uri":"/os_lec10_virtualmemorymanagement2/"},{"categories":["Computer Science"],"content":"Variable allocation variable allocation의 경우 page fault만으로 성능평가를 하는게 아니라 다른 지표도 함께 봐야한다. 예를 들어, 할당받는 page frame의 수가 달라지므로 할당받는 평균 page frame의 수를 추가적인 성능 지표로 생각할 수 있다. 동일한 page fault가 발생한다면 할당받는 page frame이 적을수록 더 좋은 알고리즘이라고 할 수 있을 것이다. ","date":"2022-04-09","objectID":"/os_lec10_virtualmemorymanagement2/:2:0","tags":["virtual memory management"],"title":"[OS] Virtual Memory Management (2)","uri":"/os_lec10_virtualmemorymanagement2/"},{"categories":["Computer Science"],"content":"Working Set Algorithm Working set process가 특정 시점에 자주 참조하는 page들의 집합 최근 일정시간 $[ t - \\Delta, t ]$ 동안 참조된 page들의 집합 Window size ($\\Delta$)는 고정한다 당연히 시간에 따라 변한다 Working set을 항상 메모리에 유지한다 page fault rate 감소, 시스템 성능 향상 locality를 고려하는 것 working set이 달라지는 시점에 page frame의 할당수도 달라질 수 있다 적재되는 page가 없어도 메모리를 반납하는 page가 있을 수 있다 새로 적재되는 page가 있더라도 교체되는 page가 없을 수 있다 단점 working set management overhead page fault가 없어도 set를 지속적으로 관리해야한다 time=1 일 때, set은 {4,3,0,2}이고 다음 time이 되면 적재될 page가 없어도 set가 {3,0,2}이기 때문에 4가 메모리에서 빠진다. 그래서 할당된 page frame의 수도 3으로 줄어든다. ","date":"2022-04-09","objectID":"/os_lec10_virtualmemorymanagement2/:2:1","tags":["virtual memory management"],"title":"[OS] Virtual Memory Management (2)","uri":"/os_lec10_virtualmemorymanagement2/"},{"categories":["Computer Science"],"content":"PFF (Page Fault Frequency) Algorithm Residence set size를 page fault rate에 따라 결정한다 Low page fault rate: process에게 할당된 page frame 수를 감소 High page fault rate: process에게 할당된 page frame 수를 증가 이는 지난 page fault와 현재 page fault 사이의 시간이 특정 값보다 큰지 작은지로 판단 Resident set 갱신 및 메모리 할당은 WS알고리즘과 다르게 page fault가 발생할때만 수행한다 ","date":"2022-04-09","objectID":"/os_lec10_virtualmemorymanagement2/:2:2","tags":["virtual memory management"],"title":"[OS] Virtual Memory Management (2)","uri":"/os_lec10_virtualmemorymanagement2/"},{"categories":["Computer Science"],"content":"Variable MIN Algorithm Variable allocation 기반 교체 기법 중 optimal algorithm 평균 메모리 할당량과 page fault 발생 횟수 모두 고려 page reference string을 미리 알고 있어야해서 실현 불가능한 기법 과정 page $i$가 $t$시간에 참조되면 $(t,t+\\Delta ]$ 사이에 다시 참조되는지 확인 참조 된다면, page $i$를 유지 참조 안된다면, page $i$를 메모리에서 내림 ","date":"2022-04-09","objectID":"/os_lec10_virtualmemorymanagement2/:2:3","tags":["virtual memory management"],"title":"[OS] Virtual Memory Management (2)","uri":"/os_lec10_virtualmemorymanagement2/"},{"categories":["Computer Science"],"content":"Other Consideration ","date":"2022-04-09","objectID":"/os_lec10_virtualmemorymanagement2/:3:0","tags":["virtual memory management"],"title":"[OS] Virtual Memory Management (2)","uri":"/os_lec10_virtualmemorymanagement2/"},{"categories":["Computer Science"],"content":"Page size 아래 표와 같은 특징이 있다. Small page size Laarge page size internal fragement 감소 internal fragement 증가 IO 시간 증가 IO 시간 감소 Locality 향상 Locality 저하 page fault 증가 page fault 감소 그런데 요즘은 CPU가 발전되고 memory size도 많이 커졌다. 따라서 IO의 시간(disk에서 memory또는cpu 사이의 IO)이 감소할수록 좋고 상대적으로 page fault가 성능을 좌지우지하는 경향이 강해져서 page size가 커지는 경향이 있다. ","date":"2022-04-09","objectID":"/os_lec10_virtualmemorymanagement2/:3:1","tags":["virtual memory management"],"title":"[OS] Virtual Memory Management (2)","uri":"/os_lec10_virtualmemorymanagement2/"},{"categories":["Computer Science"],"content":"Reference HPC Lab. KOREATECH 운영체제 강의 ","date":"2022-04-09","objectID":"/os_lec10_virtualmemorymanagement2/:4:0","tags":["virtual memory management"],"title":"[OS] Virtual Memory Management (2)","uri":"/os_lec10_virtualmemorymanagement2/"},{"categories":["Computer Science"],"content":"virtual memory를 다루는 방법들을 알아보자 이전에 virtual memory에 대해서 공부했었다. 그렇다면 이제 virtual memory를 관리하는 방법에 대해 알아보자. 왜 virtual memory를 잘 관리해야할까? 당연히 시스템 성능을 높이기 위해서다. vitual memory는 상당히 유용한 방법이지만 이를 잘 관리해야 유용한 방법이 된다. 따라서 다양한 최적화기법을 이번 챕터에서 공부하고자 한다. 먼저 관리를 잘하는지 평가하기 위해서는 cost model이 필요하다. virtual memory에서 주로 사용하는 cost model은 page fault에 관한 것이다. page fault frequency page fault rate ($F(w)$) page reference string: 프로세스 수행 중 참조한 페이지 번호 순서 $w = r_1 r_2…r_T$, $r_i$: 페이지 번호 $F(w)=\\frac{\\text{num of page faults during } w}{|w|}$ cost model을 page fault rate로 정했다면 이를 최소화하기 위해 노력해야한다. 이제 어떤 방법들이 있는지 알아보자. ","date":"2022-04-03","objectID":"/os_lec10_virtualmemorymanagement1/:0:0","tags":["virtual memory management"],"title":"[OS] Virtual Memory Management (1)","uri":"/os_lec10_virtualmemorymanagement1/"},{"categories":["Computer Science"],"content":"Hardware component Hardware적인 방법을 알아보자. 먼저 Address translation device가 있다. 이는 이전 Lec09에서 본 TLB같은 것들이다. 그 다음으로는 Bit Vectors에 대해 알아보자. Bit Vectors는 page 사용상황에 대한 정보를 기록하는 것이다. 두 가지 종류가 있다. Reference bits (used bits) 메모리에 적대된 각각의 page가 최근에 참조 되었는지를 표시 이를 통해 최근에 참조된 page들을 확인할 수 있다 프로세스에 의해 참조되면 해당 page의 Ref.bit를 1로 설정하고 이를 계속 유지하는게 아니라 주기적으로 모든 Ref.bit를 0으로 초기화 Update bits (write bits, dirty bits) page가 메모리에 적대된 후, 프로세스에 의해 수정되었는지를 표시 이를 통해 해당 page에 대한 write-back to swap device를 해야하는지 판단할 수 있다 주기적으로 초기화하지 않고 메모리에서 나올때 0으로 초기화 (write-back하면서) ","date":"2022-04-03","objectID":"/os_lec10_virtualmemorymanagement1/:1:0","tags":["virtual memory management"],"title":"[OS] Virtual Memory Management (1)","uri":"/os_lec10_virtualmemorymanagement1/"},{"categories":["Computer Science"],"content":"Software component software적으로 virtual memory 성능 향상을 위한 관리 기법들에 대해 알아보자. Allocation strategy Fetch strategy Placement strategy Replacement strategy Cleaning strategy Load control strategy ","date":"2022-04-03","objectID":"/os_lec10_virtualmemorymanagement1/:2:0","tags":["virtual memory management"],"title":"[OS] Virtual Memory Management (1)","uri":"/os_lec10_virtualmemorymanagement1/"},{"categories":["Computer Science"],"content":"Allocation strategy 각 프로세스에게 메모리를 얼마만큼, 어떻게 줄 것인가? Fixed allocation (고정할당) 프로세스의 실행동안 고정된 크기의 메모리 할당 Variable allocation (가변할당) 프로세스의 실행동안 할당하는 메모리의 크기가 유동적 프로세스 실행에 필요한 메모리 양을 예측해야 함 (어려움) 너무 큰 메모리를 할당하면 메모리가 낭비되고 너무 적은 메모리를 할당하면 page fault rate가 올라가서 시스템성능이 떨어진다. ","date":"2022-04-03","objectID":"/os_lec10_virtualmemorymanagement1/:2:1","tags":["virtual memory management"],"title":"[OS] Virtual Memory Management (1)","uri":"/os_lec10_virtualmemorymanagement1/"},{"categories":["Computer Science"],"content":"Fetch strategy 특정 page를 메모리에 언제 적재할 것인가? Demand fetch (demand paging) 프로세스가 참조하는 페이지들만 적재 page fault overhead Anticipatory fetch (pre-paging) 참조될 가능이 높은 page 예측 가까운 미래에 참조될 가능성이 높은 page를 미리 적재 예측 성공 시, page fault overhead가 없음 (어려움, prediction overhead) 일반적으로 대부분의 시스템은 Demand fetch를 사용한다고 한다. ","date":"2022-04-03","objectID":"/os_lec10_virtualmemorymanagement1/:2:2","tags":["virtual memory management"],"title":"[OS] Virtual Memory Management (1)","uri":"/os_lec10_virtualmemorymanagement1/"},{"categories":["Computer Science"],"content":"Placement strategy page/segment를 어디에 적재할 것인가? paging system에는 불필요 sementation system에서는 first-fit, best-fit, worst-fit, next-fit ","date":"2022-04-03","objectID":"/os_lec10_virtualmemorymanagement1/:2:3","tags":["virtual memory management"],"title":"[OS] Virtual Memory Management (1)","uri":"/os_lec10_virtualmemorymanagement1/"},{"categories":["Computer Science"],"content":"Replacement strategy 새로운 page를 어떤 page와 교체할 것인가? (빈 page frame이 없는 경우) 이 부분은 뒤에서 좀 더 자세히 볼 예정이다. Fixed allocation을 위한 기법 MIN, Random, FIFO, LRU, LFU, NUR, Clock, Second chance algorithm Variable allocation을 위한 기법 VMIN, WE, PFF algorithm ","date":"2022-04-03","objectID":"/os_lec10_virtualmemorymanagement1/:2:4","tags":["virtual memory management"],"title":"[OS] Virtual Memory Management (1)","uri":"/os_lec10_virtualmemorymanagement1/"},{"categories":["Computer Science"],"content":"Cleaning strategy 변경된 page를 언제 write-back 할 것인가? Demand cleaning 해당 page에 메모리에서 내려올 떄 write-back Anticipatory cleaning (pre-cleaning) 더 이상 변경될 가능성이 없다고 판단 할 떄, 미리 write-back (어려움, prediction overhead) page 교체 시 발생하는 write-back 시간 절약 근데 write-back 이후, page 내용이 또 수정되면 overhead 여기서도 대부분의 시스템은 Demand cleaning 기법을 사용한다고 한다. ","date":"2022-04-03","objectID":"/os_lec10_virtualmemorymanagement1/:2:5","tags":["virtual memory management"],"title":"[OS] Virtual Memory Management (1)","uri":"/os_lec10_virtualmemorymanagement1/"},{"categories":["Computer Science"],"content":"Load control strategy 시스템의 multi-programming degree를 조절하는 방법이다. 적정 수준의 multi-programming degree를 유지해야 한다. if 저부하 상태 시스템 자원 낭비 \u0026 성능 저하 if 고부하 상태 자원에 대한 경쟁이 심해져서 성능 저하 Thrashing(스레싱) 현상 발생: 과도한 page fault발생하는 현상 ","date":"2022-04-03","objectID":"/os_lec10_virtualmemorymanagement1/:2:6","tags":["virtual memory management"],"title":"[OS] Virtual Memory Management (1)","uri":"/os_lec10_virtualmemorymanagement1/"},{"categories":["Computer Science"],"content":"Reference HPC Lab. KOREATECH 운영체제 강의 ","date":"2022-04-03","objectID":"/os_lec10_virtualmemorymanagement1/:3:0","tags":["virtual memory management"],"title":"[OS] Virtual Memory Management (1)","uri":"/os_lec10_virtualmemorymanagement1/"},{"categories":["Causality"],"content":"MS의 causal inference를 공개한 library DoWhy에 대해 알아보자 DoWhy는 causality에 관련하여 다양한 기능을 제공한다. 이를 사용하는 tutorial을 진행하면서 DoWhy에 대해 이해하고 observational data를 이용한 causal inference의 과정에 대해 이해하고자 한다. 먼저, DoWhy에서 제공(제안)하는 causal inference의 단계는 다음과 같다. Modeling: Create a causal graph to encode assumptions Identification: Formulate what to estimate Estimation: Compute the estimate Refutation: Validate the assumptions DoWhy에서는 기본적으로 causal graph를 이용하여 inference를 진행한다. 실제 데이터에서 causal graph를 알아내기는 쉽지 않다. domain 지식을 이용해야한다. 물론 DoWhy에서 causal discovery의 기능도 제공한다. causal graph를 찾았으면 이제 identification을 할 차례이다. 이 과정은 causal graph를 이용하여 causality를 추정할 수 있는지 확인하는 과정이라고 할 수 있다. 다양한 방법들이 있다. Graphical constraint-based methods RCT Backdoor criterion Frontdoor criterion Mediation Non-graphical constraints methods Instrumental variables Regression discontinuity Difference-in-difference identification이 잘 됐다면 우리는 estimation할 수 있다. estimation에도 다양한 방법들이 있다. conditioning Matching Stratification Propensity Score-Based Propensity Mathching Inverse Propensity Weighting Synthetic Control Outcome-Based Double ML T-learner X-learner Loss-Based R-learner Threshold-based DID 마지막으로 estimation으로 causal inference를 완료하였다면 이를 validation하는 과정도 필요하다. 하지만 causality의 경우 정답지가 없기 때문에 우리가 잘했는지 확인하기 어렵다. 대신에 여러가지 가정들을 확인하면서 틀렸는지는 확인해볼 수 있다. Unit test Model Conditional independence test Identify D-seperatio test Estimate Bootstrap refuter data subset refuter Integration test Placebo treatment refuter Dummy outcome refuter Random common cause refuter sensitivity analysis simulated outcome refuter ","date":"2022-04-02","objectID":"/dowhy_00_tutorial/:0:0","tags":["DoWhy"],"title":"[DoWhy] Tutorial","uri":"/dowhy_00_tutorial/"},{"categories":["Causality"],"content":"Practice 전체코드는 github에 올려놓았다. 공홈을 거의 그대로 따라했다. ","date":"2022-04-02","objectID":"/dowhy_00_tutorial/:1:0","tags":["DoWhy"],"title":"[DoWhy] Tutorial","uri":"/dowhy_00_tutorial/"},{"categories":["Causality"],"content":"data 먼저 data를 생성해보자. beta가 true causal effect이다. data = dowhy.datasets.linear_dataset(beta=10, num_common_causes=5, num_instruments = 2, num_effect_modifiers=1, num_samples=5000, treatment_is_binary=True, stddev_treatment_noise=10, num_discrete_common_causes=1) df = data[\"df\"] data에 들어있는 값들은 아래와 같다. (df제외, df는 위의 조건대로 만들어진 pandas.DataFrame) 'treatment_name': ['v0'], 'outcome_name': 'y', 'common_causes_names': ['W0', 'W1', 'W2', 'W3', 'W4'], 'instrument_names': ['Z0', 'Z1'], 'effect_modifier_names': ['X0'], 'frontdoor_variables_names': [], 'dot_graph': 'digraph {v0-\u003ey;W0-\u003e v0; W1-\u003e v0; W2-\u003e v0; W3-\u003e v0; W4-\u003e v0;Z0-\u003e v0; Z1-\u003e v0;W0-\u003e y; W1-\u003e y; W2-\u003e y; W3-\u003e y; W4-\u003e y;X0-\u003e y;}', 'gml_graph': 'graph[directed 1node[ id \"y\" label \"y\"]node[ id \"W0\" label \"W0\"] node[ id \"W1\" label \"W1\"] node[ id \"W2\" label \"W2\"] node[ id \"W3\" label \"W3\"] node[ id \"W4\" label \"W4\"]node[ id \"Z0\" label \"Z0\"] node[ id \"Z1\" label \"Z1\"]node[ id \"v0\" label \"v0\"]edge[source \"v0\" target \"y\"]edge[ source \"W0\" target \"v0\"] edge[ source \"W1\" target \"v0\"] edge[ source \"W2\" target \"v0\"] edge[ source \"W3\" target \"v0\"] edge[ source \"W4\" target \"v0\"]edge[ source \"Z0\" target \"v0\"] edge[ source \"Z1\" target \"v0\"]edge[ source \"W0\" target \"y\"] edge[ source \"W1\" target \"y\"] edge[ source \"W2\" target \"y\"] edge[ source \"W3\" target \"y\"] edge[ source \"W4\" target \"y\"]node[ id \"X0\" label \"X0\"] edge[ source \"X0\" target \"y\"]]', 'ate': 12.852576193620925} ","date":"2022-04-02","objectID":"/dowhy_00_tutorial/:1:1","tags":["DoWhy"],"title":"[DoWhy] Tutorial","uri":"/dowhy_00_tutorial/"},{"categories":["Causality"],"content":"Model causal mechanism 위에서 만든 data를 이용하여 causal graph를 생성한다. model=CausalModel( data = df, treatment=data[\"treatment_name\"], outcome=data[\"outcome_name\"], graph=data[\"gml_graph\"] ) 생성한 데이터가 아닌 다른 데이터를 이용하려면 위와 같은 format으로 만들면 된다. 갖고 있는 데이터에 대해 저절로 찾아주는게 아니라 사용자가 알려줘야한다. # 예시 causal_graph = \"\"\" digraph { High_limit; Churn; Income_Category; Education_Level; Customer_Age; U[label=\"Unobserved Confounders\"]; Customer_Age -\u003e Education_Level; Customer_Age -\u003e Income_Category; Education_Level -\u003e Income_Category; Income_Category-\u003eHigh_limit; U-\u003eIncome_Category;U-\u003eHigh_limit;U-\u003eChurn; High_limit-\u003eChurn; Income_Category -\u003e Churn; } \"\"\" model= CausalModel( data = training, # dataframe graph=causal_graph.replace(\"\\n\", \" \"), treatment='High_limit', outcome='Churn') 그러면 어떤 causal graph가 만들어졌는지 확인해보자. model.view_model() from IPython.display import Image, display display(Image(filename=\"causal_model.png\")) 각 node가 의미하는 바는 위의 data 설명을 참고하자. ","date":"2022-04-02","objectID":"/dowhy_00_tutorial/:1:2","tags":["DoWhy"],"title":"[DoWhy] Tutorial","uri":"/dowhy_00_tutorial/"},{"categories":["Causality"],"content":"Identify the target estimand identified_estimand = model.identify_effect(proceed_when_unidentifiable=True) # proceed_when_unidentifiable. It needs to be set to True # to convey the assumption that we are ignoring any unobserved confounding print(identified_estimand) 결과로 아래와 같이 identify하는 방법들에 대한 설명이 나온다. 귀엽게 수식도 나오고 가정도 알려준다. 나중에 시간이 되면 소스코드를 보고 싶다. 이런 오픈소스를 사용하다보면 겸손해진다. Estimand type: nonparametric-ate ### Estimand : 1 Estimand name: backdoor Estimand expression: d ─────(E[y|W3,W1,W2,W4,W0]) d[v₀] Estimand assumption 1, Unconfoundedness: If U→{v0} and U→y then P(y|v0,W3,W1,W2,W4,W0,U) = P(y|v0,W3,W1,W2,W4,W0) ### Estimand : 2 Estimand name: iv Estimand expression: ⎡ -1⎤ ⎢ d ⎛ d ⎞ ⎥ E⎢─────────(y)⋅⎜─────────([v₀])⎟ ⎥ ⎣d[Z₁ Z₀] ⎝d[Z₁ Z₀] ⎠ ⎦ Estimand assumption 1, As-if-random: If U→→y then ¬(U →→{Z1,Z0}) Estimand assumption 2, Exclusion: If we remove {Z1,Z0}→{v0}, then ¬({Z1,Z0}→y) ### Estimand : 3 Estimand name: frontdoor No such variable(s) found! ","date":"2022-04-02","objectID":"/dowhy_00_tutorial/:1:3","tags":["DoWhy"],"title":"[DoWhy] Tutorial","uri":"/dowhy_00_tutorial/"},{"categories":["Causality"],"content":"Estimate causal effect causal_estimate = model.estimate_effect(identified_estimand, method_name=\"backdoor.propensity_score_stratification\") print(causal_estimate) backdoor criterion과 propensity score를 이용하여 causal effect(지금은 ATE)를 구하면 아래와 같은 결과가 나온다. true값과 거의 비슷하게 나왔다. propensity_score_stratification *** Causal Estimate *** ## Identified estimand Estimand type: nonparametric-ate ### Estimand : 1 Estimand name: backdoor Estimand expression: d ─────(E[y|W3,W1,W2,W4,W0]) d[v₀] Estimand assumption 1, Unconfoundedness: If U→{v0} and U→y then P(y|v0,W3,W1,W2,W4,W0,U) = P(y|v0,W3,W1,W2,W4,W0) ## Realized estimand b: y~v0+W3+W1+W2+W4+W0 Target units: ate ## Estimate Mean value: 10.257618758277024 ","date":"2022-04-02","objectID":"/dowhy_00_tutorial/:1:4","tags":["DoWhy"],"title":"[DoWhy] Tutorial","uri":"/dowhy_00_tutorial/"},{"categories":["Causality"],"content":"Refute estimate refute의 방법에는 여러가지가 있다. 그 중 두가지만 알아보자. 먼저 placebo방법은 treatment를 random하게 만들고 causal effect를 구해보는 것이다. 아래 결과의 New effect가 그 결과이다. 거의 0에 가까워야한다. # Replacing treatment with a random (placebo) variable res_placebo=model.refute_estimate(identified_estimand, causal_estimate, method_name=\"placebo_treatment_refuter\", placebo_type=\"permute\") print(res_placebo) Refute: Use a Placebo Treatment Estimated effect:10.257618758277024 New effect:0.004448677029791578 p value:0.49 다음은 data의 subset을 random하게 없애고 causal effect를 구하는 것이다. 일부를 없애도 New effect는 기존의 effect와 동일하게 나와야한다. # Removing a random subset of the data res_subset=model.refute_estimate(identified_estimand, causal_estimate, method_name=\"data_subset_refuter\", subset_fraction=0.9) print(res_subset) Refute: Use a subset of data Estimated effect:10.257618758277024 New effect:10.220266223065927 p value:0.37 ","date":"2022-04-02","objectID":"/dowhy_00_tutorial/:1:5","tags":["DoWhy"],"title":"[DoWhy] Tutorial","uri":"/dowhy_00_tutorial/"},{"categories":["Causality"],"content":"Reference Getting started with DoWhy: A simple example Dowhy: An end-to-end library for causal inference slide ","date":"2022-04-02","objectID":"/dowhy_00_tutorial/:2:0","tags":["DoWhy"],"title":"[DoWhy] Tutorial","uri":"/dowhy_00_tutorial/"},{"categories":["CatchMinor"],"content":"Anomaly Detection에서 설명가능한 모델과 관련한 tutorial Anomaly Detection과 관련한 분야 중 하나로 anomaly explanation이 있다. 해당 데이터가 왜 anomaly로 판단되는지 설명할 수 있다면 상당히 유용할 것이다. 이러한 방법론들은 어떤게 있는지 알아보자. 먼저 해당 tutorial에서는 크게 2가지로 나누어서 설명한다. outlying aspect mining unified anomaly detection and explanation ","date":"2022-03-27","objectID":"/survey02_anomalyexplanationindeepdetectors/:0:0","tags":["Anomaly Detection","XAI"],"title":"[Survey] Anomaly Explanation in Deep Detectors (KDD 21 tutorial)","uri":"/survey02_anomalyexplanationindeepdetectors/"},{"categories":["CatchMinor"],"content":"Outlying aspect mining 해당 방법론은 detector가 anomaly를 찾았을 때, 다른 normal data와 다른 부분(the most unusal aspects)을 찾으려고 하는 방법이다. 크게 아래같은 절차로 진행된다. anomaly detector를 통해 anomaly를 찾는다. anomaly와 관련한 the most outlying feature subspace를 찾는다. 따라서 단점은 detection과 explanation 단계가 서로 독립적이라는 것이다. 이제 접근방법을 2가지 정도 알아보자. ","date":"2022-03-27","objectID":"/survey02_anomalyexplanationindeepdetectors/:1:0","tags":["Anomaly Detection","XAI"],"title":"[Survey] Anomaly Explanation in Deep Detectors (KDD 21 tutorial)","uri":"/survey02_anomalyexplanationindeepdetectors/"},{"categories":["CatchMinor"],"content":"Finding relevant features for imbalanced binary classificaion outlying aspects mining을 imbalanced binary classification에서 feature selection/weighting 하는 것으로 생각하는 것이다. classification accuracy as outlierness Explaining outliers by subspace separability (2013) subset feature를 통해 분류를 하고 classification accuracy가 가장 높은 subset을 찾는다. Attention-guided feature weighting Beyond Outlier Detection: Outlier Interpretation by Attention-Guided Triplet Deviation Network 2021) 장단점 일반적인 imbalanced binary classification에서 사용하는 방법론들을 사용할 수 있다 efficient, scalable Difficult to generate multiple complementary outlying feature subspaces Dependent on the quality of outlier oversampling and/or inlier downsampling other similar methods Outlier detection in axis-parallel subspaces of high dimensional data (2009) Discriminative features for identifying and interpreting outliers (2014) Learning homophily couplings from non-IID data for joint feature selection and noise-resilient outlier detection (2017) ","date":"2022-03-27","objectID":"/survey02_anomalyexplanationindeepdetectors/:1:1","tags":["Anomaly Detection","XAI"],"title":"[Survey] Anomaly Explanation in Deep Detectors (KDD 21 tutorial)","uri":"/survey02_anomalyexplanationindeepdetectors/"},{"categories":["CatchMinor"],"content":"Score-and-search approach 방법 Define a measure of the outlyingness degree for a data point in any specified subspace The outlyingness degree of the query object will be compared across all possible subspaces The subspaces with the highest outlyingness degree will be selected for user further inspection 다양한 모델과 방법론을 이용해서 outlierness degree가 가장 큰 값을 갖는 feature subspaces를 찾는다. 가능한 전체 경우의 수는 $2^d - 1$일 것이다. 2-D pictorial explanation LP-Explain: Local Pictorial Explanation for Outliers (2020) a set of detected anomalies의 outlierness degree가 가장 큰 2-D feature subspaces를 찾는 방법 장단점 Many anomaly detection measures can be adapted for the scoring in feature subspace Multiple relevant feature subspaces can be easily returned dimensionality와 관련이 있는 measure들은 dimensionality bias를 고려해야 한다 feature subspace search를 하는 cost other similar methods Outlying property detection with numerical attributes (2017) Contextual outlier interpretation (2018) Sequential feature explanations for anomaly detection (2019) ","date":"2022-03-27","objectID":"/survey02_anomalyexplanationindeepdetectors/:1:2","tags":["Anomaly Detection","XAI"],"title":"[Survey] Anomaly Explanation in Deep Detectors (KDD 21 tutorial)","uri":"/survey02_anomalyexplanationindeepdetectors/"},{"categories":["CatchMinor"],"content":"Unified anomaly detection and explanation detection과 explanation이 독립적으로 이루어지는 것이 아니라 detection을 하는 과정에 녹아들어 있다고 할 수 있다. ","date":"2022-03-27","objectID":"/survey02_anomalyexplanationindeepdetectors/:2:0","tags":["Anomaly Detection","XAI"],"title":"[Survey] Anomaly Explanation in Deep Detectors (KDD 21 tutorial)","uri":"/survey02_anomalyexplanationindeepdetectors/"},{"categories":["CatchMinor"],"content":"shallow method Sequential anomaly ensemble of surrogate sparse regression Sparse modeling-based sequential ensemble learning for effective outlier detection in high-dimensional numeric data (2018) Data reconstruction using random forest Reconstruction-based Anomaly Detection with Completely Random Forest (2021) data space를 random하게 나누면서 tree들을 만들어서 reconstruction error를 통해 주요 feature를 찾아낸다 장단점 model-specific한 anomaly explanation이므로 해당 detection model에 한해서 더 faithful하다고 할 수 있다 detection model의 성능에 anomaly explanation도 달려있다 intrinsically interpretable인 모델이 제한적이다 ","date":"2022-03-27","objectID":"/survey02_anomalyexplanationindeepdetectors/:2:1","tags":["Anomaly Detection","XAI"],"title":"[Survey] Anomaly Explanation in Deep Detectors (KDD 21 tutorial)","uri":"/survey02_anomalyexplanationindeepdetectors/"},{"categories":["CatchMinor"],"content":"Deep method 크게 두 가지로 이루어져 있다. Data reconstruction Back-propagation Data reconstruction의 경우는 feature-wise reconstruction error를 이용하여 explanation을 하려고 한다. 주로 AE 계열의 모델에서 많이 사용된다. 하지만 단점은 feature-wise하게 reconstruction error를 계산하므로 feature끼리 independent하다고 가정한다는 것이다. Back-propagation의 경우는 가장 유명한 visioin계열에서 가장 유명한 Grad-CAM에 해당하는 방법이다. ","date":"2022-03-27","objectID":"/survey02_anomalyexplanationindeepdetectors/:2:2","tags":["Anomaly Detection","XAI"],"title":"[Survey] Anomaly Explanation in Deep Detectors (KDD 21 tutorial)","uri":"/survey02_anomalyexplanationindeepdetectors/"},{"categories":["Computer Science"],"content":"사용자 프로그램을 메모리에 연속하지 않게 할당하는 과정에 대해 알아보자. memory allocation을 하는 방법중에서 non-continuos memory allocation 방법을 알아보자. ","date":"2022-03-26","objectID":"/os_lec09_virtualmemory/:0:0","tags":["virtual memory"],"title":"[OS] Virtual Memory","uri":"/os_lec09_virtualmemory/"},{"categories":["Computer Science"],"content":"Virtual memory 사용자 프로그램을 여러 개의 block으로 분할하는 방법이다. 그리고 해당 프로그램 실행 시, 필요한 block들만 메모리에 적재한다. 나머지 block들은 swap device에 있다. 이러한 기법들 3가지 알아보자. paging system segmentation system hybrid system 먼저 non-continuous allocation의 경우 address mapping에 대해 알아보자. 이전에 continous의 경우와 비슷하게 가상주소와 실제주소가 있다. virtual address (= relative address) logical address 연속된 메모리 할당을 가정한 주소 real address (= absolute, physical address) 실제 메모리에 적재된 주소 사용자/프로세스는 address mapping을 통해 실행 프로그램 전체가 메모리에 연속적으로 적재되었다고 가정하고 실행할 수 있다. 그렇다면 구체적으로 어떤식으로 address mapping을 해서 프로그램이 실행되는지 알아보자. 간단한 방법 중 하나인 block mapping에 대해 알아보자. ","date":"2022-03-26","objectID":"/os_lec09_virtualmemory/:1:0","tags":["virtual memory"],"title":"[OS] Virtual Memory","uri":"/os_lec09_virtualmemory/"},{"categories":["Computer Science"],"content":"Block mapping 사용자 프로그램을 block 단위로 분할/관리 virtual address: $v=(b,d)$ $b$: 사용자 프로그램의 block number $d$: offset in a memory block block map table (BMT) 를 통해서 address mapping 정보를 관리 아래 그림에서 residence bit는 해당 block이 memory에 올라갔는지 여부를 체크 그래서 block number를 확인하고 table에서 residence bit=1이면 real address로 가서 d를 더하면 main memory에 올라간 위치에 도달할 수 있는 것이다 이제 가상메모리를 이용하는 방법들에 대해 알아보자. ","date":"2022-03-26","objectID":"/os_lec09_virtualmemory/:1:1","tags":["virtual memory"],"title":"[OS] Virtual Memory","uri":"/os_lec09_virtualmemory/"},{"categories":["Computer Science"],"content":"Paging system Paging system은 프로그램을 같은 크기의 block으로 분할하는 방법이다. 여기서 분할된 프로그램 block을 Page라고 한다. 이 방법에서는 메모리도 Page와 동일한 크기로 분할하는데 이 분할영역을 Page Frame이라고 한다. 실제 window에서 성능옵션 -\u003e 고급 에 가보면 페이징에 관련한 내용을 확인할 수 있다. 특징 논리적 분할이 아니고 크기에 따른 분할 방법이다 simple external fragmentation이 발생하지 않는다 (internal은 발생 가능: 분할을 하다보면 남는 경우가 존재) 그렇다면 이제 Paging system이 Address mapping을 하는 방법을 알아보자. virtual address는 $v=(p,d)$이고 각각 page number, displacement이다. Paging system에서는 PMT(page map table)을 통해 mapping을 한다. mapping하는 방법으로는 3가지가 있다. Direct mapping Associative mapping Hybrid direct/associative mapping 먼제 PMT는 아래와 같은 모습이다. 아래에서 secondary storage address는 swap device에서 page들의 위치를 의미한다. ","date":"2022-03-26","objectID":"/os_lec09_virtualmemory/:2:0","tags":["virtual memory"],"title":"[OS] Virtual Memory","uri":"/os_lec09_virtualmemory/"},{"categories":["Computer Science"],"content":"Direct mapping 순서 해당 프로세스의 PMT가 저장되어 있는 주소 b에 접근 해당 PMT에서 page p에 대한 entry 찾음 찾은 entry의 residence bit 검사 if 0, swap device에서 해당 page를 메모리에 적재하고 PMT를 갱신하고 3-2 수행 (이부분에서 overhead) if 1, 해당 entry에서 page frame 번호 p’를 확인 p’와 d를 사용하여 실제 주소 r 형성 실제 주소 r로 주기억장치에 접근 ","date":"2022-03-26","objectID":"/os_lec09_virtualmemory/:2:1","tags":["virtual memory"],"title":"[OS] Virtual Memory","uri":"/os_lec09_virtualmemory/"},{"categories":["Computer Science"],"content":"Associative mapping TLB 이용 PMT를 위한 전용기억장치(공간)로 swap device에서 page를 찾을 때, parallel search가 가능해서 엄청 빠르지만 비싸고 운영이 까다롭다 ","date":"2022-03-26","objectID":"/os_lec09_virtualmemory/:2:2","tags":["virtual memory"],"title":"[OS] Virtual Memory","uri":"/os_lec09_virtualmemory/"},{"categories":["Computer Science"],"content":"Hybrid direct/associative mapping Hybrid direct/associative mapping은 direct와 associative 두 가지 방법을 모두 이용하는 방법이다. PMT: 메모리에 저장 direct mapping에서의 단점: 메모리 접근 횟수가 많아서(overhead) 성능저하, PMT를 위한 메모리 공간 필요 TLB: PMT 중 일부 entry들(최근에 사용된 page들에 대한 entry)을 적재, 이는 locality를 활용하기 위함 Translation Look-aside Buffer associative mapping에서 사용 프로세스의 PMT가 TLB에 적재되어 있는지 확인한다. if TLB에 적재되어 있는 경우, residence bit를 검사하고 page frame 번호를 확인 if TLB에 적재되어 있지 않은 경우, direct mapping으로 page frame 번호를 확인하고 해당 PMT entry를 TLB에 적재 그렇다면 이제 memory management에 대해 알아보자. memory도 page와 같은 크기로 미리 분할(=page frame)하여 관리/사용한다. memory management를 하기 위해서 Frame table을 이용한다. Frame table 또한 효율성을 위해 page sharing이라는 것도 할 수 있다. 여러 프로세스가 main memory에 있는 page frame을 공유하는 것이다. 물론 이 때, 문제가 발생하지 않도록 유의(page protection)해야한다. ","date":"2022-03-26","objectID":"/os_lec09_virtualmemory/:2:3","tags":["virtual memory"],"title":"[OS] Virtual Memory","uri":"/os_lec09_virtualmemory/"},{"categories":["Computer Science"],"content":"Segementation system 프로그램을 논리적 block으로 분할하는 방법이다. 따라서 block의 크기가 다 다를 수 있다. 특징 메모리를 미리 분할하지 않음 segment sharing/protection이 용이함 address mapping 및 메모리 관리의 overhead가 큼 no internal fragmentation, external fragmentation은 발생가능 segmentation system에서도 address mapping은 비슷하다. virtual address v=(s,d)가 있고 SMT(segment map table)를 이용한다. mapping하는 방법은 paging system과 비슷하다. segment map table ","date":"2022-03-26","objectID":"/os_lec09_virtualmemory/:3:0","tags":["virtual memory"],"title":"[OS] Virtual Memory","uri":"/os_lec09_virtualmemory/"},{"categories":["Computer Science"],"content":"Hybrid paging/segmentation system 프로그램 분할 논리 단위의 segment로 분할 각 segment를 고정된 크기의 page들로 분할 page 단위로 메모리에 적재 ","date":"2022-03-26","objectID":"/os_lec09_virtualmemory/:3:1","tags":["virtual memory"],"title":"[OS] Virtual Memory","uri":"/os_lec09_virtualmemory/"},{"categories":["Computer Science"],"content":"Reference HPC Lab. KOREATECH 운영체제 강의 ","date":"2022-03-26","objectID":"/os_lec09_virtualmemory/:4:0","tags":["virtual memory"],"title":"[OS] Virtual Memory","uri":"/os_lec09_virtualmemory/"},{"categories":["CatchMinor"],"content":"다양한 모델을 통해 구한 outlier score를 ensemble하는 방법 (Outlier Analysis, Charu C. Aggarwal) ","date":"2022-03-20","objectID":"/outlieranalysis01/:0:0","tags":["Outlier Analysis","Ensemble"],"title":"[OutlierAnalysis] Model Combination for Outlier Ensembles","uri":"/outlieranalysis01/"},{"categories":["CatchMinor"],"content":"Introduction 다양한 detector 모델들을 통해 구한 outlier score를 최종적으로 ensemble할 때 (detector들의 score들이 스케일이 다르면 normalize해야 한다), 다양한 방법들이 있다. 이 책에서는 크게 3가지를 설명한다. 최종 score ensemble 방법 Averaging Median Maximum 이제 이들의 특징과 장단점에 대해 알아보자. 이전의 연구들이 [1,2,3] 상황에 따라서 좋은 성능이 나오는 방법들이 다름을 밝혔다. 따라서 우리는 최종 score를 ensemble할 때, 다양한 방법을 시도하고 가장 성능이 좋은 방법을 선택해야할 것이다. Averaging, median 방법은 상대적으로 stable해서 가장 많이 사용하는 방법이다. bias-variance trade-off 관계에서 이 둘은 variance를 줄이는데 효과가 있는 방법이다. (주의! outlier analysis에서 bias-variance는 classification에서와 완전히 동일하지는 않다, 이에 관해서는 추후에 다뤄보고자 한다) 이에 반해 maximum 방법은 stablility가 떨어지고 bias를 줄이는 것과 관련이 있다. maximum 방법을 통해 irrelevent하거나 weak한 detector들을 de-emphasize할 수 있다. 그런데 maximum 방법을 이용하면 score를 너무 overestimate하는 것 아닌가? 라는 의문이 들 수 있다. 하지만 일단 outlier score는 상대적인 것이기 때문에 괜찮다. 오히려 detector들이 찾기 어려워하는 outlier를 잘 찾을 수 있는 가능성이 존재한다. 찾기 어려워하는 outlier의 score는 inlier에 비해 상대적으로 underestimate될 것이기 때문이다. 물론 maximum의 가장 큰 문제는 variance가 증가할 수도 있다는 것이다. 특히 dataset의 크기가 작으면 그 확률이 올라간다. 결론: 상황마다 다르기 때문에 다 해보고 선택해야 한다 ","date":"2022-03-20","objectID":"/outlieranalysis01/:1:0","tags":["Outlier Analysis","Ensemble"],"title":"[OutlierAnalysis] Model Combination for Outlier Ensembles","uri":"/outlieranalysis01/"},{"categories":["CatchMinor"],"content":"Combining Bias and Variance Reduction 그렇다면 bias와 variance 모두를 고려하는 방법도 당연히 있을 것이다. 다양한 방법이 있겠지만 AOM 방법 [1] 에 대해서 알아보고자 한다. 간단하다. ","date":"2022-03-20","objectID":"/outlieranalysis01/:2:0","tags":["Outlier Analysis","Ensemble"],"title":"[OutlierAnalysis] Model Combination for Outlier Ensembles","uri":"/outlieranalysis01/"},{"categories":["CatchMinor"],"content":"AOM(Average-of-Maximum) method $m$개의 components가 있다고 한다면 이들을 각 $m/q$개의 buckets으로 나눈다. (각 bucket에는 $q$개의 components) 각 bucket 마다 maximum을 취한다. bucket들의 maximum score를 average한다. 그 반대도 가능할 것이다. MOA! ","date":"2022-03-20","objectID":"/outlieranalysis01/:2:1","tags":["Outlier Analysis","Ensemble"],"title":"[OutlierAnalysis] Model Combination for Outlier Ensembles","uri":"/outlieranalysis01/"},{"categories":["CatchMinor"],"content":"Related Paper Theoretical Foundations and Algorithms for Outlier Ensembles (2015) Outlier Ensembles: An Introduction (2017) Feature Bagging for Outlier Detection (2005) ","date":"2022-03-20","objectID":"/outlieranalysis01/:3:0","tags":["Outlier Analysis","Ensemble"],"title":"[OutlierAnalysis] Model Combination for Outlier Ensembles","uri":"/outlieranalysis01/"},{"categories":["Computer Science"],"content":"Memory Management에 대해 알아보자. ","date":"2022-03-20","objectID":"/os_lec08_memorymanagement/:0:0","tags":["Memory"],"title":"[OS] Memory Management","uri":"/os_lec08_memorymanagement/"},{"categories":["Computer Science"],"content":"Background ","date":"2022-03-20","objectID":"/os_lec08_memorymanagement/:1:0","tags":["Memory"],"title":"[OS] Memory Management","uri":"/os_lec08_memorymanagement/"},{"categories":["Computer Science"],"content":"메모리 계층구조 레지스터 캐시 메인 메모리 보조기억장치 레지스터쪽으로 갈수록 용량이 작고 비싸다. 레지스터와 캐시는 HW(CPU)가 관리하고 나머지 2개는 SW(OS)가 관리한다. block 보조기억장치와 주기억장치 사이의 데이터 전송 단위 보조기억장치에서 메인메모리로 1bit에 해당하는 데이터만 올려도 block단위(1~4kb)로 올라간다 word 메인메모리와 레지스터 사이의 데이터 전송 단위 (16~64bit) ","date":"2022-03-20","objectID":"/os_lec08_memorymanagement/:1:1","tags":["Memory"],"title":"[OS] Memory Management","uri":"/os_lec08_memorymanagement/"},{"categories":["Computer Science"],"content":"Address Binding 프로그램의 논리 주소를 실제 메모리의 물리 주소로 매핑하는 과정 binding 시점에 따라 구분 complie time binding load time binding run time binding 대부분의 OS가 사용하는 방법 Address binding을 수행시간(running state)까지 연기 HW(Memory Management Unit)의 도움이 필요 ","date":"2022-03-20","objectID":"/os_lec08_memorymanagement/:1:2","tags":["Memory"],"title":"[OS] Memory Management","uri":"/os_lec08_memorymanagement/"},{"categories":["Computer Science"],"content":"Memory allocation ","date":"2022-03-20","objectID":"/os_lec08_memorymanagement/:2:0","tags":["Memory"],"title":"[OS] Memory Management","uri":"/os_lec08_memorymanagement/"},{"categories":["Computer Science"],"content":"Continuous memory allocation 프로세스를 하나의 연속된 메모리 공간에 할당하는 정책이다. 이는 크게 두가지로 나눈다. Uni-programming 하나의 프로세스만 메모리 상에 존재 Multi-programming ","date":"2022-03-20","objectID":"/os_lec08_memorymanagement/:2:1","tags":["Memory"],"title":"[OS] Memory Management","uri":"/os_lec08_memorymanagement/"},{"categories":["Computer Science"],"content":"Multi-programming 두 가지로 나눠서 생각할 수 있다. ","date":"2022-03-20","objectID":"/os_lec08_memorymanagement/:2:2","tags":["Memory"],"title":"[OS] Memory Management","uri":"/os_lec08_memorymanagement/"},{"categories":["Computer Science"],"content":"Fixed(static) partition multi-programming 메모리 공간을 고정된 크기로 미리 분할, 메모리 관리는 편함 각 프로세스는 하나의 partition에 적재 start address, size를 통해서 partition 관리 프로세스가 kernel이나 다른 partition을 침범하지 않도록 Boundary address를 통해 방지한다 문제: Fragmentation (단편화) Internal fragmentation: Partition 크기 $\u003e$ Process 크기 External fragmentation: (남은 메모리 크기 $\u003e$ Process 크기)이지만 연속된 공간이 아니라 사용불가 메모리가 낭비된다 ","date":"2022-03-20","objectID":"/os_lec08_memorymanagement/:2:3","tags":["Memory"],"title":"[OS] Memory Management","uri":"/os_lec08_memorymanagement/"},{"categories":["Computer Science"],"content":"Variable(dynamic) partition multi-programming 초기에는 전체가 하나의 영역인데 프로세스를 처리하는 과정에서 메모리 공간이 동적으로 분할된다 프로세스가 필요한 메모리 크기 만큼 할당되는 것이다 그렇다면 프로세스들이 끝나고 메모리를 반납한 공간이 생기고 새로운 프로세스가 들어가야 할 때, 배치전략이 다양하다 First-fit 첫 번째 partition을 선택 simple, low overhead지만 공간 활용률은 떨어질 수 있다 Best-fit 프로세스가 들어갈 수 있는 partition 중에서 가장 작은 곳 선택 탐색시간이 걸린다, 크기가 큰 partition을 낭비하지 않을 수 있다, 작은 크기의 partition이 계속 발생할 수 있다 Worst-fit best-fit 과 반대 coalescing holes (공간 통합)을 통해서 인접한 빈 메모리를 하나의 patition으로 통합하는 방법도 존재한다 storage compaction (메모리 압축)은 모든 빈 공간을 하나로 통합하는 방법이다, 모든 process를 중지하고 재배치해야 할 수도 있어서 high overhead라는 단점도 존재 ","date":"2022-03-20","objectID":"/os_lec08_memorymanagement/:2:4","tags":["Memory"],"title":"[OS] Memory Management","uri":"/os_lec08_memorymanagement/"},{"categories":["Computer Science"],"content":"Non-continuous memory allocation 이 부분은 virtual memory에서 다룬다 ","date":"2022-03-20","objectID":"/os_lec08_memorymanagement/:2:5","tags":["Memory"],"title":"[OS] Memory Management","uri":"/os_lec08_memorymanagement/"},{"categories":["Computer Science"],"content":"Reference HPC Lab. KOREATECH 운영체제 강의 ","date":"2022-03-20","objectID":"/os_lec08_memorymanagement/:3:0","tags":["Memory"],"title":"[OS] Memory Management","uri":"/os_lec08_memorymanagement/"},{"categories":["Computer Science"],"content":"Deadlock에 대해 알아보자. ","date":"2022-03-19","objectID":"/os_lec07_deadlock/:0:0","tags":["Deadlock"],"title":"[OS] Deadlock","uri":"/os_lec07_deadlock/"},{"categories":["Computer Science"],"content":"Deadlock Deadlock state 프로세스가 발생 가능성이 없는 이벤트(or 자원)를 기다리는 경우: 프로세스가 deadlock 상태에 있다고 한다 starvation과 다른 점 starvation은 발생가능성이 없는게 아니다 CPU(프로세서)를 기다리는 것이다 (ready state에서 대기) 그렇다면 Deadlock이 발생하는 상황을 생각해보자. 2개의 프로세스($P1,P2$)와 2개의 자원($R1,R2$)이 있다. $P1$이 $R2$를 요청한다. $P2$가 $R1$을 요청한다. $P1$이 $R1$을 요청한다. $P2$가 $R2$를 요청한다. 위와 같은 상황이 발생하면 4번에서 deadlock 상태가 되버린다. $P1$은 $R1$을 받아서 일을 끝내고 자원을 반납해야하고 $P2$는 $R2$만 받으면 일을 끝난다. 근데 서로 물고 있어서 끝날 수가 없는 상태가 되는 것이다. ","date":"2022-03-19","objectID":"/os_lec07_deadlock/:1:0","tags":["Deadlock"],"title":"[OS] Deadlock","uri":"/os_lec07_deadlock/"},{"categories":["Computer Science"],"content":"자원의 분류 ","date":"2022-03-19","objectID":"/os_lec07_deadlock/:2:0","tags":["Deadlock"],"title":"[OS] Deadlock","uri":"/os_lec07_deadlock/"},{"categories":["Computer Science"],"content":"선점 가능 여부에 따른 분류 Preemptible resources 선점 당한 후, 돌아와도 문제가 발생하지 않는 자원 ex) processor, memory processor는 context-switching이 발생할 떄, save와 restore Non-preemptible resources 선점 당하면, 이후 진행에 문제가 발생하는 자원 rollback, restart 등 특별한 동작이 필요 ex) disk drive ","date":"2022-03-19","objectID":"/os_lec07_deadlock/:2:1","tags":["Deadlock"],"title":"[OS] Deadlock","uri":"/os_lec07_deadlock/"},{"categories":["Computer Science"],"content":"할당 단위에 따른 분류 Total allocation resources 자원 전체를 프로세스에게 할당 ex) processor, disk drive Partitioned allocation resources 하나의 자원을 여러 조작으로 나누어, 여러 프로세스들에게 할당 ex) memory ","date":"2022-03-19","objectID":"/os_lec07_deadlock/:2:2","tags":["Deadlock"],"title":"[OS] Deadlock","uri":"/os_lec07_deadlock/"},{"categories":["Computer Science"],"content":"동시 사용 가능 여부에 따른 분류 Exclusive allocation resources 한 순간에 한 프로세스만 사용 가능한 자원 ex) processor, memory, disk drive Shared allocation resource 여러 프로세스가 동시에 사용 가능한 자원 ex) program, shared data word 창 여러개 띄워서 쓰는 경우처럼 ","date":"2022-03-19","objectID":"/os_lec07_deadlock/:2:3","tags":["Deadlock"],"title":"[OS] Deadlock","uri":"/os_lec07_deadlock/"},{"categories":["Computer Science"],"content":"재사용 가능 여부에 따른 분류 Serially-reusable resources 시스템 내에 항상 존재하는 자원 사용이 끝나면, 다른 프로세스가 사용 가능 ex) processor, memory, disk drive, program Consumable resources 한 프로세스가 사용한 후에 사라지는 자원 ex) signal, message ","date":"2022-03-19","objectID":"/os_lec07_deadlock/:2:4","tags":["Deadlock"],"title":"[OS] Deadlock","uri":"/os_lec07_deadlock/"},{"categories":["Computer Science"],"content":"Deadlock 발생 필요 조건 아래의 4가지가 성립해야 deadlock이 발생한다. Exclusive use of resources Non-preemptible resources Hold and wait (Partial allocation) 자원을 하나 hold하고 다른 자원 요청 Circular wait 이제 Deadlock 해결방법에 대해 알아보자. 크게 3가지로 나누어서 생각할 수 있다. ","date":"2022-03-19","objectID":"/os_lec07_deadlock/:3:0","tags":["Deadlock"],"title":"[OS] Deadlock","uri":"/os_lec07_deadlock/"},{"categories":["Computer Science"],"content":"Deadlock 해결 방법 Prevention Avoidance Detection and Recovery ","date":"2022-03-19","objectID":"/os_lec07_deadlock/:4:0","tags":["Deadlock"],"title":"[OS] Deadlock","uri":"/os_lec07_deadlock/"},{"categories":["Computer Science"],"content":"Prevention 4가지의 deadlock 발생 필요 조건 중 하나을 제거 deadlock이 절대 발생하지 않지만 심각한 자원 낭비가 발생하거나 비현실적인 대안밖에 없다 ","date":"2022-03-19","objectID":"/os_lec07_deadlock/:5:0","tags":["Deadlock"],"title":"[OS] Deadlock","uri":"/os_lec07_deadlock/"},{"categories":["Computer Science"],"content":"모든 자원을 공유허용 Exclusive use of resources 조건 제거 현실적으로 불가능 ","date":"2022-03-19","objectID":"/os_lec07_deadlock/:5:1","tags":["Deadlock"],"title":"[OS] Deadlock","uri":"/os_lec07_deadlock/"},{"categories":["Computer Science"],"content":"모든 자원에 대해 선점 허용 Non-preemptible resources 조건 제거 현실적으로 불가능 ","date":"2022-03-19","objectID":"/os_lec07_deadlock/:5:2","tags":["Deadlock"],"title":"[OS] Deadlock","uri":"/os_lec07_deadlock/"},{"categories":["Computer Science"],"content":"필요 자원 한번에 모두 할당 hold and wait 조건 제거 자원 낭비 발생 무한 대기 발생 가능 ","date":"2022-03-19","objectID":"/os_lec07_deadlock/:5:3","tags":["Deadlock"],"title":"[OS] Deadlock","uri":"/os_lec07_deadlock/"},{"categories":["Computer Science"],"content":"Circular wait 조건 제거 자원들에게 순서를 부여해서 순서의 증가 방향으로만 자원 요청 가능하게 하면 된다 자원 낭비 발생 ","date":"2022-03-19","objectID":"/os_lec07_deadlock/:5:4","tags":["Deadlock"],"title":"[OS] Deadlock","uri":"/os_lec07_deadlock/"},{"categories":["Computer Science"],"content":"Avoidance 시스템의 상태를 감시하여서 deadlock 상태가 될 가능성이 있는 자원 할당 요청을 보류 시스템을 항상 safe state로 유지 safe state 모든 프로세스가 정상적 종료 가능한 상태 safe sequence가 존재 unsafe state deadlock 상태가 될 가능성이 있음 (반드시 발생한다는 의미는 아님) 가정 프로세스의 수가 고정됨 자원의 종류와 수가 고정됨 프로세스가 요구하는 자원 및 최대 수량을 알고 있음 프로세스는 자원을 사용 후 반드시 반납 위의 가정도 사실 not practical 하다 ","date":"2022-03-19","objectID":"/os_lec07_deadlock/:6:0","tags":["Deadlock"],"title":"[OS] Deadlock","uri":"/os_lec07_deadlock/"},{"categories":["Computer Science"],"content":"avoidance 알고리즘 Dijkstra’s algorithm 예시를 통해 이해해보자 1가지 resource가 10개 있다, 3개의 프로세스가 있다 각 프로세스의 리소스 관련 (max.claim, cur.alloc, additional need) 은 p1: (3, 1, 2), p2: (9, 5, 4), p3: (5, 2, 3) 남아 있는 리소스는 2개이고 이를 이용하여 실행 종료 순서를 고려하면 p1 -\u003e p3 -\u003e p2 : safe sequence가 존재한다, 따라서 safe state라고 할 수 있다 이런 safe sequence를 구할 수 없는 상황이라면 deadlock이 발생할 수도 있다 위의 알고리즘을 확장한 (여러 종류의 자원 고려) 것이 Habermann’s algorithm 이고 원리는 같다 단점 항상 시스템을 감시해야 한다 safe state 유지를 위해 사용되지 않는 자원이 존재 가정들이 not practical ","date":"2022-03-19","objectID":"/os_lec07_deadlock/:6:1","tags":["Deadlock"],"title":"[OS] Deadlock","uri":"/os_lec07_deadlock/"},{"categories":["Computer Science"],"content":"Detection and Recovery deadlock 방지를 위한 사전 작업을 하지 않는다 Resource Allocation Graph (RAG)를 사용하여 주기적으로 deadlock 발생을 확인하고 해결한다 ","date":"2022-03-19","objectID":"/os_lec07_deadlock/:7:0","tags":["Deadlock"],"title":"[OS] Deadlock","uri":"/os_lec07_deadlock/"},{"categories":["Computer Science"],"content":"Resource Allocation Graph (Detection) directed, bipartite graph edge는 프로세스와 리소스 사이에만 존재 Graph reduction 주어진 RAG에서 edge를 하나씩 지워가는 방법 completely reduced 모든 edge가 제거 됨 deadlock에 빠진 프로세스가 없음 irreducible 지울 수 없는 edge가 존재 하나 이상의 프로세스가 deadlock 상태 ","date":"2022-03-19","objectID":"/os_lec07_deadlock/:7:1","tags":["Deadlock"],"title":"[OS] Deadlock","uri":"/os_lec07_deadlock/"},{"categories":["Computer Science"],"content":"Graph Reduction unblocked process 필요한 자원을 모두 할당 받을 수 있는 프로세스 (아래 식이 의미하는 바) The process $P_i$ is unblocked if it satisfies $$\\forall j, | (P_i, R_j) | \\le t_j - \\sum_{\\text{all k}} | (R_j,P_k) |$$ graph reduction procedure unblocked process에 연결된 모든 edge를 제거 더이상 unblocked process가 없을 때까지 1번 반복 ","date":"2022-03-19","objectID":"/os_lec07_deadlock/:7:2","tags":["Deadlock"],"title":"[OS] Deadlock","uri":"/os_lec07_deadlock/"},{"categories":["Computer Science"],"content":"Recovery 방법 process termination deadlock 상태에 있는 프로세스를 종료시킴 강제 종료된 프로세스는 이후 재시작 됨 resource preemption deadlock 상태 해결 위해 선점할 자원 선택 선정된 자원을 가지고 있는 프로세스에서 자원을 빼았음 위의 방법들은 각각 여러가지 기준을 통해서 종료한 프로세스와 선점할 자원을 선택한다 checkpoint-restart method 프로세스의 수행 중 특점 지점마다 context를 저장 강제 종료 후, 가장 최근의 check-point에서 재시작 (rollback) ","date":"2022-03-19","objectID":"/os_lec07_deadlock/:7:3","tags":["Deadlock"],"title":"[OS] Deadlock","uri":"/os_lec07_deadlock/"},{"categories":["Computer Science"],"content":"Reference HPC Lab. KOREATECH 운영체제 강의 ","date":"2022-03-19","objectID":"/os_lec07_deadlock/:8:0","tags":["Deadlock"],"title":"[OS] Deadlock","uri":"/os_lec07_deadlock/"},{"categories":["CatchMinor"],"content":"Deep Learning for Anomaly Detection - Challenges, Methods tutorial 정리 Anomalies: points that are significantly different from most of the data Part1: challenges ","date":"2022-03-19","objectID":"/survey01_tutorialondeeplearningforanomalydetection/:0:0","tags":["Deep Anomaly Detection"],"title":"[Survey] Deep Learning for Anomaly Detection (WSDM'21 tutorial)","uri":"/survey01_tutorialondeeplearningforanomalydetection/"},{"categories":["CatchMinor"],"content":"Problem variations Binary output vs scoring mulitple ways to define what makes an anomaly different 3 common types of anomalies: point anomalies conditional anomalies (contextual anomalies) group anomlies ","date":"2022-03-19","objectID":"/survey01_tutorialondeeplearningforanomalydetection/:0:1","tags":["Deep Anomaly Detection"],"title":"[Survey] Deep Learning for Anomaly Detection (WSDM'21 tutorial)","uri":"/survey01_tutorialondeeplearningforanomalydetection/"},{"categories":["CatchMinor"],"content":"application-specifi complexities Heterogeneity different anomalies may exhibit different expression anomalies도 다같은 anoamlies가 아니다 Application-specific methodologies Unknown Nature (unsupervised setting) anomalies는 발생하기 전까지 그게 있는지 조차도 모름 Coverage 모든 anomalies를 모으는 것도 힘들다 ","date":"2022-03-19","objectID":"/survey01_tutorialondeeplearningforanomalydetection/:0:2","tags":["Deep Anomaly Detection"],"title":"[Survey] Deep Learning for Anomaly Detection (WSDM'21 tutorial)","uri":"/survey01_tutorialondeeplearningforanomalydetection/"},{"categories":["CatchMinor"],"content":"Key Challenges Low anomaly detection accuracy Contextual and high-dimensional data sample-efficient learning building generalized detection models with a limited amount of labeled anomaly data Noise-Resilient anomaly detection complex anomalies anomaly explanation ","date":"2022-03-19","objectID":"/survey01_tutorialondeeplearningforanomalydetection/:0:3","tags":["Deep Anomaly Detection"],"title":"[Survey] Deep Learning for Anomaly Detection (WSDM'21 tutorial)","uri":"/survey01_tutorialondeeplearningforanomalydetection/"},{"categories":["CatchMinor"],"content":"Traditional (Shallow) methods and Disadvantages statistical/probabilistic-based approaches statistical-test, depth-based, deviation-based proximity-based approach distance-based, density-based, clustering-based shallow ML models unsupervised ML model (one-class svm, pca) others information-theoretic, subspace method weakness weak capability of capturing intricate relationships lots of hand-crafting of algorithms and features Ad hoc nature make it difficult to incorporate supervision ","date":"2022-03-19","objectID":"/survey01_tutorialondeeplearningforanomalydetection/:0:4","tags":["Deep Anomaly Detection"],"title":"[Survey] Deep Learning for Anomaly Detection (WSDM'21 tutorial)","uri":"/survey01_tutorialondeeplearningforanomalydetection/"},{"categories":["CatchMinor"],"content":"Advantages of Deep Learning Integrates feature learning and anomaly scoring generates newly learned feature space end-to-end learning diverse neural architectures unified detection and localization of anomalies localization을 통해 anomalies에 대한 해석을 더 쉽게 할 수 있다 anomaly-informed models with improved accuracy ","date":"2022-03-19","objectID":"/survey01_tutorialondeeplearningforanomalydetection/:0:5","tags":["Deep Anomaly Detection"],"title":"[Survey] Deep Learning for Anomaly Detection (WSDM'21 tutorial)","uri":"/survey01_tutorialondeeplearningforanomalydetection/"},{"categories":["CatchMinor"],"content":"3 principal categories Deep learning for Feature Extraction DL을 이용해서 feature를 뽑아내고 이를 다른 모델에 넣어서 찾는 방법 Learning Feature Representations of Normality (가장 많이 연구됨) End-to-End Anomaly Score Learning ","date":"2022-03-19","objectID":"/survey01_tutorialondeeplearningforanomalydetection/:0:6","tags":["Deep Anomaly Detection"],"title":"[Survey] Deep Learning for Anomaly Detection (WSDM'21 tutorial)","uri":"/survey01_tutorialondeeplearningforanomalydetection/"},{"categories":["CatchMinor"],"content":"Categorization Based on Supervision Unsupervised approach anomaly-contaminated unlabeled data; no manually labeled training data Semi-supervised approach (가장 많이 연구됨) assuming the availability of a set of manually labeled normal training data Weakly-supervised approach assuming have some labels for anomaly classes yet the class labels are partial, inexact, inaccurate Part2-1: methods (The modeling perspective) ","date":"2022-03-19","objectID":"/survey01_tutorialondeeplearningforanomalydetection/:0:7","tags":["Deep Anomaly Detection"],"title":"[Survey] Deep Learning for Anomaly Detection (WSDM'21 tutorial)","uri":"/survey01_tutorialondeeplearningforanomalydetection/"},{"categories":["CatchMinor"],"content":"Deep learning for feature extraction assumption extracted features preserve the discriminative information that helps separate anomalies from normal instances 방법 pre-trained model을 사용 pre-trained model에서 feature를 추출한 뒤 다른 classifier를 학습시켜서 anomaly score를 구한다 ex) (paper) unmasking the abnormal events in video training deep feature extraction models 주로 autoencoder를 이용해서 feature extract한 뒤에 다른 분퓨 모델을 이용한다 summary 장점 구현하기 쉽다 linear model보다 dimensionaliy reduction이 성능이 좋다 다양한 sota 모델을 활용할 수 있다 단점 feature extraction이 anomaly soring이 disjointing한 과정이라서 유용한 정보가 추출되지 않을수도 있다 pre-trained model은 데이터의 종류가 제한적이다 ","date":"2022-03-19","objectID":"/survey01_tutorialondeeplearningforanomalydetection/:0:8","tags":["Deep Anomaly Detection"],"title":"[Survey] Deep Learning for Anomaly Detection (WSDM'21 tutorial)","uri":"/survey01_tutorialondeeplearningforanomalydetection/"},{"categories":["CatchMinor"],"content":"Learning feature representation of normality 크게 두가지로 구분 할 수 있다 Generic normality feature learning Anomaly measure-dependent feature learning Generic normality feature learning Autoencoders assumption normal instances can be better reconstructed from compressed feature space than anomalies gerneral framewok Bottleneck architecture + reconstruction loss The larger reconstruction errors the more abnormal GAN assumption Normal data instances can be better generated than anomalies from the latent feature space of the generative network in GANs general framework Train a GAN-based model Calculate anomaly scores by looking into the difference bewteen an input instance and its counterpart generated from the latent space of the generator 종류 AnoGAN, EBGAN … Predictability modeling assumption Normal instances are temporally more predictable than anomalies general framework Train a current/future instance prediction network Calculate the difference between the predicted instance and the actual instance as anomaly score 종류 Future frame prediction Self-supervised classification assumption Normal instances are more consistent to self-supervised classifiers than anomalies general framework Apply different augmentation operations to the data Learn a multi-class classification model using instances Calculate the inconsistency of the instance to the model as anomaly score summary 장점 Deep learning for feature extraction 보다 효율적이다 다양한 모델을 활용할 수 있다 단점 GAN 같은 경우 훈련이 쉽지 않다 unsupervised setting 이기 떄문에 anomaly contamination에 취약하다 Anomaly measure-dependent feature learning Distance-based measures assumption Anomalies are distributed far from their closest neighbors while normal instances are located in dense neighborhoods general framework orginal data를 새로운 representation space로 map하는 feature mapping function $\\pi$를 만든다 feature representation을 anomalies가 특정 reference instances와 거리가 더 커지도록 optimize한다. 그렇게 만들어진 space에서 거리를 측정하여 anomaly score로 이용한다 종류 REPEN One-class classification measure assumption All normal instances come from a single (abstract) class andn can be summarized by a compact model, to which anomalies do not conform general framework orginal data를 새로운 representation space로 map하는 feature mapping function $\\pi$를 만든다 one-class classification loss를 이용하여 feature representation을 optimize한다 그렇게 만들어진 space에서 one-class classification model을 통해 anomaly score를 구한다 종류 Deep SVDD Cluster-based measure assumption Normal isntances have stronger adherence to clusters than anomalies general framework orginal data를 새로운 representation space로 map하는 feature mapping function $\\pi$를 만든다 cluster-based loss를 이용하여 feature representation을 optimize한다 그렇게 만들어진 space에서 cluster-based model을 통해 anomaly score를 구한다 종류 DAGMM summary 장점 전통적인 방법론들이라 비교적 연구가 탄탄하다 특정 anomaly measure를 기준으로 잡고 representation을 만들기 때문에 해당 measure에 알맞는 data를 만나면 효과가 좋다 단점 성능이 anomaly measure에 heavily dependent하다 clustering 과정에 있어서 contaminated anomalies가 training data에 있는 경우 biased 될 수 있다 ","date":"2022-03-19","objectID":"/survey01_tutorialondeeplearningforanomalydetection/:0:9","tags":["Deep Anomaly Detection"],"title":"[Survey] Deep Learning for Anomaly Detection (WSDM'21 tutorial)","uri":"/survey01_tutorialondeeplearningforanomalydetection/"},{"categories":["CatchMinor"],"content":"End-to-end anomaly score learning anomaly score가 있는 상태에서 학습을 하는 (지도학습) 방법이다 크게 4가지로 구분한다 Ranking models Prior-driven models Softmax likelihood models End-to-End one-class classfication Ranking models assumption There exists an observable ordinal variable that captures some data abnormality general framework Definen the (synthtic) ordinal variable Use the variable to define a surrogate loss functions for anomaly ranking and train the detection model Given a test instance, the model firectly gives its anomaly score 종류 SDOR(Deep ordinal regression), PReNet(Pairwise relation prediction) Prior-driven models assumption The imposed prior captures the underlying (ab)normality of the dataset general framework Impose a prior over the weight parameters of a network-based anomaly scoring measure, or over the expected anomaly scores Optimize the anomaly ranking/classification with the prior Given a test instance, the model directly gives its anomaly score 종류 DevNet Sotfmax likelihood models assumption Anomalies and normal instances are respectively low- and high-probability events general framework The probability of an event is modeled using a softmax function $p(x;\\theta) = \\frac{\\exp (\\tau(x;\\theta))}{\\sum_x \\exp (\\tau(x;\\theta))}$ The parameters are then learned by a maximum likelihood function Given a test instance, the model directly gives its anomaly score by the event probability 종류 APE End-to-End one-class classification assumption Data instances that are approximated to anomalies can be effectively synthesized All normal instances can be summarized by a discriminative one-class model general framework Generate artificial outliers Train a GAN to discriminate whether a given instance is normal or an artificial outlier 종류 Fence GAN, OCAN summary 장점 anomaly scoring/ranking/classification의 과정이 end-to-end로 이뤄지기에 더 효율적일 수 있다 anomly measures에 depend하지 않는다 단점 어느정도의 labeled/synthetic anomalies가 필요하다 unseen anomalies에 대해서 성능이 떨어질 수 있다 Part2-2: methods (The supervision information perspective) ","date":"2022-03-19","objectID":"/survey01_tutorialondeeplearningforanomalydetection/:0:10","tags":["Deep Anomaly Detection"],"title":"[Survey] Deep Learning for Anomaly Detection (WSDM'21 tutorial)","uri":"/survey01_tutorialondeeplearningforanomalydetection/"},{"categories":["CatchMinor"],"content":"Unsupervised approach Training on anomaly-contaminated unlabeled data 종류 outlier-aware autoencoders robust deep autoencoders one-class method Deep SVDD pseudo labeling Deep distance-based method Deep ordinal regressioin augmented deep clustering DAGMM ","date":"2022-03-19","objectID":"/survey01_tutorialondeeplearningforanomalydetection/:0:11","tags":["Deep Anomaly Detection"],"title":"[Survey] Deep Learning for Anomaly Detection (WSDM'21 tutorial)","uri":"/survey01_tutorialondeeplearningforanomalydetection/"},{"categories":["CatchMinor"],"content":"Weakly-supervised approach A limited number of partially labeled anomalies and large unlabeled data 종류 Contrastive feature learning Deep distance-based method Prior-driven method Deviation network Surrogate learning Pairwise relation prediction Multiple instance learning ","date":"2022-03-19","objectID":"/survey01_tutorialondeeplearningforanomalydetection/:0:12","tags":["Deep Anomaly Detection"],"title":"[Survey] Deep Learning for Anomaly Detection (WSDM'21 tutorial)","uri":"/survey01_tutorialondeeplearningforanomalydetection/"},{"categories":["CatchMinor"],"content":"Semi-supervised approach Training on a large labeled normal dataset Part3: Conclusions and future opportunities ","date":"2022-03-19","objectID":"/survey01_tutorialondeeplearningforanomalydetection/:0:13","tags":["Deep Anomaly Detection"],"title":"[Survey] Deep Learning for Anomaly Detection (WSDM'21 tutorial)","uri":"/survey01_tutorialondeeplearningforanomalydetection/"},{"categories":["CatchMinor"],"content":"six possible directions for future research ","date":"2022-03-19","objectID":"/survey01_tutorialondeeplearningforanomalydetection/:1:0","tags":["Deep Anomaly Detection"],"title":"[Survey] Deep Learning for Anomaly Detection (WSDM'21 tutorial)","uri":"/survey01_tutorialondeeplearningforanomalydetection/"},{"categories":["CatchMinor"],"content":"1. Exploring anomaly-supervisory signals ","date":"2022-03-19","objectID":"/survey01_tutorialondeeplearningforanomalydetection/:1:1","tags":["Deep Anomaly Detection"],"title":"[Survey] Deep Learning for Anomaly Detection (WSDM'21 tutorial)","uri":"/survey01_tutorialondeeplearningforanomalydetection/"},{"categories":["CatchMinor"],"content":"2. Deep weakly-supervised anomaly detection ","date":"2022-03-19","objectID":"/survey01_tutorialondeeplearningforanomalydetection/:1:2","tags":["Deep Anomaly Detection"],"title":"[Survey] Deep Learning for Anomaly Detection (WSDM'21 tutorial)","uri":"/survey01_tutorialondeeplearningforanomalydetection/"},{"categories":["CatchMinor"],"content":"3. Large-scale normality learning ","date":"2022-03-19","objectID":"/survey01_tutorialondeeplearningforanomalydetection/:1:3","tags":["Deep Anomaly Detection"],"title":"[Survey] Deep Learning for Anomaly Detection (WSDM'21 tutorial)","uri":"/survey01_tutorialondeeplearningforanomalydetection/"},{"categories":["CatchMinor"],"content":"4. Deep detection of complex anomalies deep models for conditional/group anomalies multimodal anomaly detection ","date":"2022-03-19","objectID":"/survey01_tutorialondeeplearningforanomalydetection/:1:4","tags":["Deep Anomaly Detection"],"title":"[Survey] Deep Learning for Anomaly Detection (WSDM'21 tutorial)","uri":"/survey01_tutorialondeeplearningforanomalydetection/"},{"categories":["CatchMinor"],"content":"5. Interpretable and actionable deep anomaly detection Interpretable deep anomaly detection Quantifyiing the impact of detected anomalies and mitigation actions ","date":"2022-03-19","objectID":"/survey01_tutorialondeeplearningforanomalydetection/:1:5","tags":["Deep Anomaly Detection"],"title":"[Survey] Deep Learning for Anomaly Detection (WSDM'21 tutorial)","uri":"/survey01_tutorialondeeplearningforanomalydetection/"},{"categories":["CatchMinor"],"content":"6. Novel applications and settings ","date":"2022-03-19","objectID":"/survey01_tutorialondeeplearningforanomalydetection/:1:6","tags":["Deep Anomaly Detection"],"title":"[Survey] Deep Learning for Anomaly Detection (WSDM'21 tutorial)","uri":"/survey01_tutorialondeeplearningforanomalydetection/"},{"categories":["CatchMinor"],"content":"Reference WSDM 2021 Tutorial on Deep Learning for Anomaly Detection ","date":"2022-03-19","objectID":"/survey01_tutorialondeeplearningforanomalydetection/:2:0","tags":["Deep Anomaly Detection"],"title":"[Survey] Deep Learning for Anomaly Detection (WSDM'21 tutorial)","uri":"/survey01_tutorialondeeplearningforanomalydetection/"},{"categories":["Computer Science"],"content":"Process Synchronization and Mutual Exclusion 에 대한 개념 정리 (semaphore) ","date":"2022-03-11","objectID":"/os_lec06_processsynchronizationmutualexclusion/:0:0","tags":["Process Synchronization","Mutual Exclusion"],"title":"[OS] Process Synchronization and Mutual Exclusion","uri":"/os_lec06_processsynchronizationmutualexclusion/"},{"categories":["Computer Science"],"content":"Process Synchronization and Mutual Exclusion 여러 개의 프로세스들이 존재할 때, 공유자원 또는 데이터가 있을 때 문제가 발생할 수 있다. 이런 경우를 대비하기 위해 동기화를 한다. 동기화: 프로세스들이 서로 동작을 맞추는 것, 정보를 공유해서 문제가 발행하지 않도록 하는 것 Mutual exclusion 둘 이상의 프로세스가 동시에 critical section에 진입하는 것을 막는 것 critical section: 공유 데이터를 접근하는 코드 영역 ","date":"2022-03-11","objectID":"/os_lec06_processsynchronizationmutualexclusion/:1:0","tags":["Process Synchronization","Mutual Exclusion"],"title":"[OS] Process Synchronization and Mutual Exclusion","uri":"/os_lec06_processsynchronizationmutualexclusion/"},{"categories":["Computer Science"],"content":"Requirements for ME Mutual exlcusion critical section에 프로세스가 있으면, 다른 프로세스의 진입을 금지 Progress critical section 안에 있는 프로세스 외에는 다른 프로세스가 critical section에 진입하는 것을 방해하면 안됨 Bounded waiting 프로세스의 critical section 진입은 유한시간 내에 허용되어야 함 Mutual Exclusino Solutions에 대한 solution들이 많다. 그중에서 os supported SW solution중 하나인 semaphore에 대해 알아보자. ","date":"2022-03-11","objectID":"/os_lec06_processsynchronizationmutualexclusion/:1:1","tags":["Process Synchronization","Mutual Exclusion"],"title":"[OS] Process Synchronization and Mutual Exclusion","uri":"/os_lec06_processsynchronizationmutualexclusion/"},{"categories":["Computer Science"],"content":"Semaphore $S$: 음이 아닌 정수형 변수 초기화 연산 $P(),V()$로만 접근 가능 종류 binary semaphore: 상호배제나 프로세스 동기화의 목적 counting semaphore: producer-consumer 문제 등을 해결하기 위해 사용 여기서는 상호배제의 경우만 알아보자. $P(S)$ 연산 if $S( \u003e 0)$ then $S \\leftarrow S - 1$ else wait on the queue $Q_s$ $V(S)$ 연산 if any waiting processes on $Q_s$ then wakeup one of them else $S \\leftarrow S + 1$ $P_i$가 먼저 들어와서 $P(\\text{active})$ 후 critical section에 들어간다. 다음에 $P_j$가 들어왔는데 active가 0이라서 ready queue로 들어가서 대기한다. $P_i$가 끝나면 $V(\\text{active})$ 연산을 진행해서 queue에 있는 $P_j$를 wake up 하고 active=1이 된다. $P_j$는 $P(\\text{active})$연산을 진행하고 critival section에 들어간다. 위와 같은 과정을 통해 프로세스가 충돌하지 않도록, mutual exclusion 하도록 만드는 것이다. ","date":"2022-03-11","objectID":"/os_lec06_processsynchronizationmutualexclusion/:2:0","tags":["Process Synchronization","Mutual Exclusion"],"title":"[OS] Process Synchronization and Mutual Exclusion","uri":"/os_lec06_processsynchronizationmutualexclusion/"},{"categories":["Computer Science"],"content":"Reference HPC Lab. KOREATECH 운영체제 강의 ","date":"2022-03-11","objectID":"/os_lec06_processsynchronizationmutualexclusion/:3:0","tags":["Process Synchronization","Mutual Exclusion"],"title":"[OS] Process Synchronization and Mutual Exclusion","uri":"/os_lec06_processsynchronizationmutualexclusion/"},{"categories":["Computer Science"],"content":"Process scheduling에 대한 기본개념 정리 여러개의 프로세스가 시스템에 존재하기 때문에 자원을 할당 할 프로세스를 잘 관리해야한다. 이번에는 이런 프로세스를 스케쥴링하는 방법을 알아보자. ","date":"2022-03-08","objectID":"/os_lec04_processscheduling/:0:0","tags":["Process"],"title":"[OS] Process Scheduling","uri":"/os_lec04_processscheduling/"},{"categories":["Computer Science"],"content":"스케줄링의 목적 시스템의 성능 향상 성능 지표 응답시간 작업 처리량 자원 활용도 ","date":"2022-03-08","objectID":"/os_lec04_processscheduling/:1:0","tags":["Process"],"title":"[OS] Process Scheduling","uri":"/os_lec04_processscheduling/"},{"categories":["Computer Science"],"content":"스케줄링의 단계 Long-term scheduling job scheduling: kernel에 등록할 작업 결정 Mid-term scheduling memory allocation Short-term scheduling process scheduling 프로세서를 할당할 프로세스를 결정 가장 빈번하게 발생하기에 빨라야 함 ","date":"2022-03-08","objectID":"/os_lec04_processscheduling/:2:0","tags":["Process"],"title":"[OS] Process Scheduling","uri":"/os_lec04_processscheduling/"},{"categories":["Computer Science"],"content":"스케줄링 정책 Preemptive/Non-preemptive scheduling Non-preemtive 할당 받을 자원을 스스로 반납할 때까지 사용 Preemptive 타의에 의해 자원을 빼앗길 수 있음 Priority Static priority 프로세스 생성시 결정된 priority가 유지 됨 Dynamic priority 프로세스의 상태 변화에 따라 priority가 변경 ","date":"2022-03-08","objectID":"/os_lec04_processscheduling/:3:0","tags":["Process"],"title":"[OS] Process Scheduling","uri":"/os_lec04_processscheduling/"},{"categories":["Computer Science"],"content":"기본 스케줄링 알고리즘 ","date":"2022-03-08","objectID":"/os_lec04_processscheduling/:4:0","tags":["Process"],"title":"[OS] Process Scheduling","uri":"/os_lec04_processscheduling/"},{"categories":["Computer Science"],"content":"FCFS (First-Come-First-Service) Non-preemptive 도착시간 기준, 먼저 도착한 프로세스를 먼저 처리 대기시간이 길어질 수 있다, 긴 평균 응답시간 ","date":"2022-03-08","objectID":"/os_lec04_processscheduling/:4:1","tags":["Process"],"title":"[OS] Process Scheduling","uri":"/os_lec04_processscheduling/"},{"categories":["Computer Science"],"content":"RR (Round-Robin) Preemptive 도착시간 기준, 먼저 도착한 프로세스를 먼저 처리하지만 자원사용 제한시간이 있다 프로세스는 할당된 시간이 지나면 자원을 반납한다 context switch overhead가 클 수 있다 ","date":"2022-03-08","objectID":"/os_lec04_processscheduling/:4:2","tags":["Process"],"title":"[OS] Process Scheduling","uri":"/os_lec04_processscheduling/"},{"categories":["Computer Science"],"content":"SPN (Shortest-Process-Next) Non-preemptive 실행시간 기준, 실행시간이 가장 작은 프로세스를 먼저 처리 평균 대기시간이 작고, 시스템 내 프로세스 수도 작다 실행시간을 예측하기 어렵다, Starvation(무한대기) 발생 ","date":"2022-03-08","objectID":"/os_lec04_processscheduling/:4:3","tags":["Process"],"title":"[OS] Process Scheduling","uri":"/os_lec04_processscheduling/"},{"categories":["Computer Science"],"content":"SRTN (Shortest Remaining Time Next) Preemptive 잔여 실행 시간이 더 적은 프로세스가 ready가 되면 선점된다 SPN의 장점 극대화 실행시간을 예측하기 어렵고 잔여 실행을 계속 추척해야 한다 ","date":"2022-03-08","objectID":"/os_lec04_processscheduling/:4:4","tags":["Process"],"title":"[OS] Process Scheduling","uri":"/os_lec04_processscheduling/"},{"categories":["Computer Science"],"content":"HRRN (High-Response-Ratio-Next) SPN + Aging + Non-preemptive 프로세스이 대기시간(Aging)을 고려하여 기회를 제공한다 SPN의 장점 + starvation 방지 실행시간을 예측하기 어렵다 ","date":"2022-03-08","objectID":"/os_lec04_processscheduling/:4:5","tags":["Process"],"title":"[OS] Process Scheduling","uri":"/os_lec04_processscheduling/"},{"categories":["Computer Science"],"content":"MLQ (Multi-level Queue) 작업(or 우선순위)별 별도의 ready queue를 가진다 최초 배정된 queue를 바꿀 수 없다 각각의 queue는 자신만의 스케줄링 기법 사용 queue 사이에는 우선순위 기반의 스케줄링 사용 여러개의 queue로 인한 장점도 있지만 관리해야 하는 단점도 있다 우선순위가 낮은 queue는 starvation 현상이 발생 할 수도 있다 ","date":"2022-03-08","objectID":"/os_lec04_processscheduling/:4:6","tags":["Process"],"title":"[OS] Process Scheduling","uri":"/os_lec04_processscheduling/"},{"categories":["Computer Science"],"content":"MFQ (Multi-level Feedback Queue) 프로세스의 queue간 이동이 허용된 MLQ Feedback을 통해 우선 순위 조정 프로세스에 대한 사전 정보 없이 SPN ~ HRRN 기법의 효과를 볼 수 있다 MFQ를 조금씩 변형해서 사용된다 ","date":"2022-03-08","objectID":"/os_lec04_processscheduling/:4:7","tags":["Process"],"title":"[OS] Process Scheduling","uri":"/os_lec04_processscheduling/"},{"categories":["Computer Science"],"content":"Reference HPC Lab. KOREATECH 운영체제 강의 ","date":"2022-03-08","objectID":"/os_lec04_processscheduling/:5:0","tags":["Process"],"title":"[OS] Process Scheduling","uri":"/os_lec04_processscheduling/"},{"categories":["Computer Science"],"content":"Thread에 대한 개념 정리 ","date":"2022-03-05","objectID":"/os_lec05_threadmanagement/:0:0","tags":["Thread"],"title":"[OS] Thread Management","uri":"/os_lec05_threadmanagement/"},{"categories":["Computer Science"],"content":"스레드(Thread) Light weight process 프로세서 활용의 기본 단위 프로세스는 자원을 할당받고 이를 제어하는 과정인데 이 때, 제어를 여러개의 스레드로 할 수 있다 제어 요소 외 code, data 및 자원들은 프로세스 내 다른 스레드들과 공유 구성요소 Thread ID Register set (stack pointer, program pointer) 등 ","date":"2022-03-05","objectID":"/os_lec05_threadmanagement/:1:0","tags":["Thread"],"title":"[OS] Thread Management","uri":"/os_lec05_threadmanagement/"},{"categories":["Computer Science"],"content":"스레드의 장점 사용자 응답성 일부 스레드의 처리가 지연되어도 다른 스레드는 작업을 계속 처리 가능 자원 공유 자원을 공유하기 때문에 효율성이 증가 예를 들어, 게임(프로세스)을 할 때 모니터(화면출력), 마우스(사용자입력), 헤드셋 와 관련해서 멀티스레드로 게임 관련 자원을 공유하면서 3가지 작업을 동시에 진행할 수 있는 것이다. 경제성 프로세스의 생성, context switching에 비해 효율적 멀티 프로세서 활용 병렬처리를 통한 성능 향상 ","date":"2022-03-05","objectID":"/os_lec05_threadmanagement/:2:0","tags":["Thread"],"title":"[OS] Thread Management","uri":"/os_lec05_threadmanagement/"},{"categories":["Computer Science"],"content":"스레드의 구현 ","date":"2022-03-05","objectID":"/os_lec05_threadmanagement/:3:0","tags":["Thread"],"title":"[OS] Thread Management","uri":"/os_lec05_threadmanagement/"},{"categories":["Computer Science"],"content":"사용자 수준 스레드 (User Thread) 사용자 영역의 스레드 라이브러리로 구현됨 사용자 영역에서는 여러 개의 스레드가 있지만 커널 영역에는 하나의 스레드만 존재 (다대일 매핑) 커널은 스레드의 존재를 모름 장점: 커널의 관리를 받지 않음 생성 및 관리의 부하가 적음, 유연한 관리 단점: 커널은 프로세스 단위로 자원 할당 하나의 스레드가 block 상태가 되면 모든 스레드가 대기 ","date":"2022-03-05","objectID":"/os_lec05_threadmanagement/:3:1","tags":["Thread"],"title":"[OS] Thread Management","uri":"/os_lec05_threadmanagement/"},{"categories":["Computer Science"],"content":"커널 수준 스레드 (Kernel Thread) 커널이 직접 관리 커널 영역에서 스레드의 생성, 관리 수행 context switching 등 부하가 크다 (프로세스의 context switching 보다는 덜 하지만) 커널이 각 스레드를 개별적으로 관리 하나의 스레드가 block 상태가 되어도, 다른 스레드는 계속 작업 수행 가능 일대일 매핑 ","date":"2022-03-05","objectID":"/os_lec05_threadmanagement/:3:2","tags":["Thread"],"title":"[OS] Thread Management","uri":"/os_lec05_threadmanagement/"},{"categories":["Computer Science"],"content":"혼합형 스레드 n개의 사용자 수준 스레드, m개의 커널 스레드 (n \u003e m) ","date":"2022-03-05","objectID":"/os_lec05_threadmanagement/:3:3","tags":["Thread"],"title":"[OS] Thread Management","uri":"/os_lec05_threadmanagement/"},{"categories":["Computer Science"],"content":"Reference HPC Lab. KOREATECH 운영체제 강의 ","date":"2022-03-05","objectID":"/os_lec05_threadmanagement/:4:0","tags":["Thread"],"title":"[OS] Thread Management","uri":"/os_lec05_threadmanagement/"},{"categories":["Computer Science"],"content":"Process에 대한 개념 정리 ","date":"2022-03-04","objectID":"/os_lec03_processmanagement/:0:0","tags":["Process"],"title":"[OS] Process Management","uri":"/os_lec03_processmanagement/"},{"categories":["Computer Science"],"content":"프로세스의 개념 작업(Job) / 프로그램 (Program) 실행 할 프로그램 + 데이터 즉, 실행을 요청하기 전 상태 프로세스 (Process) 실행을 위해 시스템(커널)에 등록된 작업 ","date":"2022-03-04","objectID":"/os_lec03_processmanagement/:1:0","tags":["Process"],"title":"[OS] Process Management","uri":"/os_lec03_processmanagement/"},{"categories":["Computer Science"],"content":"프로세스의 정의 실행중인 프로그램 커널에 등록되고 커널의 관리하에 있는 작업 각종 자원들을 요청하고 할당 받을 수 있는 개체 PCB를 할당 받은 개체 능동적인 개체 (실행 중에 자원들을 요구, 할당, 반납하며 진행) ","date":"2022-03-04","objectID":"/os_lec03_processmanagement/:1:1","tags":["Process"],"title":"[OS] Process Management","uri":"/os_lec03_processmanagement/"},{"categories":["Computer Science"],"content":"PCB Process Control Block (PCB) os가 프로세스 관리에 필요한 정보 저장 프로세스 생성 시, 생성된다 PCB가 관리하는 정보 (os마다 조금씩 다름) PID (Process Identification Number) 스케줄링 정보 프로세스 상태 메모리 관리 정보 입출력 상태 정보 문맥 저장 영역 계정 정보 ","date":"2022-03-04","objectID":"/os_lec03_processmanagement/:2:0","tags":["Process"],"title":"[OS] Process Management","uri":"/os_lec03_processmanagement/"},{"categories":["Computer Science"],"content":"프로세스 상태 변화 ","date":"2022-03-04","objectID":"/os_lec03_processmanagement/:3:0","tags":["Process"],"title":"[OS] Process Management","uri":"/os_lec03_processmanagement/"},{"categories":["Computer Science"],"content":"Create State 작업(Job)을 커널에 등록 PCB 할당 및 프로세스 생성 이후에 memory가 할당되면 ready로 아니면 suspended ready ","date":"2022-03-04","objectID":"/os_lec03_processmanagement/:3:1","tags":["Process"],"title":"[OS] Process Management","uri":"/os_lec03_processmanagement/"},{"categories":["Computer Science"],"content":"Ready State 프로세서 이외의 자원을 할당받은 상태 프로세서 할당 대기, 즉시 실행 가능 상태 Dispatch (Schedule) ready -\u003e running ","date":"2022-03-04","objectID":"/os_lec03_processmanagement/:3:2","tags":["Process"],"title":"[OS] Process Management","uri":"/os_lec03_processmanagement/"},{"categories":["Computer Science"],"content":"Running State 프로세서와 필요한 자원을 모두 할당 받은 상태 Preemption (Time run out) 프로세서를 뺏기는 것 (eg. time-out, priority changes) running에서 ready로 Block (Sleep) I/O 같은 자원 할당 요청이 필요한 해서 asleep상태로 가는 것 running -\u003e asleep ","date":"2022-03-04","objectID":"/os_lec03_processmanagement/:3:3","tags":["Process"],"title":"[OS] Process Management","uri":"/os_lec03_processmanagement/"},{"categories":["Computer Science"],"content":"Blocked/Asleep State 프로세서 외에 다른 자원을 기다리는 상태 Wake-up Asleep -\u003e ready ","date":"2022-03-04","objectID":"/os_lec03_processmanagement/:3:4","tags":["Process"],"title":"[OS] Process Management","uri":"/os_lec03_processmanagement/"},{"categories":["Computer Science"],"content":"Suspended State 메모리를 할당받지 못한(빼앗긴) 상태 memory image를 swap device (eg. 하드디스크) 에 보관 커널 또는 사용자에 의해 발생 swap-out(suspended), swap-in(resume) ","date":"2022-03-04","objectID":"/os_lec03_processmanagement/:3:5","tags":["Process"],"title":"[OS] Process Management","uri":"/os_lec03_processmanagement/"},{"categories":["Computer Science"],"content":"Terminated/Zombie State 프로세스 수행이 끝난 상태 모든 자원 반납 후, 커널 애에 일부 PCB 정보만 남아있는 상태 ","date":"2022-03-04","objectID":"/os_lec03_processmanagement/:3:6","tags":["Process"],"title":"[OS] Process Management","uri":"/os_lec03_processmanagement/"},{"categories":["Computer Science"],"content":"인터럽트 unexpected and external events ","date":"2022-03-04","objectID":"/os_lec03_processmanagement/:4:0","tags":["Process"],"title":"[OS] Process Management","uri":"/os_lec03_processmanagement/"},{"categories":["Computer Science"],"content":"인터럽트 처리 과정 먼저 $P_i$라는 프로세스가 running 상태라고 하자 커널에 의해 interrupt가 들어오면 processor는 해당 프로세스를 멈추고 context saving을 한다 그리고 interrupt handler를 통해서 이를 어찌할지 결정하고 interrupt service를 통해 이를 해결한다 마지막으로 context restoring을 하여 $P_i$를 진행하다 다만 여기서 항상 $P_i$가 진행되는 것은 아니고 다른 ready상태였던 프로그램이 진행될 수도 있다 ","date":"2022-03-04","objectID":"/os_lec03_processmanagement/:4:1","tags":["Process"],"title":"[OS] Process Management","uri":"/os_lec03_processmanagement/"},{"categories":["Computer Science"],"content":"Context Switching Context: 프로세스와 관련한 정보들 cpu register context는 cpu register에 저장 code \u0026 data, stack, PCB는 memory에 저장 Context saving: 현재 프로세스의 register context를 저장하는 작업 Context restoring: Register context를 프로세스로 복구하는 작업 위의 두가지 과정을 Context switching (process switching) 이라고 한다. ","date":"2022-03-04","objectID":"/os_lec03_processmanagement/:5:0","tags":["Process"],"title":"[OS] Process Management","uri":"/os_lec03_processmanagement/"},{"categories":["Computer Science"],"content":"Reference HPC Lab. KOREATECH 운영체제 강의 ","date":"2022-03-04","objectID":"/os_lec03_processmanagement/:6:0","tags":["Process"],"title":"[OS] Process Management","uri":"/os_lec03_processmanagement/"},{"categories":["Python"],"content":"Python generator에 대해 알아보자. ","date":"2022-02-22","objectID":"/generator/:0:0","tags":null,"title":"[Python] Generator","uri":"/generator/"},{"categories":["Python"],"content":"개념 일단 Python docs에 있는 개념을 정리해보자. ","date":"2022-02-22","objectID":"/generator/:1:0","tags":null,"title":"[Python] Generator","uri":"/generator/"},{"categories":["Python"],"content":"generator A function which returns a generator iterator 그렇다면 generator iterator 란? An object created by a generator function next()로 함수가 실행되다가 yield를 만나면 임시적으로 processing을 멈추고 해당 값을 반환한다. 그 상태로 있다가 (함수에 사용된 local변수 등이 사라지지 않고 유지) generator iterator가 다시 시작(next() 호출)하면 다음 단계로 넘어간다. 모든 object가 소진되면 끝난다. 이는 코드를 통해 이해해보자. It looks like a normal function except that it contains yield expressions for producing a series of values usable in a for-loop or that can be retrieved one at a time with the next() function 쉽게 생각하면 yield로 iterator를 만든다고 이해할 수 있다. def gen(): x = [1,2,3] for i in x: yield i g = gen() print(type(g)) # \u003cclass 'generator'\u003e print(g.__dir__()) # ['__repr__', '__getattribute__', '__iter__', '__next__', '__del__', 'send', 'throw', 'close', 'gi_frame', 'gi_running', 'gi_code', '__name__', '__qualname__', 'gi_yieldfrom', '__doc__', '__hash__', '__str__', '__setattr__', '__delattr__', '__lt__', '__le__', '__eq__', '__ne__', '__gt__', '__ge__', '__init__', '__new__', '__reduce_ex__', '__reduce__', '__subclasshook__', '__init_subclass__', '__format__', '__sizeof__', '__dir__', '__class__'] # __iter__, __next__ 함수 존재 print(next(g)) # 1 print(next(g)) # 2 # 이런식으로 쉽게 Iterator를 만들 수 있다 def number_generator(stop): n = 0 while n \u003c stop: yield n n += 1 ","date":"2022-02-22","objectID":"/generator/:1:1","tags":null,"title":"[Python] Generator","uri":"/generator/"},{"categories":["Python"],"content":"yield from yield from은 파이썬 3.3 이상부터 사용 가능 yield from 뒤에는 iterable, iterator, generator가 올 수 있다 # 위에서 만든 것과 동일한 결과 def number_generator(): x = [1, 2, 3] yield from x def number_generator(stop): n = 0 while n \u003c stop: yield n n += 1 def three_generator(): yield from number_generator(3) for i in three_generator(): print(i) ","date":"2022-02-22","objectID":"/generator/:1:2","tags":null,"title":"[Python] Generator","uri":"/generator/"},{"categories":["Python"],"content":"generator 표현 []가 아니라 ()를 통해 만들 수 있다. # 리스트 [i for i in range(50) if i % 2 == 0] # generator (i for i in range(50) if i % 2 == 0) # 메모리 절약 import sys list_size = sys.getsizeof( [i for i in range(50) if i % 2 == 0]) get_size = sys.getsizeof((i for i in range(50) if i % 2 == 0)) print(list_size) # 312 print(get_size) # 112 데이터 사이즈가 큰 경우, generator를 이용하면 이점이 있을 것 같다. ","date":"2022-02-22","objectID":"/generator/:1:3","tags":null,"title":"[Python] Generator","uri":"/generator/"},{"categories":["Python"],"content":"Reference https://docs.python.org/3/glossary.html#term-generator https://dojang.io/mod/page/view.php?id=2412 ","date":"2022-02-22","objectID":"/generator/:2:0","tags":null,"title":"[Python] Generator","uri":"/generator/"},{"categories":["Python"],"content":"Python iterator애 대해 알아보자. ","date":"2022-02-21","objectID":"/iterator/:0:0","tags":null,"title":"[Python] Iterator","uri":"/iterator/"},{"categories":["Python"],"content":"개념 일단 Python docs에 있는 개념을 정리해보자. ","date":"2022-02-21","objectID":"/iterator/:1:0","tags":null,"title":"[Python] Iterator","uri":"/iterator/"},{"categories":["Python"],"content":"iterable 정의 An object capable of returning its members one at a time 종류 include all sequence types (such as list, str, and tuple) some non-sequence types like dict and file objects of any classes you define with an __iter__() or __getitem__() method that implements sequence semantics 작동원리 Iterables can be used in a for loop and in many other places where a sequence is needed (zip(), map(), …) When an iterable object is passed as an argument to the built-in function iter(), it returns an iterator for the object 예들 들어, list는 iterable이지만 iterator는 아니다. 이를 iterator로 만들고 싶으면 iter(해당list)처럼 iter()로 감싸면 된다. it is usually not necessary to call iter() or deal with iterator objects yourself The for statement does that automatically for you, creating a temporary unnamed variable to hold the iterator for the duration of the loop 위의 예시에서 우리는 iterator로 만드는 과정이 필요했다. 하지만 for문에서는 이를 자동으로 해준다는 의미이다. ","date":"2022-02-21","objectID":"/iterator/:1:1","tags":null,"title":"[Python] Iterator","uri":"/iterator/"},{"categories":["Python"],"content":"iterator 정의 An object representing a stream of data 작동원리 Repeated calls to the iterator’s __next__() method (or passing it to the built-in function next()) return successive items in the stream list, tuple, set, dict 등은 iterable이지만 iterator는 아니다 (next() 함수 씌우면 에러발생) When no more data are available a StopIteration exception is raised instead Iterators are required to have an __iter__() method that returns the iterator object itself so every iterator is also iterable ","date":"2022-02-21","objectID":"/iterator/:1:2","tags":null,"title":"[Python] Iterator","uri":"/iterator/"},{"categories":["Python"],"content":"코드 x = [1,2,3] # iterable x_iter = iter(x) # iterator로 만들기 print(type(x_iter)) # \u003cclass 'list_iterator'\u003e print(next(x_iter)) # 1 # iterator # __next__ 가 없으면 iterable class Counter: def __init__(self, stop): self.current = 0 self.stop = stop def __iter__(self): return self # 스스로가 iterator인 상태 def __next__(self): if self.current \u003c self.stop: r = self.current self.current += 1 return r else: raise StopIteration for i in Counter(3): print(i) # 0 # 1 # 2 c = Counter(3) print(next(c)) # 0 # iterable # __getitem__ 만 구현되어 있으면 for문은 가능 class Counter: def __init__(self, stop): self.current = 0 self.stop = stop def __getitem__(self, index): if index \u003c self.stop: return index else: raise IndexError c = Counter(3) for i in c: print(i) # 0 # 1 # 2 print(next(c)) # TypeError: 'Counter' object is not an iterator c_iter = iter(c) print(next(c_iter)) # 0 print(next(c_iter)) # 1 ","date":"2022-02-21","objectID":"/iterator/:2:0","tags":null,"title":"[Python] Iterator","uri":"/iterator/"},{"categories":["Python"],"content":"Reference https://dojang.io/mod/page/view.php?id=2406 https://wikidocs.net/16068 https://docs.python.org/3/glossary.html#term-iterable ","date":"2022-02-21","objectID":"/iterator/:3:0","tags":null,"title":"[Python] Iterator","uri":"/iterator/"},{"categories":["Tips"],"content":"pyspark와 관련한 tips 정리 ","date":"2022-02-20","objectID":"/pyspark/:0:0","tags":null,"title":"[Tips] Pyspark","uri":"/pyspark/"},{"categories":["Tips"],"content":"DataFrame join할 때, 같은 이름의 컬럼이 있는 경우 문제 발생 가능 같은 이름으로 join하는 경우 표현식을 쓰지 않고 문자열로 on 조건을 걸면 된다. : df1.join(df2, \"same_col_name\", \"[how]\") join하는 컬럼이름은 달라도 같은 이름의 컬럼이 존재하는 경우 join하기 전에 이름을 바꾸자. ","date":"2022-02-20","objectID":"/pyspark/:0:1","tags":null,"title":"[Tips] Pyspark","uri":"/pyspark/"},{"categories":["Tips"],"content":"특정 조건일 떄, 특정 컬럼의 값 바꾸기 when, otherwise 를 같이 이용하자 df = df.withColumn( \"col_name\", when(col(\"col_1\") == 1, 2).otherwise(col(\"col_name\")) ) ","date":"2022-02-20","objectID":"/pyspark/:0:2","tags":null,"title":"[Tips] Pyspark","uri":"/pyspark/"},{"categories":["Tips"],"content":"pandas를 pyspark dataframe으로 바꾸는 법 spark.createDataFrame(df) ","date":"2022-02-20","objectID":"/pyspark/:0:3","tags":null,"title":"[Tips] Pyspark","uri":"/pyspark/"},{"categories":["Tips"],"content":"새로운 컬럼을 만들 때, 특정 상수로 채우기 lit 이용 df.withColumn(\"new_col\", lit(상수)) ","date":"2022-02-20","objectID":"/pyspark/:0:4","tags":null,"title":"[Tips] Pyspark","uri":"/pyspark/"},{"categories":["Tips"],"content":"자주 쓰는 데이터 \u0026 데이터의 크기가 그렇게 크지 않는 경우: toPandas() 이용해서 pandas로 진행하자 ","date":"2022-02-20","objectID":"/pyspark/:0:5","tags":null,"title":"[Tips] Pyspark","uri":"/pyspark/"},{"categories":["Tips"],"content":"groupby하고 특정 컬럼값의 unique한 갯수 세기 countDistinct df.groupby('groupby할 컬럼').agg(countDistinct('컬럼').alias('원하는 컬럼이름')) ","date":"2022-02-20","objectID":"/pyspark/:0:6","tags":null,"title":"[Tips] Pyspark","uri":"/pyspark/"},{"categories":["Tips"],"content":"여러 개의 값들에 해당하는 row를 뽑아내기 isin df[df['컬럼'].isin([값1, 값2, ...])] ","date":"2022-02-20","objectID":"/pyspark/:0:7","tags":null,"title":"[Tips] Pyspark","uri":"/pyspark/"},{"categories":["Tips"],"content":"column-wise sum 하는 법 fancy한 방법을 찾지는 못함 lit(0)으로 0인 컬럼 만들고 더하고 싶은 컬럼들을 for문으로 반복해서 더함 ","date":"2022-02-20","objectID":"/pyspark/:0:8","tags":null,"title":"[Tips] Pyspark","uri":"/pyspark/"},{"categories":["Tips"],"content":"usere defined function udf를 이용 spark.ml에서 logit 모형을 만들었는데 예측 probability 컬럼의 schema가 VectorUDT였다. 이는 [0.9, 0.1]의 형태를 갖고 있었는데 이를 처리하기 위해 아래와 같은 방법으로 진행하였다. from pyspark.sql.functions.F import udf def get_prob(x): return float(x[0]) # wrap the function and s-tore as a variable my_udf = udf(get_prob, FloatType()) user_df = user_df.withColumn('probability', my_udf(user_df.probability)) ","date":"2022-02-20","objectID":"/pyspark/:0:9","tags":null,"title":"[Tips] Pyspark","uri":"/pyspark/"},{"categories":["Tips"],"content":"날짜(DATE) ORDER BY pyspark에서 sql쿼리 사용할 때, 날짜를 정렬해야하는 경우 ASC: 날짜가 가장 오래된 것부터 가장 최근 순으로 정렬 DESC: 반대 df = spark.sql(\"\"\" SELECT * FROM ( SELECT *, ROW_NUMBER() OVER (PARTITION BY id, sex ORDER BY dt ASC) as idx FROM user_df ) u WHERE u.idx == \"1\" \"\"\") ","date":"2022-02-20","objectID":"/pyspark/:0:10","tags":null,"title":"[Tips] Pyspark","uri":"/pyspark/"},{"categories":["Causality"],"content":"Counterfactual에 관한 기본적인 개념과 Mediation에 대해 알아보자. ","date":"2022-02-18","objectID":"/causal14/:0:0","tags":["Counterfactual","Mediation"],"title":"[인과추론] Counterfactual and Mediation","uri":"/causal14/"},{"categories":["Causality"],"content":"Counterfactual 이미 이전에 경험했던 개념이다. causal inference가 어려운 이유는 counterfactual을 알 수 없기 때문이라고 배웠다. Counterfactual: $$P(Y(t)| T=t’,Y=y’)$$ parametric SCM으로 counterfactual을 파악하는 방법을 알아보자. 먼저 전반적인 과정은 아래와 같다. Given: observation $(T,Y)$, 여기서 $Y$는 $Y(T=t)$를 의미한다. Necessary: parametric model for the structural equation for $Y$ Result: access to counterfactuals $Y(t’)$ at the unit-level 이를 예시를 통해 이해해보자. $Y$: happy or unhappy (1, 0) $T$: get a dog or don’t (1, 0) $U$: unobserved variable describing the individual (1 if dog person, 0 if anti-dog person) SCM: $Y:= UT + (1-U)(1-T)$ 이런 상황에서 observation이 $T=0,Y=0$이 있다면 $Y(1)$을 알고 싶은 것이다. 가장 먼저 $U$에 대해 식을 푼다. 위의 observation을 이용하면 $U=1$이라는 것을 알 수 있다. 그렇다면 (individualized) SCM은 $Y=T$라는 것을 알 수 있다. 따라서 우리가 궁금했던 counterfactual은 $Y(1)=1$이다. structual equation이 있다고 해도 항상 counterfactual을 구할 수 있는 것은 아니다. 위의 예시에서 structural equation이 아래와 같은 경우를 생각해보자. $Y:=$ 1, $U$ = always happy (P=0.3) 0, $U$ = never happy (P=0.2) $T$, $U$ = dog-needer (P=0.4) $1-T$, $U$ = dog-hater (P=0.1) 이런 경우에는 observation $T=0,Y=0$이 있다면 $U$는 never happy거나 dog-needer 두 가지 모두에 해당한다. 따라서 이의 counterfauctual은 0, 1 둘 중 무엇일지 모른다. 하지만 확률적으로 접근해본다면? $$P(U=\\text{never happy} | T=0, Y=0)=\\frac{0.2}{0.2+0.4}=\\frac{1}{3}$$ $$P(U=\\text{dog-hater} | T=0, Y=0)=\\frac{0.4}{0.2+0.4}=\\frac{2}{3}$$ 따라서 $P(Y(1)=1)=\\frac{2}{3}$ 같이 확률적으로만 접근할 수 있다. ","date":"2022-02-18","objectID":"/causal14/:1:0","tags":["Counterfactual","Mediation"],"title":"[인과추론] Counterfactual and Mediation","uri":"/causal14/"},{"categories":["Causality"],"content":"Mediation","date":"2022-02-18","objectID":"/causal14/:2:0","tags":["Counterfactual","Mediation"],"title":"[인과추론] Counterfactual and Mediation","uri":"/causal14/"},{"categories":["Causality"],"content":"Intervention을 통해 Causal Discovery를 진행해보자. ","date":"2022-02-15","objectID":"/causal11/:0:0","tags":["Causal Discovery"],"title":"[인과추론] Causal Discovery from Interventions","uri":"/causal11/"},{"categories":["Causality"],"content":"Structural Interventions ","date":"2022-02-15","objectID":"/causal11/:1:0","tags":["Causal Discovery"],"title":"[인과추론] Causal Discovery from Interventions","uri":"/causal11/"},{"categories":["Causality"],"content":"Single-Node Intervensions Intervention in Two-Variable Setting 변수가 2개일 때, intervention을 하는 모든 경우를 살펴보자. 우리가 보고 싶은 것은 특정 intervention을 가해졌을 때, True graph를 essential graph로 나타낸 것이다. 여기서 essential graph은 이전에 배웠던 skeleton과 immoralities로 이루어진 graph라고 이해하면 된다. 위의 그림을 통해서 이해할 수 있겠지만 하나의 intervention으로 graph를 찾아내기란 어렵다. intervention으로 essential graph를 구했어도 이에 해당하는 true graph가 2개가 존재하기 때문이다. 따라서 Two interventions are sufficient and necessary to identify the graph. 라고 한다. 즉, 위에서 $A$ 또는 $B$를 intervention한 결과가 아니라 두 가지 결과를 모두 알고 있다면 true graph를 파악할 수 있게 된다. 이제 이를 일반화해보자. Complete Graphs are the worst case complete graph에서는 immoralities가 있을 수가 없기 때문에 (collider를 uncoditioning하면 두 node가 independent해야하는데 complete에서는 불가) skeleton graph만 얻을 수 있고 이는 당연히 true graph를 identify하는데 더 어렵게 만든다. Single variable interventions $n-1$ are sufficient for $n\u003e2$ (Eberhardt et al., 2006) empty set은 제외 왜 그럴까? 2개의 node가 있을 때, 둘 중 하나만 intervene하고 그 둘이 독립인지 아닌지 확인하면 edge의 방향을 알 수 있다. 이런식으로 n-1번하면 된다. $n-1$ are necessary in the worst case (complete graph) (Eberhardt et al., 2006) ","date":"2022-02-15","objectID":"/causal11/:1:1","tags":["Causal Discovery"],"title":"[인과추론] Causal Discovery from Interventions","uri":"/causal11/"},{"categories":["Causality"],"content":"Multi-Node Intervention 한 번에 하나의 node에만 intervention이 아니라 여러개의 node에 할 수 있다면? Multiple-Node Interventions $\\lfloor \\log_2 n \\rfloor + 1$ are sufficient (Eberhardt et al., 2005) $\\lfloor \\log_2 n \\rfloor + 1$ are necessary in the worst case (Eberhardt et al., 2005) 그렇다면 worst case (complete graph)가 아닌 경우에는 interventions가 얼마나 필요할까? (given that we can intervene on unlimited nodes per intervention) 이 때, graph에서 clique로 판단한다고 한다. 아래의 정의를 보자. Theorem: $\\lceil \\log_2 c \\rceil$ multi-node interventions are sufficient and necessary in the worst case, where $c$ is the size of the largest clique. (conjectured by Eberhardt (2008) and proven by Hauser \u0026 Buhlmann (2014)) ","date":"2022-02-15","objectID":"/causal11/:1:2","tags":["Causal Discovery"],"title":"[인과추론] Causal Discovery from Interventions","uri":"/causal11/"},{"categories":["Causality"],"content":"Parametric Interventions parametric 방법이 structural을 포함한다고 할 수 있다. 더 general한 개념이라고 이해하면 된다. 따라서 우리가 주로 parametric(soft, imperfect라고도 부름)이라고 부르는 방법은 structural이외의 parametric한 방법이다. parametric intervention은 structural와 다르게 기존 node들에 intervention을 가하는게 아니라 parameter를 이용해서 intervention을 가한다. 예를 들어, 원래 $Y := f(A,B,C)$와 같은 형태였다면 $Y := f(A,B,C, \\theta)$와 같은 방법으로 intervention을 가하는 것이다. ","date":"2022-02-15","objectID":"/causal11/:2:0","tags":["Causal Discovery"],"title":"[인과추론] Causal Discovery from Interventions","uri":"/causal11/"},{"categories":["Causality"],"content":"Number of Parametric Single-Node Interventions Number of interventions for identification (Eberhardt \u0026 Scheines, 2007) $n-1$ interventions are sufficient $n-1$ interventions are necessary in the worst case ","date":"2022-02-15","objectID":"/causal11/:2:1","tags":["Causal Discovery"],"title":"[인과추론] Causal Discovery from Interventions","uri":"/causal11/"},{"categories":["Causality"],"content":"Interventional Markov Equivalence ","date":"2022-02-15","objectID":"/causal11/:3:0","tags":["Causal Discovery"],"title":"[인과추론] Causal Discovery from Interventions","uri":"/causal11/"},{"categories":["Causality"],"content":"Interventions Introduce Immoralities: Single-Node 먼저, 아래와 같은 경우가 존재한다. 이제 여기에서 intervention을 가하면 아래처럼 된다. 이런 식으로 우리는 true graph를 찾아갈 수 있는 것이다. Theorem: Two graphs augmented with single-node interventions are interventionally Markov equivalent if any only if they have the same skeletons and immoralities (Tian, \u0026 Pearl, 2001) Number of interventions for identification (Eberhardt \u0026 Scheines, 2007) $n-1$ interventions are sufficient $n-1$ interventions are necessary in the worst case ","date":"2022-02-15","objectID":"/causal11/:3:1","tags":["Causal Discovery"],"title":"[인과추론] Causal Discovery from Interventions","uri":"/causal11/"},{"categories":["Causality"],"content":"Interventional Graph: Multi-Node Interventions multi-node intervention이라는 것은 하나의 새로운 node를 통해 동시에 여러개의 기존 node에 intervention을 가하는 것을 의미한다. Theorem: Given the observational data, two graphs augmented with multi-node intervetions are interventionally Markov equivalent if and only if the have the same skeletons and immoralities (Yang et al., 2018) ","date":"2022-02-15","objectID":"/causal11/:3:2","tags":["Causal Discovery"],"title":"[인과추론] Causal Discovery from Interventions","uri":"/causal11/"},{"categories":["Causality"],"content":"Reference Brady Neal - Causal Inference ","date":"2022-02-15","objectID":"/causal11/:4:0","tags":["Causal Discovery"],"title":"[인과추론] Causal Discovery from Interventions","uri":"/causal11/"},{"categories":["Causality"],"content":"causality가 어느정도 인지 파악하기 이전에 observational data에서 causal discovery를 먼저 진행해야 한다. 이에 대해 알아보자. observational data에서 causal graph가 없다면? 우리가 찾아야 한다. 그 과정을 causal discovery라고 한다. ","date":"2022-02-14","objectID":"/causal10/:0:0","tags":["Causal Discovery"],"title":"[인과추론] Causal Discovery from Observational Data","uri":"/causal10/"},{"categories":["Causality"],"content":"Independence-Based Causal Discovery ","date":"2022-02-14","objectID":"/causal10/:1:0","tags":["Causal Discovery"],"title":"[인과추론] Causal Discovery from Observational Data","uri":"/causal10/"},{"categories":["Causality"],"content":"Assumptions Faithfulness Assumption Recall the Markov assumption: $X \\perp_G Y | Z \\Rightarrow X \\perp_P Y |Z$ Markov assumption은 causal graph에서 data로 확장하는 가정이었다면 지금 우리는 그 반대가 필요하다. Faithfulnesss: $$X \\perp_G Y | Z \\Leftarrow X \\perp_P Y |Z$$ 하지만 쉽게 위의 반례를 찾을 수 있다. (아래의 그림참조) 그래서 우리는 아래와 같은 경우는 제외하고 가정한다. Causal Sufficiency and Acyclicity Assumption Causal Sufficiency: no unobserved confounders of any of the variables in the graph Acyclicity: there are no cycles in the graph ","date":"2022-02-14","objectID":"/causal10/:1:1","tags":["Causal Discovery"],"title":"[인과추론] Causal Discovery from Observational Data","uri":"/causal10/"},{"categories":["Causality"],"content":"Markov Equivalence and Main Theorem 먼저 Markov equivalence가 무슨 의미인지 알아보자. 이전에 우리는 graph를 이루는 기본 요소들인 chain, fork, immorality를 배웠다. chain과 fork는 같은 markov equivalence class에 속한다. immorality는 혼자이다. 이를 나누는 기준은 해당 graph에서의 indepence관계를 생각하면 된다. 아래의 관계에서 graph는 node 3개, edge 2개를 갖는다. Markov equivalence class where $X_1 \\perp X_3 |X_2$ and $X_1 \\not\\perp X_3$ : chain, fork Markov equivalence class where $X_1 \\not\\perp X_3 |X_2$ and $X_1 \\perp X_3$ : immorality 위의 조건을 만족하는 모양은 (같은 어떤 indepence의 모양) 같은 markov equivalence class에 속한다고 이해할 수 있다. 위처럼 node 3개, edge 2개의 경우 chain, fork에 해당하는 graph는 총 3가지의 모양이 나올 수 있을 것이고 immorality는 한가지 밖에 없다. 여기서 Skeletons라는 새로운 개념이 나온다. edge에서 방향을 없앤 graph라고 이해하면 된다. 그러면 위에서 전제한 chain, fork의 경우 모두 동일한 모양의 Skeleton을 갖는다. 그렇다면 graph를 2가지 요소들로 구분할 수 있다. Skeleton Immorality 이와 관련한 Theorem(Verma \u0026 Pearl, 1990; Frydenburg, 1990)이 있는데 Two graphs are Markov equivalent if and only if they have the same skeleton and same immoralities 이다. ","date":"2022-02-14","objectID":"/causal10/:1:2","tags":["Causal Discovery"],"title":"[인과추론] Causal Discovery from Observational Data","uri":"/causal10/"},{"categories":["Causality"],"content":"The PC Algorithm Start with complete undirected graph Identify the skeleton $X \\perp Y | Z$인 edge들을 제거해나간다. ($Z$는 empty일 수 있다) 이 과정에서 imomorality에 대한 정보도 어느정도 얻을 수 있을 것이다. Identify immoralities and orient them 아래 두 개의 조건을 만족하면 $X-Z-Y$는 immorality이다. $X$와 $Y$ 사이에 edge가 없다. $Z$에 대해 not conditioning할 떄, $X$와 $Y$가 independent하다. Orient qualifying edges that are incident on colliders $X \\rightarrow Z - Y$에서 $X$와 $Y$를 이어주는 edge가 없다면 $X$ and $Y$ can be oriented as $Z \\rightarrow Y$ 위와 같은 과정을 지나면 우리는 정확한 graph는 알 수 없지만 data에 해당하는 Markov equivalent class를 identify할 수 있다. ","date":"2022-02-14","objectID":"/causal10/:1:3","tags":["Causal Discovery"],"title":"[인과추론] Causal Discovery from Observational Data","uri":"/causal10/"},{"categories":["Causality"],"content":"Removing Assumptions No assumed causal sufficiency: FCI algorithm (Spirtes et al, 2001) No assumed acyclicity: CCD algorithm (Richardson, 1996) Neither causal sufficiency nor acyclicity: SAT-based causal discovery (Hyttinen et al, 2013; 2014) ","date":"2022-02-14","objectID":"/causal10/:1:4","tags":["Causal Discovery"],"title":"[인과추론] Causal Discovery from Observational Data","uri":"/causal10/"},{"categories":["Causality"],"content":"Hardness of conditioinal independence Testing 위에서 살펴본 Independence-based causal discovery 알고리즘은 conditional independence testing에 의존할 수 밖에 없다. 하지만 이에 따라 당연히 한계점이 있을 수 밖에 없다. 정확한 test가 되려면 데이터가 많아야 한다고 한다. (Shah \u0026 Peters, 2020) ","date":"2022-02-14","objectID":"/causal10/:1:5","tags":["Causal Discovery"],"title":"[인과추론] Causal Discovery from Observational Data","uri":"/causal10/"},{"categories":["Causality"],"content":"Semi-Parametric Causal Discovery Independnce-Based causal Discovery가 가지는 문제점은 어떤게 있을까? Requires faithfulness assumption Large samples can be necessary for conditional independence tests Only identifies the Markov equivalence class ","date":"2022-02-14","objectID":"/causal10/:2:0","tags":["Causal Discovery"],"title":"[인과추론] Causal Discovery from Observational Data","uri":"/causal10/"},{"categories":["Causality"],"content":"No Identifiability without Parametric Assumptions 특정한 상황을 가정해보자. 2개의 variable이 있고 infinite data가 있다고 하면 이 둘의 causal한 관계를 알 수 있을까? 먼저 markov equivalent의 관점에서 살펴보면? 알 수가 없다. $X \\rightarrow Y$, $X \\leftarrow Y$ 모두 동일한 skeleton의 모양이다. 그렇다면 이제 parametric form에 대한 가정을 해보자. ","date":"2022-02-14","objectID":"/causal10/:2:1","tags":["Causal Discovery"],"title":"[인과추론] Causal Discovery from Observational Data","uri":"/causal10/"},{"categories":["Causality"],"content":"Linear Non-Gaussian setting Linear non-Gaussian Assumption 모든 structural equation(causal mechanisms that generate the data)들은 다음과 같은 form을 갖는다: $$Y := f(X) + U$$ 이 떄, $f$는 linear function, $X \\perp U$, $U$는 distributed as some non-Gaussian 이다. Identifiability in Linear Non-Gaussian Setting 왜 Non-Gaussian일까? 일단 이와 관련해서는 (Geiger \u0026 Pearl, 1988) We cannot hope to identify the graph more precisely than the Markov equivalence class in the linear Gaussian noise setting 이라는 연구가 있다고 한다. Linear Non-Gaussian setting에서 graph를 identify하는 과정을 알아보자. 먼저 Theorem을 기억하자. Theorem (Shimizu et al, 2006): In the linear non-Gaussian setting, if the true SCM is $$Y := f(X) + U,\\;\\; X\\perp U$$ then there does not exist an SCM in the reverse direction, $$X := g(Y) + \\tilde{U},\\;\\; Y \\perp \\tilde{U}$$ that can generate data consistent with $P(x,y)$ 그렇다면 어떻게 위에서 말하는대로 causal mechanism을 파악할 수 있을까? linear model을 fit하고 residual을 확인하면 된다. 이를 좀 더 extension한 경우들도 있다. Multivariate (Shimizu et al., 2006) Drop causal sufficiency assumption (Hoyer et al. 2008) Drop acyclicity assumption (Lacerda et al. 2008) ","date":"2022-02-14","objectID":"/causal10/:2:2","tags":["Causal Discovery"],"title":"[인과추론] Causal Discovery from Observational Data","uri":"/causal10/"},{"categories":["Causality"],"content":"Nonlinear Additive Noise setting Nonlinear Additive Noise Assumption $$X_i := f_i (pa_i) + U_i,\\;\\;\\text{for all } i$$ where $f_i$ is nonlinear. Theorem (Hoyer et al. 2008) Under the Markov assumption, causal sufficiency, acyclicity, the nonlinear additive noise assumption, and a technical condition from Hoyer et al. 2008, we can identify the causal graph. Post-Nonlinear Setting Zhang \u0026 Hyvarinen, 2009 $$Y := g(f(X) + U), ;; X \\perp U$$ ","date":"2022-02-14","objectID":"/causal10/:2:3","tags":["Causal Discovery"],"title":"[인과추론] Causal Discovery from Observational Data","uri":"/causal10/"},{"categories":["Causality"],"content":"Review Articles and Book Introduction to the Foundations of Causal Discovery (Eberhardt 2017) Review of Causal Discovery Methods Based on Graphical Models (Glymour, Zhang, \u0026 Spirtes, 2019) Elements of Causal Infernce (Peters, Janzing, \u0026 Scholkopf, 2017) ","date":"2022-02-14","objectID":"/causal10/:3:0","tags":["Causal Discovery"],"title":"[인과추론] Causal Discovery from Observational Data","uri":"/causal10/"},{"categories":["Causality"],"content":"Reference Brady Neal - Causal Inference ","date":"2022-02-14","objectID":"/causal10/:4:0","tags":["Causal Discovery"],"title":"[인과추론] Causal Discovery from Observational Data","uri":"/causal10/"},{"categories":["Causality"],"content":"Propensity Score에 대해 알아보자. 회사에서 업무를 하다가 Inverse Propensity Weight 방법론을 사용하게 되었는데 관련 내용을 찾다가 pycon에서 2019년에 올라온 영상을 찾았고 이를 간단히 정리하였다. ","date":"2022-01-20","objectID":"/propensity_score/:0:0","tags":["Propensity Score","Matching"],"title":"[Causality] Propensity Score","uri":"/propensity_score/"},{"categories":["Causality"],"content":"Propensity Score Matching A Non-experimental Approach to Causal Inference ","date":"2022-01-20","objectID":"/propensity_score/:1:0","tags":["Propensity Score","Matching"],"title":"[Causality] Propensity Score","uri":"/propensity_score/"},{"categories":["Causality"],"content":"Propensity Score Mathcing RCT가 불가능 할 떄 사용한다. group들이 balanced되도록 만든다. selection bias를 해결하기 위해 사용한다. 어떤 treatment의 effect가 궁금하다. 그런데 RCT가 불가능하고 observational data만 존재한다. 따라서 confounder들의 영향이 존재하고 causal effect를 측정하기 위해서는 이를 없애야 한다. Pearl이 말하는 back-door problem이라고도 할 수 있다. 이를 해결하기 위해 Propensity Score Matching을 이용한다. step Calculate the propensity Use the propensity score to create a control group matched to the exposed group Check that the exposed group and matched control group are similar Estimate effect of exposure on the outcome of interset ","date":"2022-01-20","objectID":"/propensity_score/:1:1","tags":["Propensity Score","Matching"],"title":"[Causality] Propensity Score","uri":"/propensity_score/"},{"categories":["Causality"],"content":"Propensity score probability of being exposed given a set preditors $$Pr(T = 1| X)$$ 이를 구할 떄 주로 Logistic regression을 사용한다. $X$는 현재 갖고 있는 covariate들이고 $y$ label은 treatment group(1)인지 control group(0) 여러 covariate들이 있는데 이들을 하나의 숫자(해당 instance가 treatment group에 속할 확률)로 압축해서 사용하는 것으로 볼수도 있다. ","date":"2022-01-20","objectID":"/propensity_score/:1:2","tags":["Propensity Score","Matching"],"title":"[Causality] Propensity Score","uri":"/propensity_score/"},{"categories":["Causality"],"content":"Selecting Covariates covariate들은 treatment group의 selection process와 관련이 있어야 한다. true confounders!, avoid instrumental variable 즉, covariate는 treatment에도 영향을 주고 target에도 영향을 주는 변수여야 한다. ","date":"2022-01-20","objectID":"/propensity_score/:1:3","tags":["Propensity Score","Matching"],"title":"[Causality] Propensity Score","uri":"/propensity_score/"},{"categories":["Causality"],"content":"Matching algorithm Matching에도 다양한 방법론들이 존재하는데 크게 아래처럼 나누어서 생각할 수 있다. Greediness: greedy vs optimal Distance: caliper vs nearest neighbor Symmetry: one-to-one vs one-to-many ","date":"2022-01-20","objectID":"/propensity_score/:1:4","tags":["Propensity Score","Matching"],"title":"[Causality] Propensity Score","uri":"/propensity_score/"},{"categories":["Causality"],"content":"Checking for Balance matching을 하고나서 항상 matching이 잘 됐는지 확인해야 한다. 이 또한 다양한 방법론이 존재한다. Cohen’s $d$: mean diffence와 pooled SD를 이용하여 아래처럼 계산 각 covariate마다 계산해서 mean과 sd를 계산하여 $d$값을 구하고 match 전, 후를 비교 상황마다 다르지만 절댓값 0.1 정도면 good $$d = \\frac{M_2 - M_1}{\\sqrt{\\frac{SD_{1}^2 + SD_{2}^2}{2}}}$$ ","date":"2022-01-20","objectID":"/propensity_score/:1:5","tags":["Propensity Score","Matching"],"title":"[Causality] Propensity Score","uri":"/propensity_score/"},{"categories":["Causality"],"content":"Incorporate the propensity score propensity score를 이용하는 다른 방법론에 대핸 간략히 설명했다. Regression adjustment effect model을 만들 때 propensity score를 covariate로 이용 Stratified Analysis Estimate $T$ effect within propensity score strata Inverse Probability of Treatment Weighting ","date":"2022-01-20","objectID":"/propensity_score/:1:6","tags":["Propensity Score","Matching"],"title":"[Causality] Propensity Score","uri":"/propensity_score/"},{"categories":["Causality"],"content":"Why Propensity Scores Should Noe Be Used For Matching Gary King’s Lecture 1시간짜리 영상인데 꽤 재밌었다. Propensity Score를 이용하여 matching을 진행할 때, 발생할 수 있는 문제들에 대해 알려준다. 시뮬레이션 데이터를 통해 설명해서 이해가 잘된다. 결론만 정리했다. Why propensity scores should not be used for matching Low Standards: 때로는 좋은 결과를 낼 수 있지만 최선의 결과를 찾는 과정은 아니다. The PSM Paradox: 오히려 더 안 좋아질 수 도 있다. 그 이외에 기억에 남는 것들 matching을 통해 model dependence를 줄인다. matching을 하지 않으면 모델에 따라 데이터에 대한 해석이 달라질 수 있다. (특히 causal 부분에서) RCT보다 fully blocked가 더 좋다. RCT는 observed, unobserved 모두 평균적으로 balance한데, fully blocked는 observed에서는 exact하기에 더 좋다. 결국 PS는 covariate를 하나의 수로 요약하는 것인데 이는 정보를 잃는 것으로 볼 수도 있고 따라서 효과가 그리 좋지 않을 수도 있다. ","date":"2022-01-20","objectID":"/propensity_score/:2:0","tags":["Propensity Score","Matching"],"title":"[Causality] Propensity Score","uri":"/propensity_score/"},{"categories":["Algorithmic Marketing"],"content":"RFM (Recency, Frequency, Monetary) 분석 의 기본개념을 알아보자. ","date":"2022-01-12","objectID":"/04_rfm/:0:0","tags":["RFM 분석"],"title":"[Algorithmic Marketing] RFM 분석 기본개념","uri":"/04_rfm/"},{"categories":["Algorithmic Marketing"],"content":"개념설명 RFM 분석 Recency (최근성) Frequency (구매의 빈도) Monetary (구매액) 위의 3가지 지표를 통해 구매 가능성이 높은 고객을 선정하기 위한 데이터 분석 방법이다. 이를 통해 주로 고객가치측정, 고객세분화를 하려고 한다. 이를 통해 수익성예측, 마케팅 예산 할당. 고객이탈 예측을 할 수 있을 것이다. 도메인에 따라 각 지표들의 중요성이 달라진다. 이를 고려하여 가중치를 잘 만드는 것이 중요하다. 모형은 아래와 같은 모습이다. 가중치를 이용하여 각 고객마다 RFM 점수를 구한다. 물론 항상 가중치를 이용할 필요는 없다. $$RFM = w_1 Rscore + w_2 Fscore + w_3 Mscore$$ 가중치산출은 어떻게 할까? 통계적 추정방식 각 score를 covariate으로 놓고 target을 수익성지표(매출액 등)으로 하여 회귀계수를 구하고 이를 가중치로 이용 거래비율 분할방식 R,F,M의 각 점수구간(1점~5점)에 포함되는 고객들의 비율을 이용 가중치를 산출하지 않아도 분석을 진행할 수 있다. Scoring 기법 RFM의 요인을 각 5등급으로 분류 ex1) 각 요인을 5등급으로 나누어서 총 125개의 그룹 만들기 ex2) 각 요인의 우선순위를 만들고 순차적으로 5등급씩 나누기 ex2) 군집알고리즘을 통해 총 5개의 그룹 또는 각 요인 5개 그룹이후 총 125개의 그룹 만들기 RFM분석으로 고객세분화를 진행할 떄, 각 요인마다 ‘범위, 고객수, 고객비율, 금액, 금액비율, 매출기여도 등’ 들을 같이 적어서 보는게 좋다. 물론 목적에 따라 세부적인 내용은 달라질 수 있다. 그렇다면 실제로 RFM 분석을 이용한 사례는 어떤게 있을까? 고객등급화, 세분화에 다 사용할 수 있다. 은행에서 고객등급화 RFM 점수가 낮은 고객에서 마케팅을 하지 않아서 비용절감 ","date":"2022-01-12","objectID":"/04_rfm/:1:0","tags":["RFM 분석"],"title":"[Algorithmic Marketing] RFM 분석 기본개념","uri":"/04_rfm/"},{"categories":["Algorithmic Marketing"],"content":"Multi-touch Attribution model에 대해 알아보자. 온라인 광고에서는 여러 광고주나 채널을 통해 캠페인이 진행되는 경우가 많다. 그렇다면 conversion이 일어나기까지 funnel에서 각각 attribution이 있을 것이고 multi-touch attribution 모델은 이들의 영향을 측정하려고 하는 모델이다. conversion 직전의 touch만 기억하는 LT모델에 비해 유용하다고 할 수 있다. 다양한 방법이 있지만 그 중 paper하나를 요약해보았다. ","date":"2022-01-10","objectID":"/03_multi_touch_attr/:0:0","tags":["온라인 광고"],"title":"[Algorithmic Marketing] Multi-touch Attribution","uri":"/03_multi_touch_attr/"},{"categories":["Algorithmic Marketing"],"content":"Data-driven Multi-touch Attribution Models (KDD 2011) 논문에서는 크게 크게 아래의 두 가지 방법을 제시한다. Bagged Logistic Regression Simple probabilistic model 저자들이 MTA에서 중요하게 생각하는 것은 low variability와 low misclassification이라고 할 수 있다. 또한, 결과에 대한 해석도 중요하다고 한다. 모델의 정확도와 해석이 중요한 것은 당연하다는 생각이 들었다. 그런데 low variability는 무슨 의미일까? 사실 이 또한 당연하지만 ad compaign이라는 도메인이기에 저자들이 좀 더 중요하게 다루는 것 같다. 각 contribution에 대해 stable한 estimatation이 되어야 이와 관련한 예산, 향후 campaign 계획 등 비즈니스에 핵심적인 내용이기 때문에 stability가 없으면 이를 믿기 힘들다. ","date":"2022-01-10","objectID":"/03_multi_touch_attr/:1:0","tags":["온라인 광고"],"title":"[Algorithmic Marketing] Multi-touch Attribution","uri":"/03_multi_touch_attr/"},{"categories":["Algorithmic Marketing"],"content":"Bagged Logistic Regression highly correlated covariates로 인해 생기는 estimation variability를 줄이기 위해 bagging을 이용한다. 또한 해석이 쉬운 Logistic Regression을 이용하는 것이다. 과정은 아래와 같다. 참고로 dataset에서 column은 각 channel이고 row는 각 유저들을 의미한다. 아래 실습파일을 보면 이해하기 쉽다. step1. data를 $p_s$만큼 sampling하고 covariate들을 $p_c$만큼 sampling해서 Logistic regression을 fit한다. step2. 위의 step1을 $M$번 반복하고 각 계수들의 평균을 구한다. ","date":"2022-01-10","objectID":"/03_multi_touch_attr/:1:1","tags":["온라인 광고"],"title":"[Algorithmic Marketing] Multi-touch Attribution","uri":"/03_multi_touch_attr/"},{"categories":["Algorithmic Marketing"],"content":"Simple probabilistic model rule-based 방법이라고 할 수 있다. 최종 contribution을 계산하는 과정에서는 channel간의 interaction을 고려한다. step1. 주어진 dataset을 이용하여 empirical probability를 계산한다: $y$: conversion event (binary outcome) $x_i,i=1,…,p$: p는 advertising channel $N$: 괄호안에 해당하는 channel에 impression된 유저 수, $pos$가 conversion된 유저를 의미 $$P(y|x_i) = \\frac{N_{pos}(x_i)}{N_{pos}(x_i) + N_{neg}(x_i)}$$ $$P(y|x_i,x_j) = \\frac{N_{pos}(x_i, x_j)}{N_{pos}(x_i,x_j) + N_{neg}(x_i,x_j)}$$ step2. 각 positive 유저의 channel $i$의 contribution: $N_{j \\neq i}$: channel $i$이외의 다른 channel의 수 $$C(x_i) = p(y|x_i) + \\frac{1}{2N_{j \\neq i}} \\sum_{j \\neq i} [p(y|x_i,x_j) - p(y|x_i) - p(y|x_j)]$$ ","date":"2022-01-10","objectID":"/03_multi_touch_attr/:1:2","tags":["온라인 광고"],"title":"[Algorithmic Marketing] Multi-touch Attribution","uri":"/03_multi_touch_attr/"},{"categories":["Algorithmic Marketing"],"content":"궁금한 점 imbalance가 있을텐데 왜 misclassification rate를 봤을까? 그렇다면 이게 잘됐는지 판단하기 위해서 믿을건 모델의 성능뿐? 각 유저의 funnel 순서는 고려하지 않아도 되는가? ","date":"2022-01-10","objectID":"/03_multi_touch_attr/:1:3","tags":["온라인 광고"],"title":"[Algorithmic Marketing] Multi-touch Attribution","uri":"/03_multi_touch_attr/"},{"categories":["Algorithmic Marketing"],"content":"실습 Bagged Logistic Regression ","date":"2022-01-10","objectID":"/03_multi_touch_attr/:2:0","tags":["온라인 광고"],"title":"[Algorithmic Marketing] Multi-touch Attribution","uri":"/03_multi_touch_attr/"},{"categories":["Algorithmic Marketing"],"content":"온라인 광고를 하는 과정과 애트리뷰션 모델에 대해 알아보자. ","date":"2022-01-09","objectID":"/02_online_ad/:0:0","tags":["온라인 광고"],"title":"[Algorithmic Marketing] 온라인 광고","uri":"/02_online_ad/"},{"categories":["Algorithmic Marketing"],"content":"온라인 광고 먼저 온라인 광고 환경을 구성하는 개체들을 알아보자. 브랜드 (마케터) 제품이나 서비스를 판매 광고 캠페인에 자금을 투자 광고주 (에이전시) 브랜드를 대신해 광고 캠페인을 운영 여러 채널(웹 배너, 검색 결과 페이지, 온라인 비디오 광고 등)을 통해 브랜드의 고객을 늘리는 것이 주 목표 광고 거래소 퍼블리셔들과 광고주들은 광고 거래소에 의해 연결 광고 인벤토리가 생기면 퍼블리셔들로부터 광고요청을 받고 이 요청들을 광고주들에게 분배 거래소는 광고요청을 실시간으로 처리하는 형태를 가지므로 실시간 입찰 (real time bidding, RTB) 프로세스를 진행 사용자 채널을 통해 광고를 보는 사람 광고에 노출되는 것은 임프레션(impression)이라고 함 애트리뷰션 시스템 impression과 conversion을 측정 사용자를 행적을 추적하여 광고 캠페인의 효율성을 측정 ","date":"2022-01-09","objectID":"/02_online_ad/:1:0","tags":["온라인 광고"],"title":"[Algorithmic Marketing] 온라인 광고","uri":"/02_online_ad/"},{"categories":["Algorithmic Marketing"],"content":"목표 브랜드의 목표 브랜드 인지 신규 고객 유치 리타겟팅 브랜드의 관점에서 캠페인의 전반적 효율은 신규 고객당 비용 (cost per acquistition, CPA)에 의해 측정된다. CPA는 캠페인 비용을 전체 conversion 수로 나누것이다. $$CPA = \\frac{C_camp}{N_conv}$$ 이 때, 캠페인 비용은 알기 쉽지만 conversion은 정의하기 나름이다. 예를 들어, post-view action 방법이 있다. 이는 광고에 노출된 이후 특정 기간 동안 브랜드 웹 사이트를 방문하거나 구매한 사용자 수를 세는 것을 의미한다. 더 간단하게는 광고의 클릭 횟수를 세는 것이고 이를 cost per click (CPC) 모델이라고 한다. 광고주의 입장에서는 impression 횟수와 impression당 비용을 곱으로 CPA를 생각한다. $$CPA = \\frac{N_{impr}\\cdot E[c_{impr}]}{N_{conv}} = \\frac{1}{CR}\\cdot E[c_{impr}]$$ 여기서 광고주의 마진은 RTB에서 정해진 입찰 가격을 빼야하므로 아래의 식이 성립한다. $$CPA_a = \\frac{1}{CR}\\cdot E[c_{impr} - c_{bid}]$$ 브랜드가 내는 $c_{impr}$의 경우 주로 두 가지 종류의 계약이 사용된다고 한다. (여기서 애트리뷰션은 브랜드가 측정한다고 가정) 액션당 가격 (Cost per action): 애트리뷰션 시스템에 의해 측정된 컨버전마다 정해진 비용을 지불 노출당 가격 (Cost per mile, CPM): impression마다 정해진 비용을 지불하지만 애트리뷰션 시스템을 통해 전체적 CPA를 측정 광고주는 $CPA$ 최소화하는게 고객만족이므로 이를 위해 $CR$을 최대화하다. $CPA_a$는 $c_{bid}$가 고정되지 않고 conversion 비율의 영향을 받기 때문에 $CR$과 $c_{bid}$의 동시 최적화가 필요하다. ","date":"2022-01-09","objectID":"/02_online_ad/:2:0","tags":["온라인 광고"],"title":"[Algorithmic Marketing] 온라인 광고","uri":"/02_online_ad/"},{"categories":["Algorithmic Marketing"],"content":"Attribution model ","date":"2022-01-09","objectID":"/02_online_ad/:3:0","tags":["온라인 광고"],"title":"[Algorithmic Marketing] 온라인 광고","uri":"/02_online_ad/"},{"categories":["Algorithmic Marketing"],"content":"CPA-LT 모델 그렇다면 여러 광고주가 있을 경우 애트리뷰션을 어떻게 봐야할까? 이또한 다양한 방법들이 존재한다. 가장 기본적인 방법은 마지막 impression에 모든 공을 돌리는 Last touch attribution (LT) 이다. 위에서 살펴본 CPA와 LT가정을 갖는게 CPA-LT 모델이다. CPA-LT 모델의 한계점 브랜드 인지, 고객 유치 보다는 리타겟팅에 치우쳐진다. impression없이도 conversion될 고객을 인지하는 타겟팅은 CPA-LT 모델에서는 좋은 성과를 내지만 ROI측면에서는 아니다. 광고주가 속임수를 쓸 수 있다. 이제부터 CPA-LT 모델에서 어떻게 타겟팅과 입찰전략을 최적화할 것인지 알아보자. ","date":"2022-01-09","objectID":"/02_online_ad/:3:1","tags":["온라인 광고"],"title":"[Algorithmic Marketing] 온라인 광고","uri":"/02_online_ad/"},{"categories":["Algorithmic Marketing"],"content":"CPA-LT 모델 타겟팅 CPA-LT 모델에서 타겟팅의 목표는 광고 노출 직후에 conversion할 것 같은 고객을 인지하는 것이다. 광고에 대한 사용자의 반응에 대한 정보를 사용한다. 추가로 현재 진행 중인 광고의 성과를 반영하여 타겟팅 방법을 동적으로 수정한다. 여기서 광고주는 아래와 같은 데이터를 갖고 있다고 가정한다. 방문 URL 사용자 특성 (디바이스, 앱, 페이지 사용 시간 등) bid, impression 어떻게 사용자가 광고에 노출되었는지 conversion, 브랜드 데이터 (사용자가 브랜드의 어떤 데이터를 봤는지) 이러한 데이터를 통해 예측 모델링을 진행하는 것이다. 여러가지 방법들 중에 하나를 알아보자. Perlich 등이 제안한 단계별 타겟팅 방법론이다. 이 방법은 타겟팅 프로세스를 3단계로 나눠서 진행하는 것이다. ","date":"2022-01-09","objectID":"/02_online_ad/:3:2","tags":["온라인 광고"],"title":"[Algorithmic Marketing] 온라인 광고","uri":"/02_online_ad/"},{"categories":["Algorithmic Marketing"],"content":"브랜드 근접성 사용자 $u$에 대한 브랜드 근접성 (brand proximity) $P(Y|u)$를 계산하기 위해 광고 효과에 상관없이 conversion $Y$의 확률을 추정 conversion될 확률이 높을수록 브랜드에 가깝다고 판단 캠페인 이전의 데이터를 이용하여 브랜드 사이트 방문자의 conversion 여부로 target값 설정 실제 광고 응답에 대한 데이터가 없는 캠페인 초기에 사용자를 스코어링하기 위해 사용가능 주로 URL을 사용한다고 한다. 아래식에서 $URL_i$을 방문했으면 1, 아니면 0 $$\\phi(u) = P(Y|u) = P(Y|URL_1,…,URL_n)$$ ","date":"2022-01-09","objectID":"/02_online_ad/:3:3","tags":["온라인 광고"],"title":"[Algorithmic Marketing] 온라인 광고","uri":"/02_online_ad/"},{"categories":["Algorithmic Marketing"],"content":"광고 응답 모델링 추가로 광고 $a$에 대한 조건적 conversion 확률 $P(Y|u,a)$를 추정하는 것 해당 광고에 응답했는지 여부를 분류 단순히 URL이 아니라 위의 결과를 feature로 사용하고 그 외 사용자의 추가적인 정보를 이용하여 모델링한다. $$\\Phi_a(u) = P(Y|u,a)=P(Y|\\phi_{u1},…,\\phi_{uk},f_{u1},…,f_{ur})$$ ","date":"2022-01-09","objectID":"/02_online_ad/:3:4","tags":["온라인 광고"],"title":"[Algorithmic Marketing] 온라인 광고","uri":"/02_online_ad/"},{"categories":["Algorithmic Marketing"],"content":"인벤토리 품질과 입찰 마지막 단계로 광고거래소에 제출될 입찰 가격을 정하는 것이다. 최적 입찰 가격은 아래 식처럼 conversion 가치 $v(Y)$의 기댓값으로 계산된다. $v(Y)$는 모든 사용자에 대한 상수로 가정 $$b_{opt} = E[v(Y)] = P(Y|u,a)\\cdot v(Y)$$ 모델 $\\Phi$를 이용하여 입찰을 결정할 수도 있다. 특정 사용자에 대한 입찰 가격은 아래와 같다. $s_1$은 수치를 변환하는 함수 $$b(u) = b_{base} \\cdot s_1(\\Phi_a(u))$$ 그런데 지금까지의 타겟팅 과정은 impression의 맥락이 되는 인벤토리를 고려하지 않는다. 인벤토리 $i$일 때, 확률 $w_a(u,i) = P(Y|u,a,i)$를 사용할 수 있다. $$b(u) = b_{base} \\cdot s_1(\\Phi_a(u)) \\cdot s_2 (\\frac{w_a(u,i)}{w_a(u)})$$ ","date":"2022-01-09","objectID":"/02_online_ad/:3:5","tags":["온라인 광고"],"title":"[Algorithmic Marketing] 온라인 광고","uri":"/02_online_ad/"},{"categories":["Algorithmic Marketing"],"content":"Reference 알고리즘 마케팅 ","date":"2022-01-09","objectID":"/02_online_ad/:4:0","tags":["온라인 광고"],"title":"[Algorithmic Marketing] 온라인 광고","uri":"/02_online_ad/"},{"categories":["Algorithmic Marketing"],"content":"생존분석 방법론의 기본적인 개념을 알아보자. 생존분석은 주로 의학통계에서 많이 사용해왔다. 마케팅쪽에서는 주로 고객이탈(churn)과 관련하여 방법론을 가져와서 사용하기도 한다. 그외에도 특정한 treatment를 취한 뒤에 시간의 흐름에 따른 변화를 보기위해서도 많이 사용된다. 이름이 생존분석이라 엄청 어려워보이지만 실제로는 새로운 개념 몇가지만 이해한다면 regression처럼 어렵지 않게 이해할 수 있다. ","date":"2022-01-06","objectID":"/01_survival_analysis/:0:0","tags":["생존분석"],"title":"[Algorithmic Marketing] 생존분석 기본개념","uri":"/01_survival_analysis/"},{"categories":["Algorithmic Marketing"],"content":"생존분석 자료의 형태: 어떤 사건이 발생할 때까지 걸리는 시간 (time until an event occurs) 일반적인 regression 문제 아닌가? censored data가 존재하기 때문에 생존분석 접근이 필요하다. 여기서 censored data라는 것은 중도절단된 데이터라고 할 수 있다. 예를 들어, 신약을 두 환자그룹에 투여하고 사망까지 걸리는 시간을 측정하고자 한다. 그런데 실험대상이던 홛자가 외국으로 떠나서 연락이 두절되었다. 그러면 그 환자는 실제로 사망한 것은 아니지만 실제로 살았는지 죽었는지 알 방법이 없고 데이터를 더 이상 얻을 수 없는 시점을 그 환자의 수명으로 정할 수 밖에 없다. 이처럼 우리가 기대하는 이벤트(여기서는 사망)가 아닌 다른 이유로 해당 정보를 얻을 수 없는 경우 censored data라고 한다. 자료의 예 사건: 사망, 질병발생, 구독취소 시간: 년, 달, 주 분석예시: 전립선 암 치료제 효과 비교 사건: 전립선 암으로 인한 사망 시간: randomization시점부터 사망까지의 시간 분석목적: A라는 약을 먹는 집단이 그렇지 않은 집단보다 생존 시간이 더 긴가? ","date":"2022-01-06","objectID":"/01_survival_analysis/:1:0","tags":["생존분석"],"title":"[Algorithmic Marketing] 생존분석 기본개념","uri":"/01_survival_analysis/"},{"categories":["Algorithmic Marketing"],"content":"생존분석의 특징 관심자료가 nonnegative time until an event occurs 생존시간의 분포는 주로 skewed log transformation으로 해결되지 않을 정도 생존자료가 중도절단(censored)되어 관측 아직 이벤트가 발생하지 않았지만 연구자가 멈추는 경우 우리가 보고 싶은 이벤트 때문이 아니라 다른 이유로 더 이상 관찰을 못하는 경우 ","date":"2022-01-06","objectID":"/01_survival_analysis/:1:1","tags":["생존분석"],"title":"[Algorithmic Marketing] 생존분석 기본개념","uri":"/01_survival_analysis/"},{"categories":["Algorithmic Marketing"],"content":"Notation $T$: survival time $C$: censoring time $$Y=min(T,C)$$ status indicator: $$\\delta = \\begin{cases} 1,\\;if\\;T \\le C \\\\ 0,\\;if\\;T \u003e C \\end{cases}$$ 우리가 관찰하는 dataset은 $(Y,\\delta)$ pair의 형태이다. ","date":"2022-01-06","objectID":"/01_survival_analysis/:1:2","tags":["생존분석"],"title":"[Algorithmic Marketing] 생존분석 기본개념","uri":"/01_survival_analysis/"},{"categories":["Algorithmic Marketing"],"content":"생존분석에서 관심사 생존시간의 분포 파악 (집단 1개) 생존 함수 추정: 주로 Kaplan-Meier 추정법 집단 간 생존 분포 비교 (집단 2개 이상) 생존 함수 비교: 주로 log-rank 검정 생존시간에 대한 변수들의 효과 파악 Cox 회귀 모형 ","date":"2022-01-06","objectID":"/01_survival_analysis/:2:0","tags":["생존분석"],"title":"[Algorithmic Marketing] 생존분석 기본개념","uri":"/01_survival_analysis/"},{"categories":["Algorithmic Marketing"],"content":"생존함수(Survival function) $$S(t)=P(T\u003et)=1-F(t)$$ 특정 시점 $t$보다 더 오래 살 확률 ","date":"2022-01-06","objectID":"/01_survival_analysis/:3:0","tags":["생존분석"],"title":"[Algorithmic Marketing] 생존분석 기본개념","uri":"/01_survival_analysis/"},{"categories":["Algorithmic Marketing"],"content":"KM 추정법 위의 생존함수를 추정하는 방법은 다양하지만 주로 Kaplan-Meier 추정값을 많이 사용한다. 간단하면서도 유용한 방법이기 때문이다. $$S_t = \\frac{n_t - d_t}{n_t}$$ $n_t$ : 시간 $t$에 이벤트를 경험할 위험에 놓인 개체의 수 $d_t$ : 시간 $t$에 이벤트를 경험한 개체의 수 $$\\hat{S}(t) = \\prod_{i \\le t} S_i = \\prod_{i \\le t} (1 - \\frac{d_i}{n_i})$$ 위의 식을 Kaplan-Meier 추정값이라고 한다. (MLE이다) 표준오차를 통해서 신뢰구간도 알 수 있다. 비모수적 생존함수 추정법 survival curve 를 항상 그려보자. (코드예시) ","date":"2022-01-06","objectID":"/01_survival_analysis/:3:1","tags":["생존분석"],"title":"[Algorithmic Marketing] 생존분석 기본개념","uri":"/01_survival_analysis/"},{"categories":["Algorithmic Marketing"],"content":"두 집단 생존함수 비교 위와 같은 방법으로 생존함수를 구했다면 집단간의 차이가 있는지 궁금할 수 있다. 예를 들어, 신약을 먹은 집단과 신약을 먹지 않은 집단간의 생존함수가 차이가 있는지 검정하고 싶은 경우를 생각해 볼 수 있다. 신약의 효과에 대해서 검정할 수 있는 것이다. (censored data도 없고 less skewed되어 있다면 그냥 t-test같은 방법도 가능할 것이다) 두 집단의 생존함수가 같은지 비교, 검정한다. 특정 시점에서의 비교가 아니라 모든 시점을 비교하는 것이다. $$H_0: S_1(t) = S_2(t), \\forall t$$ ","date":"2022-01-06","objectID":"/01_survival_analysis/:4:0","tags":["생존분석"],"title":"[Algorithmic Marketing] 생존분석 기본개념","uri":"/01_survival_analysis/"},{"categories":["Algorithmic Marketing"],"content":"log-rank test 일관적인 차이를 검출한다. 여기서 일반적인이란 두 그룹의 survival curve를 그렸을 때, 서로 교차하지 않는 것을 의미한다. 교차하게 되면 검정할 수 없다. 시점별 다른 가중치를 고려할 수 있다. 세 집단 이상도 비교 가능하다. 디테일한 유도과정은 생략 (코드예시) ","date":"2022-01-06","objectID":"/01_survival_analysis/:4:1","tags":["생존분석"],"title":"[Algorithmic Marketing] 생존분석 기본개념","uri":"/01_survival_analysis/"},{"categories":["Algorithmic Marketing"],"content":"위험도함수(hazard function) $$h(t) = \\lim_{\\vartriangle t \\rightarrow 0} \\frac{P(t \u003c T \\le t + \\vartriangle t | T \u003e t)}{\\vartriangle t}$$ 특정 시점 $t$까지 살아남았을 때, 시간 단위당 순간 사건 발생률 조건부가 존재하기에 확률은 아니다. 왜 위험도함수가 필요할까? propotional hazards model의 기반이 된다. censored data로 인해 바로 접근하기 어렵기 때문에 새로운 개념인 위험도함수를 통해서 (생존함수도 마찬가지) 접근하면 문제를 더 쉽게 해결할 수 있기 때문이다. ","date":"2022-01-06","objectID":"/01_survival_analysis/:5:0","tags":["생존분석"],"title":"[Algorithmic Marketing] 생존분석 기본개념","uri":"/01_survival_analysis/"},{"categories":["Algorithmic Marketing"],"content":"생존분석에서 식들의 관계 $$h(t) = \\lim_{\\vartriangle t \\rightarrow 0} \\frac{P(t \u003c T \\le t + \\vartriangle t | T \u003e t)}{\\vartriangle t}$$ $$= \\lim_{\\vartriangle t \\rightarrow 0} \\frac{P( (t \u003c T \\le t + \\vartriangle t ) \\cap (T \u003e t))}{P(T \u003e t) \\vartriangle t}$$ $$=\\lim_{\\vartriangle t \\rightarrow 0} \\frac{P(t \u003c T \\le t + \\vartriangle t )/\\vartriangle t}{P(T \u003e t) }=\\frac{f(t)}{S(t)}$$ where $f(t) = \\lim_{\\vartriangle t \\rightarrow 0} \\frac{P(t \u003c T \\le t + \\vartriangle t )}{\\vartriangle t}$ : probability density function associated with $T$ ","date":"2022-01-06","objectID":"/01_survival_analysis/:6:0","tags":["생존분석"],"title":"[Algorithmic Marketing] 생존분석 기본개념","uri":"/01_survival_analysis/"},{"categories":["Algorithmic Marketing"],"content":"Proportional Hazards Model survival time을 여러 covariates로 모델링을 하고 싶은 경우 아래와 같이 hazard function의 형태를 가정하여 접근한다. (코드예시) $$h(t|x_i) = h_0 (t) \\exp (\\sum_{j=1}^p x_{ij}\\beta_j)$$ where $h_0(t) \\ge 0$ is an unspecified function (baseline hazard) functional form에 대한 가정이 없기 때문에 flexible하게 모델링 가능 물론 proportional한 가정자체가 이미 한계가 존재하는 것은 사실이다. 이외에도 survival forest와 같은 접근법도 존재한다. 위의 내용을 proportional hazard assumption 이라고 한다. ","date":"2022-01-06","objectID":"/01_survival_analysis/:7:0","tags":["생존분석"],"title":"[Algorithmic Marketing] 생존분석 기본개념","uri":"/01_survival_analysis/"},{"categories":["Algorithmic Marketing"],"content":"Partial Likelihood 그런데 baseline hazard의 형태를 모르기 때문에 parameter ($\\beta$)를 추정할 수 없다. 하지만 cox’s proportional hazards model에서는 가능하다. 아래의 과정을 보자. 가정 일단 이벤트가 발생한 시간이 no ties 를 가정한다. $\\delta_i = 1$, 따라서 $t_i = y_i$ total hazard at time $y_i$ for the at risk observations: $$\\sum_{i’ : y_{i’} \\ge y_i}h_0(y_i) \\exp (\\sum_{j=1}^p x_{i’j}\\beta_j)$$ the probability that the ith observation is the one to fail at time $y_i$: $$\\frac{h_0(y_i) \\exp (\\sum_{j=1}^p x_{ij}\\beta_j)}{\\sum_{i’ : y_{i’} \\ge y_i}h_0(y_i) \\exp (\\sum_{j=1}^p x_{i’j}\\beta_j)} = \\frac{ \\exp (\\sum_{j=1}^p x_{ij}\\beta_j)}{\\sum_{i’ : y_{i’} \\ge y_i} \\exp (\\sum_{j=1}^p x_{i’j}\\beta_j)}$$ 위의 식을 이용하여 $\\delta_i = 1$인 경우만 고려하여 partial likelihood를 구하면 $$PL(\\beta) = \\prod_{i:\\delta_i = 1} \\frac{ \\exp (\\sum_{j=1}^p x_{ij}\\beta_j)}{\\sum_{i’ : y_{i’} \\ge y_i} \\exp (\\sum_{j=1}^p x_{i’j}\\beta_j)}$$ logistic regression 처럼 iterative하게 parameter를 추정한다. $\\beta$를 추정하면 일반적인 회귀방법론들처럼 계수에 대한 p-value, confidence interval을 구할 수 있다. 맨처음 가정이 깨지는 경우 (당연히 깨지는 경우가 더 많다), 이를 해결하는 방법들이 있다. ","date":"2022-01-06","objectID":"/01_survival_analysis/:7:1","tags":["생존분석"],"title":"[Algorithmic Marketing] 생존분석 기본개념","uri":"/01_survival_analysis/"},{"categories":["Algorithmic Marketing"],"content":"Reference ISLR 2nd edition 연세대학교 응용통계학과 강상욱 교수님 특강자료 알고리즘 마케팅 ","date":"2022-01-06","objectID":"/01_survival_analysis/:8:0","tags":["생존분석"],"title":"[Algorithmic Marketing] 생존분석 기본개념","uri":"/01_survival_analysis/"},{"categories":["ML Engineering"],"content":"Git 기본적인 명령어 정리 ","date":"2021-12-20","objectID":"/03-git-basic/:0:0","tags":["Git"],"title":"[Git] 기본 내용 정리","uri":"/03-git-basic/"},{"categories":["ML Engineering"],"content":"기본 개념 \u0026 명령어 원격 저장소(Remote Repository): 원격 저장소 전용 서버 로컬 저장소(Local Repository): 내 PC에 파일이 저장되는 개인 전용 저장소 작업공간과 저장소 사이에 인덱스라는 가상의 공간이 있으며 commit하기 위해서는 그 공간에 파일을 stage 해야 한다. (git add) HEAD 브랜치가 여러 개 있을 때, HEAD로 브랜치나 커밋을 가리킨다. 브랜치는 커밋을 가리키므로 HEAD도 커밋을 가리킨다. 결국 HEAD는 현재 작업 중인 브랜치의 최근 커밋을 가리킨다. git reset [파일명] : unstage 시키는 명령어 git log -n\u003c숫자\u003e : 최신 n개의 커밋만 살펴본다. git log --oneline --graph --decorate --all : CLI환경에서 이력을 확인하기에 좋다. git remote add \u003c원격저장소 이름\u003e \u003c원격저장소 주소\u003e: 원격저장소를 등록 commit, push, pull ","date":"2021-12-20","objectID":"/03-git-basic/:1:0","tags":["Git"],"title":"[Git] 기본 내용 정리","uri":"/03-git-basic/"},{"categories":["ML Engineering"],"content":"브랜치 여러 명이서 동시에 작업을 할 때에 다른 사람의 작업에 영향을 주거나 받지 않도록, 먼저 메인 브랜치에서 자신의 작업 전용 브랜치를 만든다. 그리고 원하는 기능을 추가삭제한다. 나중에 병합(merge)하여서 하나로 합치기도 한다. git branch: 현재 브랜치 확인 git branch \u003c브랜치 이름\u003e: 브랜치 생성 git checkout \u003c브랜치 이름\u003e: 해당하는 브랜치로 체크아웃 근데 Git 2.23 부터 checkout을 대신해 switch, restore가 도입되었다. checkout의 기능들을 나누어서 가져갔다고 이해하면 된다. switch: switch branch restore: restore working tree files git restore \u003c파일\u003e: 파일의 수정 내용 복원 git restore --staged \u003c파일\u003e: stage에서 다시 빼내기 git merge \u003c브랜치 이름\u003e: 브랜치 병합 예시) bugfix라는 브랜치를 만들어서 업무를 진행한 뒤에 master 브랜치에 병합하고 싶다. 그러면 먼저 master 브랜치로 switch를 하고 병합명령어를 진행하면 된다. 그러면 master 브랜치가 가리키는 커밋이 bugfix 브랜치와 같아진다. 이를 fast-forward (빨리감기) 병합이라고 한다. 그런데 병합을 하려는데 master 브랜치에 그 사이에 변경사항이 존재한다면? 당연히 fast-forward가 불가능하다. 이런 경우 먼저 양쪽의 변경을 반영한 병합커밋(merge commit)을 만들고 병합해야한다. 이 경우에는 브랜치가 남겨지므로 작업 확인 및 관리에서 유용한 경우가 생길 수 있다. 물론 복잡해진다. (non fast-forward 병합) # bugfix 브랜치에서 기능수정 진행 # git switch master git merge bugfix # master에서 변경사항이 없으면 fast-forward 진행 git rebase \u003c브랜치 이름\u003e: 브랜치 rebase merge와는 조금 다른 rebase라는 방법도 있다. non fast-forward의 상황과 동일하지만 브랜치의 이력을 남기지 않고 master 브랜치 뒤에 bugfix를 놓고 (rebase) fast-forward 병합을 진행한다. rebase의 경우 충돌 부분을 수정 한 후에는 commit이 아니라 --continue 옵션으로 실행한다. # bugfix 브랜치에서 기능수정 진행 # git rebase master # bugfix 브랜치에서 진행 # 충돌 수정 # git add . git rebase --continue git reset --hard \u003c이동할 커밋 체크섬\u003e: 현재 브랜치를 지정한 커밋으로 옮긴다. 작업폴더의 내용도 함께 변경된다. 근데 ‘커밋 체크섬’을 사용하는게 쉽지는 않다. 이런 경우 HEAD~와 같이 이용한다. 여기서 HEAD~는 바로 헤드의 부모 커밋, HEAD~2는 할아버지 커밋을 의미한다. git branch -d \u003c브랜치 이름\u003e: 브랜치 삭제 ","date":"2021-12-20","objectID":"/03-git-basic/:2:0","tags":["Git"],"title":"[Git] 기본 내용 정리","uri":"/03-git-basic/"},{"categories":["ML Engineering"],"content":"원격저장소 pull: 원격 저장소에서 로컬로 pull하는 경우 충돌이 없으면 자동으로 병합커밋이 만들어 진다. 충돌이 있으면 수동으로 수정하고 커밋을 해야한다. fetch: 단순히 원격 저장소의 내용을 확인만 하고 로컬 데이터와 병합은 하고 싶지 않은 경우 사용한다. pull은 내부적으로 fetch + merge ","date":"2021-12-20","objectID":"/03-git-basic/:3:0","tags":["Git"],"title":"[Git] 기본 내용 정리","uri":"/03-git-basic/"},{"categories":["ML Engineering"],"content":"태그 (tag) 커밋을 참조하기 쉽도록 이름을 붙이는 것 일반태그, 주석태그 git tag \u003c태그이름\u003e 현재 HEAD가 가리키는 커밋에 태그가 붙는다. git tag -am \u003c태그설명\u003e \u003c태그이름\u003e: 해당 tag에 대한 설명 작성 git tag -d \u003c태그이름\u003e: tag 지우기 ","date":"2021-12-20","objectID":"/03-git-basic/:4:0","tags":["Git"],"title":"[Git] 기본 내용 정리","uri":"/03-git-basic/"},{"categories":["ML Engineering"],"content":"커밋 변경 git commit --amend -m \u003c커밋메세지\u003e: 이전에 작성한 커밋 수정하기 # 일단 commit을 한 상태 # 그 이후에 추가적으로 수정을 진행 git add . git commit --amend -m \"bugfix commit\" git revert HEAD: HEAD가 가르키는 해당 커밋을 지운다. 지운 이력이 남는다. git reset --hard HEAD~: 필요없어진 커밋 지우기 더 이상 필요 없어진 커밋들을 버릴 수 있다. 명령어 실행 시 어떤 모드로 실행할 지 지정하여 ‘HEAD’ 위치와 인덱스, 작업 트리 내용을 함께 되돌릴지 여부를 선택할 수 있다. 종류는 soft, mixed, hard 가 있다. git cherry-pick \u003c특정 커밋\u003e: 특정 커밋을 가져오고 싶을 때 사용 ","date":"2021-12-20","objectID":"/03-git-basic/:5:0","tags":["Git"],"title":"[Git] 기본 내용 정리","uri":"/03-git-basic/"},{"categories":["ML Engineering"],"content":"Reference 팀 개발을 위한 Git GitHub 시작하기 (한빛미디어) 누구나 쉽게 이해할 수 있는 Git 입문 ","date":"2021-12-20","objectID":"/03-git-basic/:6:0","tags":["Git"],"title":"[Git] 기본 내용 정리","uri":"/03-git-basic/"},{"categories":["Causality"],"content":"DID 방법론에 대해 알아보자. ","date":"2021-12-03","objectID":"/causal09/:0:0","tags":["DID"],"title":"[인과추론] Difference-in-Difference","uri":"/causal09/"},{"categories":["Causality"],"content":"ATT 이전에 ATE를 위해 가정했던 것과는 다르게 $$Y(0) \\perp T$$ 이것만 가정하면 (ATE보다 약한 가정) 우리는 average treatment effect on the treated (ATT)를 구할 수 있다. ATT $$E[Y(1)-Y(0)|T=1]$$ $$E[Y(1)-Y(0)|T=1] = E[Y(1)|T=1] - E[Y(0)|T=1] \\\\ = E[Y|T=1] - E[Y(0)|T=1] \\\\ = E[Y|T=1] - E[Y(0)|T=0] \\\\ = E[Y|T=1] - E[Y|T=0]$$ ","date":"2021-12-03","objectID":"/causal09/:1:0","tags":["DID"],"title":"[인과추론] Difference-in-Difference","uri":"/causal09/"},{"categories":["Causality"],"content":"Introducing Time 지금부터는 time(시간)을 추가해서 고민해보자. 지금까지 동일하게 treatment, control group이 있다. 특정 시간 이후에 treatment group에게만 treatment가 행해진다. 특정 시간 ($\\tau$)에서 treatment $t$가 행해진 potential outcome을 나타나는 random variable은 $Y_{\\tau}(t)$로 표시하자. 시간을 고려하면서 우리가 알고 싶은 것은 treatment group에 treatment가 적용된 causal estimand이다 : $$E[Y_1 (1) - Y_1 (0) | T=1]$$ 이제 이 값을 identification하고 estimation하는 방법까지 알아보자. ","date":"2021-12-03","objectID":"/causal09/:2:0","tags":["DID"],"title":"[인과추론] Difference-in-Difference","uri":"/causal09/"},{"categories":["Causality"],"content":"Identification ","date":"2021-12-03","objectID":"/causal09/:3:0","tags":["DID"],"title":"[인과추론] Difference-in-Difference","uri":"/causal09/"},{"categories":["Causality"],"content":"Assumptions Consistency (extended to Time) $$\\forall \\tau , ; T=t \\Rightarrow Y_{\\tau} = Y_{\\tau}(t)$$ consistency 가정으로 causal estimand $E[T_{\\tau}(1)|T=1]$와 statistical estimand $E[T_{\\tau}|T=1]$가 같다고 할 수 있다. Parallel Trends treatment group이 treatment를 받지 않았을 때, 시간에 따른 trend가 control group과 같다 해당하는 assumption이 있어야 treat를 받지 않은 treatment의 값(counterfactual)을 알 수 있다. $$E[Y_1 (0) - Y_0 (0) | T=1] = E[Y_1 (0) - Y_0 (0)|T=0]$$ $$(Y_1(0) - Y_0(0)) \\perp T$$ No Pretreatment Effect treatment가 이행되기 전에는 treatment group에 영향을 주지 않는다 $$E[Y_0 (1) - Y_0 (0) | T=1] = 0$$ ","date":"2021-12-03","objectID":"/causal09/:3:1","tags":["DID"],"title":"[인과추론] Difference-in-Difference","uri":"/causal09/"},{"categories":["Causality"],"content":"Result and Proof DID identification Given consistency, parallel trends, and no pretreatment effect, we have the following: $$E[Y_1 (1) - Y_1 (0) | T=1] \\\\ = (E[Y_1|T=1]-E[Y_0 | T=1]) - (E[Y_1|T=0] - E[Y_0|T=0])$$ (proof) $$E[Y_1 (1) - Y_1 (0) | T=1] = E[Y_1 (1) | T=1] - E[Y_1 (0) | T=1] \\\\ =E[Y_1 | T=1] - E[Y_1 (0) | T=1] \\; \\text{(consistency)}$$ 위의 식에서 두 번째 항 $E[Y_1 (0) | T=1]$은 counterfactual이고 이를 알 수 없지만 parallel trends assumption으로 구할 수 있다. $$E[Y_1 (0) | T=1] = E[Y_0 (0) | T=1] + E[Y_1 (0)|T=0] - E[Y_0 (0) | T=0]$$ consistency를 이용하면 $$= E[Y_0 (0) | T=1] + E[Y_1 |T=0] - E[Y_0 | T=0] $$ 그런데 정리한 식에서도 counterfactual이 존재한다. 이제 pretreatment effect assumption을 이용하면 $$=E[Y_0 (1) | T=1] + E[Y_1 |T=0] - E[Y_0 | T=0]$$ 다시 consistency를 이용하면 $$=E[Y_0 | T=1] + E[Y_1 |T=0] - E[Y_0 | T=0]$$ 드디어 $E[Y_1 (0) | T=1]$를 identify했다. 이제 식을 정리하면 최종 결과가 나온다. ","date":"2021-12-03","objectID":"/causal09/:3:2","tags":["DID"],"title":"[인과추론] Difference-in-Difference","uri":"/causal09/"},{"categories":["Causality"],"content":"Problem parallel trends assumption이 깨질 수 있다. confounder때문이라면 controlled parallel trends assumption으로 어느 정도 해결 할 수 있다. Controlled Parallel Trends $$E[Y_1(0) - Y_0(0)|T=1,W] = E[Y_1(0)-Y_0(0)|T=0,W]$$ 그런데 만약 시간과 treatment 사이에 interaction이 있다면 parallel trends를 기대하기 어렵다. 또한 parallel trends assumption은 scale-specific하다. parallel trends가 성립해도 $Y$를 변환시킨다면 trends가 유지된다고 할 수 없다는 의미이다. (parallel trends assumptions isn’t nonparametric) ","date":"2021-12-03","objectID":"/causal09/:4:0","tags":["DID"],"title":"[인과추론] Difference-in-Difference","uri":"/causal09/"},{"categories":["Causality"],"content":"Reference Brady Neal - Causal Inference ","date":"2021-12-03","objectID":"/causal09/:5:0","tags":["DID"],"title":"[인과추론] Difference-in-Difference","uri":"/causal09/"},{"categories":["Causality"],"content":"unobserved confounding이 있는 경우는 어떻게 할까? 이전 chapter에서도 알아봤지만 여기서는 instrumental vairable $Z$을 이용하고자 한다. $Z$는 3가지 특징이 있다. Relevance: treatment $T$에 영향을 준다. Exclusion Restriction: $T$를 통해서만 $Y$에 영향을 준다. (fully mediated by $T$) Instrumental Unconfoundedness: $Y$와 $Z$는 unconfounded하다. (no unblockable backddor paths to $Y$) observed variables에 대해 conditioning하고 unconfoundedness가 성립한면 conditional instruments라고도 하며 3번째 가정의 weaker version이다. 또한 $Z$를 사용하여 causal effect를 identify하기 위해서는 parametric form을 가정해야 한다. Unobserved confounder $U$가 있다고 가정하기 때문에 (backdoor path cannot be blocked) nonparametric identification를 할 수 없다. ","date":"2021-12-03","objectID":"/causal08/:0:0","tags":["Instrumental Variables"],"title":"[인과추론] Instrumental Variables","uri":"/causal08/"},{"categories":["Causality"],"content":"Linear Setting 일단 outcome에 대해 Linear assumption을 해보자. 먼저 outcome이 binary인 경우를 알아보자. $$Y := \\delta T + \\alpha_u U$$ $$E[Y|Z=1] - E[Y|Z=0] \\\\ = E[\\delta T + \\alpha_u U | Z=1] - E[\\delta T + \\alpha_u U | Z = 0] \\; \\text{Exclusion Restriction} \\\\ = \\delta (E[T|Z=1]-E[T|Z=0]) + \\alpha_u (E[U|Z=1]-E[U|Z=0]) \\\\ = \\delta (E[T|Z=1]-E[T|Z=0]) + \\alpha_u (E[U] - E[U])\\;\\text{instrumental unconfoundedness} \\\\ =\\delta(E[T|Z=1] - E[T|Z=0])$$ $$\\therefore \\delta = \\frac{E[Y|Z=1] - E[Y|Z=0]}{E[T|Z=1] - E[T|Z=0]}$$ 위의 분모는 Relevance assumption으로 0이 아니라고 가정한다. $\\delta$를 나타내는 값을 Wald estimand라고 하고 이에 대한 Wald estimator는 $$\\hat{\\delta} = \\frac{\\frac{1}{n_1}\\sum_{i:z_i = 1}Y_i - \\frac{1}{n_0}\\sum_{i:z_i = 0}Y_i}{\\frac{1}{n_1}\\sum_{i:z_i = 1}T_i - \\frac{1}{n_0}\\sum_{i:z_i = 0}T_i}$$ 이번에는 $T,Z$가 continuous인 경우를 살펴보자. outcome에 대한 Linear assumption은 동일하다. $$Cov(Y,Z) = E[YZ] - E[Y]E[Z] \\\\ = E[(\\delta T + \\alpha_u U)Z] - E[\\delta T + \\alpha_u U]E[Z] \\\\ = \\delta E[TZ] + \\alpha_u E[UZ] - \\delta E[T]E[Z] - \\alpha_u E[U]E[Z] \\\\ = \\delta (E[TZ] - E[T]E[Z]) + \\alpha_u (E[UZ] - E[U]E[Z]) \\\\ = \\delta Cov(T,Z) + \\alpha_u Cov(U,Z) \\\\ = \\delta Cov(T,Z)$$ $$\\therefore \\delta = \\frac{Cov(Y,Z)}{Cov(T,Z)}$$ $$\\hat{\\delta} = \\frac{\\hat{Cov(Y,Z)}}{\\hat{Cov(T,Z)}}$$ ","date":"2021-12-03","objectID":"/causal08/:1:0","tags":["Instrumental Variables"],"title":"[인과추론] Instrumental Variables","uri":"/causal08/"},{"categories":["Causality"],"content":"Two-Stage Least Squares Estimator 여기 추가적으로 Two-Stage Least Squares Estimator를 알아보자. (binary, continuous 다 된다) $\\hat{T}$를 사용하기 때문에 $U$가 없어진다고 이해할 수 있다. Linearly regress $T$ on $Z$ to estimate $E[T|Z]$ Linearly regress $Y$ on $\\hat{T}$ to estimate $E[Y|\\hat{T}]$ Obtain out estimate $\\hat{\\delta}$ as the fitted coefficient in front of $\\hat{T}$ ","date":"2021-12-03","objectID":"/causal08/:1:1","tags":["Instrumental Variables"],"title":"[인과추론] Instrumental Variables","uri":"/causal08/"},{"categories":["Causality"],"content":"Nonparametric Identification of Local ATE linear assumption은 간단하면서 강력하다. 다만 동시에 제한적이기도 하다. 그렇다면 linear assumption말고 nonparametric하게 할 수 있을까? Yes! Binary의 경우를 예시로 이해해보자. $Z=1$인 경우, treatment가 일어나도록 한다면 이를 $T(1)=T(Z=1)$로 표시할 수 있다. 반대의 경우도 당연히 된다. 물론 항상 $Z=1$이 $T(1)=1$을 만드는 것은 아니다. 이 때 총 4가지 경우의 수를 생각할 수 있다. Principal Strata Compliers : $T(1)=1,T(0)=0$ Defiers : $T(1)=0,T(0)=1$ Always-takers : $T(1)=1,T(0)=1$ Never-takers : $T(1)=0,T(0)=0$ Always, Never-takers는 $Z$에서 $T$로 향하는 edge가 없다. (no causality) 그런데 우리는 $Z$를 사용할 때, 이 4가지 경우에서 어떤 경우에 해당하는지 알 수도 있다. Observational data이라 potential outcome이 없기에 identification을 할 수 없다는 것이다. 이를 위해서는 추가적인 가정이 필요할 것으로 보인다. 아래에서 알아보자. ","date":"2021-12-03","objectID":"/causal08/:2:0","tags":["Instrumental Variables"],"title":"[인과추론] Instrumental Variables","uri":"/causal08/"},{"categories":["Causality"],"content":"Local ATE unobserved confounder때문에 ATE를 nonparametrically identity하기는 어렵지만 대신 local ATE를 구할 수 있다. Local Average Treatment Effect (LATE) or Complier average causal effect (CACE) $$E[Y(T=1) - Y(T=0) | T(Z=1)=1, T(Z=0)=0] $$ $$= \\frac{E[Y|Z=1] - E[Y|Z=0]}{E[T|Z=1] - E[T|Z=0]}$$ 위의 LATE가 어떻게 정의되었는지, identify하기 위해서는 어떤 과정이 필요한지 알아보자. 위의 식이 성립하기 위해서는 linearity assumption이 아닌 monotonicity assumption이 필요하다. Monotonicity Assumption (No Defiers) $$\\forall i, T_i (Z=1) \\ge T_i (Z=0)$$ Monotonicity가 의미하는 것은 $Z=1$이 treatment가 발생하도록 encourage하다고 이해 할 수 있다. 그렇게 되면 defiers는 사라지게 된다. 이제 LATE nonparametric identification을 알아보자. LATE nonparametric identification $$E[Y(1) - Y(0) | T(1)=1, T(0)=0] = \\frac{E[Y|Z=1] - E[Y|Z=0]}{E[T|Z=1] - E[T|Z=0]}$$ proof) $$E[Y(Z=1) - Y(Z=0)] = \\\\ E[Y(Z=1)-Y(Z=0)|T(1)=1,T(0)=0]P(T(1)=1,T(0)=0) \\\\ +E[Y(Z=1)-Y(Z=0)|T(1)=0,T(0)=1]P(T(1)=0,T(0)=1) \\\\ + E[Y(Z=1)-Y(Z=0)|T(1)=1,T(0)=1]P(T(1)=1,T(0)=1) \\\\ +E[Y(Z=1)-Y(Z=0)|T(1)=0,T(0)=0]P(T(1)=0,T(0)=0)$$ 여기서 defier가 일어날 확률이 0이므로 없어진다. always, never-takers 또한 $E$부분이 0이 된다. $$\\therefore E[Y(Z=1) - Y(Z=0)] \\\\ = E[Y(Z=1)-Y(Z=0)|T(1)=1,T(0)=0]P(T(1)=1,T(0)=0)$$ 이제 이를 정리하면 $$E[Y(Z=1)-Y(Z=0)|T(1)=1,T(0)=0] \\\\ = \\frac{E[Y(Z=1) - Y(Z=0)]}{P(T(1)=1,T(0)=0)}$$ 위의 식에서 분자는 instrumental unconfoundedness assumption으로 인해 $E[Y|Z=1] - E[Y|Z=0]$이 된다. 분모는 compliers의 확률이므로 1에서 compliers가 아닐 확률을 빼서 진행하자. 이때 monotonicity로 인해 defier의 확률은 0이고 always, never-takers의 확률은 각각 $P(T=1|Z=0),P(T=0|Z=1)$이 된다. (defier가 없기 때문에) $$P(T(1)=1,T(0)=0) \\\\ = 1 - P(T=0|Z=1) - P(T=1|Z=0) \\\\ = 1 - (1- P(T=1|Z=1)) - P(T=1|Z=0) \\\\ = P(T=1|Z=1)-P(T=1|Z=0) \\\\ = E[T|Z=1] - E[T|Z=0]$$ linearity assumption에서 구한 결과와 같다. 두 가지 가정 모두 우리에게 Wald estimand를 구할 수 있게 해주었다. nonparametric하게 ATE는 못구해도 monotonicity가정으로 LATE는 구할 수 있음을 알게 되었다. 다만 monotonicity가 만족한다는 보장은 없는 한계도 존재한다. 또한 LATE의 경우, 이는 ATE는 아니기 때문에 (whole population이 아닌 compliers만) 우리가 주로 원하는 값은 아니다. ","date":"2021-12-03","objectID":"/causal08/:2:1","tags":["Instrumental Variables"],"title":"[인과추론] Instrumental Variables","uri":"/causal08/"},{"categories":["Causality"],"content":"More General Settings for the ATE ","date":"2021-12-03","objectID":"/causal08/:3:0","tags":["Instrumental Variables"],"title":"[인과추론] Instrumental Variables","uri":"/causal08/"},{"categories":["Causality"],"content":"Nonparametric Outcome with Additive Noise $$Y:=f(T,W)+U$$ noise term을 추가해서 접근한다. 최신 논문에서 $f$를 deep learning으로 구한 경우도 있다. (Hartford et al. (2017), Xu et al. (2020)) ","date":"2021-12-03","objectID":"/causal08/:3:1","tags":["Instrumental Variables"],"title":"[인과추론] Instrumental Variables","uri":"/causal08/"},{"categories":["Causality"],"content":"Set Identification of ATE point가 아니라 구간으로 ATE를 구하는 것이다. (Pearl’s 책 8장) additive noise assumption을 이용하기도 한다. (Kilbertus et al. (2020)) ","date":"2021-12-03","objectID":"/causal08/:3:2","tags":["Instrumental Variables"],"title":"[인과추론] Instrumental Variables","uri":"/causal08/"},{"categories":["Causality"],"content":"Reference Brady Neal - Causal Inference ","date":"2021-12-03","objectID":"/causal08/:4:0","tags":["Instrumental Variables"],"title":"[인과추론] Instrumental Variables","uri":"/causal08/"},{"categories":["Causality"],"content":"No unobserved confounding은 솔직히 비현실적이다. 이 때 사용하는 좀 더 robust한 방법 nonparametric bounds sensitivity analysis ","date":"2021-12-03","objectID":"/causal07/:0:0","tags":["Unobserved Confounding","Bounds","Unobserved Confounding"],"title":"[인과추론] Unobserved Confounding, Bounds, and Unobserved Confounding","uri":"/causal07/"},{"categories":["Causality"],"content":"Bounds unconfoundendness 가정을 좀 약하게 하면? point($E[Y(1)-Y(0)]$)가 아니라 interval(set identification)로 생각하는 것이다. 일반적으로 potential outcome은 bounded! 그래서 ITE, ATE도 아래와 같은 bound를 갖고 있다. $$a \\le Y(t) \\le b$$ $$a-b \\le E[Y(1)-Y(0)] \\le b-a$$ 이제 Bound를 정의하는 다양한 방법을 알아보자. 이 방법에 따라 interval의 length도 달라질 것이다. 우리는 interval의 크기가 작은게 좋다. 그리고 위에서 가장 basic한 접근법으로 interval의 length는 $2(b-a)$이다. 이를 기억하자. ","date":"2021-12-03","objectID":"/causal07/:1:0","tags":["Unobserved Confounding","Bounds","Unobserved Confounding"],"title":"[인과추론] Unobserved Confounding, Bounds, and Unobserved Confounding","uri":"/causal07/"},{"categories":["Causality"],"content":"No-Assumptions Bound 먼저 ATE를 decomposition해보자. $$E[Y(1) - Y(0)] = E[Y(1)] - E[Y(0)] $$ $$= P(T=1)E[Y(1)|T=1] + P(T=0)E[Y(1)|T=0] \\\\ - (P(T=1)E[Y(0)|T=1] + P(T=0)E[Y(0)|T=0])$$ $$= P(T=1)E[Y|T=1] + P(T=0)E[Y(1)|T=0] \\\\ - (P(T=1)E[Y(0)|T=1] + P(T=0)E[Y|T=0])$$ 이를 Observational-Counterfactual Decomposition이라고 한다. 하지만 $E[Y(1)|T=0],E[Y(0)|T=1]$은 counterfactual이라 우리가 알 수 없다. 대신에 interval을 구할 수 있지 않을까? No-Assumptions Bound $\\pi$가 $P(T=1)$라고 하고 $T$가 binary random variable이라고 하자. outcome $Y$가 $[a,b]$ 사이의 값을 가지면 $$E[Y(1)-Y(0)] \\le \\pi E[Y|T=1] + (1-\\pi)b - \\pi a - (1-\\pi)E[Y|T=0] \\\\ E[Y(1)-Y(0)] \\ge \\pi E[Y|T=1] + (1-\\pi)a - \\pi b - (1-\\pi)E[Y|T=0]$$ 이때 interval의 length는 $b-a$ 이다. 별다른 가정도 없었는데 (consistency assumption은 필요) length가 절반으로 줄었다. Example outcome $Y$가 $[-1,1]$ $\\pi = 0.3$ $E[Y|T=1]=0.9,;E[Y|T=0]=0.2$ No-Assumptions Bound에 따르면 $$-0.17 \\le E[Y(1)-Y(0)] \\le 0.83$$ ","date":"2021-12-03","objectID":"/causal07/:1:1","tags":["Unobserved Confounding","Bounds","Unobserved Confounding"],"title":"[인과추론] Unobserved Confounding, Bounds, and Unobserved Confounding","uri":"/causal07/"},{"categories":["Causality"],"content":"Monotone Treatment Response assume always $Y_i (1) \\ge Y_i (0)$ 반대의 가정도 있다 : Nonpositive MTR $Y_i (1) \\le Y_i (0)$ Example outcome $Y$가 $[-1,1]$ $\\pi = 0.3$ $E[Y|T=1]=0.9,;E[Y|T=0]=0.2$ nonnegative MTR에 따르면 $$0 \\le E[Y(1)-Y(0)] \\le 0.83$$ ","date":"2021-12-03","objectID":"/causal07/:1:2","tags":["Unobserved Confounding","Bounds","Unobserved Confounding"],"title":"[인과추론] Unobserved Confounding, Bounds, and Unobserved Confounding","uri":"/causal07/"},{"categories":["Causality"],"content":"Monotone Treatment Selection Treatment groups’ potential outcomes are better than control groups' $$E[Y(1)|T=1] \\ge E[Y(1)|T=0] \\ E[Y(0)|T=1] \\ge E[Y(0)|T=0]$$ $$\\therefore E[Y(1)-Y(0)] \\le E[Y|T=1] - E[Y|T=0]$$ Example outcome $Y$가 $[-1,1]$ $\\pi = 0.3$ $E[Y|T=1]=0.9,;E[Y|T=0]=0.2$ MTS에 따르면 $$-0.17 \\le E[Y(1)-Y(0)] \\le 0.7$$ ","date":"2021-12-03","objectID":"/causal07/:1:3","tags":["Unobserved Confounding","Bounds","Unobserved Confounding"],"title":"[인과추론] Unobserved Confounding, Bounds, and Unobserved Confounding","uri":"/causal07/"},{"categories":["Causality"],"content":"Optimal Treatment Selection Assumption individuals always receive the treatment that is best for them: $$T_i = 1 \\rightarrow Y_i (1) \\ge Y_i (0) \\ T_i = 0 \\rightarrow Y_i (0) \\ge Y_i (1)$$ $$\\therefore E[Y(1)-Y(0)] \\le \\pi E[Y|T=1] - \\pi a$$ $$\\therefore E[Y(1)-Y(0)] \\ge (1 - \\pi)a - (1 - \\pi)E[Y|T=0] - a$$ Example outcome $Y$가 $[-1,1]$ $\\pi = 0.3$ $E[Y|T=1]=0.9,;E[Y|T=0]=0.2$ nonnegative MTR에 따르면 $$-0.14 \\le E[Y(1)-Y(0)] \\le 0.27$$ ","date":"2021-12-03","objectID":"/causal07/:1:4","tags":["Unobserved Confounding","Bounds","Unobserved Confounding"],"title":"[인과추론] Unobserved Confounding, Bounds, and Unobserved Confounding","uri":"/causal07/"},{"categories":["Causality"],"content":"Sensitivity Analysis confounder가 $W$뿐만 아니라 unobserved confounder $U$가 있다고 가정해보자. 그러면 confounding bias가 발생한다. 이와 관련해서 분석하는 것이 sensitivity analysis라고 할 수 있다. 우리가 구한 ATE에 대해 validataion하는 것이다. ","date":"2021-12-03","objectID":"/causal07/:2:0","tags":["Unobserved Confounding","Bounds","Unobserved Confounding"],"title":"[인과추론] Unobserved Confounding, Bounds, and Unobserved Confounding","uri":"/causal07/"},{"categories":["Causality"],"content":"Linear Single Confounder 먼저, noiseless linear data generating process를 가정해보자. $$T:=\\alpha_w W + \\alpha_u U \\ Y := \\beta_w W + \\beta_u U + \\delta T$$ 여기서 $W,U$ 모두를 알고 있으면 ATE는 $$E[Y(1)-Y(0)] = E_{W,U}[E[Y|T=1,W,U]-E[Y|T=0,W,U]]=\\delta$$ 이제 bias를 계산해보자. $$E_W [E[Y|T=t,W]] = E_W [E[\\beta_w W + \\beta_u U + \\delta T|T=t,W]] \\\\ =E_W [\\beta_w W + \\beta_u E[U|T=t,W]+\\delta t]\\\\ =E_W [\\beta_w W + \\beta_u (\\frac{t-\\alpha_w W}{\\alpha_u}) + \\delta t] \\\\ = E_W [\\beta_w W + \\frac{\\beta_u}{\\alpha_u}t - \\frac{\\beta_u \\alpha_w}{\\alpha_u}W + \\delta t] \\\\ = \\beta_w E[W] + \\frac{\\beta_u}{\\alpha_u}t - \\frac{\\beta_u \\alpha_w}{\\alpha_u}E[W] + \\delta t$$ 따라서 ATE estimate는 $$E_W [E[Y|T=1,W]-E[Y|T=0,W]]=\\delta + \\frac{\\beta_u}{\\alpha_u}$$ 따라서 bias $\\frac{\\beta_u}{\\alpha_u}$가 발생한다. ","date":"2021-12-03","objectID":"/causal07/:2:1","tags":["Unobserved Confounding","Bounds","Unobserved Confounding"],"title":"[인과추론] Unobserved Confounding, Bounds, and Unobserved Confounding","uri":"/causal07/"},{"categories":["Causality"],"content":"Towards More General Settings 이와 관련해서 다양한 논문들이 존재한다. 이들에 대해 간단히 알아보자. Binary Treatment Rosenbaum \u0026 Rubin (1983), Imbens (2003) simple parametric form for $Y$, $T$ $U$ : binary, scalar $$P(T=1|W,U) = sigmoid(\\alpha_w W + \\alpha_u U)$$ $$Y = \\beta_w W + \\beta_u U + \\delta T + Noise$$ 그런데 최근에 Cinelli \u0026 Hazlett (2020)에서 위를 더 발전시켰다고 한다. Making Sense of Sensitivity: Extending Omitted Variable Bias (Cinelli \u0026 Hazlett 2020) no parametric form for structural equation for $T$ Allows for multiple confounders (can be a vector) No assumed distribution on $U$ Sense and Sensitivity Analysis (Veitch \u0026 Zaveri 2020) Both the treatment mechanism and the outcome mechanism can be modeled with arbitrary machine learning models, and we still get a closed-form expression for the bias 강의 마지막 부분에 논문을 추천해준다. 나중에 필요하면 참고하자. ","date":"2021-12-03","objectID":"/causal07/:2:2","tags":["Unobserved Confounding","Bounds","Unobserved Confounding"],"title":"[인과추론] Unobserved Confounding, Bounds, and Unobserved Confounding","uri":"/causal07/"},{"categories":["Causality"],"content":"Reference Brady Neal - Causal Inference ","date":"2021-12-03","objectID":"/causal07/:3:0","tags":["Unobserved Confounding","Bounds","Unobserved Confounding"],"title":"[인과추론] Unobserved Confounding, Bounds, and Unobserved Confounding","uri":"/causal07/"},{"categories":["Causality"],"content":"causality를 estimate하는 방법을 알아보자. ","date":"2021-12-03","objectID":"/causal06/:0:0","tags":["Estimation"],"title":"[인과추론] Estimation","uri":"/causal06/"},{"categories":["Causality"],"content":"Conditional Outcome Modeling (COM) $$\\tau = E[Y(1) - Y(0)]=E_W [E[Y|T=1,W]-E[Y|T=0,W]]$$ 좌항은 causal estimand이고 우항은 statistical estimand이다. 이제 이를 estimate값을 구하는 과정을 알아보자. 가장 직관적인 방법은 conditional expectation $E[Y|T,W]$을 statistical(or ML) model로 구하는 것이다. 그리고 이를 $n$개의 data가 있다고 하면 empirical mean을 구하면 우리가 원하는 값을 얻을 수 있다. 편의를 위해 아래의 notation을 사용하자. $$\\mu(1,w) - \\mu(0,w) = E[Y|T=1,W]-E[Y|T=0,W]$$ 우리는 $\\mu$를 approximation하기 위해 모델링을 할 것이고 우리가 구한 모델을 $\\hat{\\mu}$라고 한다. 이 모델을 conditional outcome model이라고 한다. 이를 이용하여 ATE에 대한 model-assisted estimator를 아래와 같이 구할 수 있다. $$\\therefore \\hat{\\tau} = \\frac{1}{n}\\sum_i [\\hat{\\mu}(1,w_i)-\\hat{\\mu}(0,w_i)]$$ 이런 estimator를 COM estimator라고 부른다. CATE estimation에서 $\\mu$는 아래와 같고 $$\\mu(t,w,x) = E[Y|T=t, W=w, X=x]$$ 이를 통해 COM estimator for the CATE $\\tau(x)$는 $$\\hat{\\tau}(x) = \\frac{1}{n_x}\\sum_{i:x_i=x} [\\hat{\\mu}(1,w_i,x)-\\hat{\\mu}(0,w_i,x)]$$ 여기서 $n_x$는 $x_i = x$인 data의 갯수를 의미한다. ","date":"2021-12-03","objectID":"/causal06/:1:0","tags":["Estimation"],"title":"[인과추론] Estimation","uri":"/causal06/"},{"categories":["Causality"],"content":"COM estimation’s many faces G-computation estimators Parametric G-formula Standardization S-learner (S us for Single) ","date":"2021-12-03","objectID":"/causal06/:1:1","tags":["Estimation"],"title":"[인과추론] Estimation","uri":"/causal06/"},{"categories":["Causality"],"content":"Problem with COM estimation in high dimensions 예를 들어 COM estimator를 구하기 위해 모델링을 한다고 가정해보자. $T$의 경우 1차원, $W$의 경우는 고차원인 경우가 발생할 것이다. 이를 Neural net에 넣는다고하면 $T$의 effect는 무시당할 확률이 크다. 따라서 ATE estimate는 0으로 가게되는 것이다. 이외에도 COM estimator가 zero biased된다는 논문도 있다. ","date":"2021-12-03","objectID":"/causal06/:1:2","tags":["Estimation"],"title":"[인과추론] Estimation","uri":"/causal06/"},{"categories":["Causality"],"content":"Grouped Conditional Outcome Modeling (GCOM) 위에서 COM estimator의 문제를 알아보았다. 그렇다면 어떻게 모델이 $T$를 무시하지 못하게 할 수 있을까? 아래와 같은 모델 두 개를 만들면 된다. $$\\mu_1 (w) = E[Y|T=1,W=w],;\\mu_0 (w) = E[Y|T=0,W=w]$$ $T$에 따라 그룹을 나누어서 모델을 훈련시키는 것이다. 이렇게 얻어진 estimator를 grouped conditional outcome model estimators라고 한다. $$\\hat{\\tau} = \\frac{1}{n}\\sum_i [\\hat{\\mu}_1(w_i)-\\hat{\\mu}_0(w_i)]$$ CATE를 위한 GCOM estimator는 $$\\hat{\\tau}(x) = \\frac{1}{n_x}\\sum_{i:x_i=x} [\\hat{\\mu}_1(w_i,x)-\\hat{\\mu}_0(w_i,x)]$$ GCOM estimation을 통해 COM estimation에서 발생하는 zero treatment effect를 방지할 수 있다. 하지만 이 또한 데이터를 나누어서 모델링을 해야하는 단점이 존재한다. 효율적이지도 않고 variance가 높아질 수 있다. 물론 이를 보완하기 위한 모델링 방법도 존재한다. ","date":"2021-12-03","objectID":"/causal06/:2:0","tags":["Estimation"],"title":"[인과추론] Estimation","uri":"/causal06/"},{"categories":["Causality"],"content":"Increasing Data Efficiency ","date":"2021-12-03","objectID":"/causal06/:3:0","tags":["Estimation"],"title":"[인과추론] Estimation","uri":"/causal06/"},{"categories":["Causality"],"content":"TARNet ","date":"2021-12-03","objectID":"/causal06/:3:1","tags":["Estimation"],"title":"[인과추론] Estimation","uri":"/causal06/"},{"categories":["Causality"],"content":"X-Learner Estimate $\\hat{\\mu}_1(x)$ and $\\hat{\\mu}_0(x)$ Impute ITEs Treatment group: $\\hat{\\tau}_{1,i}=Y_i(1) - \\hat{\\mu}_0 (x_i)$ Control group: $\\hat{\\tau}_{0,i}=\\hat{\\mu}_1 (x_i) - Y_i(0)$ Fit a model $\\hat{\\tau}_1 (x)$ to predict $\\hat{\\tau} _ {1,i}$ from $x_i$ in treatment group and Fit a model $\\hat{\\tau}_0(x)$ to predict $\\hat{\\tau} _ {0,i}$ from $x_i$ in control group. $\\hat{\\tau}(x) = g(x)\\hat{\\tau}_0(x) + (1-g(x))\\hat{\\tau}_1(x)$ where $g(x)$ is some weighting function (ex; propensity score) ","date":"2021-12-03","objectID":"/causal06/:3:2","tags":["Estimation"],"title":"[인과추론] Estimation","uri":"/causal06/"},{"categories":["Causality"],"content":"Propensity Scores vector of variables $W$가 backdoor critetion을 만족한다고 하자. 그러면 $W$를 conditioning하여 causality를 파악하려고 할 것이다. 그러데 $W$가 고차원이면 이를 계산하기가 까다로워진다. 이를 해결하기 위한 것이 propensity score $e(w)$이다. $$e(w) = P(T=1|W=w)$$ $e(w)$는 scalar이므로 상당히 계산이 간단해진다. Propensity Score Theorem Given positivity, unconfoundedness given $W$ implies unconfoundedness given the propensity score $e(W)$ $$(Y(1),Y(0))\\perp T | W \\Rightarrow (Y(1),Y(0))\\perp T | e(W)$$ 이는 수학적으로 증명되있기도 하다. graphical하게 이해해도 된다. 그렇다면 $e(W)$는 어떻게 구할까? logistic regression같은 모델을 이용하여 $T$를 target, $W$는 input으로 놓고 모델링을 하면 된다. ","date":"2021-12-03","objectID":"/causal06/:4:0","tags":["Estimation"],"title":"[인과추론] Estimation","uri":"/causal06/"},{"categories":["Causality"],"content":"Inverse Probability Weighting (IPW) confounder $W$에서 $T$로 가는 edge를 없애는 것이 우리가 하고 싶은 일이다. 이를 가중치를 통해 해결하는 것이 IPW방법론이다. $T=1$인 경우, $1/e(W)$의 가중치를 곱하고 continuous의 경우에는 $1/P(T|W)$를 곱한다. 따라서 $$E[Y(t)] = E[\\frac{1(T=t)Y}{P(t|W)}]$$ $$\\tau = E[Y(1)-Y(0)] = E[\\frac{1(T=1)Y}{e(w)}] - E[\\frac{1(T=0)Y}{1-e(w)}]$$ (proof) $$E[Y(t)] = E[E[Y|t, W]] \\; \\text{(given unconfoundedness and positivity)} $$ $$ = \\sum_w \\sum_y y P(y|t,w)P(w) \\\\ = \\sum_w \\sum_y y P(y|t,w)P(w) \\frac{P(t|w)}{P(t|w)} \\\\ = \\sum_w \\sum_y y P(y,t,w)\\frac{1}{P(t|w)} \\\\ = \\sum_w E[1(T=t,W=w)Y]\\frac{1}{P(t|w)} \\\\ = E[\\frac{1(T=t)Y}{P(t|W)}]$$ ","date":"2021-12-03","objectID":"/causal06/:5:0","tags":["Estimation"],"title":"[인과추론] Estimation","uri":"/causal06/"},{"categories":["Causality"],"content":"Other Methods Doubly Robust Method Using both conditional outcome model and propensity score Consistent if either $\\hat{\\mu}(t,w)$ or $\\hat{e}(w)$ is consistent Theoretically converge to the estimand at a faster rate than COM/IPW Match treat와 control 그룹 간에 비슷한 객체들을 찾는 방법 Double Machine Learning stage1 Fit a model to predict $Y$ from $W$ to get the predicted $\\hat{Y}$ Fit a model to predict $T$ from $W$ to get the predicted $\\hat{T}$ stage2 Partial out $W$ by fitting a model to predict $Y-\\hat{Y}$ from $T-\\hat{T}$ Causal Trees and Forests ","date":"2021-12-03","objectID":"/causal06/:6:0","tags":["Estimation"],"title":"[인과추론] Estimation","uri":"/causal06/"},{"categories":["Causality"],"content":"Reference Brady Neal - Causal Inference ","date":"2021-12-03","objectID":"/causal06/:7:0","tags":["Estimation"],"title":"[인과추론] Estimation","uri":"/causal06/"},{"categories":["Causality"],"content":"Randomized Experiment에 대해 알아보고 causal effect를 identification하는 방법에 대해 알아보자. ","date":"2021-12-03","objectID":"/causal05/:0:0","tags":["Randomized Experiment","Frontdoor adjustment"],"title":"[인과추론] Randomized Experiments and Identification","uri":"/causal05/"},{"categories":["Causality"],"content":"Randomized Experiment 언제나 우리가 관측하지 못한 confounder가 있다. 이를 conditioning하지 못할 것이다. 따라서 RCT (Randomized control trial)이 아주 강력한 것이다. 기업에서 많이들 A/B test를 하는데 이게 RCT이다. treatment, control group을 random하게 나누는 것이다. RCT를 통해 association이 causation이 되는데 이를 각기 다른 3가지 측면에서 살펴보자. ","date":"2021-12-03","objectID":"/causal05/:1:0","tags":["Randomized Experiment","Frontdoor adjustment"],"title":"[인과추론] Randomized Experiments and Identification","uri":"/causal05/"},{"categories":["Causality"],"content":"Comparability and covariate balance 먼저 covariate balance란 두 그룹의 distribution of covariates $X$가 같다는 것을 의미한다. $$P(X|T=1) = P(X|T=0)$$ Randomization implies covariate balance treatment를 random하게 적용하기 때문에 covariate $X$들과 독립이다. 이 때 covariate들이 observed or unobserved 인지 상관없이 독립적이다. $$P(X|T=1) = P(X|T=0) = P(X)$$ Covariate balance implies association is causation $$P(y|do(t)) = \\sum_x P(y|t,x)P(x) \\\\ = \\sum_x \\frac{P(y|t,x)P(t|x)P(x)}{P(t|x)}\\ = \\sum_x \\frac{P(y,t,x)}{P(t|x)} \\\\ = \\sum_x \\frac{P(y,t,x)}{P(t)} \\\\ = \\sum_x P(y,x|t)\\ =P(y|t)$$ ","date":"2021-12-03","objectID":"/causal05/:1:1","tags":["Randomized Experiment","Frontdoor adjustment"],"title":"[인과추론] Randomized Experiments and Identification","uri":"/causal05/"},{"categories":["Causality"],"content":"Exchangeability RCT를 exchangeability의 측면에서 살펴보자. RCT를 하면 exchangeability가 성립할 수 밖에 없다. 동전을 던져서 treatment를 할지 말지 결정하기 때문에 당연히 아래의 식이 성립하고 association이 causation이 되는 것이다. $$E[Y(1)|T=1] = E[Y(1)|T=0] \\ E[Y(0)|T=0] = E[Y(0)|T=1]$$ $$E[Y(1)]-E[Y(0)] = E[Y(1)|T=1] - E[Y(0)|T=0] \\\\ =E[Y|T=1] = E[Y|T=0]$$ ","date":"2021-12-03","objectID":"/causal05/:1:2","tags":["Randomized Experiment","Frontdoor adjustment"],"title":"[인과추론] Randomized Experiments and Identification","uri":"/causal05/"},{"categories":["Causality"],"content":"No backdoor paths graphical causal model에서도 RCT를 통해 association이 causation이 된다. $T$의 incoming edges가 사라지기 때문이다. 따라서 backdoor path들도 사라지고 association이 causal이 되는 것이다. ","date":"2021-12-03","objectID":"/causal05/:1:3","tags":["Randomized Experiment","Frontdoor adjustment"],"title":"[인과추론] Randomized Experiments and Identification","uri":"/causal05/"},{"categories":["Causality"],"content":"Frontdoor adjustment 아래의 그림처럼 $W$가 unobserved인 경우 backdoor path를 막을 수 없고 따라서 causal association도 구할 수 없게 된다. 그러면 어떻게 할까? Frontdoor adjustment! 위의 그림에서 mediator $M$에 집중하면 된다. 과정은 아래와 같다. Identify the causal effect of $T$ on $M$ Identify the causal effect of $M$ on $Y$ Combine the above steps to identify the causal effect of $T$ on $Y$ step1에서 $Y$는 $T-M$ path through $W$에 대해 collider이고 이는 backdoor path를 막아준다. 따라서 우리는 아래와 같은 identification이 성립함을 알 수 있다. $$P(m|do(t)) = P(m|t)$$ step2에서 $T$를 conditioning하면 backdoor path $M \\leftarrow T \\leftarrow W \\rightarrow Y$를 막을 수 있다. $$P(y|do(m)) = \\sum_t P(y|m,t)P(t)$$ 이제 위에서 알게된 내용을 합쳐서 $T$의 변화가 $Y$를 얼마나 변하게 하는지 알 수 있게 된다. $$P(y|do(t))=\\sum_m P(m|do(t))P(y|do(m))$$ (proof) 위의 사진으로 진행한다. truncated factorization으로 $$P(w,m,y|do(t))=P(w)P(m|t)P(y|w,m)$$ $w,m$에 대해 marginalize하면 $$\\sum_m \\sum_w P(w,m,y|do(t)) = \\sum_m \\sum_w P(w)P(m|t)P(y|w,m) \\\\ P(y|do(t)) = \\sum_m P(m|t) \\sum_w P(w)P(y|w,m) $$ 그런데 우항에 unobserved $w$가 있기에 marginalization을 진행할 수 없다. 따라서 우리는 $w$를 식에서 없애는 작업이 필요할 것이다. 그림에서 $T$가 주어진다면 $P(w|t)=P(w|t,m)$이므로 $$P(y|do(t)) = \\sum_m P(m|t) \\sum_w P(w)P(y|w,m) \\\\ = \\sum_m P(m|t) \\sum_w P(y|w,m)\\sum_{t’}P(w|t’)P(t’) \\\\ = \\sum_m P(m|t) \\sum_w P(y|w,m)\\sum_{t’}P(w|t’,m)P(t’) \\\\ = \\sum_m P(m|t) \\sum_{t’}P(t’) \\sum_w P(y|w,m)P(w|t’,m) \\\\ = \\sum_m P(m|t) \\sum_{t’}P(t’) \\sum_w P(y|w,m,t’)P(w|t’,m) \\\\ = \\sum_m P(m|t) \\sum_{t’}P(t’) \\sum_w P(y,w|m,t’) \\\\ =\\sum_m P(m|t) \\sum_{t’}P(t’)P(y|m,t’)$$ ","date":"2021-12-03","objectID":"/causal05/:2:0","tags":["Randomized Experiment","Frontdoor adjustment"],"title":"[인과추론] Randomized Experiments and Identification","uri":"/causal05/"},{"categories":["Causality"],"content":"Frontdoor Criterion 아래의 조건이 사실이면 set of variables $M$들이 $T,Y$에 대해 the frontdoor criterion을 만족한다. $M$ completely mediates the effect of $T$ on $Y$ (all causal paths from $T$ to $Y$ go through $M$) There is no unblocked backdoor path from $T$ to $M$ All backdoor paths from $M$ to $Y$ are blocked by $T$ ","date":"2021-12-03","objectID":"/causal05/:2:1","tags":["Randomized Experiment","Frontdoor adjustment"],"title":"[인과추론] Randomized Experiments and Identification","uri":"/causal05/"},{"categories":["Causality"],"content":"Frontdoor Adjustment 만약 $(T,M,Y)$이 the frontdoor criterion을 만족하고 positivity를 만족하면 $$P(y|do(t))=\\sum_m P(m|t) \\sum_{t’}P(y|m,t’)P(t’)$$ ","date":"2021-12-03","objectID":"/causal05/:2:2","tags":["Randomized Experiment","Frontdoor adjustment"],"title":"[인과추론] Randomized Experiments and Identification","uri":"/causal05/"},{"categories":["Causality"],"content":"Pearl’s do-calculus backdoor adjustment가 성립하지 않더라도 frondoor adjustment라는 방법을 통해 identification이 성립할 수 있음을 알게되었다. 그렇다면 둘다 성립하지 않을 때는 어떻게 해야할까? do-calculus ! do-calculus는 causal graph에 녹아있는 any causal assumptions을 사용하여 causal effects를 identify할 수 있는 tool을 제공한다. notation $G$ : causal graph $G_{\\overline{X}}$ : the graph that remove all of the incoming edges to nodes in the set $X$ $G_{\\underline{X}}$ : the graph that remove all of the outgoing edges to nodes in the set $X$ ","date":"2021-12-03","objectID":"/causal05/:3:0","tags":["Randomized Experiment","Frontdoor adjustment"],"title":"[인과추론] Randomized Experiments and Identification","uri":"/causal05/"},{"categories":["Causality"],"content":"Rules of do-calculus Given a causal graph $G$, an associated distribution $P$, and disjoint sets of vairables $Y,T,Z,W$ the following rules hold: Rule1 : if $Y \\perp_{G_{\\overline{T}}} Z | T,W$ $$P(y|do(t),z,w)=P(y|do(t),w)$$ Rule2 : if $Y \\perp_{G_{\\overline{T}, \\underline{Z}}} Z | T,W$ $$P(y|do(t),do(z),w) = P(y|do(t),z,w)$$ Rule3 : if $Y \\perp_{G_{\\overline{T}, \\overline{Z(W)}}} Z | T,W$ $Z(W)$ : the set of nodes of $Z$ that aren’t ancestors of any node of $W$ in $G_{\\overline{T}}$ $$P(y|do(t),do(z),w) = P(y|do(t),w)$$ 위의 rule들을 좀 더 쉽게 이해하기위해 $T$에 해당하는 부분을 없애면 각각은 generalization of d-seperation if $Y \\perp_G Z | T,W$ $$P(y|z,w)=P(y|w)$$ backdoor adjustment/criterion if $Y \\perp_{G_{\\underline{Z}}} Z | T,W$ $$P(y|do(z),w) = P(y|z,w)$$ $Z(W)$ 가정이 없으면 collider 때문에 문제발생 if $Y \\perp_{G_{\\overline{Z(W)}}} Z | T,W$ $$P(y|do(z),w) = P(y|w)$$ 이에 대한 증명은 ‘Pearl (1995) Causal diagrams for empirical research’를 읽어보면 될 것이다. 그렇다면 do-calculs만 있으면 causal estimands들이 무조건 identifiable할 수 있을까? 2000년대에 나온 논문들이 이를 증명했다고 한다. 즉, 위의 3가지 rule들이 sufficient to identify all identifiable causal estimands라는 것을 의미한다. 위의 identification은 nonparametric identification에 속한다. 추후에 parametric identification에 대해서도 살펴볼 것이다. ","date":"2021-12-03","objectID":"/causal05/:3:1","tags":["Randomized Experiment","Frontdoor adjustment"],"title":"[인과추론] Randomized Experiments and Identification","uri":"/causal05/"},{"categories":["Causality"],"content":"Determining identifiability from the graph 이 부분은 잘 모르겠다. ","date":"2021-12-03","objectID":"/causal05/:4:0","tags":["Randomized Experiment","Frontdoor adjustment"],"title":"[인과추론] Randomized Experiments and Identification","uri":"/causal05/"},{"categories":["Causality"],"content":"Unconfounded children criterion This criterion is satisfied if it is possible to block all backdoor paths from the treatment variable $T$ to all of its children that are ancestors of $Y$ with a single conditioning set (Tian \u0026 Pearl, 2002) Sufficient condition for identifiability when $T$ is a single variable ","date":"2021-12-03","objectID":"/causal05/:4:1","tags":["Randomized Experiment","Frontdoor adjustment"],"title":"[인과추론] Randomized Experiments and Identification","uri":"/causal05/"},{"categories":["Causality"],"content":"Necessary condition for identifiability For each backdoor path from $T$ to any child $M$ of $T$ that is an ancestor of $Y$, it is possible to block that path. ","date":"2021-12-03","objectID":"/causal05/:4:2","tags":["Randomized Experiment","Frontdoor adjustment"],"title":"[인과추론] Randomized Experiments and Identification","uri":"/causal05/"},{"categories":["Causality"],"content":"Necessary and sufficient condition Shpitser \u0026 Pearl, 2006a, 2006b: hedge criterion ","date":"2021-12-03","objectID":"/causal05/:4:3","tags":["Randomized Experiment","Frontdoor adjustment"],"title":"[인과추론] Randomized Experiments and Identification","uri":"/causal05/"},{"categories":["Causality"],"content":"Reference Brady Neal - Causal Inference ","date":"2021-12-03","objectID":"/causal05/:5:0","tags":["Randomized Experiment","Frontdoor adjustment"],"title":"[인과추론] Randomized Experiments and Identification","uri":"/causal05/"},{"categories":["Causality"],"content":"Causal Model이란? Causal Estimand를 구하기 위해서 우리는 결국 Statistical Estimand를 Estimate해야한다. 이 때 Causal Estimand를 Statistical Estimand로 만들어주는 것이 Causal Model이 하는 일이다. ","date":"2021-12-03","objectID":"/causal04/:0:0","tags":["Causal Model"],"title":"[인과추론] Causal Models","uri":"/causal04/"},{"categories":["Causality"],"content":"do-operator Conditioing vs intervening Conditioning이라함은 population에서 subpopulation을 뽑아서 다루는 것이고 Intervening이라함은 특정한 treatment를 population에 행하는 것이다. 특정 subpopulation을 고려하지 않는다. 특정한 intervening을 했다는 것을 나타내는 operator가 $do$-operator이다. 이는 이전에 potential outcome framework에서 사용한 정의와도 연결되어 있다. $$P(Y(t)=y) = P(Y=y|do(T=t)) = P(y|do(t))$$ $P(Y|do(T=t))$처럼 $do$-operator가 있으면 Interventional distibutions이라고 한다. Interventional data는 주로 실험(experiment)이 필요한 경우가 많다. 이전에 배운 Identifiability가 $P(y | do(t))$를 $P(y|t)$로 구하는 것을 의미했다. (confounder가 있다면 $E_X [P(y|t,X)]$) ","date":"2021-12-03","objectID":"/causal04/:1:0","tags":["Causal Model"],"title":"[인과추론] Causal Models","uri":"/causal04/"},{"categories":["Causality"],"content":"Modularity 어떤 causal mechanism에 대한 정의는 다양할 수 있지만 여기서는 $X_i$가 발생하는 causal mechanism은 conditional distribution $P(X_i |pa_i)$라고 할 것이다. causal identification을 얻기 위해서 지금 정의할 가정은 invervention이 local하다는 것이다. 이를 Modularity라고 한다. ","date":"2021-12-03","objectID":"/causal04/:2:0","tags":["Causal Model"],"title":"[인과추론] Causal Models","uri":"/causal04/"},{"categories":["Causality"],"content":"Modularity assumption If we intervene on a node $X_i$, then only the mechanism $P(x_i|pa_i)$ changes. All other mechanisms $P(x_j | pa_j)$ where $i \\neq j$ remain unchanged. = independent mechanism, autonomy, invariance, etc ","date":"2021-12-03","objectID":"/causal04/:2:1","tags":["Causal Model"],"title":"[인과추론] Causal Models","uri":"/causal04/"},{"categories":["Causality"],"content":"Modularity assumption (formal) If we intervene on a set of nodes $S \\in [1,2,…,n]$, setting them to constants, then for all $i$, we have the following: If $i \\notin S$, then $P(x_i | pa_i)$ remains unchanged. If $i \\in S$, then $P(x_i | pa_i)=1$ if $x_i$ is the value that $X_i$ was set to by the intervention; otherwise $P(x_i | pa_i)=0$. interventional distribution이 있는 causal graph는 일반적인 observational graph와 동일한 모습이다. 다만 intervened node로 향하는 edge들은 다 지워진다. intervened node는 parent가 없어지는 것이다. 이는 위의 modularity assumption에 의해 intervened node가 발생할 확률이 1이기 때문이다. 다른 시각으로는 intervention하여서 해당 node가 constant이므로 parent들의 영향이 없어진 것으로 바라볼 수도 있다. ","date":"2021-12-03","objectID":"/causal04/:2:2","tags":["Causal Model"],"title":"[인과추론] Causal Models","uri":"/causal04/"},{"categories":["Causality"],"content":"Truncated factorization under Markov, modularity assumption a set of intervention nodes $S$ $$P(x_1 ,…, x_n | do(S=s)) = \\prod_{i \\notin S} P(x_i | pa_i)$$ if $x$ is consistent with the intervention (= if $x_i$ is the value that $X_i$ was set to by the intervention). Otherwise $$P(x_1,…,x_n | do(S=s))=0$$ 예시를 통해 더 잘 이해해보자. identification via truncated factorizartion Goal: identify $P(y|do(t))$ graph: $T \\leftarrow X \\rightarrow Y, T\\rightarrow Y$ 위의 상황에서 Bayesian network factorization: $$P(y,t,x)=P(x)P(t|x)P(y|t,x)$$ Truncated factorization: $$P(y,x|do(t))=P(x)P(y|t,x)$$ Marginalize: $$P(y|do(t))=\\sum_x P(y|t,x)P(x)$$ ","date":"2021-12-03","objectID":"/causal04/:2:3","tags":["Causal Model"],"title":"[인과추론] Causal Models","uri":"/causal04/"},{"categories":["Causality"],"content":"Backdoor adjustment direct path를 통한 causal flow가 아닌 non-causal association flow가 지나는 모든 path를 backdoor path라고 한다. 이들을 잘 block하면 우리가 구하고 싶은 $P(y|do(t))$를 구할 수 있는 것이다. treatment를 intervention(experiment)할 수 있다면 backdoor path는 사라진다. treatment로 향하는 edge가 다 사라지기 떄문이다. 하지만 observation의 경우는 그럴 수가 없다. 이런 경우 어떻게 할 수 있을까? 이전에 배운대로 conditioning하면 된다. ","date":"2021-12-03","objectID":"/causal04/:3:0","tags":["Causal Model"],"title":"[인과추론] Causal Models","uri":"/causal04/"},{"categories":["Causality"],"content":"Backdoor Criterion A set of variables $W$ satisfies the backdoor criterion relative to $T$ and $Y$ if the following are true: $W$ blocks all backdoor paths from $T$ to $Y$ $W$ does not contain any descendants of $T$ ","date":"2021-12-03","objectID":"/causal04/:3:1","tags":["Causal Model"],"title":"[인과추론] Causal Models","uri":"/causal04/"},{"categories":["Causality"],"content":"Backdoor Adjustment under modularity assumtion, $W$가 backdoor criterion을 만족하고 positivity가 성립하면 causal effect $T$ on $Y$를 identify할 수 있다: $$P(y|do(t)) =\\sum_w P(y|t,w)P(w)$$ (proof) graph: $T \\leftarrow W \\rightarrow Y, T \\rightarrow Y$ $W$가 backdoor criterion을 만족한다고 가정 아래 수식에서 두번째 줄은 $W$를 conditioning해서 $T$에서 $Y$로 가는 path만 남기 때문이다. 아래 수식에서 세번째 줄은 $Y$가 collider가 되기 때문이다. $$P(y|do(t)) = \\sum_w P(y|do(t),w)P(w|do(t)) \\\\ =\\sum_w P(y|t,w)P(w|do(t)) \\\\ =\\sum_w P(y|t,w)P(w)$$ $do(t)$해서 $T$로 들어오는 edge를 없애서 Backdoor path를 막을 수 있지만 observation data에서는 다른 변수들을 conditioning하는 것이다. ","date":"2021-12-03","objectID":"/causal04/:3:2","tags":["Causal Model"],"title":"[인과추론] Causal Models","uri":"/causal04/"},{"categories":["Causality"],"content":"Structural causal models structural equation for A as a cause of B: $$B := f(A)$$ 이러한 structural equation은 causal mechanism을 나타낸다. 위의 수식에 unobserved variable $U$을 추가하면 $$B := f(A,U)$$ $f$에 대해서 특정한 모델로 정의하지 않으면 비모수(nonparametric)적인 함수가 될 것이다. 또한 $f$가 deterministic하더라도 $U$가 있기 때문에 stochastic한 mapping을 할 수 있다. 위의 그림에서 structual equation: $$B:=f_B(A,U_B) \\\\ C:=f_C(A,B,U_C) \\\\ D:=f_D(A,C,U_D)$$ 여기서 known variable을 endogenous variable, unknown variable을 exogenous variable이라고 한다. 그렇다면 이제 SCM의 정의를 알아보자. SCM A structural causal model is a tuple of the following sets: A set of endogenous variables $V$ A set of exogenous variables $U$ A set of functions $f$ ","date":"2021-12-03","objectID":"/causal04/:4:0","tags":["Causal Model"],"title":"[인과추론] Causal Models","uri":"/causal04/"},{"categories":["Causality"],"content":"condition on descendants of treatment 첫번째 그림 $Z$가 collider 이기 때문에 conditioning 하지 말자. 두번째 그림 $M$의 descendant도 conditioning하면 하지말자. 왜냐하면 우리가 모르는 $U_M$이 존재하는 경우 $M$도 collider가 되기 때문이다. 따라서 결론은 Don’t conditionon post-treatment covariates! 물론 pre-treatment를 항상 conditioning해서도 안된다. M-bias라는 것이 존재하기 때문이다. 아래의 사진처럼 우리가 모르는 $Z_1,Z_3$가 존재하는 경우 $Z_2$를 conditioning하면 backdoor-path가 생겨버린다. ","date":"2021-12-03","objectID":"/causal04/:5:0","tags":["Causal Model"],"title":"[인과추론] Causal Models","uri":"/causal04/"},{"categories":["Causality"],"content":"Reference Brady Neal - Causal Inference ","date":"2021-12-03","objectID":"/causal04/:6:0","tags":["Causal Model"],"title":"[인과추론] Causal Models","uri":"/causal04/"},{"categories":["Causality"],"content":"Graph를 통해 causality를 알아보자. ","date":"2021-12-03","objectID":"/causal03/:0:0","tags":["Causal Graph"],"title":"[인과추론] The Flow of Causation and Association in Graphs","uri":"/causal03/"},{"categories":["Causality"],"content":"Terminology 여기서 graph라고 하는 것은 node와 edge로 이루어진 것을 의미한다. undirected graph : edge에 방향성이 없는 graph directed graph : edge에 방향성이 있는 graph parent, child : edge가 출발하는 node를 parent, 그 edge가 도착한 node를 child adjacent : 하나의 edge로 연결이 되어있는 두 node들을 adjacent하다고 한다. (un, directed 둘 다) path : (방향성과 상관없이) 두 node들 사이에 edge들이 있으면 path가 있다고 한다. directed path : path중에서 directed edge들의 방향이 일정한 경우 Ancestor, Descendant : 특정 노드(Ancestor)에서 시작하여 directed path로 특정 노드(descendant)로 끝날 때, 각 노드를 이렇게 부른다. Directed Acyclic Graph (DAG) : cycle이 없는 directed graph cycle : node가 자기 자신으로 돌아오는 directed path가 있는 경우 Immorality : 아래 사진에서 $A\\rightarrow C \\leftarrow B$를 의미 (parent가 child를 공유, parent끼리는 연결되지 않음) ","date":"2021-12-03","objectID":"/causal03/:1:0","tags":["Causal Graph"],"title":"[인과추론] The Flow of Causation and Association in Graphs","uri":"/causal03/"},{"categories":["Causality"],"content":"Baysian networks and causal graphs Baysian network는 통계에서 probabilistic graphical model의 한 종류이다. 그런데 이 모델의 특징이 causality를 다루기에 좋기 때문에 많이 이용한다. 100% 그대로 쓰는 것은 아니고 조금씩 수정해서 사용하는 것으로 알고 있다. 먼저, causal을 생각하지 않고 진행해보자. joint distribution을 modeling하는 경우 많은 양의 parameter들을 고려해야하는 경우가 생긴다. 그런데 이 때 dependency를 파악할 수 있는 정보가 있다면? 더 적은 수의 parameters 고려해도 된다. 이와 관련한 가정이 Local markov assumption이다. Local markov assumption DAG에서 parent가 주어진다면(given) 나머지 non-descendant들과는 independent 하다. 예시를 통해 이해해보자. 먼저 dependency가 없는 경우, $$P(x_1, x_2, x_3, x_4) = P(x_1)P(x_2 | x_1)P(x_3 | x_2, x_1)P(x_4 |x_3, x_2, x_1)$$ 아래의 그림과 같은 DAG와 Local markov assumption을 고려하면 $$P(x_1, x_2, x_3, x_4) = P(x_1)P(x_2 | x_1)P(x_3 | x_2, x_1)P(x_4 |x_3)$$ 이처럼 더 간단해진다. Bayesian network factorization theorem 확률분포 $P$와 DAG $G$가 주어지고, $P$는 $G$에 따라 아래의 식처럼 factorize될 수 있다. $$P(x_1,…,x_n) = \\prod_i P(x_i | pa_i)$$ Bayesian network factorization과 Local Markov assumption은 사실 같은 내용이다 (증명도 있다). 지금까지는 independency에 관한 내용이었는데 dependency에 관한 내용도 당연히 있을 것이다. Minimality assumption Local Markov assumption + Adjacent nodes in the DAG are dependent 이때, 왜 Adjacent nodes in the DAG are dependent라는 가정이 추가로 필요할까? 예시를 통해 이해해보자. 예를 들어, $X$에서 $Y$로 arrow가 향하고 있는 graph가 있다. 이런 상황에서 local markov assumption만 가정한다면 $p(x,y)=p(x)p(y|x)$ 뿐만 아니라 $P(x,y)=p(x)p(y)$도 성립하게 된다. 후자의 상황을 막기 위해 추가적인 가정이 필요한 것이다. Minimality assumption을 통해 dependency도 다룰 수 있으므로 우리는 이제 DAG에서 association flow를 다룰 수 있게 되었다. 그렇다면 다음은 causation을 다룰 차례! Causal Edges assumption In a directed graph, every parent is a direct cause of all its children ","date":"2021-12-03","objectID":"/causal03/:2:0","tags":["Causal Graph"],"title":"[인과추론] The Flow of Causation and Association in Graphs","uri":"/causal03/"},{"categories":["Causality"],"content":"Graphical building blocks 이제는 the flow of association and causation in DAG 를 알아보자. 일단 3가지 building block들을 살펴보자. chain, fork, immorality 위의 사진들의 모습을 잘 기억하자. 이제 각각의 특징을 살펴보자. ","date":"2021-12-03","objectID":"/causal03/:3:0","tags":["Causal Graph"],"title":"[인과추론] The Flow of Causation and Association in Graphs","uri":"/causal03/"},{"categories":["Causality"],"content":"Chains, Forks : dependence $X_1,X_3$는 dependent하다. $X_1$에서 $X_3$로 association flow가 흐른다. symmetric하게 $X_3$에서 $X_1$으로도 흐른다. causation flow는 symmetric하지 않다. 한쪽의 방향으로만 흐른다. ","date":"2021-12-03","objectID":"/causal03/:3:1","tags":["Causal Graph"],"title":"[인과추론] The Flow of Causation and Association in Graphs","uri":"/causal03/"},{"categories":["Causality"],"content":"Chains, Forks : independence $$P(X_1,X_3 | X_2)=P(X_1 | X_2)P(X_3 | X_2)$$ (proof) Bayeisan Network Factorization과 Bayes rule을 이용 $$\\text{Chain: }P(X_1,X_3 | X_2) = \\frac{P(X_1,X_2,X_3)}{P(X_2)} \\\\ =\\frac{P(X_1)P(X_2|X_1)P(X_3|X_2)}{P(X_2)}=P(X_1 | X_2)P(X_3 | X_2)$$ $$\\text{Forks: } P(X_1,X_3 | X_2) = \\frac{P(X_1,X_2,X_3)}{P(X_2)} \\\\ =\\frac{P(X_2)P(X_1|X_2)P(X_3|X_2)}{P(X_2)}=P(X_1 | X_2)P(X_3 | X_2)$$ 위에서 independent한 상황의 경우 blocked path라고 하고 반대는 unblock path라고 부른다. ","date":"2021-12-03","objectID":"/causal03/:3:2","tags":["Causal Graph"],"title":"[인과추론] The Flow of Causation and Association in Graphs","uri":"/causal03/"},{"categories":["Causality"],"content":"Immorality $X_2$를 collider라고 한다. 위에 두 가지의 경우와 반대 conditioning on the collider $\\rightarrow$ unblocked path conditioning을 하지 않으면 아래의 식처럼 block path가 존재한다. (independence) (proof) $$P(X_1, X_3) = \\sum_{X_2} P(X_1, X_2, X_3) \\\\ =\\sum_{X_2} P(X_1)P(X_3)P(X_2|X_1,X_3) \\\\ =P(X_1)P(X_3) \\sum_{X_2} P(X_2|X_1,X_3) \\\\ =P(X_1)P(X_3) $$ conditioning on descendants of colliders는 이 또한 association을 야기한다. ","date":"2021-12-03","objectID":"/causal03/:3:3","tags":["Causal Graph"],"title":"[인과추론] The Flow of Causation and Association in Graphs","uri":"/causal03/"},{"categories":["Causality"],"content":"The flow of association and causation d-separation 두 개(또는 집합)의 노드들 $X,Y$사이의 모든 path가 노드(들) $Z$에 의해 blocked되면 이를 Two (sets of) nodes $X$ and $Y$ are d-separated by a set of nodes $Z$ graph에서 d-separated되면 이를 확률적으로도 conditional independence하게 이용할 수 있다. $$X \\perp_G Y | Z \\rightarrow X\\perp_P Y |Z$$ 일반적인 Bayesian network graph의 경우, association만 다룰 수 있다. 하지만 우리가 여기에 추가적인 가정을 더하면 causal association을 구할 수 있는 것이다. We refer to the flow of association along directed paths as causal association d-separation implies association is causation d-separate된 경우, $T$에서 $Y$로의 path를 살리면 해당하는 association은 purely causal association이므로! ","date":"2021-12-03","objectID":"/causal03/:4:0","tags":["Causal Graph"],"title":"[인과추론] The Flow of Causation and Association in Graphs","uri":"/causal03/"},{"categories":["Causality"],"content":"Reference Brady Neal - Causal Inference ","date":"2021-12-03","objectID":"/causal03/:5:0","tags":["Causal Graph"],"title":"[인과추론] The Flow of Causation and Association in Graphs","uri":"/causal03/"},{"categories":["Causality"],"content":"Potential Outcomes 이란? ","date":"2021-12-03","objectID":"/causal02/:0:0","tags":["Potential Outcome"],"title":"[인과추론] Potential Outcomes Framework","uri":"/causal02/"},{"categories":["Causality"],"content":"notation $T$ : observed treatment $Y$ : observed outcome $i$ : to denote a specific unit/individual $Y_i (1)$ : potential outcome under treatment $Y_i (0)$ : potential outcome under no treatment (individual) Causal effect : $Y_i (1) - Y_i (0)$ ","date":"2021-12-03","objectID":"/causal02/:1:0","tags":["Potential Outcome"],"title":"[인과추론] Potential Outcomes Framework","uri":"/causal02/"},{"categories":["Causality"],"content":"The fundamental problem of causal inference (individual) Causal effect : $Y_i (1) - Y_i (0)$ 위의 식에서 causal effect를 알 수가 없다. 예를 들어서, 약을 먹으면 병이 낫는지 알고 싶다. 즉, causal effect를 알고 싶다. 그런데 약을 먹었을 때의 결과 $Y(1)$와 먹지 않았을 때의 결과 $Y(0)$를 동시에 알 수 없기 때문에 문제가 발생한다. 결국에는 모든 개체 $i$들의 outcome은 둘 중 하나의 potential outcome만을 얻을 수 밖에 없는 것이다. (이 때 반대의 예상되는 결과는 counterfactual outcome이라고 함) 이것이 우리가 마주하게 되는 문제이다. 그렇다면 이를 어떻게 해결해야 할까? ","date":"2021-12-03","objectID":"/causal02/:2:0","tags":["Potential Outcome"],"title":"[인과추론] Potential Outcomes Framework","uri":"/causal02/"},{"categories":["Causality"],"content":"Average treatment effect (ATE) 위에서 처럼 모든 개체들의 두 가지 outcome을 얻을 수 없다면 평균이라는 강력한 무기를 이용할 수 있다. Average treatment effect (ATE) : $$E[Y_i (1) - Y_i (0)] = E[Y(1) - Y(0)] = E[Y(1)] - E[Y(0)]$$ Associational difference : $$E[Y|T=1] - E[Y|T=0]$$ 그렇다면 ATE와 associational difference가 같도록 하는 가정은 무엇일까. 하나씩 알아보자. ","date":"2021-12-03","objectID":"/causal02/:3:0","tags":["Potential Outcome"],"title":"[인과추론] Potential Outcomes Framework","uri":"/causal02/"},{"categories":["Causality"],"content":"Ignorability (exchangeability) Ignorability : $$(Y(1),Y(0)) \\perp T$$ 또 다른 시점으로는 (계산, 수학적으로 같은 의미) exchangeability : 두 그룹을 바꿔서 treatment나 not treatment를 해도 똑같은 결과를 나오는 가정 $$E[Y(1)|T=1] = E[Y(1)|T=0] \\rightarrow = E[Y(1)] \\\\ E[Y(0)|T=1] = E[Y(0)|T=0] \\rightarrow = E[Y(0)]$$ 결국 treatment, non treatment 두 그룹이 comparable해야한다는 것이다. 위의 가정을 만족한다면 우리는 아래와 같은 식을 얻을 수 있다. $$E[Y(1)] - E[Y(0)] = E[Y(1)|T=1] - E[Y(0)|T=0]$$ 위의 식을 보면 causal notation에서 점점 statistical notation으로 변화하는 느낌을 받을 수 있다. data를 통해 결국 측정하는 것은 statistical inference의 영역인 것이다. 여기서 identifiability라는 개념이 나온다. identifiability 만약에 causal quantity (ex, $E[Y(t)]$)를 statistical quantity(ex, $E[Y|t]$)로 계산할 수 있다면 우리는 이 causal quantity가 identifiable하다고 한다. 위의 ignorability(exchangeability)라는 중요한 가정을 배웠다. 그런데 이를 실제로 만족하도록 하기 위해서는 어떻게 해야할까? Randomized control trial (RCT)이 필요하다. 동전을 던져서 그룹을 나누는 것이다. 즉, 그룹이 나누어질 때 confounder를 없어지고 두 그룹이 동일한 특징(comparable)을 가진다는 것이다. ","date":"2021-12-03","objectID":"/causal02/:4:0","tags":["Potential Outcome"],"title":"[인과추론] Potential Outcomes Framework","uri":"/causal02/"},{"categories":["Causality"],"content":"Conditional exchangeability 하지만 obserbational data에서는 ignorability가정을 만족하기가 어렵다. 이유는 당연히 RCT를 하지 못한 상태이기 때문에 confounder가 있을 수 밖에 없다. 따라서 이를 해결하기 위해 conditional exchangeability가정을 주로 이용한다. covariate $X$들을 conditioning함으로서 subgroup들이 exchangeable하게 만드는 것이다. confounder들을 제어함으로서 RCT처럼 동일한(comparable) 두 집단을 만들어가는 과정이라고 볼 수 있다. 물론 모든 confounder를 파악할 수 없기에 RCT와 동일하다고 할 수는 없다. Conditional Exchangeability (Unconfoundedness): $$(Y(1),Y(0)) \\perp Y |X$$ graphical하게 표현하면 아래와 같다. $$E[Y(1) - Y(0) | X] = E[Y(1)|X] - E[Y(0)|X] $$ $$ = E[Y(1)|T=1,X]-E[Y(0)|T=0,X]$$ marginal effect는 $$E[Y(1) - Y(0)] = E_X E[Y(1) - Y(0)|X]$$ 근데 주의해야 할 점은 이 assumption은 untestable하다는 것이다. 우리가 conditioning하지 못한 숨겨진 confounder가 있기 때문이다. ","date":"2021-12-03","objectID":"/causal02/:5:0","tags":["Potential Outcome"],"title":"[인과추론] Potential Outcomes Framework","uri":"/causal02/"},{"categories":["Causality"],"content":"Positivity/Overlap and Extrapolation 위의 unconfoundedness도 중요한 가정이지만 추가적으로 고려해야하는 가정도 존재한다. Positivity (Overlap, Extrapolation) : 모든 covariates $x$에 대해 $$0 \u003c P(T=1|X=x) \u003c 1$$ 이 가정이 필요한 이유를 먼저 수학적으로 살펴보자. $$E[Y(1) - Y(0)] = E_X [E[Y|T=1, X] - E[Y|T=0, X]]$$ $$\\sum_x P(X=x)(\\sum_y y P(Y=y|T=1,X=x) - \\sum_y y P(Y=y|T=0,X=x)) $$ $$ =\\sum_x P(X=x)(\\sum_y y \\frac{P(Y=y, T=1,X=x)}{P(T=1 | X=x)P(X=x)} - \\sum_y y \\frac{P(Y=y,T=0,X=x)}{P(T=0 | X=x)P(X=x)})$$ 위 식에서 분모에 $P(T=1|X=x)+P(T=0|X=x)=1$이다. 따라서 $P(T=1|X=x)$이 0 또는 1이면 문제가 생긴다. 이에 대해 생각해보면 당연한 결과이다. 특정 covariate값에서 관찰할 수 있는 것이 treatment 또는 non- treatment의 결과만 존재한다면 이는 causal effect를 제대로 측정하지 못하게 되는 것을 의미한다. ","date":"2021-12-03","objectID":"/causal02/:6:0","tags":["Potential Outcome"],"title":"[인과추론] Potential Outcomes Framework","uri":"/causal02/"},{"categories":["Causality"],"content":"No interference, Consistency 마지막으로 추가적인 가정들을 알아보자. No Interference 내 outcome이 다른 이들의 treatment로 영향을 받지 않아야한다 $$Y_i (t_1, t_2,…t_i,…, t_n) = Y_i (t_i)$$ Consistency 우리가 관측하는 $Y$의 값이 관측된 treatment $T$의 potential outcome이여야 한다. $$T=t \\rightarrow Y = Y(t) \\\\ Y = Y(T)$$ Consistency에 대해 예를 들어보자. 강아지와 함께 살면 행복지수가 높아질 것이다. 위와 같은 causal effect를 구하고자 한다. 의도한 것은 강아지의 어떤 친밀함과 같은 교류 덕에 행복지수가 높아지는 효과(potential outcome)일 것이다. 그런데 나이가 많은 강아지가 treatment가 되었다면 우리가 의도한대로 결과가 나오지 않을 수도 있다. 이처럼 treatment specification으로 잡히지 않은 요인들 때문에 consistency가 중요한 것이다. (no muliple version of treatment) consistency 가정이 성립한다면 $$E[Y(1) - Y(0) | X] = E[Y(1)|X] - E[Y(0)|X] \\\\ = E[Y(1)|T=1,X]-E[Y(0)|T=0,X] \\\\ =E[T|T=1,X] - E[Y|T=0,X]$$ 지금까지의 가정들을 총집합해보면 Unconfoundedness Positivity No interference Consistency $$E[Y(1) - Y(0)] = E[Y(1)] - E[Y(0)]\\;\\text{(linearity of expectation)} \\\\ =E_X [E[Y(1)|X] - E[Y(0)|X]] \\;\\text{(law of iterated expectations)} \\\\ =E_X [E[Y(1)|T=1,X] - E[Y(0)|T=0,X]] \\;\\text{(unconfoundedness, positivity)} \\\\ =E_X [E[Y|T=1,X] - E[Y|T=0,X]] \\; \\text{(consistency)}$$ 최종적으로 우리는 통계적인 추론을 통해 (최종식이 모두 확률변수, 평균 등으로 이루어진 식) 우리가 궁금해했던 ATE를 구할 수 있게 된다. ","date":"2021-12-03","objectID":"/causal02/:7:0","tags":["Potential Outcome"],"title":"[인과추론] Potential Outcomes Framework","uri":"/causal02/"},{"categories":["Causality"],"content":"Reference Brady Neal - Causal Inference ","date":"2021-12-03","objectID":"/causal02/:8:0","tags":["Potential Outcome"],"title":"[인과추론] Potential Outcomes Framework","uri":"/causal02/"},{"categories":["Causality"],"content":"Causal Inference시 주의할 점 ","date":"2021-12-03","objectID":"/causal01/:0:0","tags":["Correlation"],"title":"[인과추론] Introduction","uri":"/causal01/"},{"categories":["Causality"],"content":"Simpson’s paradox Simpson’s paradox는 주로 observational data에 주로 발생하는 경우가 많다. 환자들에게 약(Treatment)을 통해 효과가 어떤지 확인하는 상황을 가정해보자. 아래의 표는 두 가지 약을 처방받은 사람들의 사망률이다. Total A 16% (240/1500) B 19%(105/550) 위의 표에 따른 수치에 따르면 A가 더 좋다. 정말 그럴까? 사망한 환자의 아픈정도(Condition)에 따라 나눠서 생각해보자. Mild Severe Total A 15% (210/1400) 30% (30/100) 16% (240/1500) B 10% (5/50) 20% (100/500) 19% (105/550) 전체적으로는 A약의 사망률이 더 낮은데 상태별로 나눠서 보니 B약의 사망률이 두 가지 경우 모두 낮다. 그렇다면 어떤 약을 사용해야할까? 이에 대해서는 두 가지의 시나리오가 있다. 먼저 아픈정도(Condition)가 어떤 약(Treatment)을 투여하는지와 사망률(Outcome) 모두에게 영향을 주는 경우 : 이런 경우는 B 선호 예를 들어, 의사가 상태가 Mild한 환자에게는 A약을 투여하고 상태가 Severe한 환자에게는 B약을 투여한 상황을 생각해보자. 이미 Severe한 환자는 사망할 확률이 높았고 따라서 A약의 사망률이 더 낮게 나온 것이다. (Condition confounds the effect of treatment on morality) 이 예시에서처럼 treatment와 outcome 모두에 영향을 미치는 변수를 confounder 라고 부른다. 약(Treatment)이 아픈정도(Condition)와 사망률(Outcome) 모두에게 영향을 주는 경우 : 이런 경우는 A 선호 예를 들어, B약은 약의 특징상 2번 맞아야하는데 그 사이의 시간이 꽤 긴 편이다. 따라서 B약을 처방받은 사람은 그 사이의 시간동안 아픈상태가 Severe해지는 경우가 발생할 수 있다. 그래서 B약을 맞은 사람의 전체사망률이 높아질수 있다. 이처럼 어떤 인과모형을 갖느냐에 따라 결론이 바뀌게 된다. 따라서 우리는 인과관계를 통해 decision-making을 할 때, 적절한 과정을 거쳐야하는 것이다. ","date":"2021-12-03","objectID":"/causal01/:1:0","tags":["Correlation"],"title":"[인과추론] Introduction","uri":"/causal01/"},{"categories":["Causality"],"content":"Correlation does not imply causation ‘신발을 신고 자는 것’과 ‘일어나서 두통이 있는 것’이 상관관계가 높다. 그러면 신발을 신고자면 다음날 일어나서 두통이 있을 것이라고 말할 수 있을까? 즉, 인과관계가 있다고 할 수 있을까? 그럴 수 없다. common cause가 있다면? 술을 마신 경우를 생각해보자. 취해서 신발을 신고 자게된다. 숙취 때문에 다음날 일어나서 두통이 있을 확률이 높다. 즉 total association이 confounding association과 causal association으로 이루어진 것이다. (correlation is technically only a measure of linear statistical dependence. We will largely be using the term ‘association’ to refer to statistical dependence from now on) 이처럼 우리는 data를 보고 인과관계를 함부로 판단해서는 안된다. 추후에는 인과관계를 파악하기 위한 방법론들을 알아보자. ","date":"2021-12-03","objectID":"/causal01/:2:0","tags":["Correlation"],"title":"[인과추론] Introduction","uri":"/causal01/"},{"categories":["Causality"],"content":"Causation in Observation Studies RCT를 하거나 두 그룹이 comparable하게 하여 confounder를 없애서 인과관계를 파악할 수 있다. 하지만 그렇지 못해서 observational study만 가능한 경우가 있다. 이런 경우에는 causal effect를 측정할 수 있을까? 가능하다. 사실 이 부분이 실제 필드에서 가장 많이 필요할 것이다. 뒤에서 차차 배워보자. ","date":"2021-12-03","objectID":"/causal01/:3:0","tags":["Correlation"],"title":"[인과추론] Introduction","uri":"/causal01/"},{"categories":["Causality"],"content":"Reference Brady Neal - Causal Inference ","date":"2021-12-03","objectID":"/causal01/:4:0","tags":["Correlation"],"title":"[인과추론] Introduction","uri":"/causal01/"},{"categories":["ML Engineering"],"content":"Docker 기본적인 명령어 정리 docker hub에서 pull해서 image를 다운받고 run해서 container를 살행한다. 도커 이미지 확인 docker images 그러면 아래처럼 뜬다 REPOSITORY TAG IMAGE ID CREATED SIZE minsoo/flaskapp latest ecad9ae45c3d 2 weeks ago 897MB \u003cnone\u003e \u003cnone\u003e b36cd113e3f5 2 weeks ago 897MB container 띄우기 docker run [OPTION] image이름 [COMMAND] -d 옵션주면 background 모드로 실행 container 시작 docker start container이름 -a 옵션 : Attach STDOUT/STDERR and forward signals -i 옵션 : Attach container’s STDIN -a 옵션주면 exit해도 container가 꺼지지 않는다..! container 멈추기 docker stop container이름 현재 살아있는 container docker ps 모든 container 확인 docker ps -a 로그 출력 docker logs container이름 실시간 docker logs -f container이름 container 삭제 docker rm container이름 image 삭제 docker rmi image이름 도커 Host한에 독립적인 Container들이 존재하는 것이다. 따라서 Host의 port와 Container의 port를 연결해줘야 우리가 Container와 연결이 된다. 이를 port forwarding이라고 한다. docker run -p 80:80 image이름 : docker host 80번과 container 80번 연결 실행중인 도커 Container에 명령어 실행 docker exec container이름 [COMMAND] ","date":"2021-12-03","objectID":"/02-docker/:0:0","tags":["Docker"],"title":"[Docker] 생활코딩 입문 수업 정리","uri":"/02-docker/"},{"categories":["ML Engineering"],"content":"생활코딩 리눅스 명령어 정리 ","date":"2021-12-03","objectID":"/01-linux/:0:0","tags":["Linux"],"title":"[Linux] 리눅스 명령어","uri":"/01-linux/"},{"categories":["ML Engineering"],"content":"file \u0026 directory pwd : 현재 경로 확인 ls : 현재 위치에 있는 파일, 디렉토리들 확인 ls -l : 파일, 디렉토리들 정보도 같이 확인 가능 ls -a : 감춰진 것들도 확인 가능 ls -al : 위 두개를 동시에 확인 mkdir 디렉토리이름 : 디렉토리 만들기 cd 특정위치 : 특정위치로 이동 (절대경로, 상대경로 모두 사용가능) rm : 파일 삭제 rm -r 디렉토리 : directory를 rm으로 삭제가 안되고 이 명령어 사용 rmdir : directory를 삭제 touch : 파일 만들때 쓰는듯 ","date":"2021-12-03","objectID":"/01-linux/:0:1","tags":["Linux"],"title":"[Linux] 리눅스 명령어","uri":"/01-linux/"},{"categories":["ML Engineering"],"content":"help \u0026 man 명령어 --help : 해당 명령어에 대한 설명이 나옴 man 명령어 : 더 자세히 설명이 나오는듯 ","date":"2021-12-03","objectID":"/01-linux/:0:2","tags":["Linux"],"title":"[Linux] 리눅스 명령어","uri":"/01-linux/"},{"categories":["ML Engineering"],"content":"파일이동, 복사 cp 복사당할파일위치 복사할파일위치 : 파일복사 예시) cp /home/a.txt /home/move/b.txt mv 이동당할파일위치 이동할파일위치 : 파일이동 파일이름 바꾸때도 mv 쓰면 되겠구나 ","date":"2021-12-03","objectID":"/01-linux/:0:3","tags":["Linux"],"title":"[Linux] 리눅스 명령어","uri":"/01-linux/"},{"categories":["ML Engineering"],"content":"sudo sudo : super user do 각각의 사용자마다 권한을 다르게 지정되어있는데 일반적인 사용자의 경우 sudo를 통해 강한 권한 ","date":"2021-12-03","objectID":"/01-linux/:0:4","tags":["Linux"],"title":"[Linux] 리눅스 명령어","uri":"/01-linux/"},{"categories":["ML Engineering"],"content":"package manager apt라는 package manager를 사용해보자 apt-get update : 이 명령어를 통해 최신상태 소프트웨어 목록을 다운받는다 apt-cache search 원하는소프트웨어 : 위에서 다운받은 목록에서 원하는 소프트웨어와 관련한 내용을 보여준다 apt-get install 원하는소프트웨어 : 해당 소프트웨어 다운 apt-get upgrade 원하는소프트웨어 : 해당 소프트웨어 업그레이드 apt-get upgrade 그냥 이렇게 하면 전부 다 업그레이드 apt-get remove 원하는소프트웨어 : 해당 소프트웨어 삭제 ","date":"2021-12-03","objectID":"/01-linux/:0:5","tags":["Linux"],"title":"[Linux] 리눅스 명령어","uri":"/01-linux/"},{"categories":["ML Engineering"],"content":"file download : wget wget 다운받을주소 : 파일다운로드 wget -O 저장하고싶은이름 다운받을주소 : 원하는 이름으로 파일이 저장된다 ","date":"2021-12-03","objectID":"/01-linux/:0:6","tags":["Linux"],"title":"[Linux] 리눅스 명령어","uri":"/01-linux/"},{"categories":["ML Engineering"],"content":"why CLI? GUI보다 메모리도 덜 먹고 편함 연속적으로 명령이 가능! 예를 들어 mkdir minsoo; cd minsoo ; 세미콜론은 그냥 편의상 명령어를 구분하는 역할 근데 주의! 앞의 명령어가 오류가 나도 뒤의 명령어가 진행된다 ","date":"2021-12-03","objectID":"/01-linux/:0:7","tags":["Linux"],"title":"[Linux] 리눅스 명령어","uri":"/01-linux/"},{"categories":["ML Engineering"],"content":"pipeline cat sample.txt : sample.txt 파일을 보여준다 grep 특정단어 특정파일 : 특정파일에 특정단어가 들어가있는 행을 보여준다. pipeline 예시 (| 사용) ls --help | grep sort ","date":"2021-12-03","objectID":"/01-linux/:0:8","tags":["Linux"],"title":"[Linux] 리눅스 명령어","uri":"/01-linux/"},{"categories":["ML Engineering"],"content":"IO Redirection \u003e ls -l \u003e result.txt : 앞의 내용(standard output)을 result.txt로 redirection해서 파일을 만든다. 근데 이때 \u003e는 1\u003e을 의미한다. 이는 standard output을 redirection할때 사용하는 것이다. 근데 rm result.txt이 에러가 나는 명령어라고 가정하면 이는 standard error이고 이를 rediection하기 위해서는 rm result.txt 2\u003e error.txt 해야한다. cat cat result.txt 와 cat \u003c result.txt는 똑같은 결과는 낸다. 다른점은? 전자의 경우는 result.txt를 Command-line Argument로 받은 것이고 후자는 Standard input으로 받은 것! \u003e\u003e 기존에 result.txt 파일이 있다고 하면 예를 들어, ls -al \u003e\u003e result.txt 하면 ls -al의 결과가 result.txt에 append된다. ","date":"2021-12-03","objectID":"/01-linux/:0:9","tags":["Linux"],"title":"[Linux] 리눅스 명령어","uri":"/01-linux/"},{"categories":["ML Engineering"],"content":"Directory structure /bin : user binaries, 우리가 사용하는 명령어들 /sbin : system binaries /etc : configuration files, 설정 /var : variable files /home : home directories, user들의 file 기타등등 ","date":"2021-12-03","objectID":"/01-linux/:0:10","tags":["Linux"],"title":"[Linux] 리눅스 명령어","uri":"/01-linux/"},{"categories":["ML Engineering"],"content":"file find : locate, find, whereis locate 원하는파일 : 원하는 파일 찾을 수 있다 find 원하는파일 : 원하는 파일 찾을 수 있다 더 다양한 사용법이 존재 whereis : 주로 명령어, binary 파일 위치 찾을 때 쓰는듯 which : 사용하는 명령어의 위치 알려줌 ","date":"2021-12-03","objectID":"/01-linux/:0:11","tags":["Linux"],"title":"[Linux] 리눅스 명령어","uri":"/01-linux/"},{"categories":["ML Engineering"],"content":"background execute 어떤 프로그램을 사용하다가 Ctrl+Z를 누르면 해당 프로그램이 background로 간다 그리고 jobs 라는 명령어를 치면 background에 돌아가는 프로그램을 보여준다 원하는 background에 있는 프로그램에 돌아가려면 fg %해당프로그림의번호 명령어를 이용하면 된다 \u0026 시간이 오래걸리는 프로그램이 있으면 ~명령어~ \u0026를 통해서 바로 background로 보내고 나는 다른 일을 하면 된다 ","date":"2021-12-03","objectID":"/01-linux/:0:12","tags":["Linux"],"title":"[Linux] 리눅스 명령어","uri":"/01-linux/"},{"categories":["ML Engineering"],"content":"daemon ls, rm ... 과 같은 프로그램은 필요할 때만 사용 그렇다면 항상 켜져있도록하는 프로그램도 있을 것! ex) server 이를 daemon이라고 한다 /etc/init.d : 여기에 daemon 파일들이 있다 service 프로그램 start, service 프로그램 stop 컴퓨터 시작할 때 자동으로 실행되도록 하고 싶으면 /etc/rc3.d에 link를 만들면 된다 ","date":"2021-12-03","objectID":"/01-linux/:0:13","tags":["Linux"],"title":"[Linux] 리눅스 명령어","uri":"/01-linux/"},{"categories":["ML Engineering"],"content":"CRON CRON : 정기적으로 명령을 실행시켜주는 도구 예를 들어, 사용자가 server로 메일을 보내면 바로 완료되었다고 뜨지만 server에서는 해당내용을 체크만 하고 cron을 통해서 체크된 내용을 정기적으로 진행한다 crontab crontab -e 명령어를 치면 에디터가 열리고 거기에 명령어를 만들어주면 된다 ","date":"2021-12-03","objectID":"/01-linux/:0:14","tags":["Linux"],"title":"[Linux] 리눅스 명령어","uri":"/01-linux/"},{"categories":["ML Engineering"],"content":"startup scipt shell을 시작할 때, 특정 명령어 실행되도록 하는 것 에디터로 .bashrc 파일을 열어보면 이미 만들어져있다 여기에 원하는 명령어를 추가하면 된다 예를 들어, alias l='ls -al' 이렇게 별명을 붙여주기가 가능하는데 이런거는 미리 만들어두면 편하게 이용할 수 있을 것이다 ","date":"2021-12-03","objectID":"/01-linux/:0:15","tags":["Linux"],"title":"[Linux] 리눅스 명령어","uri":"/01-linux/"},{"categories":["ML Engineering"],"content":"Mult user id id 명령어를 치면 지금 user에 대한 정보 보여준다 who who 명령어를 치면 누가 접속했는지 보여준다 ","date":"2021-12-03","objectID":"/01-linux/:0:16","tags":["Linux"],"title":"[Linux] 리눅스 명령어","uri":"/01-linux/"},{"categories":["ML Engineering"],"content":"Root user 리눅스에는 크게 두 가지 user super(root) user user sudo 명령어로 user가 root user처럼 명령할 수 있다 하지만 아무나 사용은 못하고 이를 사용할 수 있도록 명령어를 추가로 해야한다 su 사용자이름 명령어를 통해 user를 바꿀 수 있다 ","date":"2021-12-03","objectID":"/01-linux/:0:17","tags":["Linux"],"title":"[Linux] 리눅스 명령어","uri":"/01-linux/"},{"categories":["ML Engineering"],"content":"Add user useradd -m 이름 : 해당 이름 user가 만들어진다 passwd 이름 : 해당 이름에서 사용한 비밀번호 지정 ","date":"2021-12-03","objectID":"/01-linux/:0:18","tags":["Linux"],"title":"[Linux] 리눅스 명령어","uri":"/01-linux/"},{"categories":["ML Engineering"],"content":"Permission file, directory에 대해 user의 권한을 지정 read, write, excute 에 대한 권한을 지정 -rw-r--r-- 1 root root 485 Jul 2 12:38 result.txt : ls -l result.txt 라는 명령어를 친 결과 -rw-r--r-- 에서 맨 앞은 type(file or directory), 뒷부분은 access mode를 의미 rw-r--r-- : 여기에서 rw-는 owner의 권한, r--는 그룹의 권한, r--는 나머지들의 권한 root root 에서 앞부분은 owner, 뒤부분은 group을 의미 directory에서 read를 안에있는 파일을 읽을수있는지, write는 안에있는 파일을 수정할수있는지, execute는 해당 directory에 들어갈수있는지 chmod r : read, w : write, x : excute 위에서 chomod o-r result.txt하면 나머지들은 read도 못한다 추가는 chomod o+r result.txt 이런식으로 가능 u, g, o, a 에 +,-,= 연산자와 mode 이용 Octal modes도 있다 예를들어 chomod 111 result.txt 처럼 owner, group, other 모두 한번에 1(excute only)이 되도록 한다 ","date":"2021-12-03","objectID":"/01-linux/:0:19","tags":["Linux"],"title":"[Linux] 리눅스 명령어","uri":"/01-linux/"},{"categories":["ML Engineering"],"content":"Reference (생활코드)[https://www.youtube.com/playlist?list=PLuHgQVnccGMBT57a9dvEtd6OuWpugF9SH] ","date":"2021-12-03","objectID":"/01-linux/:0:20","tags":["Linux"],"title":"[Linux] 리눅스 명령어","uri":"/01-linux/"},{"categories":["Deep Generative Model"],"content":"Auto-Encoding Variational Bayes (2014) ","date":"2021-12-03","objectID":"/07-vae/:0:0","tags":["VAE"],"title":"[Generative Model] VAE","uri":"/07-vae/"},{"categories":["Deep Generative Model"],"content":"Introduction 저자들은 continuous latent variables나 parameters with intractable posterior를 가진 model을 학습하거나 추론시에 approximation을 잘하는 방법을 찾고 싶어 했다. 그래서 이 논문을 통해 Auto-Encoding VB algorithm을 제시하는 것이다. ","date":"2021-12-03","objectID":"/07-vae/:1:0","tags":["VAE"],"title":"[Generative Model] VAE","uri":"/07-vae/"},{"categories":["Deep Generative Model"],"content":"Problem setting dataset $\\textbf{X} = { \\textbf{x}^{(i)} }_{i=1}^{N}$이고 각 sample은 iid continuous or discrete varable이다. 이러한 data가 만들어지는 과정에 있어서 latent(unobserved) continuous random variable $\\textbf{z}$가 있다고 가정하자. 그 과정은 그렇다면 두 가지로 생각할 수 있는데 a value $\\textbf{z}^{(i)}$가 prior distribution $p(\\textbf{z};\\theta)$에서 생성된다. a value $\\textbf{x}^{(i)}$가 conditional distribution $p(\\textbf{x}|\\textbf{z};\\theta)$에서 생성된다. 또한 위의 두 prior와 likelihood는 parametric하며 $\\theta, \\textbf{z}$에 대해 미분가능 하다고 한다. 이러한 경우에 있어서 Intractability, large dataset의 경우에도 문제를 해결할 수 있는 solution을 찾아야한다. Intractability : marginal likelihood $p(\\textbf{x})=\\int p(\\textbf{z};\\theta) p(\\textbf{x}|\\textbf{z};\\theta)d\\textbf{z}$가 intractable한 경우를 의미한다. 이는 posterior $p(\\textbf{z}|\\textbf{x})=p(\\textbf{x}|\\textbf{z};\\theta)p(\\textbf{z};\\theta)/p(\\textbf{x};\\theta)$ 또한 구할 수 없게 된다. large dataset : Sampling기반의 방법들은 너무 느리다. 그래서 저자들은 해결하고 싶은 3가지를 제시한다. Efficient approximate ML or MAP estimation for the parameters $\\theta$ parameter를 잘 구한다면 이전에는 몰랐던 generation process에 대해 파악할 수 있다. Efficient approximate posterior inference of the latent variable $\\textbf{z}$ given an observed value $\\textbf{x}$ for a choice of parameters $\\theta$ latent variable에 대한 파악을 통해 representation task가 가능하다. Efficient approximate marginal inference of the variable $\\textbf{x}$ $\\textbf{x}$에 대한 이해 필요한 task, 예를 들어 vision분야에서 image denoising, super-resolution 등의 task를 할 수 있게 된다. 이를 위해 저자들은 recognition model $q(\\textbf{z}|\\textbf{x};\\phi)$를 이용한다. 이는 intractable true posterior $p(\\textbf{z}|\\textbf{x};\\theta)$에 대한 approximation이다. generative model에 해당하는 $p(\\textbf{x}|\\textbf{z};\\theta)$와 함께 parameter를 학습하게 된다. ","date":"2021-12-03","objectID":"/07-vae/:2:0","tags":["VAE"],"title":"[Generative Model] VAE","uri":"/07-vae/"},{"categories":["Deep Generative Model"],"content":"Variational bound 이전(참고링크)에 variational inference를 통해 아래의 과정을 이해할 수 있다. log marginal likelihood는 $\\sum \\log p(\\textbf{x}^{(i)})$이고 각 data point마다 살펴보자. $$\\log p(\\textbf{x}^{(i)};\\theta)=D_{KL}[q(\\textbf{z}|\\textbf{x};\\phi) || p(\\textbf{z}|\\textbf{x};\\theta)]+L(\\theta,\\phi,;\\textbf{x}^{(i)})$$ $$\\log p(\\textbf{x}^{(i)}; \\theta) \\ge L(\\theta,\\phi,; \\textbf{x}^{(i)})$$ $$=E_{q(\\textbf{z}|\\textbf{x};\\phi)}[-\\log q(\\textbf{z}|\\textbf{x};\\phi)+\\log p(\\textbf{x},\\text{z};\\theta)] $$ $$= -D_{KL}[q(\\textbf{z}|\\textbf{x};\\phi) || p(\\textbf{z};\\theta)]+E_{q(\\textbf{z}|\\textbf{x};\\phi)}[\\log p(\\textbf{x}^{(i)}|\\textbf{z};\\theta)]$$ 결국 우리는 Lower bound를 최대화해야 한다. 이를 위해 Lower bound는 variational parameter $\\phi$와 generative parameter $\\theta$에 대해 미분하여 optimize한다. 바로 구할 수 없기 때문에 이를 위해서 lower bound에 대한 estimator가 필요하고 이는 sampling에 기반한다. 아래에서 살펴보자. ","date":"2021-12-03","objectID":"/07-vae/:3:0","tags":["VAE"],"title":"[Generative Model] VAE","uri":"/07-vae/"},{"categories":["Deep Generative Model"],"content":"Reparameterization trick $z \\sim q_{\\phi}(z|x)$ 라고 하자. random variable $z$를 deterministic variable $z=g_{\\phi}(\\epsilon, x)$로 표현할 수 있는 경우도 있다. ($\\epsilon$ : auxiliary variable with independent marginal $p(\\epsilon)$) 왜 이렇게 해야할까? 이렇게 reparametrization을 하면 $q_{\\phi}(z|x)$에 대한 expectation을 $\\phi$에 대해 미분이 가능한 Monte Carlo estimate of the expectation으로 근사해서 구할 수 있기 때문이다. (미분이 가능하다면? neural net에서 사용할 수 있겠구나~) $$\\int q_{\\phi}(z|x)f(z)dz \\approx \\frac{1}{L}\\sum_{l=1}^{L}f(g_{\\phi}(\\epsilon^{(l)}, x))$$ 이를 VAE에서 사용한 normal분포의 예시를 통해 이해해보자. $$z\\sim p(z|x)=N(\\mu, \\sigma^2)$$ $$\\text{reparameterize:};z=\\mu+\\sigma\\epsilon,; \\epsilon\\sim N(0,1)$$ $$\\therefore E_{N(z;\\mu, \\sigma^2)}[f(z)]\\approx \\frac{1}{L}\\sum_{l=1}^{L} f(\\mu+\\sigma\\epsilon^{(l)})$$ ","date":"2021-12-03","objectID":"/07-vae/:4:0","tags":["VAE"],"title":"[Generative Model] VAE","uri":"/07-vae/"},{"categories":["Deep Generative Model"],"content":"SGVB estimator and AEVB algorithm 위에서 lower bound에 대한 식을 2개 살펴보았다. 각각에 대한 estimator를 알아볼 것이다. 후자가 variance가 더 작기에 우리는 후자를 사용한다. (sampling을 덜 하기 때문) 후자의 경우 KL-divergence term을 analytically 구할 수 있기 때문이다. (appendix 참고) $$\\tilde{L1}(\\theta,\\phi;\\textbf{x}^{(i)})=\\frac{1}{L}\\sum_{l=1}^L [ \\log p(\\textbf{x}^{(i)},\\textbf{z}^{(i,l)};\\theta)-\\log q(\\textbf{z}^{(i,l)}|\\textbf{x}^{(i)};\\phi)]\\ \\text{where } \\textbf{z}^{(i,l)} \\\\ =g(\\epsilon^{(i,l)},\\textbf{x}^{(i)})\\;\\text{and}\\;\\epsilon^{(l)}\\sim p(\\epsilon)$$ $$\\tilde{L2}(\\theta,\\phi;\\textbf{x}^{(i)})=-D_{KL}[q(\\textbf{z}|\\textbf{x};\\phi) || p(\\textbf{z};\\theta)]+\\frac{1}{L}\\sum_{l=1}^L[\\log p(\\textbf{x}^{(i)}|\\textbf{z}^{(i,l)};\\theta)]\\ \\text{where } \\textbf{z}^{(i,l)} \\\\ =g(\\epsilon^{(i,l)},\\textbf{x}^{(i)})\\;\\text{and}\\;\\epsilon^{(l)}\\sim p(\\epsilon)$$ 위의 식을 이용하여 우리는 $M$개의 data point로 이루어진 minibatch에 기반하여 estimator를 구할 수 있다. $$L(\\theta, \\phi; \\textbf{X})\\approx\\tilde{L}^M (\\theta, \\phi; \\textbf{X}^M)=\\frac{N}{M}\\sum_{i=1}^M \\tilde{L}(\\theta, \\phi; \\textbf{x}^{(i)}) $$ ","date":"2021-12-03","objectID":"/07-vae/:5:0","tags":["VAE"],"title":"[Generative Model] VAE","uri":"/07-vae/"},{"categories":["Deep Generative Model"],"content":"Variational AutoEncoder 그렇다면 위의 과정을 통해 parametric model로 deep network를 사용하자. probabilistic encoder $q(\\textbf{z}|\\textbf{x};\\phi)$에 neural network 사용 latent variables에 대한 prior $p(\\textbf{z})$는 centered isotropic multivariate Gaussian $N(\\textbf{0}, \\textbf{I})$으로 가정 decoder $p(\\textbf{x}|\\textbf{z};\\theta)$는 task에 따라 multivariate Gaussian (in case of real-valued data) 또는 Bernoulli (in case of binary data) whose distribution parameters are computed from $\\textbf{z}$ with a MLP variational approximate posterior 는 multivariate Gaussian with a diagonal covariance structure (이 분포의 parameter는 encoder의 output) : $$\\log q_{\\phi}(\\textbf{z}|\\textbf{x}^{(i)}) = \\log N(\\textbf{z};\\boldsymbol{\\mu}^{(i)},\\boldsymbol{\\sigma}^{2(i)}\\textbf{I})$$ 최종적으로 data point $x^{(i)}$의 estimator은 $$L(\\boldsymbol{\\theta} ,\\boldsymbol{\\phi};\\textbf{x}^{(i)})\\approx \\frac{1}{2}\\sum_{j=1}^{J}(1+\\log(\\sigma_{j}^{2(i)}) -\\mu_{j}^{2(i)} - \\sigma_{j}^{2(i)}) + \\frac{1}{L}\\sum_{l=1}^L \\log p_{\\boldsymbol{\\theta}}(\\textbf{x}^{(i)} | \\textbf{z}^{(i,l)}) $$ $$ \\textbf{z}^{(i,l)} = \\boldsymbol{\\mu}^{(i)}+\\boldsymbol{\\sigma}^{(i)} \\odot \\boldsymbol{\\epsilon}^{(l)},; \\boldsymbol{\\epsilon}^{(l)} \\sim N(\\textbf{0},\\textbf{I})$$ 여기에 음수부호를 붙여서 VAE의 loss function이 되는 것이다. ","date":"2021-12-03","objectID":"/07-vae/:6:0","tags":["VAE"],"title":"[Generative Model] VAE","uri":"/07-vae/"},{"categories":["Deep Generative Model"],"content":"Deep Variational Information Bottelneck 논문을 간단하게 리뷰하였다. models trained with the VIB objective outperform those that are trained with other forms of regularization, in terms of generalization performance and robustness to adversarial attack deep network에 정보이론은 접목시켜보자. 먼저, encoder $p(\\boldsymbol{z}|\\boldsymbol{x};\\boldsymbol{\\theta})$가 있고 우리는 target Y에 대한 정보를 최대한 담고있는 encoder를 만들고자 한다. 이를 mutual information으로 접근해보자. 아래의 식을 최대화하는 것이 목표이다. $$I(Z,Y;\\theta)=\\int dxdyp(z,y|\\theta)\\log\\frac{p(z,y|\\theta)}{p(z|\\theta)p(y|\\theta)}$$ 그런데 아무런 제약식이 없으면 위의 식은 Z=X일 때 최대가 된다. 따라서 제약식 $I(X,Z)\\le I_{c}$라는 제약식을 넣어으면 최종 objective는 아래의 식이 된다. $$\\max_{\\theta}I(Z,Y;\\theta)-\\beta I(Z,X;\\theta)$$ 결국 우리는 Y에 대해 최대한 expressive하고 동시에 X에 대해 compressive한 encoding Z를 구하는 것이 목표인 것이다. 이런 접근을 information bottleneck (IB) 이라고 한다. 이제 이를 최적화하는 과정을 수식으로 살펴보자. Assume : $$p(X,Y,Z) =p(Z|X,Y)p(Y|X)p(X)=p(Z|X)p(Y|X)p(X)\\\\ \\rightarrow p(Z|X,Y)=p(Z|X)$$ $I(Z,Y) :$ $$I(Z,Y) =\\int dydzp(y,z)\\log\\frac{p(y,z)}{p(y)p(z)}\\\\ =\\int dydzp(y,z)\\log\\frac{p(y|z)}{p(y)}p(y|z)\\\\ =\\int dxp(x,y|z) =\\int dx\\frac{p(z|x)p(y|x)p(x)}{p(z)}$$ $$q(y|z)\\text{ : variational approximation to } p(y|z)$$ $$KL\\left[p(Y|Z),q(Y|Z)\\right] =\\int dyp(y|z)\\log\\frac{p(y|z)}{q(y|z)}\\ge 0 \\\\ \\rightarrow \\int dyp(y|z)\\log p(y|z) \\ge\\int dyp(y|z)\\log q(y|z)$$ $$I(Z,Y) \\ge\\int dydzp(y,z)\\log\\frac{q(y|z)}{p(y)}\\\\ =\\int dydzp(y,z)\\log q(y|z)-\\int dyp(y)\\log p(y)\\\\ =\\int dydzp(y,z)\\log q(y|z)+H(Y)$$ $$\\therefore I(Z,Y) \\ge\\int dxdydzp(x,y,z)\\log q(y|z)\\\\ =\\int dxdydzp(z|x)p(y|x)p(x)\\log q(y|z)$$ $\\beta I(Z,X) :$ $$I(Z,X)=\\int dzdxp(x,z)\\log\\frac{p(z|x)}{p(z)}\\\\ =\\int dzdxp(x,z)\\log p(z|x)-\\int dzp(z)\\log(z)$$ $$r(x)\\text{ : variational approximation to }p(z)$$ $$KL\\left[p(Z),r(Z)\\right] =\\int dzp(z)\\log\\frac{p(z)}{r(z)}\\ge0 \\\\ \\rightarrow \\int dzp(z)\\log p(z)\\ge\\int dzp(z)\\log r(z)$$ $$\\therefore I(Z,X)\\le\\int dxdzp(x)p(z|x)\\log\\frac{p(z|x)}{r(z)}$$ • 위에서 구한 결과를 통해 $$I(Z,Y)-\\beta I(Z,X) \\ge L \\\\ = \\int dxdydzp(z|x)p(y|x)p(x)\\log q(y|z) - \\beta\\int dxdzp(x)p(z|x)\\log\\frac{p(z|x)}{r(z)}\\\\ \\approx\\frac{1}{N}\\sum_{n=1}^{N}\\left[\\int dz\\{ p(z|x_{n})\\log q(y_{n}|z)-\\beta p(z|x_{n})\\log\\frac{p(z|x_{n})}{r(z)}\\} \\right]$$ $$\\text{encoder of the form } p(z|x)=N(z|f_{e}^{\\mu}(x),f_{e}^{\\Sigma}(x))\\rightarrow \\text{ reparameterization trick}$$ $$J_{IB}=\\frac{1}{N}\\sum_{n=1}^{N}E_{\\epsilon\\sim p(\\epsilon)}\\left[-\\log q(y_{n}|f(x_{n},\\epsilon))\\right]+\\beta KL\\left[p(Z|x_{n}),r(Z)\\right]$$ 지금까지 Deep network를 이용하여 IB를 최적화과정을 알아보았다. 위의 결과(단 위의 과정은 label을 이용하는 supervised learning)와 과정을 보다보면 VAE 모델과 유사한 부분이 많음을 알 수 있고 논문에서도 둘의 관계를 설명하고 있다. VAE는 generative model이기에 Y 대신에 X를 넣어서 전개하면 된다. $$I(Z,X) =\\int dxdzp(x,z)\\log\\frac{p(x,z)}{p(x)p(z)}\\\\ =\\int dxdzp(x,z)\\log\\frac{p(x|z)}{p(x)}\\\\ =\\int dzp(z)\\int dxp(x|z)\\log p(x|z)+H(x)\\\\ \\ge\\int dzp(z)\\int dxp(x|z)\\log q(x|z)\\\\ =\\int dxp(x)\\int dzp(z|x)\\log q(x|z)I(Z,i)\\\\ =\\frac{1}{N}\\sum_{i}\\int dzp(z|x_{i})\\log\\frac{p(z|x_{i})}{p(z)} \\le\\frac{1}{N}\\sum_{i}\\int dzp(z|x_{i})\\log\\frac{p(z|x_{i})}{r(z)}$$ $$\\therefore I(Z,X)-\\beta I(Z,i)\\le\\int dxp(x)\\int dzp(z|x)\\log q(x|z)-\\beta\\frac{1}{N}\\sum_{i}KL\\left[p(Z|x_{i}),r(Z)\\right]$$ 이는 VAE의 형태이다. 수식은 비슷해보이지만 해석적인 부분에서 차이는 존재한다. VAE는 encoder $p(z|x)$부분에서 $q(z|x)$으로 variational approximation하지만 IB에서는 decoder $p(x|z)$부분을 approximation한다. ","date":"2021-12-03","objectID":"/06-ib/:0:0","tags":["VIB"],"title":"[Generative Model] Deep Variational Information Bottelneck (ICLR 2017)","uri":"/06-ib/"},{"categories":["Deep Generative Model"],"content":"TimeGAN 논문을 간단하게 리뷰하였다. ","date":"2021-12-03","objectID":"/05-timegan/:0:0","tags":["TimeGAN"],"title":"[Generative Model] TimeGAN","uri":"/05-timegan/"},{"categories":["Deep Generative Model"],"content":"Time-series Generative Adversarial Networks (NeurIPS 2019) synthetic sequential data를 만들어내는 알고리즘이다. GAN으로 만드는 다른 data들과 가장 큰 차이는 temporal dynamics를 잘 잡아내야한다는 것이다. 그렇다면 TimeGAN이 어떤식으로 문제들을 해결했는지 살펴보자. 일단 TimeGAN이 다른 GAN과 다른 점을 알아보자. unsupervised adversarial loss on both real and synthetic data는 동일 supervised loss 추가 to capture the stepwise conditional distributions in the data embedding network 추가 to provide a reversible mapping between features and latent representations thereby reducing the high-dimensionality of the adversarial learning space can handle the mixed-data static과 time-series data를 같이 생성할 수 있다. 그렇다면 이제 TimeGAN이 어떻게 이루어져있는지 살펴보자. TimeGAN은 크게 4개의 network로 이루어져있다. embedding function recovery function sequence generator sequence discriminator ","date":"2021-12-03","objectID":"/05-timegan/:1:0","tags":["TimeGAN"],"title":"[Generative Model] TimeGAN","uri":"/05-timegan/"},{"categories":["Deep Generative Model"],"content":"Embedding and Recovery Functions Embedding, Recovery function은 feature와 latent space를 매핑하는 역할을 한다. 이를 통해 adversarial network가 lower-dimension으로 underlying temporal dynamics를 학습할 수 있게 된다. (lower-dim adversarial learning space) $\\mathcal{H_{S}},;\\mathcal{H_{X}}$ : latent vector spaces of feature space $\\mathcal{S},;\\mathcal{X}$ $e$ : embedding function $$\\mathcal{S}\\times\\prod_{t}\\mathcal{X}\\rightarrow\\mathcal{H_{S}\\times\\prod} _ {t}\\mathcal{H_{X}}$$ takes static \u0026 temporal features to latent codes $$\\boldsymbol{h} _ {S},\\boldsymbol{h} _ {1:T}=e(\\boldsymbol{s},\\boldsymbol{x} _ {1:T})$$ $$\\boldsymbol{h} _ {S} = e _ {S}(\\boldsymbol{s}),\\;\\boldsymbol{h} _ {t} = e _ {\\mathcal{X}}(\\boldsymbol{h} _ {S},\\boldsymbol{h} _ {t-1},\\boldsymbol{x} _ {t})$$ $e$는 recurrent network로 만든다 $r$ : recovery function $$\\mathcal{H_{S}\\times\\prod} _ {t}\\mathcal{H_{X}}\\rightarrow\\mathcal{S}\\times\\prod_{t}\\mathcal{X}$$ takes latent codes to feature representations $$\\tilde{\\boldsymbol{s}},\\tilde{\\boldsymbol{x}} _ {1:T}=r(\\boldsymbol{h} _ {S},\\boldsymbol{h} _ {1:T})$$ $$\\tilde{\\boldsymbol{s}}=r_{S}(\\boldsymbol{h} _ {s}),\\; \\tilde{\\boldsymbol{x} _ {t}}=r_{\\mathcal{X}}(\\boldsymbol{h}_{t})$$ – $r$은 feedforward network로 만든다 Embedding, Recovery function들은 꼭 위의 network가 아니여도 attention, temporal convolution등을 통해 만들 수도 있다. ","date":"2021-12-03","objectID":"/05-timegan/:1:1","tags":["TimeGAN"],"title":"[Generative Model] TimeGAN","uri":"/05-timegan/"},{"categories":["Deep Generative Model"],"content":"Sequence Generator and Discriminator 일반적인 GAN처럼 feature space에서 바로 데이터를 만드는 것이 아니라 generator는 embedding space를 만든다. $\\mathcal{Z_{S}}.;\\mathcal{Z_{X}}$ : vector spaces over which known distributions are defined (generator의 input으로 r.v를 뽑아낸다) $g$ : generator function $$\\mathcal{Z_{S}}\\times\\prod_{t}\\mathcal{Z_{X}}\\rightarrow\\mathcal{H_{S}\\times\\prod} _ {t}\\mathcal{H _ {X}}$$ takes a tuple of static and temporal random vectors to synthetic latent codes $$\\hat{\\boldsymbol{h}} _ {S},\\hat{\\boldsymbol{h}} _ {1:T}=g(\\boldsymbol{z} _ {S},\\boldsymbol{z} _ {1:T})$$ $$\\hat{\\boldsymbol{h}} _ {S} = g _ {S}(\\boldsymbol{z} _ {S}),\\;,\\hat{\\boldsymbol{h}} _ {t} = g _ {\\mathcal{X}}(\\hat{\\boldsymbol{h}} _ {S},\\hat{\\boldsymbol{h}} _ {t-1,}\\boldsymbol{z} _ {t})$$ $g$는 recurrent network discriminator는 embedding space에서 나온 값은 input으로 받는 것이다. $d$ : discrimination function $\\mathcal{H_{S}\\times\\prod} _ {t}\\mathcal{H _ {X}}\\rightarrow[0,1]\\times\\prod_{t}[0,1]$ receives the static and temporal codes, returning classification $$\\tilde{y} _ {S},\\tilde{y} _ {1:T}=d(\\boldsymbol{h} _ {S},\\boldsymbol{h} _ {1:T})$$ $$\\tilde{y} _ {\\mathcal{S}} = d_{\\mathcal{S}}(\\tilde{\\boldsymbol{h}} _ {\\mathcal{S}}),\\; \\tilde{y} _ {t} = d _ {\\mathcal{X}}(\\overleftarrow{\\boldsymbol{u}} _ {t},\\overrightarrow{\\boldsymbol{u}} _ {t})$$ $$\\text{where } \\overrightarrow{\\boldsymbol{u}} _ {t}=\\overrightarrow{c} _ {\\mathcal{X}}(\\tilde{\\boldsymbol{h}} _ {\\mathcal{S}},\\tilde{\\boldsymbol{h}} _ {t},\\overrightarrow{\\boldsymbol{u}} _ {t-1}),\\;\\overleftarrow{\\boldsymbol{u}} _ {t} = \\overleftarrow{c} _ {\\mathcal{X}}(\\tilde{\\boldsymbol{h}} _ {\\mathcal{S}},\\tilde{\\boldsymbol{h}} _ {t},\\overleftarrow{\\boldsymbol{u}} _ {t+1}))$$ $d$는 bidirectional recurrent network with a feeforward output layer ","date":"2021-12-03","objectID":"/05-timegan/:1:2","tags":["TimeGAN"],"title":"[Generative Model] TimeGAN","uri":"/05-timegan/"},{"categories":["Deep Generative Model"],"content":"Jointly Learning to Encode, Generate, and Iterate reconstruction loss $$L_{R} = E_{\\boldsymbol{s},\\boldsymbol{x} _ {1:T\\sim P}}\\left[\\left\\Vert \\boldsymbol{s}-\\tilde{\\boldsymbol{s}}\\right\\Vert _{2} + \\sum _ {t}\\left\\Vert \\boldsymbol{x} _ {t}-\\tilde{\\boldsymbol{x} _ {t}}\\right\\Vert _{2}\\right]$$ unsupervised loss $$L_{U} = E_{\\boldsymbol{s},\\boldsymbol{x} _ {1:T\\sim P}}\\left[\\log y_{\\mathcal{S}} + \\sum_{t}\\log y_{t}\\right]+E_{\\boldsymbol{s},\\boldsymbol{x} _ {1:T\\sim\\hat{P}}}\\left[\\log(1-\\hat{y} _ {\\mathcal{S}})+\\sum_{t}\\log(1-\\hat{y}_{t})\\right]$$ 위의 discriminator를 통해 unsupervised loss는 부족하다고 판단되었다. 따라서 추가적으로 generator를 효율적으로 학습시키기 위해 superviesd loss를 추가로 사용하였다. generator는 실제 data의 sequences of embeddings $\\boldsymbol{h}_{1:t-1}$의 값을 받는 것이다. 이를 통해 temporal dynamics를 더 잘 잡을 수 있었다고 한다. supervised loss $$L_{S}=E_{\\boldsymbol{s},\\boldsymbol{x} _ {1:T\\sim P}}\\left[\\sum_{t}\\left\\Vert \\boldsymbol{h} _ {t} - g _ {\\mathcal{X}}(\\boldsymbol{h} _ {\\mathcal{S}},\\boldsymbol{h} _ {t-1,}\\boldsymbol{z}_{t})\\right\\Vert _{2}\\right]$$ ","date":"2021-12-03","objectID":"/05-timegan/:1:3","tags":["TimeGAN"],"title":"[Generative Model] TimeGAN","uri":"/05-timegan/"},{"categories":["Deep Generative Model"],"content":"Optimization $$\\text{min} _ {\\theta_{e}.\\theta_{r}}(\\lambda L_{S}+L_{R})$$ $$\\text{min} _ {\\theta_{g}}(\\eta L_{S}+\\text{max}_{\\theta _ {d}}L _ {U})$$ ","date":"2021-12-03","objectID":"/05-timegan/:1:4","tags":["TimeGAN"],"title":"[Generative Model] TimeGAN","uri":"/05-timegan/"},{"categories":["Deep Generative Model"],"content":"LSGAN 논문을 간단하게 리뷰하였다. ","date":"2021-12-03","objectID":"/04-lsgan/:0:0","tags":["LSGAN"],"title":"[Generative Model] LSGAN","uri":"/04-lsgan/"},{"categories":["Deep Generative Model"],"content":"Least Squares Generative Adversarial Networks (2017) GAN과 거의 똑같은 형태를 갖는다. 달라진 점은 loss function! 이라고 할 수 있다. 이를 통해 (vanilla) GAN이 갖고 있는 문제점을 어느 정도 해결하였고 더 좋은 성능을 보였다고 한다. GAN은 disciminator에서 sigmoid cross entropy loss function을 사용한다. 이는 fake data가 discriminator에 의해 real로 판단된 경우 문제가 생긴다. fake data가 정말 real해서 판단되면 상관이 없지만 real 차이가 많이 나는 경우에도 불구하고 real이라고 discriminator가 판단하는 경우가 있는 것이다. 이렇게 되면 generator를 학습할 때 해당하는 data를 통해 학습할 수 없게 된다. (gradient vanishing) 그래서 LSGAN은 위와 같은 data도 학습에 사용된다면 더 좋은 결과가 나오지 않을까? 라는 생각을 했다. 이를 위해 새로운 loss function을 제안한 것이다. ","date":"2021-12-03","objectID":"/04-lsgan/:1:0","tags":["LSGAN"],"title":"[Generative Model] LSGAN","uri":"/04-lsgan/"},{"categories":["Deep Generative Model"],"content":"LSGAN $a,b$는 각각 fake, real data labels $c$는 the value that $G$ wants to $D$ to believe for fake data $$\\min_D V(D)=\\frac{1}{2}E_{x\\sim p_{data}(x)}[(D(x)-b)^2]+\\frac{1}{2}E_{z\\sim p(z)}[(D(G(z))-a)^2]$$ $$\\min_G V(G)=\\frac{1}{2}E_{z\\sim p(z)}[(D(G(z))-c)^2]$$ 위와 같이 loss function을 바꾸면 LSGAN의 원하는대로 더 학습을 잘 시킬 수 있게 된다. ","date":"2021-12-03","objectID":"/04-lsgan/:1:1","tags":["LSGAN"],"title":"[Generative Model] LSGAN","uri":"/04-lsgan/"},{"categories":["Deep Generative Model"],"content":"Benefits of LSGANs 위에서 설명한대로 이미 잘 속인 경우에도 penalty를 주어서 최대한 real과 비슷하게 만들도록 한다. generator를 학습시킬 때, discriminator는 fixed시킨다. 즉, decision boundary가 고정된 상태에서 decision boundary쪽으로 data가 최대한 가까워지도록 만드는 것이다. 이 의미는 결국 최대한 긴가민가한 data를 만들겠다는 의도로 이해할 수 있다. (위의 같은 이유 덕에) 덤으로 LSGAN은 학습과정이 더 stable하다. ","date":"2021-12-03","objectID":"/04-lsgan/:1:2","tags":["LSGAN"],"title":"[Generative Model] LSGAN","uri":"/04-lsgan/"},{"categories":["Deep Generative Model"],"content":"Relation to f-divergence optimal discriminator $D$ for a fixed $G$ : $$D^* (x)=\\frac{bp_d (x)+ap_g(x)}{p_d(x)+p_g(x)}$$ Peason $\\chi^2$ divergence if we set $b-c=1,\\;b-a=2$ $\\min_D V(G)=\\frac{1}{2}E_{x\\sim p_{data}(x)}[(D(x)-c)^2]+\\frac{1}{2}E_{z\\sim p(z)}[(D(G(z))-c)^2]$ : 이를 최소화하는 것은 Peason $\\chi^2$ divergence between $p_d + p_g$ and $2p_g$ 를 최소화하는 것과 같다. $$2C(G)=E_{x\\sim p_{data}(x)}[(D^* (x)-c)^2]+E_{z\\sim p(z)}[(D^* (G(z))-c)^2]$$ $$ =\\chi^2 \\text{ Pearson} (p_d + p_g || 2p_g)$$ ","date":"2021-12-03","objectID":"/04-lsgan/:1:3","tags":["LSGAN"],"title":"[Generative Model] LSGAN","uri":"/04-lsgan/"},{"categories":["Deep Generative Model"],"content":"GAN의 논문과 youtube에서 본 내용을 간단히 정리하였다. ","date":"2021-12-03","objectID":"/03-gan/:0:0","tags":["GAN"],"title":"[Generative Model] GAN","uri":"/03-gan/"},{"categories":["Deep Generative Model"],"content":"Main problem and solution problem complex/high dimensional training distribution에서 sampling하고 싶다 근데 어렵다 solution Gan에서는 2-step으로 이 문제를 해결 sample from a simple distribution learn a transformation(by NN) to the training distribution ","date":"2021-12-03","objectID":"/03-gan/:1:0","tags":["GAN"],"title":"[Generative Model] GAN","uri":"/03-gan/"},{"categories":["Deep Generative Model"],"content":"GAN do not work with any explicit density function take a game-theoreric approach generator network directly produces samples $\\tilde{\\textbf{x}} = G(\\textbf{z};\\theta_g)$ $\\textbf{z}$는 random noise discriminator network train data와 generator가 만든 sample을 구분 ","date":"2021-12-03","objectID":"/03-gan/:2:0","tags":["GAN"],"title":"[Generative Model] GAN","uri":"/03-gan/"},{"categories":["Deep Generative Model"],"content":"Training objective function $$\\min_{\\theta_G} \\max_{\\theta_D} [E_{x\\sim p_{data}}\\log D_{\\theta_d}(x)+E_{z\\sim p(z)}\\log (1-D_{\\theta_d}(G_{\\theta_G}(z)))]$$ 실제 학습을 진행할 때는 두 네트워크를 동시에 학습시키지 않고 따로따로 업데이트를 한다. D를 학습시킬 때는 G를 고정한 상태에서, G를 학습시킬 때는 D를 고정한 상태에서 진행한다. 먼저, D를 학습하기 위해서는 G의 parameter를 고정한 상태에서 batch size의 수만큼의 data를 넣어서 V를 높이는 방향으로 parameter를 업데이트한다. discriminator : maximize $J_D$ wrt $\\theta_d$ $$J_D = E_{x\\sim p_{data}}\\log D_{\\theta_d}(x)+E_{z\\sim p(z)}\\log (1-D_{\\theta_D}(G_{\\theta_g}(z)))$$ $$ \\approx\\frac{1}{m}\\sum_{i=1}^m\\log D_{\\theta_D}(x_i)+\\frac{1}{m}\\sum_{i=1}^m\\log (1-D_{\\theta_d}(G_{\\theta_g}(z_i)))$$ generator : minimize $J_G$ wrt $\\theta_g$ $$J_G =E_{z\\sim p(z)}\\log (1-D_{\\theta_d}(G_{\\theta_g}(z)))\\ \\approx \\frac{1}{m}\\sum_{i=1}^m\\log (1-D_{\\theta_d}(G_{\\theta_g}(z_i)))$$ gradient ascent on discriminator, gradient descent on generator $\\log (1-D(G(z)))$의 경우 $D(G(z))=0$에서 기울기가 거의 0 이다. 반대로 $D(G(z))=1$에서는 기울기가 크다. 즉 fake에 가까울수록 gradient가 커서 학습이 잘되야 하는데 반대의 경우가 되버리는 것이다. 이러면 특히 학습초반에 fake image가 잘 만들어지지 않을 때 문제가 생기게 되는 것이다. 그래서 generator의 objective function을 바꾼다. 이제 generator도 gradient ascent가 된다. $$\\max_{\\theta_G}E_{z\\sim p(z)}\\log (D_{\\theta_D}(G_{\\theta_g}(z)))$$ ","date":"2021-12-03","objectID":"/03-gan/:3:0","tags":["GAN"],"title":"[Generative Model] GAN","uri":"/03-gan/"},{"categories":["Deep Generative Model"],"content":"Each gradient update discriminator update (repeat k times per iteration) discriminator가 generator보다 앞서서 학습해야 더 잘된다고 함 real data m개, fake data m개 -\u003e 총 2m개 gradient ascent generator update(once per iteration) backward gradient from discriminator output but update $\\theta_G$ only ","date":"2021-12-03","objectID":"/03-gan/:4:0","tags":["GAN"],"title":"[Generative Model] GAN","uri":"/03-gan/"},{"categories":["Deep Generative Model"],"content":"Performance evaluation entropy high entropy = high randomness, less predictable GAN이 원하는 결과는? quality low entropy (high predictable) conditional label distribution $p(y|x)$ 어떤 label인지 바로 맞출수있게! diversity high entropy (less predictable) $p(y)=\\int p(y|x=G(z))dz$ 다양한 data가 generate가 가능하게! Inception score 높은수록 좋다. quality와 diversity 둘 다 고려 $$IS(G)=\\exp (E_{x\\sim G} [D_{KL}(p(y|x)|| p(y))])$$ FID 낮을수록 좋다. $$FID(x_r, x_f) = ||\\mu_r - \\mu_f ||^2 + Tr(\\Sigma_r + \\Sigma_f - 2(\\Sigma_r \\Sigma_f)^{1/2})$$ precision, recall, F1 score ","date":"2021-12-03","objectID":"/03-gan/:5:0","tags":["GAN"],"title":"[Generative Model] GAN","uri":"/03-gan/"},{"categories":["Deep Generative Model"],"content":"GAN의 발전 depth and convolution DCGAN (2015) : deep하고 convnet사용 class-conditional generation Conditional GAN (2014) : 진짜같지 않으니 label을 알려주자. AC-GAN* (2016) : ensemble of specialized classifiers, 100개의 generator를 만들어서 각 10개의 label을 만들었다. spectral normalization SN-GAN (2018) : 하나의 generator로 모든 label을 만들었다, spectral normalization Spectral normalization 각 layer의 weight들을 SVD해서 가장 큰 singular value로 weight들을 나눠준다. 그렇게하면 learning이 상당히 stable해진다. 그래서 GAN을 죽이지 않고 오래동안 학습이 가능해졌다고 한다. two-timescale update rule TTUR (Two-timescale update rule) : 이론적으로 generator의 learning rate가 discriminator 것보다 더 빠르게 줄어들면 convergence에 도움을 된다는 것을 밝힘, 실제로는 그냥 서로 다른 learning rate를 쓰면 충분하다고 한다. self-attention non-local neural nets (2017) : self-attention과 non-local filtering operation을 연결시킴 SAGAN (2018) : non-local neural net을 layer로 사용, generation을 할 때 symmetric을 이용하자(eg, 눈), unusually shaped도 잘 만드려고 했다 ","date":"2021-12-03","objectID":"/03-gan/:6:0","tags":["GAN"],"title":"[Generative Model] GAN","uri":"/03-gan/"},{"categories":["Deep Generative Model"],"content":"Challenge Mode collapse (sample의 variety 부족) Gan은 VAE보다 Sharp한 결과를 만듬 왜 이런 결과가 나오는 걸까? 중명은 생략하고 결과만 보자. $p:p_{data},q:p_{model}$이라고 가정하자. $D_{KL}(p||q)$ name : maximum likelihood key property : mean-seeking high $q(x)$ anywhere $p(x)$ is high lower quality but more diverse samples $D_{KL}(q||p)$ name : reverse KL key property : mode-seeking rarely high $q(x)$ anywhere $p(x)$ is low higher quality but less diverse samples 그렇다면 GAN은? Jensen-Shannon divergence symmetric penalizes poor images badly : revese KL과 비슷 $$D_{JS}(p||q)=\\frac{1}{2}D_{KL}(p||\\frac{p+q}{2})+\\frac{1}{2}D_{KL}(q||\\frac{p+q}{2})$$ GAN : optimizing generator = minimizing JS divergence 2014 GAN 논문에서 discriminator가 optimal한 상태라면 generator의 objective function은 아래처럼 JS-divergence를 최소화하는 것이다라고 했다. $$J(D^*, G)=2D_{JS}(p_{data}|| p_{model})-\\log 4$$ 최적의 D가 전제되었다면 gan의 목적함수를 최적화하는 것은 $p_{data}$와 $p_{g}$사이의 Jensen-Shannon divergence를 최소화하는 것과 같다. 즉, data의 분포와 G가 생성하는 분포 사이의 차이를 줄인다고 할 수 있다. 따라서 최적의 결과는 $p_{data}=p_{g}$이다. $$\\min_{G}V(D^* , G)=E_{x\\sim p_{data}(x)}[\\log D^* (\\textbf{x})]+E_{z\\sim p_{g}(z)}[\\log (1-D^*(\\textbf{x})) ]$$ $$=E_{x\\sim p_{data}(x)}\\left[\\log\\frac{P_{data}(\\textbf{x})}{P_{data}(\\textbf{x})+P_{g}(\\textbf{x})}\\right]+E_{x\\sim p_{g}(z)}\\left[\\log\\frac{P_{g}(\\textbf{x})}{P_{data}(\\textbf{x})+P_{g}(\\textbf{x})}\\right]$$ $$=\\int_{x}p_{data}(x)\\log\\left[\\frac{P_{data}(\\textbf{x})}{P_{data}(\\textbf{x})+P_{g}(\\textbf{x})}\\right]dx+\\int_{x}p_{g}(x)\\log\\left[\\frac{P_{g}(\\textbf{x})}{P_{data}(\\textbf{x})+P_{g}(\\textbf{x})}\\right]dx$$ $$=-\\log4+\\int_{x}p_{data}(x)\\log\\left[\\frac{p_{data}(x)}{\\frac{p_{data}(x)+p_{g}(x)}{2}}\\right]dx+\\int_{x}p_{g}(x)\\log\\left[\\frac{P_{g}(\\textbf{x})}{\\frac{P_{data}(\\textbf{x})+P_{g}(\\textbf{x})}{2}}\\right]dx$$ $$=-\\log4+KL\\left(p_{data}(x)||\\frac{p_{data}(x)+p_{g}(x)}{2}\\right)+KL\\left(p_{g}(x)||\\frac{p_{data}(x)+p_{g}(x)}{2}\\right)$$ $$=-\\log4+2*JS\\left(p_{data}(x)||p_{g}(x)\\right)\\; JS(\\cdot)=0;\\text{if};p_{data}=P_{g}$$ 그래서 이전에는 GAN의 sharp/real 한 이미지를 만드는 이유가 reverse KL 과 비슷한 JS divergence때문이라고 생각했다. 근데 최근에는 해당하는 이유는 아니라고 밝혀졌다. GAN을 원래와 다른 $D_{KL}$로 학습해봤더니 그래도 비슷한 결과가 나오더라. reverse KL이 특정한 mode를 선호한다는 근거가 부족하다. mode collapsing은 divergence보다는 training의 어려움 때문에 발생할 것이다. generate한 image가 sharp한 이유는 아직까지도 not clear 하다. ","date":"2021-12-03","objectID":"/03-gan/:7:0","tags":["GAN"],"title":"[Generative Model] GAN","uri":"/03-gan/"},{"categories":["Deep Generative Model"],"content":"GAN training challenges non-convergence 두 model을 동시에 훈련하다보니까 문제 발생 mode collapse 서로 다른 input을 generator에 넣었음에도 동일한 output이 나오는 문제 발생 maxmin solution과 minmax solution이 달라서가 아닌가? 라는 의문 존재 이를 해결하기 위한 접근 augmented/different objective function unrolled GAN, DRAGAN, EBGAN architecture chage MAD-GAN, MRGAN minibatch discrimination progressive GAN diminished gradient discriminator가 너무 성능이 좋아지면 generator gradient vanishing이 발생한다고 한다. generator/discriminator unbalance cause overfitting hyperparmeter sensitivity ","date":"2021-12-03","objectID":"/03-gan/:8:0","tags":["GAN"],"title":"[Generative Model] GAN","uri":"/03-gan/"},{"categories":["Deep Generative Model"],"content":"Tips and Tricks train with labels one-sided label smoothing real label을 $1-\\epsilon$으로 바꿔서 regularization virtual batch normalization GAN에서는 BN을 사용하지 않는다. 그래서 다른 trick으로 BN사용 balancing generator/discriminator D가 살짝 앞서가도록 한다. D가 G보다 layers/filter를 더 많이 갖게 한다. 근데 너무 D가 앞서가면 안된다. ","date":"2021-12-03","objectID":"/03-gan/:9:0","tags":["GAN"],"title":"[Generative Model] GAN","uri":"/03-gan/"},{"categories":["Deep Generative Model"],"content":"Advantages and disadvantages 논문에서 말하는 장단점은 아래와 같다. advantage No need of Markov chain only backprop with gradient. No need of inference during training. Wide variety of functions can be incorporated into the model. disadvantage There is no explicit rep[resentation of $p_{g}(\\textbf{x})$. D must be synchronized well with G during training. ","date":"2021-12-03","objectID":"/03-gan/:10:0","tags":["GAN"],"title":"[Generative Model] GAN","uri":"/03-gan/"},{"categories":["Deep Generative Model"],"content":"VAE를 공부하기 위해 variational inference에 대해 간단하게 공부해보자. ","date":"2021-12-03","objectID":"/02-variationalinference/:0:0","tags":["Variational Inference"],"title":"[Generative Model] Variational Inference","uri":"/02-variationalinference/"},{"categories":["Deep Generative Model"],"content":"Variational Inference MCMC와 같이 sampling에 기반한 방법으로 posterior를 구하는 것이 아니라 inference problem을 optimization problem으로 바꾼다는 것이라고 할 수 있다. 전체적인 흐름을 정리하고 공부해보자. latent $\\textbf{z}$의 posterior $p(\\textbf{z}|\\textbf{x})$를 approximation하는 분포의 family를 $Q$라고 하자. 우리는 $Q$에 속하는 분포들 중에서 exact posterior와 가장 가까운 분포 $q(\\textbf{z})$를 구하고자 한다. $$q(\\textbf{z})=\\arg\\min_{q(\\textbf{z}) \\in Q}D_{KL}[q(\\textbf{z}) || p(\\textbf{z}|\\textbf{x})]$$ 결국 approximation하는 $q(\\textbf{z})$를 구해서 우리가 원하는 task를 진행하면 된다. 그렇가면 KL-divergence를 최소화하는 optimization을 진행하기 위해서는 적절한 $Q$를 정해야 한다. 여기서 고려해야할 점이 있다. 우리가 posterior를 tractable하지 않아서 approximation하는 것이므로 $Q$는 적절한 restriction을 걸어서 tractable하게 정해야한다. 하지만 그 restriction이 너무 강하다면 posterior에 근접하지 못한 결과를 얻을 것이다. ","date":"2021-12-03","objectID":"/02-variationalinference/:1:0","tags":["Variational Inference"],"title":"[Generative Model] Variational Inference","uri":"/02-variationalinference/"},{"categories":["Deep Generative Model"],"content":"ELBO 이제 variational inference를 어떻게 하는지 살펴보자. 이 과정에 있어서는 다양한 접근방법이 존재한다. 다양한 자료를 살펴보면 이해의 폭을 넓힐수 있을 것이다. $$D_{KL}[q(\\textbf{z}) || p(\\textbf{z}|\\textbf{x})]=\\int q(\\textbf{z})\\frac{\\log q(\\textbf{z})}{\\log p(\\textbf{z}|\\textbf{x})}d\\textbf{z}$$ $$=E_\\textbf{z}[\\log q(\\textbf{z})]-E_\\textbf{z}[\\log p(\\textbf{z}|\\textbf{x})] $$ $$=E_\\textbf{z}[\\log q(\\textbf{z})]-E_\\textbf{z}[\\log p(\\textbf{z},\\textbf{x})]+\\log p(\\textbf{x})$$ 그런데 위의 식에서 마지막 부분인 $\\log p(\\textbf{x})$을 보자. obseved data의 분포를 쉽게 구할 수 있을까? intractable하다. 그래서 우리는 위의 식을 directly optimization하는 것이 아니라 Evidence lower bound (ELBO) 를 최대화하는 방법으로 우회한다. 어떻게 하는지 알아보자. 아래의 식에서 우항을 ELBO하고 부른다. $$\\log p(\\textbf{x})-D_{KL}[q(\\textbf{z})|| p(\\textbf{z}|\\textbf{x})] = E_\\textbf{z} [\\log p(\\textbf{z},\\textbf{x})]-E_\\textbf{z}[\\log q(\\textbf{z})]$$ 우리는 원래 $D_{KL}$을 최소화하는 것이 목표였다. 그 의미는 결국 ELBO를 최대화 하는 것과 같다. (좌변의 $\\log p(\\textbf{x})$는 어차피 constant wrt $q(\\textbf{z})$) 여기서 또한 왜 ELBO라고 부르는지 알 수 있다. evidence $p(\\textbf{x})$의 lower-bound이기 때문인데, KL-divergence가 항상 0이상의 값을 가진다는 사실과 아래의 식을 보면 이해할 수 있다. $$\\log p(\\textbf{x}) = \\text{ELBO} + D_{KL}[q(\\textbf{z})|| p(\\textbf{z}|\\textbf{x})]$$ ELBO를 조금 더 알아보자. $$L(q) = E_\\textbf{z} [\\log p(\\textbf{z},\\textbf{x})]-E_\\textbf{z}[\\log q(\\textbf{z})] $$ $$= E_\\textbf{z} [\\log p(\\textbf{x}|\\textbf{z})] + E_\\textbf{z} [\\log p(\\textbf{z})]-E_\\textbf{z}[\\log q(\\textbf{z})] $$ $$ =E_\\textbf{z} [\\log p(\\textbf{x}|\\textbf{z})]-D_{KL}[q(\\textbf{z})|| p(\\textbf{z})]$$ 최종식에서 앞부분은 expected log likelihood of the data 뒷부분은 KL-D berween prior $p(\\textbf{z})$ and $q(\\textbf{z})$ 으로 이해할 수 있다. ","date":"2021-12-03","objectID":"/02-variationalinference/:2:0","tags":["Variational Inference"],"title":"[Generative Model] Variational Inference","uri":"/02-variationalinference/"},{"categories":["Deep Generative Model"],"content":"Restriction on Q 이 글의 초반에 적절한 $Q$를 정해야 한다고 했다. 이를 위해 주로 사용하는 restriction을 두가지 정도 알아보자. Parameterization 식 $q$를 parametric distribution으로 한정한다. $q(\\textbf{z};\\phi)=q_{\\phi}(\\textbf{z})$ $\\phi$ : variational parameters 그렇다면 이제 posterior inference는 variational parameters inference가 되는 것이다. VAE에서는 $q_{\\phi}(\\textbf{z})$를 neural net으로 modeling한다. Factorization assume $q(\\textbf{z})=\\prod_{j=1}^m q_j (z_j)$ 마지막으로 variational inference에 대한 간단한 예시를 통해 어떤 식으로 진행되는지 정리해보자. 먼저, 어떠한 임의의 model $p(\\textbf{x},\\textbf{z})$로 시작한다. 적절한 approximation function $q_{\\phi}(\\textbf{z})$를 정한다. ELBO를 구한다. 예를 들어, $L(\\phi)= \\textbf{x}^2\\phi^3+\\log \\phi$ derivatives를 구해서 optimize한다. $\\phi_{t+1} = \\phi_{t} + \\alpha \\triangledown_\\phi L(\\phi)$ ","date":"2021-12-03","objectID":"/02-variationalinference/:3:0","tags":["Variational Inference"],"title":"[Generative Model] Variational Inference","uri":"/02-variationalinference/"},{"categories":["Deep Generative Model"],"content":"Generative model에 대해 간단하게 정리하였다. ","date":"2021-12-03","objectID":"/01-introductiontogenerativemodels/:0:0","tags":["Generative Model"],"title":"[Generative Model] Introduction to Generative Models","uri":"/01-introductiontogenerativemodels/"},{"categories":["Deep Generative Model"],"content":"Discriminative vs Generative models in supervised learning 공통적인 목적은 learn a function to map $\\textbf{x}\\rightarrow y$ 이라고 할 수 있다. discriminative goal : directly estimate $p(y|\\textbf{x})$ should : $f(\\textbf{x})=\\arg\\max_y p(y|\\textbf{x})$ 그래서 decision bounday를 구한다. generative goal : estimate $p(\\textbf{x}|y)$, then find $p(y|\\textbf{x})$ should : $f(\\textbf{x})=\\arg\\max_y p(\\textbf{x}|y)p(y)$ probability distribution을 구한다. ","date":"2021-12-03","objectID":"/01-introductiontogenerativemodels/:1:0","tags":["Generative Model"],"title":"[Generative Model] Introduction to Generative Models","uri":"/01-introductiontogenerativemodels/"},{"categories":["Deep Generative Model"],"content":"Generative model in unsupervised learning unsupervised learning에서 generative model은 주로 density estimation sample generation 의 역할을 한다. generative model은 크게 두 가지로 나눠서 이해할 수 있다 (Taxonomy of generative models) explicit density estimation explicitly define and solve $P_\\text{model} (\\textbf{x})$ implicit density estimation learn a model that can sample from $P_\\text{model} (\\textbf{x})$ w/o explicitly defining it 주로 공부할 분야는 explicit에서 approximation에 해당하는 VAE와 implicit에서의 GAN에 대해 공부할 것이다. 그렇다면 왜 요즘 들어 neural net을 이용한 generative models이 연구되고 있을까? 전통적인 generative model의 단점을 살펴보자. data structure에 대한 강한 가정을 필요로 한다. approximation을 하는 경우 suboptimal한 결과를 얻는다. MCMC같은 경우 computationally expensive하다. 그럼 이에 반해 neural net기반 모델들은 어떤 장점이 있을까? backprop을 통해 function approximation에서 강한 면모를 보여준다. 예를 들어 VAE의 경우, 강한 가정이 필요없다. 훈련속도가 빠르다. approximation이기는 하지만 성능이 좋다. 그렇다면 neural net기반의 generative model의 종류를 살펴보자. Autoregressive model model $p(\\textbf{x})$ by $\\prod_{i=1}^n p(\\textbf{x}_i | \\textbf{x} _{i-1},\\textbf{x} _{i-2},…,\\textbf{x} _1 )$ eg) PixelRNN, PixelCNN, WaveNet… Helmholtz machine model $p(\\textbf{x})$ by $\\int p(\\textbf{z})p(\\textbf{x}|\\textbf{z})d\\textbf{z}$ eg) VAE Generative adversarial network no explicit density modeling train models by solving minmax problem 복잡해 보이는 generative model을 왜 공부해야하는지 Goodfellow가 몇가지 알려줬는데 살펴보자. to represent/manipulate high-dim/complicated probability distribution can be incorporated into RL can be trained with missing data (expand to semi-sup-learning) enable machine learning to work with multi-modal outputs enable inference of latent representations realistic generation of samples ","date":"2021-12-03","objectID":"/01-introductiontogenerativemodels/:2:0","tags":["Generative Model"],"title":"[Generative Model] Introduction to Generative Models","uri":"/01-introductiontogenerativemodels/"},{"categories":["Deep Generative Model"],"content":"Posterior inference 비단 딥러닝뿐만 아니라 통계학에서도 posterior inference은 상당히 중요하다. 결국에는 모델은 구하고 훈련하는 모든 과정은 posterior inference를 하는 것이다. latent variables $\\textbf{z}$와 observed variables $\\textbf{x}$가 있을 때 우리는 latent variables의 posterior를 구하는 것이 목표이다. 주로 우리가 해야하는 task는 posterior distribution을 구하는 경우나 posterior를 이용한 expectation을 구하는 경우가 많다. 하지만 이는 쉽지 않다. 왜? latent space가 너무 차원이 높다. posterior가 너무 complex해서 analytically tractable하다. (deep learning의 경우) hidden variable간의 interaction이 너무 많다. 그래서 우리는 approximation을 한다. ","date":"2021-12-03","objectID":"/01-introductiontogenerativemodels/:3:0","tags":["Generative Model"],"title":"[Generative Model] Introduction to Generative Models","uri":"/01-introductiontogenerativemodels/"},{"categories":["Deep Generative Model"],"content":"Approximate posterior inference 우리는 posterior를 왜 approximation하는지 알아봤다. 이제는 그럼 approximation하는 방법론에 대해 간단히 알아보자. Stochastic 대표적인 방법론은 MCMC computationally demanding Deterministic 대표적인 방법론은 Variational Inference posterior에 analytical approximations never generate exact results ","date":"2021-12-03","objectID":"/01-introductiontogenerativemodels/:4:0","tags":["Generative Model"],"title":"[Generative Model] Introduction to Generative Models","uri":"/01-introductiontogenerativemodels/"},{"categories":["알고리즘"],"content":"Dynamic Programming + Python ","date":"2021-12-02","objectID":"/algo-17-dp/:0:0","tags":["동적계획법","Dynamic Programming"],"title":"[알고리즘] 동적계획법","uri":"/algo-17-dp/"},{"categories":["알고리즘"],"content":"Fibonacci 예시 def fib(n): if n==1 or n==2: return 1 else: return fib(n-2) + fib(n-1) 많은 계산이 중복된다. ","date":"2021-12-02","objectID":"/algo-17-dp/:0:1","tags":["동적계획법","Dynamic Programming"],"title":"[알고리즘] 동적계획법","uri":"/algo-17-dp/"},{"categories":["알고리즘"],"content":"Memoization 중복되는 계산을 caching함으로써 중복계산을 피한다. def fib(n): if n==1 or n==2: return 1 elif f[n] \u003e -1: # 배열 f가 -1로 초기화되어 있음 return f[n] else: f[n] = fib(n-2) + fib(n-1) return f[n] ","date":"2021-12-02","objectID":"/algo-17-dp/:1:0","tags":["동적계획법","Dynamic Programming"],"title":"[알고리즘] 동적계획법","uri":"/algo-17-dp/"},{"categories":["알고리즘"],"content":"Dynamic Programming bottom-up 방식으로 중복계산을 피한다. def fib(n): f[1], f[2] = 1, 1 for i in range(3, n+1): f[n] = f[n-1] + f[n-2] return f[n] ","date":"2021-12-02","objectID":"/algo-17-dp/:2:0","tags":["동적계획법","Dynamic Programming"],"title":"[알고리즘] 동적계획법","uri":"/algo-17-dp/"},{"categories":["알고리즘"],"content":"Memoization vs Dynamic Programming 순환식의 값을 계산하는 기법들이다. 둘 다 동적계획법의 일종으로 보기도 한다. Memoization은 top-down방식, 실제로 필요한 subproblem만 푼다. 기본적으로 recursion으로 한다. Dynamic Programming은 bottom-up방식, recursion에 수반되는 overhead가 없다. ","date":"2021-12-02","objectID":"/algo-17-dp/:2:1","tags":["동적계획법","Dynamic Programming"],"title":"[알고리즘] 동적계획법","uri":"/algo-17-dp/"},{"categories":["알고리즘"],"content":"행렬 경로 문제 n*n 행렬의 좌상단에서 우하단까지 이동한다. 단, 오른쪽이나 아래쪽 방향으로만 이동할 수 있다. 이때, 방문한 칸에 있는 정수들의 합이 최소가 되는 경우? 순환식 $L[i,j]$ : (1,1)에서 (i,j)까지 이르는 최소합 $L[i,j]=min(L[i-1,j], L[i,j-1])+m_{ij}$ 이를 그대로 recursive하게 진행하면 중복계산이 많다. # Memoization def mat(i, j): if L[i][j] != -1: return L[i][j] elif i == 1: L[i][j] = mat(1, j-1) + m[i][j] elif j == 1: L[i][j] = mat(i-1, 1) + m[i][j] else: L[i][j] = min(mat(i-1, j), mat(i, j-1)) + m[i][j] return L[i][j] # Bottom-up def mat(): for i in range(1, n+1): for j in range(1, n+1): if i==1 \u0026 j==1: L[i][j] = m[1][1] elif i==1: L[i][j] = m[i][j] + L[i][j-1] elif j==1: L[i][j] = m[i][j] + L[i-1][1] else: L[i][j] = m[i][j] + min(L[i-1][j], L[i][j-1]) return L[n][n] ","date":"2021-12-02","objectID":"/algo-17-dp/:2:2","tags":["동적계획법","Dynamic Programming"],"title":"[알고리즘] 동적계획법","uri":"/algo-17-dp/"},{"categories":["알고리즘"],"content":"동적계획법 일반적으로 최적화문제(최소, 최대값) 혹은 카운팅(counting)문제에 적용된다. 주어진 문제에 대한 순환식을 정의 -\u003e 순환식을 memoization 혹은 bottom-up 방식으로 푼다. 순환식을 잘 만드는것이 핵심포인트! 최적해의 일부분이 그부분에 대한 최적해인가? 질문해보자 ex) 행렬 경로 문제 참고 순환식은 optimal substructure를 표현 subproblem을 풀어서 원래 문제를 푸는 방식 분할정복법과 공통점이 있겠구나 분할정복법에서는 분할된 문제들이 서로 disjoint하지만 동적계획법에서는 그렇지 않다. 즉, 서로 overlapping하는 subproblem들을 해결함으로써 원래 문제를 해결하고자 한다. ","date":"2021-12-02","objectID":"/algo-17-dp/:3:0","tags":["동적계획법","Dynamic Programming"],"title":"[알고리즘] 동적계획법","uri":"/algo-17-dp/"},{"categories":["알고리즘"],"content":"Matrix-Chain 곱하기 행렬 $A;:10100,;B;:1005,;C;:5*50$ $(AB)C$ : 7500번의 곱셈이 필요 $A(BC)$ : 75000번의 곱셈이 필요 곱하는 순서에 따라서 연산량이 다르다. 그렇다면 n개의 행렬곱 $A_1 A_2 … A_n$을 계산하는 최적의 순서는? optimal substructure 최종 결과는 앞부분의 곱과 뒷부분의 곱의 결과를 곱한 것! $(Z=A_a A_b)$ 순환식 $m[i,j]:;A_i A_{i+1} …A_j$의 최소곱셈 횟수 $m[i,j]=min_{i \\le k \\le j-1} (m[i,k]+m[k+1,j] + p_{i-1} p_k p_j)$ ","date":"2021-12-02","objectID":"/algo-17-dp/:3:1","tags":["동적계획법","Dynamic Programming"],"title":"[알고리즘] 동적계획법","uri":"/algo-17-dp/"},{"categories":["알고리즘"],"content":"Reference 권오흠 교수님 알고리즘 Java예시를 Python으로 바꿔서 구현 ","date":"2021-12-02","objectID":"/algo-17-dp/:4:0","tags":["동적계획법","Dynamic Programming"],"title":"[알고리즘] 동적계획법","uri":"/algo-17-dp/"},{"categories":["알고리즘"],"content":"Dijkstra, Floyd + python ","date":"2021-12-02","objectID":"/algo-16-minpath/:0:0","tags":["Dijkstra","Floyd"],"title":"[알고리즘] 최단경로문제","uri":"/algo-16-minpath/"},{"categories":["알고리즘"],"content":"최단경로 가중치 (방향) 그래프 경로의 길이는 경로상의 모든 가중치의 합을 의미 가중치가 없으면 BFS로 최단경로 쉽게 구할 수 있다. $\\delta(u,v)$ : 노드 u에서 v까지의 최단경로의 길이 ","date":"2021-12-02","objectID":"/algo-16-minpath/:1:0","tags":["Dijkstra","Floyd"],"title":"[알고리즘] 최단경로문제","uri":"/algo-16-minpath/"},{"categories":["알고리즘"],"content":"최단경로문제의 유형 single-source : 하나의 출발 노드부터 다른 모든 노드까지의 최단 경로 Dijkstra의 알고리즘 single-destination : 모든 노드로부터 하나의 목적지 노드까지의 최단 경로 single-source 문제와 동일 single-pair : 주어진 하나의 출발 노드 s로부터 하나의 목적지 노드 t까지의 최단 경로를 찾아라 최악의 경우 시간복잡도에서 single-source 문제보다 나은 알고리즘이 없음 All-pairs : 모든 노드 쌍에 대해서 최단 경로 Floyd 알고리즘 ","date":"2021-12-02","objectID":"/algo-16-minpath/:1:1","tags":["Dijkstra","Floyd"],"title":"[알고리즘] 최단경로문제","uri":"/algo-16-minpath/"},{"categories":["알고리즘"],"content":"최단경로와 음수 가중치 음수 가중치는 없다고 가정하는 알고리즘이 대부분이다. (Dijkstra 알고리즘) 음수 사이클이 있고 이들이 포함되면 최단 경로가 정의되지 않는다. 음수 사이클이 없다고 가정하는 경우가 대부분이겠구나. ","date":"2021-12-02","objectID":"/algo-16-minpath/:1:2","tags":["Dijkstra","Floyd"],"title":"[알고리즘] 최단경로문제","uri":"/algo-16-minpath/"},{"categories":["알고리즘"],"content":"최단경로의 기본특성 최단 경로의 어떤 부분경로도 역시 최단경로이다. 최단 경로는 사이클을 포함하지 않는다. ","date":"2021-12-02","objectID":"/algo-16-minpath/:1:3","tags":["Dijkstra","Floyd"],"title":"[알고리즘] 최단경로문제","uri":"/algo-16-minpath/"},{"categories":["알고리즘"],"content":"single-source 최단경로문제 입력 : 음수 사이클이 없는 가중치 방향그래프와 출발노드 s 목적 : 각 노드에 대해서 다음을 계산한다. $d[v]$ : distance estimate 처음에는 $d[s]=0,;d[v]=\\infty$ 로 시작한다. 알고리즘이 진행됨에 따라서 감소해간다. 하지만 항상 $d[v] \\ge \\delta(s,v)$ 유지한다. 최종적으로는 $d[v]=\\delta(s,v)$가 된다. $\\pi [v]$ : s에서 v까지의 최단경로상에서 v의 직전 노드 그런 노드가 없는 경우 $\\pi [v] = null$ 이를 통해 최단경로가 어떤 노드를 거쳐왔는지 알 수 있겠다. 대부분의 single-source 최단경로 알고리즘의 기본구조 초기화 edge들에 대한 반복적인 relaxation 위의 과정을 거치면 최단경로인가? 그럼 몆번 반복? s부터 v까지의 최단 경로라면 edge의 수는 최대 n-1개이고 각각 node마다 relaxation하면 $d[v_i]=\\delta(s,v_i)$가 되기 때문이다. 즉, n-1번의 반복으로 충분하다. ","date":"2021-12-02","objectID":"/algo-16-minpath/:1:4","tags":["Dijkstra","Floyd"],"title":"[알고리즘] 최단경로문제","uri":"/algo-16-minpath/"},{"categories":["알고리즘"],"content":"기본연산 : Relaxation 대부분의 최단경로 알고리즘이 갖고 있는 기본연산 u에서 v로 간다고 가정 # pseudo code RELAX(u,v,w) if d[v] \u003e d[u] + w(u,v) then d[v] = d[v] + w(u+v) # 더 짧은 경로가 있다면 갱신 pi[v] = u ","date":"2021-12-02","objectID":"/algo-16-minpath/:1:5","tags":["Dijkstra","Floyd"],"title":"[알고리즘] 최단경로문제","uri":"/algo-16-minpath/"},{"categories":["알고리즘"],"content":"Dijkstra의 알고리즘 음수 가중치가 없다고 가정 진행과정 시작노드 s로부터 최단경로의 길이를 이미 알아낸 노드들의 집합 S를 유지한다. S의 시작은 공집합 S에 속하지 않은 노드 u에 대해서 $d(u)$는 이미 S에 속한 노드들만 거쳐서 s로부터 u까지 가는 최단경로의 길이라고 하자. 이 때, $d(u)$가 s에서 u까지의 최단경로의 길이 $\\delta (s,u)$ 이다! 이제 u를 집합 S에 추가한다. S가 변경되었으므로 다른 노드들의 $d(v)$값을 갱신한다. $d(v) = min {d(v), d(u)+w(u,v)}$만 하면 된다. 시간복잡도 prim 알고리즘과 동일 우선순위 큐를 사용하지 않고 단순하게 구현할 경우 $O(n^2)$ 이진힙을 우선순위 큐로 사용할 경우 $O(n\\log_2 n + m \\log_2 n)$ import heapq INF = int(1e9) # 노드의 개수, 간선의 개수 n, m = map(int, input().split()) # 시작 노드 번호 입력 start = int(input()) # 각 노드에 연결되어 있는 노드에 대한 정보 # 인덱스는 1부터 시작하도록 graph = [[] for i in range(n+1)] # 최단 거리 table distance = [INF] * (n+1) # 그래프에 대한 정보 for _ in range(m): a, b, c = map(int, input().split()) graph[a].append((b,c)) # 여기서 b : 연결된 노드, c : weight def dijkstra(start): q = [] heapq.heappush(q, (0,start)) distance[start] = 0 while q: # 최단거리가 가장 짧은 경우 꺼내기 dist, now = heapq.heappop(q) # 현재 노드가 이미 처리되었으면 넘어가기 if distance[now] \u003c dist: continue # 현재 노드와 연결된 인접노드들에 대한 relaxing for i in graph[now]: cost = dist + i[1] # 현재 노드를 지나서 가는게 더 짧은 경우 if cost \u003c distance[i[0]]: distance[i[0]] = cost heapq.heappush(q, (cost, i[0])) # 실행 dijkstra(start) for i in range(1,n+1): print(distance[i]) ","date":"2021-12-02","objectID":"/algo-16-minpath/:2:0","tags":["Dijkstra","Floyd"],"title":"[알고리즘] 최단경로문제","uri":"/algo-16-minpath/"},{"categories":["알고리즘"],"content":"Floyd-Warshall 알고리즘 가중치 방향 그래프 모든 노드 쌍들간의 최단경로의 길이를 구함 $d^k [i,j]$ : 중간에 노드집합 {1,2,…,k} 에 속한 노드들만 거쳐서 노드 i에서 j까지 가는 최단경로의 길이 노드 i에서 j까지 가는 최단경로는 두가지 경우 노드 k를 지나지 않는 경우, k를 지나는 경우 $d^k [i,j] = min (d^{k-1}[i,j], d^{k-1}[i,k]+d^{k-1}[k,j])$ 이를 반복하면 최단경로를 다 구할 수 있겠다! INF = int(1e9) # node 개수, edge 개수 n, m = map(int, input().split()) # 2차원 리스트를 만들고 무한대로 초기회 graph = [[INF]*(n+1) for _ in range(n+1)] # 자기자신은 0으로 초기화 for a in range(1, n+1): for b in range(1, n+1): graph[a][b] = 0 # input for _ in range(m): a, b, c = map(int, input().split()) graph[a][b] = c # 알고리즘 실행 for k in range(1, n+1): for a in range(1, n+1): for b in range(1, n+1): graph[a][b] = min(graph[a][b], graph[a][k]+graph[k][b]) # 결과 출력 for a in range(1, n+1): for b in range(1, n+1): if graph[a][b] == INF: print('no', end=' ') else: print(graph[a][b]) print() ","date":"2021-12-02","objectID":"/algo-16-minpath/:3:0","tags":["Dijkstra","Floyd"],"title":"[알고리즘] 최단경로문제","uri":"/algo-16-minpath/"},{"categories":["알고리즘"],"content":"Reference 권오흠 교수님 알고리즘 Java예시를 Python으로 바꿔서 구현 이것이 코딩 테스트다 (나동빈지음) ","date":"2021-12-02","objectID":"/algo-16-minpath/:4:0","tags":["Dijkstra","Floyd"],"title":"[알고리즘] 최단경로문제","uri":"/algo-16-minpath/"},{"categories":["알고리즘"],"content":"Kruskal, Prim + python ","date":"2021-12-02","objectID":"/algo-15-mst/:0:0","tags":["Kruskal","Prim"],"title":"[알고리즘] 최소신장트리(MST)","uri":"/algo-15-mst/"},{"categories":["알고리즘"],"content":"최소신장트리 Minimum spanning tree 예시 입력 : n개의 도시, 도시와 도시를 연결하는 비용 문제 : 최소의 비용으로 모든 도시들이 서로 연결되게 한다. 해가 유일하지는 않음, 즉 같은 graph에서 MST는 여러개가 나올 수 있다. 무방향 가중치 그래프 ","date":"2021-12-02","objectID":"/algo-15-mst/:1:0","tags":["Kruskal","Prim"],"title":"[알고리즘] 최소신장트리(MST)","uri":"/algo-15-mst/"},{"categories":["알고리즘"],"content":"왜 트리라고 부르는걸까? cycle이 없는 connected 무방향 그래프를 트리라고 한다. 우리가 일반적으로 생각하는 root에 내려오는 트리는 rooted tree라고 할 수 있다. 조금 더 좁은 의미라고 이해하면 될 것 같다. MST 문제의 답은 항상 트리가 된다. MST에서 cycle은 필요없다. 모두 연결되어 있다. 노드가 n개인 트리는 항상 n-1개의 엣지를 갖는다. ","date":"2021-12-02","objectID":"/algo-15-mst/:1:1","tags":["Kruskal","Prim"],"title":"[알고리즘] 최소신장트리(MST)","uri":"/algo-15-mst/"},{"categories":["알고리즘"],"content":"Generic MST 알고리즘 어떤 MST의 부분집합 A에 대해서 $A + {(u,v)}$도 역시 어떤 MST의 부분집합이 될 경우 edge $(u,v)$는 A에 대해서 safe(안전하다) 하다고 한다. Generic MST 알고리즘 처음에는 A를 공집합으로 시작 안전한 edge 하나 찾은 후 이것을 A에 더한다. edge의 갯수가 n-1개가 될 때까지 2번을 반복한다. 대표적인 종류 2가지 kruskal, prim 알고리즘 ","date":"2021-12-02","objectID":"/algo-15-mst/:1:2","tags":["Kruskal","Prim"],"title":"[알고리즘] 최소신장트리(MST)","uri":"/algo-15-mst/"},{"categories":["알고리즘"],"content":"안전한 edge 찾기 그래프의 정점들을 두 개의 집합 $S$와 $V-S$로 분할한 것을 cut $(S, V-S)$라고 부른다. $u\\in S,;v\\in V-S$, edge (u,v)가 존재한다면 이 edge는 cut $(S, V-S)$를 cross 한다고 한다. edge들의 부분집합 A에 속한 어떤 edge도 cut $(S,V-S)$를 cross하지 않을 때 cut $(S,V-S)$는 A를 respect 한다고 한다. 결론 A가 어떤 MST의 부분집합이고 $(S,V-S)$는 A를 respect하는 cut이라고 하자. 이 cut을 cross하는 edge들 중 가장 가중치가 작은 edge $(u,v)$는 A에 대해서 safe하다. ","date":"2021-12-02","objectID":"/algo-15-mst/:1:3","tags":["Kruskal","Prim"],"title":"[알고리즘] 최소신장트리(MST)","uri":"/algo-15-mst/"},{"categories":["알고리즘"],"content":"Kruskal의 알고리즘 edge들을 가중치의 오름차순으로 정렬한다. edge들을 그 순서대로 하나씩 선택해간다. 단, 이미 선택된 edge들과 cycle을 형성하면 선택하지 않는다. n-1개의 edge가 선택되면 종료한다. 시간복잡도 : $O(E \\log_2 E)$ ","date":"2021-12-02","objectID":"/algo-15-mst/:2:0","tags":["Kruskal","Prim"],"title":"[알고리즘] 최소신장트리(MST)","uri":"/algo-15-mst/"},{"categories":["알고리즘"],"content":"왜 Kruskal의 알고리즘이 MST를 찾는가? Kruskal의 알고리즘의 임의의 한 단계를 생각해보자. A를 현재까지 알고리즘이 선택한 edge의 집합이라고 하고 A를 포함하는 MST가 존재한다고 가정하자. 이를 두 집합으로 cut한 상태를 가정하자. 이 때 cycle을 만들지 않는 lightest edge를 만드는 것이 Kruskal 알고리즘이고 이는 cut을 cross하고 A에 대해서 safe하므로 다시 MST의 부분집합이 된다. (by 안전한 edge 찾기 결론) ","date":"2021-12-02","objectID":"/algo-15-mst/:2:1","tags":["Kruskal","Prim"],"title":"[알고리즘] 최소신장트리(MST)","uri":"/algo-15-mst/"},{"categories":["알고리즘"],"content":"cycle 검사 Kruskal 알고리즘을 진행하는 한 단계를 생각해보자. 연결이 되어있는 노드마다 집합으로 표현하면 {a}, {b,c,d}, {d,e} 이런식으로 생각할 수 있다. 이제 가중치가 최소인 edge를 고려하는데 그 edge가 이미 한 집합인 노드간 edge인 경우 cycle을 만들게 되므로 skip해야한다. 그러면 Kruskal 알고리즘을 구현하기 위해 위의 disjoint한 집합을 어떻게 표현할지 고민이 든다. ","date":"2021-12-02","objectID":"/algo-15-mst/:2:2","tags":["Kruskal","Prim"],"title":"[알고리즘] 최소신장트리(MST)","uri":"/algo-15-mst/"},{"categories":["알고리즘"],"content":"집합들의 표현 Kruskal을 구현할 때, 가중치가 최소인 edge에 연결된 두 node의 각 집합을 찾아서 동일한지 비교하고 (find) 동일하지 않다면 합치는 과정이 필요하다. (union) Union-find을 제공하는 자료구조를 이용해야하는 것이다. 각 집합을 하나의 트리로 표현한다. 누가 root이고 누가 누구의 부모이든 상관없다. root 노드의 부모는 자기자신이 되도록 한다. 이진트리도 아니다. 다만 상향식 트리 (트리의 각 노드는 자식노드가 아닌 부모 노드의 주소를 가짐) 모든 트리를 하나의 배열로 표현가능! 간단하다. 배열에 부모가 누구인지 넣으면 된다. 상향식 트리라서 가능한 것이다. ","date":"2021-12-02","objectID":"/algo-15-mst/:2:3","tags":["Kruskal","Prim"],"title":"[알고리즘] 최소신장트리(MST)","uri":"/algo-15-mst/"},{"categories":["알고리즘"],"content":"Find 자신이 속한 트리의 root를 찾아서 동일한지 비교하면 된다. 시간복잡도 : $O$(트리의 높이) 최악의 경우 $O(V)$ ","date":"2021-12-02","objectID":"/algo-15-mst/:2:4","tags":["Kruskal","Prim"],"title":"[알고리즘] 최소신장트리(MST)","uri":"/algo-15-mst/"},{"categories":["알고리즘"],"content":"Union 한 트리의 root를 다른 트리 root의 자식 노드로 만들면 된다. 시간복잡도 : root 노드를 찾은 이후에는 $O(1)$ ","date":"2021-12-02","objectID":"/algo-15-mst/:2:5","tags":["Kruskal","Prim"],"title":"[알고리즘] 최소신장트리(MST)","uri":"/algo-15-mst/"},{"categories":["알고리즘"],"content":"Weighted Union 두 집합을 union할 때 작은 트리의 루트를 큰 트리의 루트의 자식으로 만든다. 그러면 트리의 높이가 무작정 높아지지 않기에 find를 할 경우 속도가 빨라진다. 각 트리의 크기를 count하고 있어야 한다. ","date":"2021-12-02","objectID":"/algo-15-mst/:2:6","tags":["Kruskal","Prim"],"title":"[알고리즘] 최소신장트리(MST)","uri":"/algo-15-mst/"},{"categories":["알고리즘"],"content":"Path Compression root를 찾아가는 과정이 길수도 있으니까 중간과정의 노드들을 스킵하고 바로 root쪽이랑 연결되도록 해보자 # parent는 list이고 해당 index 노드의 부모를 갖고 있다 def find_parent(parent, x): if parent[x] != x: parent[x] = find_parent(parent, parent[x]) return parent[x] ","date":"2021-12-02","objectID":"/algo-15-mst/:2:7","tags":["Kruskal","Prim"],"title":"[알고리즘] 최소신장트리(MST)","uri":"/algo-15-mst/"},{"categories":["알고리즘"],"content":"Weighted Union with Path Compression (WUPC) M번의 union-find 연산의 총 시간복잡도는 $O(N+M\\log* N)$ $N$은 원소의 개수 $\\log* N$ : 로그를 연속으로 몇 번 취하면 N이 1이되는지 $\\log* 1=0,;\\log* 2=1,;…\\log* 65536=4,…$ 거의 선형시간 알고리즘이다. 즉, 한 번의 Find 혹은 Union이 $O(1)$의 시간이 걸린다. 그래서 Kruskal 알고리즘의 시간복잡도는 edge를 정렬하는 시간이 dominant하다. # Kruskal 알고리즘 def find_parent(parent, x): if parent[x] != x: parent[x] = find_parent(parent, parent[x]) return parent[x] def union_parent(parent, a, b): a = find_parent(parent, a) b = find_parent(parent, b) # 여기서는 Weighted Union을 사용하지는 않음 # 수가 작을수록 root로 만드는 기준만 사용 if a \u003c b: parent[b] = a else: parent[a] = b v, e = map(int, input().split()) parent = [0] * (v+1) # 부모 테이블 초기화 edges = [] result = 0 for i in range(1, v+1): parent[i] = i for _ in range(e): a, b, cost = map(int, input().split()) edges.append((cost, a, b)) # edge값에 따라 정렬 edges.sort() for edge in edges: cost, a, b = edge if find_parent(parent, a) != find_parent(parent, b): union_parent(parent, a, b) result += cost print(result) ","date":"2021-12-02","objectID":"/algo-15-mst/:2:8","tags":["Kruskal","Prim"],"title":"[알고리즘] 최소신장트리(MST)","uri":"/algo-15-mst/"},{"categories":["알고리즘"],"content":"Prim의 알고리즘 임의의 노드를 출발노드로 선택 출발 노드를 포함하는 트리를 점점 키워감 매 단계에서 이미 트리에 포함된 노드와 포함되지 않은 노드를 연결하는 edge들 중 가장 가중치가 작은 edge 선택 구현에서 핵심은 포함되지 않은 나머지 edge들 중에서 가중치가 가장 작은 edge를 찾는 것 ","date":"2021-12-02","objectID":"/algo-15-mst/:3:0","tags":["Kruskal","Prim"],"title":"[알고리즘] 최소신장트리(MST)","uri":"/algo-15-mst/"},{"categories":["알고리즘"],"content":"왜 Prim의 알고리즘이 MST를 찾는가? Prim의 알고리즘의 임의의 한 단계를 생각해보자. A를 현재까지 알고리즘이 선택한 edge의 집합이라고 하고 A를 포함하는 MST가 존재한다고 가정하자. 이제 아직 연결되지 않은 노드와 연결하는 edge들 중에서 가장 가중치가 작은 edge를 연결 이는 cut을 cross하고 A에 대해서 safe하므로 다시 MST의 부분집합이 된다. (by 안전한 edge 찾기 결론) ","date":"2021-12-02","objectID":"/algo-15-mst/:3:1","tags":["Kruskal","Prim"],"title":"[알고리즘] 최소신장트리(MST)","uri":"/algo-15-mst/"},{"categories":["알고리즘"],"content":"가중치가 최소인 edge 찾기 $V_A$ : 이미 트리에 포함된 노드들 $V_A$에 아직 속하지 않은 각 노드 v에 대해서 다음과 같은 값을 유지 $key(v)$ : 이미 $V_A$에 속한 노드와 자신을 연결하는 edge들 중 가중치가 최소인 edge $(u,v)$의 가중치 $\\pi(v)$ : 그 edge의 끝점 $u$ 그러면 가중치가 최소인 edge를 찾는 대신 key값이 최소인 노드를 찾으면 된다. 그리고 연결! 그리고 key값, pi값을 갱신해준다. (시간복잡도 : $O(V)$) 이 때, 모든 값을 갱신할 필요는 없고 방금 추가된 node와 연결된 노드들의 key값, pi값만 갱신하면 되는 것이다. 위의 과정을 반복하면 Prim의 알고리즘! (시간복잡도 : $O(V^2)$) ","date":"2021-12-02","objectID":"/algo-15-mst/:3:2","tags":["Kruskal","Prim"],"title":"[알고리즘] 최소신장트리(MST)","uri":"/algo-15-mst/"},{"categories":["알고리즘"],"content":"key값이 최소인 노드 찾기 key값을 하나씩 찾으면 $O(V)$ 시간이 걸린다. 근데 최소 우선순위 큐를 사용하면 key값이 최소인 노드를 찾는 시간이 $O(\\log V)$이다. ","date":"2021-12-02","objectID":"/algo-15-mst/:3:3","tags":["Kruskal","Prim"],"title":"[알고리즘] 최소신장트리(MST)","uri":"/algo-15-mst/"},{"categories":["알고리즘"],"content":"Prim의 알고리즘 : 시간복잡도 이진힙을 사용하여 우선순위 큐를 구현한 경우 while loop: $V$번의 extract-min 연산 : $O(V \\log V)$ $E$번의 decrease-key 연산 : $O(E \\log V)$ 따라서 시간복잡도 : $O(V \\log V + E \\log V)=O(E \\log V)$ $E$이 더 큰 경우가 대부분 우선순위 큐를 사용하지 않고 단순하게 구현할 경우 : $O(V^2)$ mygraph = { 'a' : {'b':7, 'd':5}, 'b' : {'a':7, 'c':8, 'd':9,}, 'c' : {'b':8}, 'd' : {'a':5, 'b':9} } from heapdict import heapdict def prim(graph, start): mst = list() # keys, pi, result 초기화 keys, pi, result = heapdict(), dict(), 0 for node in graph.keys(): keys[node] = float('inf') pi[node] = None keys[start], pi[start] = 0, start while keys: # extract-min 연산 # 우선순위 큐를 통해서 쉽게 진행 current_node, current_key = keys.popitem() result += current_key # mst를 구해야하는 경우 mst.append([pi[current_node], current_node, current_key]) # decrease-key 연산 for adjacent, weight in graph[current_node].items(): if adjacent in keys and weight \u003c keys[adjacent]: keys[adjacent] = weight pi[adjacent] = current_node return result ","date":"2021-12-02","objectID":"/algo-15-mst/:3:4","tags":["Kruskal","Prim"],"title":"[알고리즘] 최소신장트리(MST)","uri":"/algo-15-mst/"},{"categories":["알고리즘"],"content":"Reference 권오흠 교수님 알고리즘 Java예시를 Python으로 바꿔서 구현 ","date":"2021-12-02","objectID":"/algo-15-mst/:4:0","tags":["Kruskal","Prim"],"title":"[알고리즘] 최소신장트리(MST)","uri":"/algo-15-mst/"},{"categories":["알고리즘"],"content":"그래프 순회 + python ","date":"2021-12-02","objectID":"/algo-14-graph2/:0:0","tags":["그래프 순회"],"title":"[알고리즘] 그래프 순회","uri":"/algo-14-graph2/"},{"categories":["알고리즘"],"content":"그래프 순회 순회 : 그래프의 모든 노드들을 방문하는 일 두 가지 방법 BFS 너비우선순회 DFS 깊이우선순회 ","date":"2021-12-02","objectID":"/algo-14-graph2/:1:0","tags":["그래프 순회"],"title":"[알고리즘] 그래프 순회","uri":"/algo-14-graph2/"},{"categories":["알고리즘"],"content":"BFS (너비우선순회) 동심원 형태로 방문 특정 출발 노드에서 시작하여서 바로 연결된 이웃들을 방문 다 방문한 뒤에 해당 노드들의 바로 연결된 이웃들을 방문 ","date":"2021-12-02","objectID":"/algo-14-graph2/:2:0","tags":["그래프 순회"],"title":"[알고리즘] 그래프 순회","uri":"/algo-14-graph2/"},{"categories":["알고리즘"],"content":"큐를 이용한 BFS check the start node insert the start node into the queue queue가 다 빌 때까지, node를 하나씩 뺀다 queue에서 나온 node의 이웃 중에서 unchecked 이웃을 check하고 queue에 넣는다 결국 모든 node가 check된다 # BFS def iterative_bfs(start_v): discovered = [start_v] queue = [start_v] while queue: v = queue.pop(0) for w in graph[v]: if w is not in discovered: discovered.append(w) queue.append(w) return discovered ","date":"2021-12-02","objectID":"/algo-14-graph2/:2:1","tags":["그래프 순회"],"title":"[알고리즘] 그래프 순회","uri":"/algo-14-graph2/"},{"categories":["알고리즘"],"content":"BFS와 최단경로 BFS로 각 노드에 대해서 최단 경로의 길이를 구할 수 있다 graph = [ [], [2,3,8], [1,7], [1,4,5], [3,5], [3,4], [7], [2,6,8], [1,7] ] from collections import deque def bfs_min_distance(num_node, graph, start, end): q = deque([start]) # 방문여부 체크 visited = [False] * (num_node+1) visited[start] = True # 최단거리 dist = [False] * (num_node+1) dist[start] = 0 while q: v = q.popleft() for i in graph[v]: if not visited[i]: q.append(i) visited[i] = True dist[i] += dist[v]+1 return dist[end] print(bfs_min_distance(8, graph, 1, 5)) ","date":"2021-12-02","objectID":"/algo-14-graph2/:2:2","tags":["그래프 순회"],"title":"[알고리즘] 그래프 순회","uri":"/algo-14-graph2/"},{"categories":["알고리즘"],"content":"DFS (깊이우선순회) 현재 노드를 visited로 mark하고 인접한 노드들 중 unvisited 노드가 존재하면 그 노드로 간다. 1번을 계속 반복한다. 만약 unvisited인 이웃 노드가 존재하지 않는 동안 계속해서 직전 노드로 되돌아간다. 다시 2번을 반복한다. 시작노드로 돌아오고 더 이상 갈 곳이 없으면 종료한다. 그래프가 disconnected이거나 혹은 방향그래프라면 DFS에 의해서 모든 노드가 방문되지 않을 수도 있음 # DFS (재귀) def recursive_dfs(v, visited=[]): visited.append(v) for w in graph[v]: if not w in visited: visited = recursive_dfs(w, visited) return visited ","date":"2021-12-02","objectID":"/algo-14-graph2/:3:0","tags":["그래프 순회"],"title":"[알고리즘] 그래프 순회","uri":"/algo-14-graph2/"},{"categories":["알고리즘"],"content":"DAG (Directed Acyclic Graph) 방향 사이클(directed cycle)이 없는 방향 그래프 예) 작업들의 우선순위 ","date":"2021-12-02","objectID":"/algo-14-graph2/:4:0","tags":["그래프 순회"],"title":"[알고리즘] 그래프 순회","uri":"/algo-14-graph2/"},{"categories":["알고리즘"],"content":"위상정렬 DAG에서 노드들의 순서화 단, 모든 edge$(v_i ,v_j)$에 대해서 i \u003c j 방법1 먼저, indegree가 0인 노드를 찾는다. 배열 A에 해당 노드를 넣는다. (A[i] = u) 해당 노드와 outgoing edge를 제거한다. 위의 과정을 반복하면 위상정렬된다. ","date":"2021-12-02","objectID":"/algo-14-graph2/:5:0","tags":["그래프 순회"],"title":"[알고리즘] 그래프 순회","uri":"/algo-14-graph2/"},{"categories":["알고리즘"],"content":"Reference 권오흠 교수님 알고리즘 Java예시를 Python으로 바꿔서 구현 ","date":"2021-12-02","objectID":"/algo-14-graph2/:6:0","tags":["그래프 순회"],"title":"[알고리즘] 그래프 순회","uri":"/algo-14-graph2/"},{"categories":["알고리즘"],"content":"그래프 개념 ","date":"2021-12-02","objectID":"/algo-13-graph1/:0:0","tags":["그래프"],"title":"[알고리즘] 그래프","uri":"/algo-13-graph1/"},{"categories":["알고리즘"],"content":"그래프 Graph (undirected) graph $G(V,E)$ $V$ : 노드(node), vertex $E$ : edge, link 개체들 간의 이진관계를 표현 directed graph edge가 방향이 있는 것 weighted graph edge마다 가중치가 있는 것 directed, undirected 둘 다 존재 ","date":"2021-12-02","objectID":"/algo-13-graph1/:1:0","tags":["그래프"],"title":"[알고리즘] 그래프","uri":"/algo-13-graph1/"},{"categories":["알고리즘"],"content":"그래프의 표현 (undirected) 인접행렬 (adjacency matrix) 그래프의 연결을 n*n 행렬로 표현 node가 연결되어 있으면 1, 아니면 0 저장 공간 : $O(n^2)$ 어떤 node에 인접한 모든 node 찾기 : $O(n)$ 어떤 edge가 존재하는지 검사 : $O(1)$ 인접리스트 (adjacency list) node 집합을 표현하는 하나의 배열과 각 node마다 인접한 node들의 연결리스트 이 때, 인접한 node들을 표현한 연결리스트에서 총 노드 수는 2 * 전체edge수(m) 저장 공간 : $O(n+m)$ 어떤 node에 인접한 모든 node 찾기 : $O(degree(v))$ 어떤 edge가 존재하는지 검사 : $O(degree(v))$ ","date":"2021-12-02","objectID":"/algo-13-graph1/:1:1","tags":["그래프"],"title":"[알고리즘] 그래프","uri":"/algo-13-graph1/"},{"categories":["알고리즘"],"content":"그래프의 표현 (directed) 인접행렬은 비대칭 인접리스트는 연결리스트에서 총 노드 수는 전체edge수(m) ","date":"2021-12-02","objectID":"/algo-13-graph1/:1:2","tags":["그래프"],"title":"[알고리즘] 그래프","uri":"/algo-13-graph1/"},{"categories":["알고리즘"],"content":"그래프의 표현 (weighted) 인접행렬에서 1대신 edge의 가중치를 저장하면 된다 ","date":"2021-12-02","objectID":"/algo-13-graph1/:1:3","tags":["그래프"],"title":"[알고리즘] 그래프","uri":"/algo-13-graph1/"},{"categories":["알고리즘"],"content":"경로와 연결성 undirected에서 두 node 사이의 path(경로)가 존재할 때 연결되어 있다고 한다 모든 node 쌍들이 연결된 그래프를 연결된(connected) 그래프라고 한다 ","date":"2021-12-02","objectID":"/algo-13-graph1/:1:4","tags":["그래프"],"title":"[알고리즘] 그래프","uri":"/algo-13-graph1/"},{"categories":["알고리즘"],"content":"Reference 권오흠 교수님 알고리즘 ","date":"2021-12-02","objectID":"/algo-13-graph1/:2:0","tags":["그래프"],"title":"[알고리즘] 그래프","uri":"/algo-13-graph1/"},{"categories":["알고리즘"],"content":"Hash 개념 + python ","date":"2021-12-02","objectID":"/algo-12-hash/:0:0","tags":["해시","Hash"],"title":"[알고리즘] Hash","uri":"/algo-12-hash/"},{"categories":["알고리즘"],"content":"Hash table 해쉬테이블은 dynamic set을 구현하는 효과적인 방법의 하나 적절한 가정하에서 평균 탐색, 삽입, 삭제시간 $O(1)$ 보통 최악의 경우 $O(n)$ 해쉬함수(hash function) h를 사용하여 key k를 T[h(k)]에 저장 key k가 h(k)로 해슁되었다고 말함 즉 각 key에 대한 해쉬함수값을 그 key를 저장할 배열 인덱스로 사용 ","date":"2021-12-02","objectID":"/algo-12-hash/:1:0","tags":["해시","Hash"],"title":"[알고리즘] Hash","uri":"/algo-12-hash/"},{"categories":["알고리즘"],"content":"해쉬 함수의 예 h(k) = k % m 즉, key를 하나의 자연수로 해석한 후 테이블의 크기 m으로 나눈 나머지 항상 0 ~ m-1 사이의 정수가 됨 ","date":"2021-12-02","objectID":"/algo-12-hash/:1:1","tags":["해시","Hash"],"title":"[알고리즘] Hash","uri":"/algo-12-hash/"},{"categories":["알고리즘"],"content":"충돌 collision 근데 배열의 크기가 데이터의 수보다 작은 경우는? 충돌이 발생할 수 밖에 없다. 즉, 다른 key값을 가지지만 같은 인덱스를 가질 수 있는 것이다. 서로 다른 두 key a와 b에 대해서 h(a) = h(b) 인 상황 대처 방법 chaining과 open addressing ","date":"2021-12-02","objectID":"/algo-12-hash/:2:0","tags":["해시","Hash"],"title":"[알고리즘] Hash","uri":"/algo-12-hash/"},{"categories":["알고리즘"],"content":"Chaining에 의한 충돌 해결 동일한 장소로 해슁된 모든 key들을 하나의 연결리스트로 저장 key의 삽입 연결리스트 T[h(k)]의 맨 앞에 삽입 : $O(1)$ 중복된 key가 들어올 수 있고 중복 저장이 허용되지 않는다면 삽입시 리스트를 검색해야 함 : 이 경우 시간복잡도는 리스트의 길이에 비례 key의 검색 리스트 T[h(k)]에서 순차검색 시간복잡도는 key가 저장된 리스트의 길이에 비례 key의 삭제 리스트 T[h(k)]로부터 key를 검색 후 삭제 일단 key를 검색해서 찾은 후에는 $O(1)$시간에 삭제 가능 최악의 경우는 모든 key가 하나의 해싱값을 가지는 경우 길이가 n인 하나의 연결리스트가 만들어짐 따라서 최악의 경우 탐색시간은 $O(n)$+해쉬함수 계산시간 평균시간복잡도는 key들이 여러 슬롯에 얼마나 잘 분배되느냐에 의해서 결정된다! ","date":"2021-12-02","objectID":"/algo-12-hash/:2:1","tags":["해시","Hash"],"title":"[알고리즘] Hash","uri":"/algo-12-hash/"},{"categories":["알고리즘"],"content":"SUHA (simple uniform hashing assumption) 각각의 key가 모든 슬롯들에 균등한 확률로 독립적으로 해슁된다는 가정 hash 함수는 deterministic하므로 현실에서는 불가능 Load factor $\\alpha = n/m$ n : 테이블에 저장될 key의 개수 m : 해쉬테이블의 크기, 즉, 연결리스트의 개수 각 슬롯에 저장된 key의 평균 개수 연결리스트 T[j]의 길이를 $n_j$라고 하면 $E[n_j]=\\alpha$ 만약 $n=O(m)$이면 평균검색시간은 $O(1)$ ","date":"2021-12-02","objectID":"/algo-12-hash/:2:2","tags":["해시","Hash"],"title":"[알고리즘] Hash","uri":"/algo-12-hash/"},{"categories":["알고리즘"],"content":"Open addressing에 의한 충돌 해결 모든 key를 해쉬 테이블 자체에 저장 테이블의 각 슬롯에는 1개의 key만 저장 충돌 해결 기법 Linear probing Quadratic probing Double hashing ","date":"2021-12-02","objectID":"/algo-12-hash/:2:3","tags":["해시","Hash"],"title":"[알고리즘] Hash","uri":"/algo-12-hash/"},{"categories":["알고리즘"],"content":"Open addressing - Linear probing 들어가야할 슬롯에 이미 데이터가 있다면 순서대로 $h(k)+1, h(k)+2 …$ 검사하여 처음으로 빈 슬롯에 저장 단점 cluster가 생성되면 점점 더 커지는 현상이 생김 이에 대한 보완방법 Quadratic probing 충돌 발생시 $h(k)+1^2,;h(k)+2^2…$ Double hashing 서로 다른 두 해쉬함수 h1,h2를 이용 h1(k) = k mod m, h2(k) = h1(k) + (k mod 어떤 수) 즉, 겹쳤을 때 건너뛰는 정도가 key값마다 달라지는 것 ","date":"2021-12-02","objectID":"/algo-12-hash/:2:4","tags":["해시","Hash"],"title":"[알고리즘] Hash","uri":"/algo-12-hash/"},{"categories":["알고리즘"],"content":"Open addressing - key의 삭제 단순히 key를 삭제할 경우 문제 발생 dynamic set같은 경우 데이터의 추가,삭제가 빈번한다 그렇다면 삭제가 많이 발생한 경우 중간에 빈칸이 많이 생기고 이는 search연산을 진행할 때 쓸데없는 시간을 소비하게 한다 그래서 데이터를 삭제한 뒤에 뒤에 있는 데이터를 가져온다 (같은 해쉬값을 갖는 데이터들만) ","date":"2021-12-02","objectID":"/algo-12-hash/:2:5","tags":["해시","Hash"],"title":"[알고리즘] Hash","uri":"/algo-12-hash/"},{"categories":["알고리즘"],"content":"좋은 해쉬 함수란? 현실에서는 key들이 랜덤하지 않음 만약 key들의 통계적 분포에 대해 알고 있다면 이를 이용해서 해쉬 함수를 고안하는 것이 가능하겠지만 현실적으로 어려움 key들이 어떤 특정한 패턴을 가지더라도 해쉬함수값이 불규칙적이 되도록 하는게 바람직 해쉬함수값이 key의 특정 부분에 의해서만 결정되지 않아야한다 예를 들어, 학번 : 2014xxxx 같은 패턴이 있다 ","date":"2021-12-02","objectID":"/algo-12-hash/:3:0","tags":["해시","Hash"],"title":"[알고리즘] Hash","uri":"/algo-12-hash/"},{"categories":["알고리즘"],"content":"해쉬 함수 Division 기법 h(k)= k mod m 장점 : 빠르다. 단점 : 어떤 m값에 대해서는 해쉬함수값이 key값의 특정 부분에 의해서 결정되는 경우가 있다. Multiplication 기법 0에서 1사이의 상수 A를 선택 kA의 소수부분만을 택한다. 소수 부분에 m을 곱한 후 소수점 아래를 버린다. ","date":"2021-12-02","objectID":"/algo-12-hash/:4:0","tags":["해시","Hash"],"title":"[알고리즘] Hash","uri":"/algo-12-hash/"},{"categories":["알고리즘"],"content":"파이썬에서 hash 파이썬은 Open addressing 방법을 사용 파이썬에서 해시 테이블로 구현된 자료형 : 딕셔너리 import hashlib hash_obj = hashlib.sha256() hash_obj.update(b'hello world') hex_dig = hash_obj.hexdigest() print(hex_dig) # 결과 # b94d27b9934d3e08a52e52d7da7dabfac484efe37a5380ee9088f7ace2efcde9 # 해시맵, 개별체이닝 구현 class ListNode: def __init__(self, key=None, value=None): self.key = key self.value = value self.next = next import collections class HashMap: def __init__(self): self.size = 1000 self.table = collections.defaultdict(ListNode) def put(self, key: int, value: int) -\u003e None: index = key % self.size # division 기법 # index에 노드가 없는 경우 # defaultdict는 index가 없으면 바로 생성하기에 # if self.table[index] is None: 이렇게 하면 무조건 True if self.table[index].value is None: self.table[index] = ListNode(key, value) return # 노드가 있는 경우 p = self.table[index] while p: if p.key == key: p.value = value return if p.next is None: return p = p.next p.next = ListNode(key, value) def get(self, key: int) -\u003e int: index = key % self.size # 해당하는 index가 비어있는 경우 if self.table[index].value is None: return -1 # 해당하는 index에서 값을 찾는다 p = self.table[index] while p: if p.key == key: return p.value p = p.next return -1 def remove(self, key: int) -\u003e None: index = key % self.size # 해당하는 index가 비어있는 경우 if self.table[index].value is None: return # index의 첫번째 노드일 때 삭제처리 p = self.table[index] if p.key == key: # if self.table[index].value is None: 이부분이 에러나지 않도록하기 위해 self.table[index] = ListNode() if p.next is None else p.next return # 연결 리스트 노드 삭제 prev = p while p: if p.key == key: prev.next = p.next return prev, p = p, p.next ","date":"2021-12-02","objectID":"/algo-12-hash/:5:0","tags":["해시","Hash"],"title":"[알고리즘] Hash","uri":"/algo-12-hash/"},{"categories":["알고리즘"],"content":"Reference 권오흠 교수님 알고리즘 Java예시를 Python으로 바꿔서 구현 ","date":"2021-12-02","objectID":"/algo-12-hash/:6:0","tags":["해시","Hash"],"title":"[알고리즘] Hash","uri":"/algo-12-hash/"},{"categories":["알고리즘"],"content":"이진검색트리 + python ","date":"2021-12-02","objectID":"/algo-11-bst2/:0:0","tags":["이진검색트리"],"title":"[알고리즘] 이진검색트리(BST)","uri":"/algo-11-bst2/"},{"categories":["알고리즘"],"content":"Dynamic set 여러 개의 키를 저장 다음과 같은 연산들을 지원하는 자료구조 INSERT : 새로운 키 삽입 SEARCH : 키 탐색 DELETE : 키 삭제 위를 구현하는데 다양한 방법들 존재 정렬된 혹은 정렬되지 않은 배열, 연결 리스트를 사용하면 위의 연산중에 적어도 하나는 $O(n)$ 트리 계열 해쉬 계열 ","date":"2021-12-02","objectID":"/algo-11-bst2/:1:0","tags":["이진검색트리"],"title":"[알고리즘] 이진검색트리(BST)","uri":"/algo-11-bst2/"},{"categories":["알고리즘"],"content":"검색트리 Dynamic set을 트리의 형태로 구현 일반적으로 SEARCH, INSERT, DELETE 연산이 트리의 높이에 비례하는 시간복잡도를 가짐 ","date":"2021-12-02","objectID":"/algo-11-bst2/:2:0","tags":["이진검색트리"],"title":"[알고리즘] 이진검색트리(BST)","uri":"/algo-11-bst2/"},{"categories":["알고리즘"],"content":"이진검색트리 (BST) 이진 트리이면서 각 노드에 하나의 키를 저장 각 노드 v에 대해서 그 노드의 왼쪽 subtree에 있는 키들은 key[v]보다 작거나 같고, 오른쪽 subtree에 있는 값은 크거나 같다. 각종 연산의 시간복잡도 $O(h)$, 최악의 경우는 트리의 높이가 $h=O(n)$이 될 수도 있다. 균형잡힌 트리(ex. 레드-블랙 트리)를 만들면 높이를 $O(\\log_2 n)$ class Node: def __init__(self, data): self.data = data self.left = None self.right = None class BinarySearchTree: def __init__(self): self.root = None ","date":"2021-12-02","objectID":"/algo-11-bst2/:3:0","tags":["이진검색트리"],"title":"[알고리즘] 이진검색트리(BST)","uri":"/algo-11-bst2/"},{"categories":["알고리즘"],"content":"최소값, 최대값 해당하는 최소값은 왼쪽자식이 없겠구나 root에서 왼쪽으로만 내려가서 더 이상 내려갈 곳이 없을 때 최대값은 반대! 시간복잡도 : $O(h)$ ","date":"2021-12-02","objectID":"/algo-11-bst2/:3:1","tags":["이진검색트리"],"title":"[알고리즘] 이진검색트리(BST)","uri":"/algo-11-bst2/"},{"categories":["알고리즘"],"content":"Successor 노드 x의 successor란 key[x]보다 크면서 가장 작은 키를 가진 노드 모든 키들이 서로 다르다고 가정 3 가지 경우 존재 노드 x의 오른쪽 subtree가 존재할 경우, 오른쪽 subtree의 최소값 오른쪽 subtree가 없는 경우, 어떤 노드 y의 왼쪽 subtree의 최대값이 x가 되는 그런 노드 y가 x의 successor 그런 노드 y가 존재하지 않을 경우 successor가 없음 (x가 최대값) 시간복잡도 : $O(h)$ ","date":"2021-12-02","objectID":"/algo-11-bst2/:3:2","tags":["이진검색트리"],"title":"[알고리즘] 이진검색트리(BST)","uri":"/algo-11-bst2/"},{"categories":["알고리즘"],"content":"Predecessor 노드 x의 successor란 key[x]보다 작으면서 가장 작은 키를 가진 노드 ","date":"2021-12-02","objectID":"/algo-11-bst2/:3:3","tags":["이진검색트리"],"title":"[알고리즘] 이진검색트리(BST)","uri":"/algo-11-bst2/"},{"categories":["알고리즘"],"content":"SEARCH class BinarySearchTree: ... def find(self, key): return self._find_value(self.root, key) def _find_value(self, root, key): if root is None or root.data == key: return root is not None elif key \u003c root.data: return self._find_value(root.left, key) else: return self._find_value(root.right, key) 시간복잡도 : $O(h)$ 여기서 $h$는 트리의 높이 ","date":"2021-12-02","objectID":"/algo-11-bst2/:3:4","tags":["이진검색트리"],"title":"[알고리즘] 이진검색트리(BST)","uri":"/algo-11-bst2/"},{"categories":["알고리즘"],"content":"INSERT x, y 두 포인터를 이용 또는 재귀 class BinarySearchTree: ... def insert(self, data): self.root = self._insert_value(self.root, data) return self.root is not None def _insert_value(self, node, data): if node is None: node = Node(data) else: if data \u003c= node.data: node.left = self._insert_value(node,left, data) else: node.right = self._insert_value(node.right, data) return node 시간복잡도 : $O(h)$ ","date":"2021-12-02","objectID":"/algo-11-bst2/:3:5","tags":["이진검색트리"],"title":"[알고리즘] 이진검색트리(BST)","uri":"/algo-11-bst2/"},{"categories":["알고리즘"],"content":"DELETE 삭제하려는 노드의 자식노드가 없는 경우 : 그냥 삭제 삭제하려는 노드의 자식노드가 1개인 경우 : 해당 자식노드를 나의 노드 위치로 보내면 된다 삭제하려는 노드의 자식노드가 2개인 경우 삭제하려는 노드의 successor를 찾는다 그 successor를 삭제하려는 노드로 옮긴다 그리고 successor는 최대 1개의 자식노드를 가지니까 이를 successor로 옮긴다 class BinarySearchTree: ... def delete(self, key): self.root, deleted = self._delete_value(self.root, key) return deleted def _delete_value(self, node, key): if node is None: return node, False deleted = False # 해당 노드가 삭제할 노드일 경우 if key == node.data: deleted = True # 삭제할 노드가 자식이 두개일 경우 if node.left and node.right: # 오른쪽 서브 트리에서 가장 왼쪽에 있는 노드를 찾고 교체 parent, child = node, node.right while child.left is not None: parent, child = child, child.left child.left = node.left if parent != node: parent.left = child.right child.right = node.right node = child # 자식 노드가 하나일 경우 해당 노드와 교체 elif node.left or node.right: node = node.left or node.right # 자식 노드가 없을 경우 그냥 삭제 else: node = None elif key \u003c node.data: node.left, deleted = self._delete_value(node.left, key) else: node.right, deleted = self._delete_value(node.right, key) return node, deleted 시간복잡도 : $O(h)$ ","date":"2021-12-02","objectID":"/algo-11-bst2/:3:6","tags":["이진검색트리"],"title":"[알고리즘] 이진검색트리(BST)","uri":"/algo-11-bst2/"},{"categories":["알고리즘"],"content":"Reference 권오흠 교수님 알고리즘 Java예시를 Python으로 바꿔서 구현 ","date":"2021-12-02","objectID":"/algo-11-bst2/:4:0","tags":["이진검색트리"],"title":"[알고리즘] 이진검색트리(BST)","uri":"/algo-11-bst2/"},{"categories":["알고리즘"],"content":"트리와 이진트리의 개념 + python ","date":"2021-12-02","objectID":"/algo-10-bst1/:0:0","tags":["트리","이진트리"],"title":"[알고리즘] 트리와 이진트리","uri":"/algo-10-bst1/"},{"categories":["알고리즘"],"content":"트리 Tree 계층적인 구조를 표현 노드(node)들과 노드들을 연결하는 링크(link or edge)들로 구성 맨 위의 노드를 루트 (root) 부모노드, 자식노드 형제관계 부모가 동일한 노드들을 형제 관계라고 부름 leaf 노드 자식이 없는 노드들 조상-자손 관계 부모-자식 관계를 확장한 것 부트리 subtree 트리의 일부분인 트리 레벨 트리의 깊이를 의미 level1이 root 위치를 의미 높이 ","date":"2021-12-02","objectID":"/algo-10-bst1/:1:0","tags":["트리","이진트리"],"title":"[알고리즘] 트리와 이진트리","uri":"/algo-10-bst1/"},{"categories":["알고리즘"],"content":"트리의 기본적인 성질 노드가 N개인 트리는 항상 N-1개의 링크를 가진다. 트리는 루트에서 어떤 노드로 가는 경로는 유일하다. (단 노드를 반복방문하지 않는다는 가정하에서) ","date":"2021-12-02","objectID":"/algo-10-bst1/:2:0","tags":["트리","이진트리"],"title":"[알고리즘] 트리와 이진트리","uri":"/algo-10-bst1/"},{"categories":["알고리즘"],"content":"이진트리 Binary Tree 각 노드는 최대 2개의 자식을 가진다. 자식이 한 명이여도 왼쪽, 오른쪽 자식인지 구분 ","date":"2021-12-02","objectID":"/algo-10-bst1/:3:0","tags":["트리","이진트리"],"title":"[알고리즘] 트리와 이진트리","uri":"/algo-10-bst1/"},{"categories":["알고리즘"],"content":"이진트리의 표현 연결구조 표현 각 노드에 하나의 데이터 필드와 왼쪽자식, 오른쪽 자식, 부모노드의 주소를 저장 부모노드의 주소는 반드시 필요한 경우가 아니면 보통 생략 ","date":"2021-12-02","objectID":"/algo-10-bst1/:3:1","tags":["트리","이진트리"],"title":"[알고리즘] 트리와 이진트리","uri":"/algo-10-bst1/"},{"categories":["알고리즘"],"content":"이진트리의 순회 (traversal) 순회 : 이진트리의 모든 노드를 방문하는 일 중순위(inorder) 순회 left subtree를 inorder 순회 root를 순회 right subtree를 inorder 순회 recursive 하다 선순위(preorder) 순회 후순위(postorder) 순회 레벨오더(level-order) 순회 레벨 순으로 방문 동일 레벨에서는 왼쪽에서 오른쪽 순서로 큐를 이용하여 구현 # 전위(Pre-Order) 순회 : NLR def preorder(node): if node is None: return print(node.val) preorder(node.left) preorder(node.right) # 중의(In-Order) 순회 : LNR def inorder(node): if node is None: return inorder(node.left) print(node.val) inorder(node.right) # 후위(Post-Order) 순회 : LRN def postorder(node): if node in None: return postorder(node.left) postorder(node.right) print(node.val) # level-order 순회 # pseudo code visit the root enque root into Q while Q is not empty do v = dequeue(Q) visit children of v enqueue children of v into Q end ","date":"2021-12-02","objectID":"/algo-10-bst1/:3:2","tags":["트리","이진트리"],"title":"[알고리즘] 트리와 이진트리","uri":"/algo-10-bst1/"},{"categories":["알고리즘"],"content":"Reference 권오흠 교수님 알고리즘 Java예시를 Python으로 바꿔서 구현 ","date":"2021-12-02","objectID":"/algo-10-bst1/:4:0","tags":["트리","이진트리"],"title":"[알고리즘] 트리와 이진트리","uri":"/algo-10-bst1/"},{"categories":["알고리즘"],"content":"Counting, Radix sort + python ","date":"2021-12-02","objectID":"/algo-09-sort6/:0:0","tags":["Counting sort","Radix sort"],"title":"[알고리즘] Sort in linear time","uri":"/algo-09-sort6/"},{"categories":["알고리즘"],"content":"Counting sort 조건 n개의 정수를 정렬 단, 모든 정수는 0에서 k사이의 정수 (사전지식) k가 주로 너무 크지 않은 경우 사용한다. 방법 길이 k인 배열에 각 정수의 개수를 count한다. 그 count개수를 기준으로 하나씩 뽑아내면 정렬한 결과가 나온다. 예를 들어, [4,1,2,1] 데이터가 있는 경우 count 배열은 [0,2,1,0,1]이 된다. 그러면 1은 2번, 2를 1번, 4를 1번로 하여 print하면 되는 것이다. 근데 위에서 문제는 우리가 정렬하는 데이터들은 다른 데이터들과 함께 묶여있는 경우가 많다. 예를 들어, 학생정보가 있는 데이터를 학생의 시험점수로 정렬하고자 하는 경우 그래서 윈래의 데이터 reference를 갖고 정렬하는 과정이 필요하다. 이를 위한 해결방법은 누적을 이용하는 것이다. 예를 들어, [4,1,2,1] 데이터가 있는 경우 count 배열은 [0,2,3,3,4]이 된다. 각 원소의 개수를 누적합으로 표현한다. 그리고 원래 데이터배열 [4,1,2,1] 뒤에서부터 하나씩 빼온다. 맨 뒤에 있는 1이 뽑힌다. 이렇게 맨 뒤에서부터 뽑으면 stable 정렬이 가능하다. stable 정렬 알고리즘 : 입력에 동일한 값이 있을때 입력에 먼저 나오는 값이 (정렬된)출력에서도 먼저 나온다. count배열에서 1이하의 값은 2개이므로 sort배열의 2번째 위치에 해당 값을 넣는다. (new sort배열 필요, index를 1부터 시작) count배열에서 1의 개수에서 1을 뺀다. 이런식으로 반복을 하면 정렬된 배열을 얻을 수 있다. data = [1,5,6,4,2,3] # 데이터수는 n # 데이터는 0부터 k의 값을 가진다. def counting_sort(data, n=None, k=None): if n is None: n = len(data) if k is None: k = max(data) sort_list = [0]*(n+1) # index를 1부터 하기 위해 count_list = [0]*(k+1) # data 원소별 개수 count for ele in data: count_list[ele] += 1 # 누적합 for i in range(1,len(count_list)): count_list[i] = count_list[i-1] + count_list[i] # 정렬 # data의 맨 뒤부터 시작 -\u003e stable 정렬이 가능 for i in range(n-1, -1, -1): sort_list[count_list[data[i]]] = data[i] count_list[data[i]] -= 1 return sort_list[1:] # index를 1부터 사용했으니까 print(counting_sort(data, len(data), max(data))) 시간복잡도 $O(n+k);\\text{or};O(n);\\text{if};k=O(n)$ $k$가 클 경우 비실용적 ","date":"2021-12-02","objectID":"/algo-09-sort6/:1:0","tags":["Counting sort","Radix sort"],"title":"[알고리즘] Sort in linear time","uri":"/algo-09-sort6/"},{"categories":["알고리즘"],"content":"Radix sort n개의 d자리 정수들 정수가 꼭 아니여도 된다 ex. d자리 문자열 가장 낮은 자리수부터 정렬 stable 정렬을 이용해야한다. 예를 들어, [77,66,69] 이라는 배열이 있다. 먼저 일의 자리에 따라 정렬하면 [66,77,69] 가 되고 다음 십의 자리에 따라 정렬하면 [66,69,77]이 된다. 여기서 66과 69는 십의 자리가 같지만 제대로 정렬이 되는 이유는 이전에 일의 자리에서 정렬한 순서를 그대로 유지했지 때문이다. (stable) stable 정렬에 counting sort이용하면 되겠다. 이런 경우 시간복잡도 $O(d(n+k))$ 그런데 $d$가 상수고 $k=O(n)$이면 $O(n)$ data = [13,22,16,4,12,23] def counting_sort_for_radix(data, digit): n = len(data) sort_list = [0]*(n+1) count_list = [0]*10 for i in data: idx = i // digit count_list[idx % 10] += 1 for i in range(1,10): count_list[i] = count_list[i-1] + count_list[i] for i in range(n-1, -1, -1): idx = data[i] // digit sort_list[count_list[idx % 10]] = data[i] count_list[idx % 10] -= 1 return sort_list[1:] def radix_sort(arr): max_val = max(arr) digit = 1 while max_val // digit \u003e 0: arr = counting_sort_for_radix(arr, digit) digit *= 10 return arr print(radix_sort(data)) ","date":"2021-12-02","objectID":"/algo-09-sort6/:2:0","tags":["Counting sort","Radix sort"],"title":"[알고리즘] Sort in linear time","uri":"/algo-09-sort6/"},{"categories":["알고리즘"],"content":"Reference 권오흠 교수님 알고리즘 Java예시를 Python으로 바꿔서 구현 ","date":"2021-12-02","objectID":"/algo-09-sort6/:3:0","tags":["Counting sort","Radix sort"],"title":"[알고리즘] Sort in linear time","uri":"/algo-09-sort6/"},{"categories":["알고리즘"],"content":"정렬 알고리즘의 lower bound는? comparison sort 데이터들간의 상대적 크기관계만을 이용해서 정렬하는 알고리즘 이전까지 배운 bubble, insertion, merge, quick, heap sort 등 non-comparison sort 정렬할 데이터에 대한 사전지식을 이용 예) 100점만점 시험인 학생들의 점수(최대100점이라는 사전지식이 있는 것) : 90점대, 80점대.. 이렇게 분류한 뒤 정렬 Bucket sort Radix sort ","date":"2021-12-02","objectID":"/algo-08-sort5/:0:0","tags":["정렬"],"title":"[알고리즘] 정렬의 lower bound","uri":"/algo-08-sort5/"},{"categories":["알고리즘"],"content":"하한 (Lower Bound) 입력된 데이터를 한벅씩 다 보기위해서 최소 $O(n)$의 시간복잡도 필요 merge, heap sort의 시간복잡도는 $O(n\\log_2 n)$ 어떤 comparison sort 알고리즘도 $O(n\\log_2 n)$보다 나을수 없다. 이에 대한 증명은 decision tree로 한다. n개의 data를 정렬하고자 한다. 그렇다면 가능한 경우의 수는? n! 이를 decision tree를 통해 그 과정을 나타내면 leaf가 n!개인 decision tree가 완성될 것이다. 따라서 $height \\ge \\log_2 n!$임을 알 수 있다. height는 시간복잡도를 의미한다고 할 수 있다. 비교를 할 때 2개의 숫자중 큰것, 작은것으로 나누기 때문이다. 그런데 수학적인 증명을 통해 $\\log_2 n! = O(n\\log_2 n)$라고 한다. ","date":"2021-12-02","objectID":"/algo-08-sort5/:1:0","tags":["정렬"],"title":"[알고리즘] 정렬의 lower bound","uri":"/algo-08-sort5/"},{"categories":["알고리즘"],"content":"Reference 권오흠 교수님 알고리즘 ","date":"2021-12-02","objectID":"/algo-08-sort5/:2:0","tags":["정렬"],"title":"[알고리즘] 정렬의 lower bound","uri":"/algo-08-sort5/"},{"categories":["알고리즘"],"content":"우선순위 큐 + python ","date":"2021-12-02","objectID":"/algo-07-sort4/:0:0","tags":["우선순위 큐"],"title":"[알고리즘] 힙의 응용","uri":"/algo-07-sort4/"},{"categories":["알고리즘"],"content":"힙의 응용 : 우선순위 큐 우선순위 큐도 최대, 최소 우선순위 큐가 존재한다. FIFO queue 다음의 두 가지 연산을 지원하는 자료구조이다. INSERT : 새로운 원소를 삽입 EXTRACT_MAX(MIN) : 최대(최소)값을 삭제하고 반환 ","date":"2021-12-02","objectID":"/algo-07-sort4/:1:0","tags":["우선순위 큐"],"title":"[알고리즘] 힙의 응용","uri":"/algo-07-sort4/"},{"categories":["알고리즘"],"content":"INSERT heap에 새로운 원소를 넣는 과정 맨 마지막 위치에 원소를 넣고 원소의 부모와 값을 비교해가면서 완성된 heap을 만들어간다. data = ['no use',1,5,6,4,2,3] n = len(data)-1 # max heap 생성 for i in range(n, 0, -1): max_heapify(data, i, n) def insert(data, original_heap_size, new_data): heap_size = original_heap_size + 1 data[heap_size] = new_data i = heap_size # i \u003e1 : i가 root가 아니고 # data[i//2] \u003c data[i] : new_data가 부모보다 큰 경우 while i \u003e 1 and data[i//2] \u003c data[i]: data[i//2], data[i] = data[i], data[i//2] i //= 2 시간복잡도 $O(log_2 n)$ ","date":"2021-12-02","objectID":"/algo-07-sort4/:1:1","tags":["우선순위 큐"],"title":"[알고리즘] 힙의 응용","uri":"/algo-07-sort4/"},{"categories":["알고리즘"],"content":"EXTRACT_MAX() root값이 max이므로 root의 값을 뽑기 \u0026 삭제 맨 뒤에 있는 원소를 root로 보내기 heapify 위에서 맨 뒤에 있는 원소를 root로 보내면 다른 영역에서 heap이 무너지지 않는다. 즉, 전체에 대해 heapify할 상태가 된 것이다. heapify를 하면 문제가 해결되는 것이다. data = ['no use',1,5,6,4,2,3] n = len(data)-1 # max heap 생성 for i in range(n, 0, -1): max_heapify(data, i, n) def extract_max(data, heap_size): if heap_size \u003c 1: return # heap의 root는 max max_val = data[1] # 맨 마지막원소를 root로 보내기 data[1] = data[heap_size] # root값을 뺐으니까 heap_size -= 1 # root의 subtree들은 heap인 상태므로 heapify max_heapify(data, 1, heap_size) return max_val ","date":"2021-12-02","objectID":"/algo-07-sort4/:1:2","tags":["우선순위 큐"],"title":"[알고리즘] 힙의 응용","uri":"/algo-07-sort4/"},{"categories":["알고리즘"],"content":"Reference 권오흠 교수님 알고리즘 Java예시를 Python으로 바꿔서 구현 ","date":"2021-12-02","objectID":"/algo-07-sort4/:2:0","tags":["우선순위 큐"],"title":"[알고리즘] 힙의 응용","uri":"/algo-07-sort4/"},{"categories":["알고리즘"],"content":"Heap sort + python ","date":"2021-12-02","objectID":"/algo-06-sort3/:0:0","tags":["Heap sort"],"title":"[알고리즘] Heap sort","uri":"/algo-06-sort3/"},{"categories":["알고리즘"],"content":"Heap sort (힙 정렬) 최악의 경우 시간복잡도 $O(n\\log_2 n)$ 추가 배열 불필요 이진 힙 (binary heap) 자료구조를 사용 ","date":"2021-12-02","objectID":"/algo-06-sort3/:1:0","tags":["Heap sort"],"title":"[알고리즘] Heap sort","uri":"/algo-06-sort3/"},{"categories":["알고리즘"],"content":"Binary tree (이진 트리) 트리인데 각 노드가 최대 2명의 자식을 갖는 트리 자식은 왼쪽자식, 오른쪽자식으로 구분 full binary tree : 모든 레벨에 노드들이 꽉 차있는 형태 complete binary tree : 마지막 레벨을 제외하면 완전히 꽉 차있고, 마지막 레벨에는 가장 오른쪽부터 연속된 몇 개의 노드가 비어있을 수 있다. ","date":"2021-12-02","objectID":"/algo-06-sort3/:2:0","tags":["Heap sort"],"title":"[알고리즘] Heap sort","uri":"/algo-06-sort3/"},{"categories":["알고리즘"],"content":"Heap의 정의 heap은 complete binary tree heap property를 만족 max heap property : 부모는 자식보다 크거나 같다 min heap property : 부모는 자식보다 작거나 같다 동일한 데이터를 가진 힙은 유일하지 않다. 여러개가 존재할 수 있다. ","date":"2021-12-02","objectID":"/algo-06-sort3/:3:0","tags":["Heap sort"],"title":"[알고리즘] Heap sort","uri":"/algo-06-sort3/"},{"categories":["알고리즘"],"content":"Heap의 표현 힙은 일차원 배열로 표현가능! A[1,2,...,n] 의 배열이 있을 때 (index를 1부터 시작) root node : A[1] A[i]의 부모 = A[i/2] (python에서는 A[i//2] 의미) A[i]의 왼쪽 자식 = A[2i] A[i]의 오른쪽 자식 = A[2i+1] ","date":"2021-12-02","objectID":"/algo-06-sort3/:3:1","tags":["Heap sort"],"title":"[알고리즘] Heap sort","uri":"/algo-06-sort3/"},{"categories":["알고리즘"],"content":"기본 연산 : max-heapify 현재 상황 root만이 heap property를 만족 안한다. 즉, 자식중에 더 큰 수가 존재한다. 단, 왼쪽, 오른쪽 subtree(root 기준 왼쪽, 오른쪽 자식이 root가 되는 tree)는 heap인 상태 이런 경우 부모의 값이 더 작은 경우 자식과 swap한다. 이를 반복하면 전체 트리가 heap이 된다. # recursive def max_heapify(A, i): left = 2*i right = 2*i + 1 # 자식이 없는 경우 if (left \u003e len(A)-1) and (right \u003e len(A)-1): return else: # i의 자식 중에 큰 값 찾기 # 2*i+1 \u003e len(A)-1 : 왼쪽 자식만 있거나 # A[2*i] \u003e= A[2*i+1] : 왼쪽 자식이 오른쪽 자식보다 크거나 같은 경우 if right \u003e len(A)-1 or A[left] \u003e= A[right]: k = left else: k = right # 부모(i)보다 자식(k)이 더 작으면 swap if A[i] \u003e= A[k]: return else: A[i], A[k] = A[k], A[i] max_heapify(A, k) # index 1 아래의 subtree들은 이미 heap이라고 가정하고 진행한 것 max_heapify(data, 1) print(data) ","date":"2021-12-02","objectID":"/algo-06-sort3/:3:2","tags":["Heap sort"],"title":"[알고리즘] Heap sort","uri":"/algo-06-sort3/"},{"categories":["알고리즘"],"content":"정렬할 배열을 힙으로 만들기 배열을 사용하는데 이를 complete binary tree의 형태로 이해하자. heap정렬을 하기위해서는 먼저 tree를 heap으로 만들어야한다. 이를 위해서 tree에서 작은 subtree들부터 (아래부터) heapify를 진행한다. 점점 위로 올라가면서 (heap이 된 tree들을 포함하는 더 큰 tree)들을 heapify하면서 전체 tree(배열)을 heap으로 만든다. 수학적으로 계산하면 heap으로 만드는 시간복잡도는 $O(n)$이다. ","date":"2021-12-02","objectID":"/algo-06-sort3/:4:0","tags":["Heap sort"],"title":"[알고리즘] Heap sort","uri":"/algo-06-sort3/"},{"categories":["알고리즘"],"content":"정렬 heap은 정렬된 상태라고 할 수 없다. 다만 확실한 것은 root가 최대값이라는 것이다. 이 특징을 이용하여 heap sort를 진행할 것이다. 주어진 데이터로 heap을 만든다. heap에서 최대값(root값)을 가장 마지막 값과 바꾼다. 이 때 heap의 크기가 1 줄어든 것으로 간주 즉, 마지막값은 heap의 일부가 아닌 것 root node에 대해서 heapify(1)한다. 위의 과정을 반복하면서 정렬할 수 있다. (계속해서 최대값을 구하는 과정이므로) # pseudo code HEAPSORT(A) BUILD-MAX-HEAP(A) : O(n) for i \u003c- heap_size downto 2 do : n-1 times exchange A[1] \u003c-\u003e A[i] : O(1) heap_size \u003c- heap_size - 1 : O(1) MAX-HEAPIFY(A,1) : O(log n) # max-heap sort data = ['no use',1,5,6,4,2,3] def max_heapify(A, i): left = 2*i right = 2*i + 1 if (left \u003e len(A)-1) and (right \u003e len(A)-1): return else: if right \u003e len(A)-1 or A[left] \u003e= A[right]: k = left else: k = right if A[i] \u003e= A[k]: return else: A[i], A[k] = A[k], A[i] max_heapify(A, k) def heap_sort(data, n): # max heap 생성 for i in range(n, 0, -1): max_heapify(data, i, n) # sort for j in range(n, 0, -1): # heap에서 root가 max이므로 # 맨뒤로 보낸다 data[1], data[j] = data[j], data[1] # heap size(n)을 하나씩 줄인다 n -= 1 max_heapify(data, 1, n) heap_sort(data, len(data)-1) print(data) 시간복잡도 $O(n\\log_2 n)$ ","date":"2021-12-02","objectID":"/algo-06-sort3/:4:1","tags":["Heap sort"],"title":"[알고리즘] Heap sort","uri":"/algo-06-sort3/"},{"categories":["알고리즘"],"content":"Reference 권오흠 교수님 알고리즘 Java예시를 Python으로 바꿔서 구현 ","date":"2021-12-02","objectID":"/algo-06-sort3/:5:0","tags":["Heap sort"],"title":"[알고리즘] Heap sort","uri":"/algo-06-sort3/"},{"categories":["알고리즘"],"content":"Merge, Quick sort + python 두 가지 방법 모두 분할정복법 의 전략을 사용한다. 해결하고자 하는 문제를 작은 크기의 동일한 문제들로 분할 각각의 작은 문제를 순환적으로 해결 작은 문제의 해를 합하여(merge) 원래 문제에 대한 해를 구함 ","date":"2021-12-02","objectID":"/algo-05-sort2/:0:0","tags":["Merge sort","Quick sort"],"title":"[알고리즘] 정렬 알고리즘 (2)","uri":"/algo-05-sort2/"},{"categories":["알고리즘"],"content":"Merge sort (병합정렬) 데이터가 저장된 배열을 절반으로 나눔 (divide) 각각을 순환적으로 정렬 (recursively sort) 정렬된 두 개의 배열을 합쳐서 전체를 정렬 (merge) 계속 나누다보면 길이가 1인 배열이 남을 것이다. 이를 merge할 때, sort를 한다. 이때, 두 배열을 앞에서부터 서로 비교를 하면서 작은 원소를 뽑아서 임시배열에 넣으면 된다. 이 과정에서 임시배열을 위한 별도의 저장 공간이 필요하다. data = [5,2,3,1,4] def merge_sort(data): def sort(start, end): if start \u003c end: mid = (start+end) // 2 sort(start, mid) sort(mid+1, end) merge(start, mid, end) else: return def merge(start, mid, end): # 임시 배열이 필요 # 임시 배열에 두 배열의 원소들을 비교하면서 # 넣어주고 다 넣으면 data를 tmp로 수정 tmp = [0] * len(data) i, j = start, mid+1 k = start # 정렬된 두 배열을 merge하는 과정 while i \u003c= mid and j \u003c= end: if data[i] \u003c data[j]: tmp[k] = data[i] i += 1 k += 1 else: tmp[k] = data[j] j += 1 k += 1 # 만약에 merge하는 두 배열중에 한쪽이 다 끝나면 # 나머지 한쪽 배열의 원소들은 그대로 tmp에 넣으면 되니까 while i \u003c= mid: tmp[k] = data[i] i += 1 k += 1 while j \u003c= end: tmp[k] = data[j] j += 1 k += 1 # tmp에 mergesort된 배열로 data를 수정 for i in range(start, end+1): data[i] = tmp[i] return sort(0, len(data)-1) merge_sort(data) print(data) 시간복잡도 $T(n)$ : n개의 data를 정렬하는데 걸리는 시간 if n=1, $T(n)=0$ otherwise, $T(n) = T(n/2) + T(n/2) + n$ 여기서 $n$은 정렬된 두 배열의 원소들을 하나씩 비교하면서 merge하는 과정 최종적으로 $O(n \\log n)$ 그림을 그리면서 고민해보면 이진트리처럼 모양이 나온다. 각 depth마다 연산량이 $n$이기 때문에! ","date":"2021-12-02","objectID":"/algo-05-sort2/:1:0","tags":["Merge sort","Quick sort"],"title":"[알고리즘] 정렬 알고리즘 (2)","uri":"/algo-05-sort2/"},{"categories":["알고리즘"],"content":"Quick sort (퀵정렬) 분할정복법 분할 배열의 원소중 하나를 pivot으로 선정한다. [pivot보다 작은 원소들], [pivot보다 큰 원소들] 두 부분으로 나눈다. 정복 : 각 부분을 순환적으로 정렬한다. 합병 : 해당사항이 없다. data = [5,2,3,1,4] def quick_sort(data): def sort(start, end): if start \u003c end: q = partition(start, end) sort(start, q-1) sort(q+1, end) else: return def partition(start, end): # 맨 뒤에 있는 원소를 pivot으로 지정 pivot = data[end] # i는 pivot보다 작은원소들중 마지막 원소의 위치 i = start - 1 # j은 pivot과 비교하는 원소의 위치 # 처음부터 pivot전까지 순서대로 쭉 간다 for j in range(start, end): # 원소가 pivot보다 작으면 i++ 하고 i와 j위치 swap # 그러면 i는 작은원소들중 마지막 원소의 위치 유지 # i이하의 원소들은 다 pivot보다 작은 원소들 # 원소가 pivot보다 크면 nothing if data[j] \u003c pivot: i += 1 data[i], data[j] = data[j], data[i] # pivot 앞에 위치한 원소까지 다하면 # i+1의 위치의 원소와 pivot을 swap하면 정렬완료! data[i+1], data[end] = data[end], data[i+1] # pivot의 위치 return return i+1 return sort(data, 0, len(data)-1) quick_sort(data) print(data) 시간복잡도 최악의 경우 $O(n^2)$ 항상 한 쪽은 0개 다른 쪽은 n-1개로 분할되는 경우 pivot의 값이 어떤 값 걸리냐에 따라 달라지겠다. pivot값이 전체에서 최소, 최대값인 경우 $O(n^2)$이 되는 것이다. 최선의 경우 $O(n\\log n)$ 항상 절반으로 분할이 되는 경우 일반적으로 quick sort가 선호되는 이유는 무엇일까. 항상 한쪽이 적어도 1/9 이상이 되도록 분할된다면 가정해보자. 그림 영상 40분 참고 제일 오래 걸리는 경우는 계속 분할이 0.9만큼 되는 경우이므로 $(\\frac{9}{10})^k * n = 1$ 이라고 할 수 있다. 따라서 $k=\\log_{10/9}n \\approx \\log n$ 이라고 할 수 있다. 1:9만 되더라도 $O(n\\log n)$이 되는 것이다. 실제로 극단적으로 최악의 경우가 되는 경우는 많지 않으니까 quick sort가 일반적으로 좋은 성능을 보인다고 할 수 있다. 실제로 quick sort의 평균시간복잡도를 수학적으로 계산하면 $O(n\\log_2 n)$이 나온다. pivot의 선택 첫번째 값이나 마지막 값을 pivot으로 선택 좋은 방법은 아니다. 이미 정렬된 데이터 혹은 거꾸로 정렬된 데이터가 들어오는 경우 최악의 경우가 된다. Median of three 중간값을 pivot으로 선택 정렬된 데이터가 들어와도 최악의 경우가 발생하지 않는다. 그렇다고 최악의 경우에 해당하는 시간복잡도가 달라지는 것은 아니다. Randomized Quicksort pivot을 랜덤하게 선택 최악의 경우가 되는 경우는 확률적으로 거의 없지만 없다고는 할 수 없다. ","date":"2021-12-02","objectID":"/algo-05-sort2/:2:0","tags":["Merge sort","Quick sort"],"title":"[알고리즘] 정렬 알고리즘 (2)","uri":"/algo-05-sort2/"},{"categories":["알고리즘"],"content":"Reference 권오흠 교수님 알고리즘 Java예시를 Python으로 바꿔서 구현 ","date":"2021-12-02","objectID":"/algo-05-sort2/:3:0","tags":["Merge sort","Quick sort"],"title":"[알고리즘] 정렬 알고리즘 (2)","uri":"/algo-05-sort2/"},{"categories":["알고리즘"],"content":"Selection, Bubble, Insertion sort + python ","date":"2021-12-02","objectID":"/algo-04-sort1/:0:0","tags":["Selection sort","Bubble sort","Insertion sort"],"title":"[알고리즘] 정렬 알고리즘 (1)","uri":"/algo-04-sort1/"},{"categories":["알고리즘"],"content":"Selection sort 순서대로 하나씩 비교하면서 가장 큰 값을 맨 뒤로 보낸다. data = [5,2,3,1,4] def selection_sort(data): n = len(data) # for 루프는 n-1번 반복 for last in range(n-1, 0, -1): max_val = data[last] # 가장 큰 수를 찾기 위해 last번 반복 for k in range(0, last): if max_val \u003c data[k]: data[last], data[k] = data[k], data[last] selection_sort(data) print(data) 시간복잡도 $(n-1)+(n-2)+…+1=O(n^2)$ 최악, 최선, 평균의 경우 모두 동일 ","date":"2021-12-02","objectID":"/algo-04-sort1/:1:0","tags":["Selection sort","Bubble sort","Insertion sort"],"title":"[알고리즘] 정렬 알고리즘 (1)","uri":"/algo-04-sort1/"},{"categories":["알고리즘"],"content":"Bubble sort 두 개씩 비교해서 큰 값을 뒤로 보낸다. 이를 반복하면 가장 큰 값이 맨 뒤로 간다. data = [5,2,3,1,4] def bubble_sort(data): n = len(data) # for 루프는 n-1번 반복 for last in range(n-1, 0, -1): # for 루프는 last번 반복 for k in range(0, last): if data[k] \u003e data[k+1]: data[k], data[k+1] = data[k+1], data[k] bubble_sort(data) print(data) 시간복잡도 $(n-1)+(n-2)+…+1=O(n^2)$ 최악, 최선, 평균의 경우 모두 동일 ","date":"2021-12-02","objectID":"/algo-04-sort1/:2:0","tags":["Selection sort","Bubble sort","Insertion sort"],"title":"[알고리즘] 정렬 알고리즘 (1)","uri":"/algo-04-sort1/"},{"categories":["알고리즘"],"content":"Insertion sort (삽입정렬) 예를 들어 [2,4,3,1]을 정렬한다고 생각해보자. [2]는 하나이므로 정렬된 상태 4을 [2]의 원소와 비교하여 2뒤에 삽입 : [2,4] 3을 [2,4]의 원소와 비교하여 2뒤, 4앞에 삽입 : [2,3,4] 1을 [2,3,4]의 원소와 비교하여 2앞에 삽입 : [1,2,3,4] 근데 여기서 삽입을 위해 이미 정렬된 배열의 원소들과 비교할 때 뒤에서부터, 즉 큰 값들부터 비교하는게 더 빠르다. 앞에서부터(작은 값부터) 비교하면 맨 뒤까지 가야하지만 뒤에서부터(큰 값부터) 내려오다가 삽입값보다 작은 값을 만나면 멈추고 삽입할 수 있기 때문이다. data = [5,2,3,1,4] def insert_sort(data): n = len(data) # for 루프는 n-1번 반복 for i in range(1,n): insert_val = data[i] # 최악의 경우 i-1번 반복 while i \u003e 0 and data[i-1] \u003e insert_val: data[i] = data[i-1] i -= 1 data[i] = insert_val insert_sort(data) print(data) 시간복잡도 최악 : $(n-1)+(n-2)+…+1=O(n^2)$ 최선 : $O(n)$ ","date":"2021-12-02","objectID":"/algo-04-sort1/:3:0","tags":["Selection sort","Bubble sort","Insertion sort"],"title":"[알고리즘] 정렬 알고리즘 (1)","uri":"/algo-04-sort1/"},{"categories":["알고리즘"],"content":"Reference 권오흠 교수님 알고리즘 Java예시를 Python으로 바꿔서 구현 ","date":"2021-12-02","objectID":"/algo-04-sort1/:4:0","tags":["Selection sort","Bubble sort","Insertion sort"],"title":"[알고리즘] 정렬 알고리즘 (1)","uri":"/algo-04-sort1/"},{"categories":["알고리즘"],"content":"멱집합, 조합 + python ","date":"2021-12-02","objectID":"/algo-03-recursion3/:0:0","tags":["Recursion"],"title":"[알고리즘] 멱집합, 조합","uri":"/algo-03-recursion3/"},{"categories":["알고리즘"],"content":"멱집합(powerset) 임의의 data에 대해 모든 부분집합을 의미한다. 이를 recursion으로 해결해보고자 한다. {a,b,c,d}의 모든 부분집합을 나열하려면 {c,d}의 모든 부분집합에 {a}를 추가한 집합들을 나열한다. {c,d}의 모든 부분집합에 {a,b}를 추가한 집합들을 나열한다. 이런 과정에서 recursion으로 진행하는 것이다. 이를 실제로 구현하기 위해서 어떤 식으로 접근해야할지 고민해보자. 위에서 {c,d}를 집합 S라고 하자. 이는 k번째부터 마지막 원소까지 연속된 원소들이다. {a}, {a,b}는 처음부터 k-1번째 원소들 중의 일부이다. 이를 P집합이라 하자. 즉, S의 멱집합을 구한 후 각각에 집합 P를 합집합하면 되는 것이다. 이를 위해서 k라는 매개변수가 필요함을 알 수 있다. 그렇다면 집합 P은 어떻게 표현해야할까? include라는 list를 만들어서 True면 포함, False면 빼면 된다. 이를 통해 k-1번째까지 원소들의 집합들을 만들 수 있을 것이다. 상태공간트리의 형태로 이해해도 좋다. (개인적으로 이게 더 편했다) 왼쪽 자식 노드는 k번째 data를 제외 오른쪽 자식 노드는 k번재 data를 포함하여서 내려간다. 제일 왼쪽 마지막 노드는 공집합, 오른쪽 마지막 노드는 모든 원소가 포함된 집합 data = ['a','b','c','d'] # 전역변수 n = len(data) include = [0]*n # 모든 멱집합을 print하는 함수 def powerset(k: int): tmp = [] if k == n: for i in range(n): # include가 1인 경우만 print if include[i] == 1: tmp.append(data[i]) print(tmp) return # k번재 원소 제외 include[k] = 0 powerset(k+1) # k번째 원소 포함 include[k] = 1 powerset(k+1) powerset(0) ","date":"2021-12-02","objectID":"/algo-03-recursion3/:1:0","tags":["Recursion"],"title":"[알고리즘] 멱집합, 조합","uri":"/algo-03-recursion3/"},{"categories":["알고리즘"],"content":"순열(permutation) {a,b,c,d}의 모든 순열은? {b,c,d}의 모든 순열에 a를 추가 {a,c,d}의 모든 순열에 b를 추가 {a,b,d}의 모든 순열에 c를 추가 {a,b,c}의 모든 순열에 d를 추가 이런식으로 recursion을 진행하는 것이다. 여기서도 매개변수 k를 사용하자. k부터 나머지 원소의 순열에 0 ~ k-1까지 원소는 추가해주는 원리이다. data = ['a','b','c'] def perm(k: int): if k == len(data)-1: print(data) return else: for i in range(k, len(data)): data[k], data[i] = data[i], data[k] perm(k+1) data[i], data[k] = data[k], data[i] perm(0) ","date":"2021-12-02","objectID":"/algo-03-recursion3/:2:0","tags":["Recursion"],"title":"[알고리즘] 멱집합, 조합","uri":"/algo-03-recursion3/"},{"categories":["알고리즘"],"content":"Reference 권오흠 교수님 알고리즘 Java예시를 Python으로 바꿔서 구현 ","date":"2021-12-02","objectID":"/algo-03-recursion3/:3:0","tags":["Recursion"],"title":"[알고리즘] 멱집합, 조합","uri":"/algo-03-recursion3/"},{"categories":["알고리즘"],"content":"미로찾기, n queens problem + python ","date":"2021-12-02","objectID":"/algo-02-recursion2/:0:0","tags":["Recursion"],"title":"[알고리즘] Recursion의 응용","uri":"/algo-02-recursion2/"},{"categories":["알고리즘"],"content":"미로찾기 ","date":"2021-12-02","objectID":"/algo-02-recursion2/:1:0","tags":["Recursion"],"title":"[알고리즘] Recursion의 응용","uri":"/algo-02-recursion2/"},{"categories":["알고리즘"],"content":"Recursive Thinking 현재 위치에서 출구까지 가는 경로가 있으려면 현재 위치가 출구이거나 혹은 이웃한 셀들 중 하나에서 현재 위치를 지나지 않고 출구까지 가는 경로가 있거나 from collections import deque n, m = map(int, input().split()) maze = [] for i in range(n): maze.append(list(map(int, input()))) def findMaze(x: int, y: int): on_path = 0 # visited이며 아직 출구로 가는 경로가 될 가능성 존재 wall = 1 blocked = 2 # visited이며 출구로 가는 경로가 안됨 path = 3 # 출구로 가는 경로 # maze의 크기를 벗어나는 경우 if x \u003c 0 or y \u003c 0 or x \u003e=n or y \u003e= m: return False # 출구로 가는 경로가 될 가능성이 없는 경우 제외 elif maze[x][y] != on_path: return False # 길을 찾은 경우 elif x == n-1 \u0026 y == m-1: maze[x][y] = path return True # recursion else: maze[x][y] = path if findMaze(x-1, y) or findMaze(x, y+1) or\\ findMaze(x+1, y) or findMaze(x, y-1): return True maze[x][y] = blocked # 위에서 True가 아니면 경로에 포함이 안되니까 return False print(maze) print(findMaze(0,0)) print(maze) ","date":"2021-12-02","objectID":"/algo-02-recursion2/:1:1","tags":["Recursion"],"title":"[알고리즘] Recursion의 응용","uri":"/algo-02-recursion2/"},{"categories":["알고리즘"],"content":"Counting Cells in a Blob 입력으로 흑백 binary 이미지가 주어진다. 각 픽셀은 background pixel이거나 혹은 image pixel 서로 연결된 image pixel들의 집합을 blob이라고 부른다. (대각방향도 포함) n, m = map(int, input().split()) image = [] for i in range(n): image.append(list(map(int, input()))) def count_cell(x: int, y: int) -\u003e int: background_color = 0 image_color = 1 counted_color = 2 if x \u003c 0 or y \u003c 0 or x \u003e= n or y \u003e= m: return 0 elif image[x][y] != image_color: return 0 else: image[x][y] = counted_color return 1 + count_cell(x-1, y) + count_cell(x-1, y+1) +\\ count_cell(x, y+1) + count_cell(x+1, y+1) +\\ count_cell(x+1, y) + count_cell(x+1, y-1)+\\ count_cell(x, y-1)+count_cell(x-1, y-1) print(image) print(count_cell(1,1)) print(image) ","date":"2021-12-02","objectID":"/algo-02-recursion2/:2:0","tags":["Recursion"],"title":"[알고리즘] Recursion의 응용","uri":"/algo-02-recursion2/"},{"categories":["알고리즘"],"content":"n queens problem 체스에서 여왕은 모든 길로 갈 수 있다. N*N 체스판에 N개의 Queen을 놓고 싶다. 그런데 서로를 공격하지 않게 올려놓고 싶다. 총 몇 가지 경우의 수가 있을까? 모든 경우의 수를 고려하면 O(N^N) 조합이 존재한다. 이를 더 빠르게 해야겠구나! 그래서 Backtracking 기법 조합의 숫자를 셀 때, 모든 조합이 아닌 특정조건에 한정해서 조합을 카운트하는 개념 일반적으로 DFS(깊이우선탐색)을 통하여 구현 (recursion이나 stack사용할 수 있겠구나) ","date":"2021-12-02","objectID":"/algo-02-recursion2/:3:0","tags":["Recursion"],"title":"[알고리즘] Recursion의 응용","uri":"/algo-02-recursion2/"},{"categories":["알고리즘"],"content":"상태공간트리 찾는 해를 포함하는 트리 즉, 해가 트리의 어떤 한 노드(노드가 갖고있는 값)에 해당한다. 이 문제를 풀기 위해 상태공간 트리의 모든 노드를 탐색해야 하는 것은 아니다. 깊이 내려가지 전에 이미 infeasible한 경우가 있기 때문에 # 매개변수 level은 현재 노드의 위치(깊이) # 전역변수 배열 cols를 이용하여 # cols[i] = j # 으로 여왕이 (i행, j열) 에 있음을 표시한다. # level == N 이면 모든 말이 놓였다는 의미 -\u003e 성공! n = int(input()) class Queen: def __init__(self, n: int): self.n = n self.cols = [-1]*n self.counts = 0 def search(self, level: int): # 현재 level이 n이라는 것은 # 0~n-1 까지 다 여왕을 놓았다는 의미 if level == self.n: self.counts += 1 print(self.cols) return self.counts else: for i in range(self.n): self.cols[level] = i if self._is_possible(level): self.search(level+1) def _is_possible(self, level: int): # 0~level-1 까지의 여왕들과 만나는지 확인해야한다. # 행은 이미 다르므로 # 같은 열 or 대각선에 있는지 확인이 필요하다. for i in range(level): # 같은 열에 있는지 확인 if self.cols[i] == self.cols[level]: return False # 대각선에 있는지 확인 elif abs(i-level) == abs(self.cols[i]-self.cols[level]): return False return True q = Queen(n) print(q.search(0)) ","date":"2021-12-02","objectID":"/algo-02-recursion2/:4:0","tags":["Recursion"],"title":"[알고리즘] Recursion의 응용","uri":"/algo-02-recursion2/"},{"categories":["알고리즘"],"content":"Reference 권오흠 교수님 알고리즘 Java예시를 Python으로 바꿔서 구현 ","date":"2021-12-02","objectID":"/algo-02-recursion2/:5:0","tags":["Recursion"],"title":"[알고리즘] Recursion의 응용","uri":"/algo-02-recursion2/"},{"categories":["알고리즘"],"content":"Recursion(재귀)의 개념 + python ","date":"2021-12-02","objectID":"/algo-01-recursion1/:0:0","tags":["Recursion"],"title":"[알고리즘] Recursion의 개념과 기본 예제들","uri":"/algo-01-recursion1/"},{"categories":["알고리즘"],"content":"순환이란? 자기 자신을 호출하는 함수 무한루프에 빠지지 않으려면? Base case를 통해 적어도 하나의 recursion에 빠지지 않는 경우가 존재해야 한다. def func(n: int) -\u003e int: # Base case if n == 0: return 0 else: # recursive case return n + func(n-1) ","date":"2021-12-02","objectID":"/algo-01-recursion1/:1:0","tags":["Recursion"],"title":"[알고리즘] Recursion의 개념과 기본 예제들","uri":"/algo-01-recursion1/"},{"categories":["알고리즘"],"content":"Recursive Thinking 수학함수 뿐만 아니라 다른 많은 문제들을 recursion으로 해결 할 수 있다. # 문자열의 길이 계산 def len_str(s: str) -\u003e int: if len(s) == 1: return 1 else: return 1 + len(s[1:]) # 문자열의 프린트 def print_str(s: str) -\u003e str: if len(s) == 1: return s else: return s[0] + print_str(s[1:]) # 문자열을 뒤집어 프린트 def reverse_print_str(s: str) -\u003e str: if len(s) == 1: return s else: return s[-1] + reverse_print_str(s[:-1]) # 2진수로 변환하여 출력 def print_as_binary(n: int) -\u003e int: if n \u003c 2: print(n) else: print_as_binary(n//2) print(n%2) # 최대값 찾기 def find_max(n: int, nums: List[int]) -\u003e int: if n == 1: return nums[0] else: return max(nums[n-1], find_max(n-1, nums)) ","date":"2021-12-02","objectID":"/algo-01-recursion1/:2:0","tags":["Recursion"],"title":"[알고리즘] Recursion의 개념과 기본 예제들","uri":"/algo-01-recursion1/"},{"categories":["알고리즘"],"content":"Recursion vs Iteration 모든 순환함수는 반복문으로 변경 가능 그 역도 성립 순환함수는 복잡한 알고리즘을 단순하고 알기 쉽게 표현하는 것을 가능하게 함 ","date":"2021-12-02","objectID":"/algo-01-recursion1/:3:0","tags":["Recursion"],"title":"[알고리즘] Recursion의 개념과 기본 예제들","uri":"/algo-01-recursion1/"},{"categories":["알고리즘"],"content":"순환적 알고리즘 설계 암시적 매개변수를 명시적 매개변수로 바꾸어라 # 순차 탐색 예시 # 여기서 index 0은 보통 생략 -\u003e 즉, 암시적 매개변수 def search(data: List, target: int) -\u003e int: for i in range(len(data)): if data[i] == target: return i return -1 # 매개변수의 명시화 : 순차탐색 def search(data: List, begin: int, target: int) -\u003e int: if begin \u003e len(data): return -1 elif target == data[begin]: return begin else: return search(data, begin+1, target) # 매개변수의 명시화 : 최대값 찾기 def findmax(data: List, begin: int): if begin == len(data): return -1 else: return max(data[begin], findmax(data, begin+1)) # 매개변수의 명시화 : 이진탐색 def binarySearch(data: List, begin: int, end: int, target: int) -\u003e int: if begin \u003e end: return -1 else: mid = (begin+end) // 2 if data[mid] == target: return mid elif data[mid] \u003c target: return binarySearch(data, mid, end, target) else: return binarySearch(data, begin, mid, target) ","date":"2021-12-02","objectID":"/algo-01-recursion1/:4:0","tags":["Recursion"],"title":"[알고리즘] Recursion의 개념과 기본 예제들","uri":"/algo-01-recursion1/"},{"categories":["알고리즘"],"content":"Reference 권오흠 교수님 알고리즘 Java예시를 Python으로 바꿔서 구현 ","date":"2021-12-02","objectID":"/algo-01-recursion1/:5:0","tags":["Recursion"],"title":"[알고리즘] Recursion의 개념과 기본 예제들","uri":"/algo-01-recursion1/"},{"categories":["자료구조"],"content":"비선형적인 자료구조 트라이에 대해 정리 ","date":"2021-12-01","objectID":"/ds-09/:0:0","tags":["트라이"],"title":"[자료구조] 트라이","uri":"/ds-09/"},{"categories":["자료구조"],"content":"트라이 검색 트리의 일종으로 일반적으로 키가 문자열인 동적 배열 또는 연관 배열을 저장하는데 사용되는 정렬된 트리 자료구조 ","date":"2021-12-01","objectID":"/ds-09/:1:0","tags":["트라이"],"title":"[자료구조] 트라이","uri":"/ds-09/"},{"categories":["자료구조"],"content":"트라이 구현 (python) import collections class TrieNode: def __init__(self): self.word = False self.children = collections.defaultdict(TrieNode) class Trie: def __init__(self): self.root = TrieNode() def insert(self, word): node = self.root for char in word: node = node.children[char] node.word = True def search(self, word): node = self.root for char in word: if char not in node.children: return False node = node.children[char] return node.word def startWith(self, prefix): node = self.node for char in prefix: if char not in node.children: return False node = node.children[char] return True ","date":"2021-12-01","objectID":"/ds-09/:2:0","tags":["트라이"],"title":"[자료구조] 트라이","uri":"/ds-09/"},{"categories":["자료구조"],"content":"Reference 파이썬 알고리즘 인터뷰 (박상길 지음) ","date":"2021-12-01","objectID":"/ds-09/:3:0","tags":["트라이"],"title":"[자료구조] 트라이","uri":"/ds-09/"},{"categories":["자료구조"],"content":"비선형적인 자료구조 힙에 대해 정리 ","date":"2021-12-01","objectID":"/ds-08/:0:0","tags":["힙"],"title":"[자료구조] 힙","uri":"/ds-08/"},{"categories":["자료구조"],"content":"힙 트리 기반의 자료구조 우선순위 큐를 주로 힙으로 구현한다. 이전에도 heapq를 사용했었다. (근데 힙은 주로 배열로 구현) 여러 개의 값들 중에서 최댓값이나 최솟값을 빠르게 찾아내도록 만들어진 자료구조이다. 힙은 정렬된 구조는 아니다. 힙 트리에서는 중복된 값을 허용한다. (이진 탐색 트리에서는 중복된 값을 허용하지 않는다.) ","date":"2021-12-01","objectID":"/ds-08/:1:0","tags":["힙"],"title":"[자료구조] 힙","uri":"/ds-08/"},{"categories":["자료구조"],"content":"힙의 종류 이진 힙 자식이 둘인 힙 힙을 애기할때는 주로 이진힙을 의미 최소 힙 부모가 항상 자식보다 작거나 같다 최대 힙 최소 힙과 반대 ","date":"2021-12-01","objectID":"/ds-08/:2:0","tags":["힙"],"title":"[자료구조] 힙","uri":"/ds-08/"},{"categories":["자료구조"],"content":"힙 구현 대개 트리의 배열 표현의 경우 index 계산을 편하게 하기 위해 index는 1부터 시작한다. 이진힙에서 부모의 index를 계산할 때 본인 index를 2로 나눈 몫 # 최소힙구현 class BinaryHeap: def __init__(self): self.items = [None] def __len__(self): return len(self.items) - 1 # 삽입 : O(logn) # 반복 구조 def _percolate_up(self): # 배열 가장 마지막에 먼저 삽입 i = len(self) parent = i // 2 # 부모가 더 큰 값을 가지는 경우 스왑 while parent \u003e 0: if self.items[i] \u003c self.items[parent]: self.items[parent], self.itmes[i] = \\ self.items[i], self.items[parent] i = parent parent = i // 2 def insert(self, k): self.items.append(k) self._percolate_up() # 추출 : O(logn) # 재귀 구조 def _percolate_down(self, idx): left = idx * 2 right = idx * 2 + 1 smallest = idx if left \u003c= len(self) and self.items[left] \u003c self.items[smallest]: smallest = left if right \u003c= len(self) and self.items[right] \u003c self.items[smallest]: smallest = right if smallest != idx: self.items[idx], self.items[smallest] = \\ self.items[smallest], self.items[idx] self._percolate_down(smallest) def extract(self): extracted = self.items[1] self.items[1] = self.items[len(self)] self.items.pop() self._percolate_down(1) return extracted ","date":"2021-12-01","objectID":"/ds-08/:3:0","tags":["힙"],"title":"[자료구조] 힙","uri":"/ds-08/"},{"categories":["자료구조"],"content":"Python 예시 Link 배열의 K번째 큰 값 찾기 heapq 사용법 heapq.heapify(my_list) 를 통해 리스트를 heap으로 만든다. heapq.nlargest(k, my_list)를 통해 리스트에서 큰 순서대로 k개 return한다. ","date":"2021-12-01","objectID":"/ds-08/:4:0","tags":["힙"],"title":"[자료구조] 힙","uri":"/ds-08/"},{"categories":["자료구조"],"content":"Reference 파이썬 알고리즘 인터뷰 (박상길 지음) ","date":"2021-12-01","objectID":"/ds-08/:5:0","tags":["힙"],"title":"[자료구조] 힙","uri":"/ds-08/"},{"categories":["자료구조"],"content":"비선형적인 자료구조 트리에 대해 정리 ","date":"2021-12-01","objectID":"/ds-07/:0:0","tags":["트리"],"title":"[자료구조] 트리","uri":"/ds-07/"},{"categories":["자료구조"],"content":"트리 그래프 vs 트리 트리는 순환 구조를 갖지 않는 그래프 트리에서 부모 노드는 단 하나, 루트도 하나 ","date":"2021-12-01","objectID":"/ds-07/:1:0","tags":["트리"],"title":"[자료구조] 트리","uri":"/ds-07/"},{"categories":["자료구조"],"content":"이진 트리 가장 널리 사용되는 트리는 이진트리와 이진탐색트리(BST) 일반적으로 트리라고 하면 대부분 이진트리를 의미 이진트리는 노드의 차수가 2이하인 트리 이진트리 표현법 배열, 리스트 노드와 링크로 직접 class 구현 ","date":"2021-12-01","objectID":"/ds-07/:2:0","tags":["트리"],"title":"[자료구조] 트리","uri":"/ds-07/"},{"categories":["자료구조"],"content":"트리순회 그래프 순회의 한 형태로 트리 자료구조에서 각 노드를 정확히 한 번 방문하는 과정 종류 pre-order in-order post-order # 전위(Pre-Order) 순회 : NLR def preorder(node): if node is None: return print(node.val) preorder(node.left) preorder(node.right) # 중의(In-Order) 순회 : LNR def inorder(node): if node is None: return inorder(node.left) print(node.val) inorder(node.right) # 후위(Post-Order) 순회 : LRN def postorder(node): if node in None: return postorder(node.left) postorder(node.right) print(node.val) ","date":"2021-12-01","objectID":"/ds-07/:3:0","tags":["트리"],"title":"[자료구조] 트리","uri":"/ds-07/"},{"categories":["자료구조"],"content":"이진 탐색 트리 (Binary Search Tree) 여기서 탐색이란 정렬되었다는 것을 의미한다. 노드의 왼쪽에는 작은 값, 오른쪽에는 같거나 큰 값이 위치한다. 장점은? 탐색이 $O(\\log n)$ # BST # search def search(self, key): if self.size == 0: return None v = self.root while v != None: if v.key == key : return v elif v.key \u003c key: v = v.right else: v = v.left ","date":"2021-12-01","objectID":"/ds-07/:4:0","tags":["트리"],"title":"[자료구조] 트리","uri":"/ds-07/"},{"categories":["자료구조"],"content":"균형 이진 탐색 트리 (Balanced BST) 트리의 높이가 너무 높아지지 않도록 조정 rotation 회전을 통해 조정 종류 AVL tree Red-Black (2,3,4) tree splay tree ","date":"2021-12-01","objectID":"/ds-07/:5:0","tags":["트리"],"title":"[자료구조] 트리","uri":"/ds-07/"},{"categories":["자료구조"],"content":"Python 예시 Link 이진트리 최대깊이 deque를 이용하여 bfs 이진 트리의 직경 dfs 가장 긴 동일값의 경로 dfs 이진트리반전 재귀, 큐, 스택 두 이진 트리 병합 재귀 이진 트리 직렬화 bfs 균형 이진 트리 정렬된 배열의 이진 탐색 트리 변환 이진 탐색 트리를 더 큰 수 합계 트리로 이진 탐색 트리 합의 범위 ","date":"2021-12-01","objectID":"/ds-07/:6:0","tags":["트리"],"title":"[자료구조] 트리","uri":"/ds-07/"},{"categories":["자료구조"],"content":"Reference 파이썬 알고리즘 인터뷰 (박상길 지음) 신찬수, 한국외대, 컴퓨터전자시스템공학부, 자료구조 2020-1 ","date":"2021-12-01","objectID":"/ds-07/:7:0","tags":["트리"],"title":"[자료구조] 트리","uri":"/ds-07/"},{"categories":["자료구조"],"content":"비선형적인 자료구조 그래프에 대해 정리 ","date":"2021-12-01","objectID":"/ds-06/:0:0","tags":["그래프"],"title":"[자료구조] 그래프","uri":"/ds-06/"},{"categories":["자료구조"],"content":"그래프 탐색 BFS 주로 큐로 구현 DFS 주로 스택, 재귀로 구현 그래프를 표현하는 방법 인접리스트 인접행렬 # 인접리스트 graph = { 1 : [2,3,4], 2 : [5], 3 : [5], 4 : [], 5 : [6,7], 6 : [], 7 : [3], } # DFS (재귀) def recursive_dfs(v, discovered=[]): discovered.append(v) for w in graph[v]: if not w in discovered: discovered = recursive_dfs(w, discovered) return discovered # BFS def iterative_bfs(start_v): discovered = [start_v] queue = [start_v] while queue: v = queue.pop(0) for w in graph[v]: if w is not in discovered: discovered.append(w) queue.append(w) return discovered ","date":"2021-12-01","objectID":"/ds-06/:1:0","tags":["그래프"],"title":"[자료구조] 그래프","uri":"/ds-06/"},{"categories":["자료구조"],"content":"Python 예시 Link 섬의 갯수 dfs, 재귀 전화번호 문자 조합 dfs, 재귀 순열 객체 복사는 copy()를 사용, 복잡한 리스트의 경우는 copy.deepcopy()로 처리 itertools.permutations()를 통해서 쉽게 permutation을 계산할 수 있다. 조합 itertools.combinations() 조합의 합 dfs, 재귀 부분 집합 dfs 일정 재구성 dfs ","date":"2021-12-01","objectID":"/ds-06/:2:0","tags":["그래프"],"title":"[자료구조] 그래프","uri":"/ds-06/"},{"categories":["자료구조"],"content":"Reference 파이썬 알고리즘 인터뷰 (박상길 지음) ","date":"2021-12-01","objectID":"/ds-06/:3:0","tags":["그래프"],"title":"[자료구조] 그래프","uri":"/ds-06/"},{"categories":["자료구조"],"content":"선형적인 자료구조 해시 테이블에 대해 정리 ","date":"2021-12-01","objectID":"/ds-05/:0:0","tags":["해시테이블"],"title":"[자료구조] 해시 테이블","uri":"/ds-05/"},{"categories":["자료구조"],"content":"해시 테이블 (Hash Table) 키를 값에 매핑할 수 있는 구조인 연관 배열 추상 자료형을 구현하는 자료구조 대부분 연산의 시간 복잡도가 $O(1)$ Python에서 해시 테이블로 구현된 자료형 : dictionary ","date":"2021-12-01","objectID":"/ds-05/:1:0","tags":["해시테이블"],"title":"[자료구조] 해시 테이블","uri":"/ds-05/"},{"categories":["자료구조"],"content":"로드 팩터 (Load Factor) 해시 테이블에 저장된 데이터 개수 $n$을 버킷의 개수 $k$로 나눈 것 ","date":"2021-12-01","objectID":"/ds-05/:2:0","tags":["해시테이블"],"title":"[자료구조] 해시 테이블","uri":"/ds-05/"},{"categories":["자료구조"],"content":"해시 함수(Hash Function) 해시함수 임의 크기 데이터를 고정 크기 값으로 매핑하는데 사용하는 함수 해시함수를 만드는 방법은 다양하다. 좋은 해시함수? less collision fast computation ","date":"2021-12-01","objectID":"/ds-05/:3:0","tags":["해시테이블"],"title":"[자료구조] 해시 테이블","uri":"/ds-05/"},{"categories":["자료구조"],"content":"충돌 (Collision) 충돌이 일어나는 경우 이를 방지하기 위한 방법이 필요하다. 체이닝 (Chaining), 오픈 어드레싱 (Open addressing) Python은 Open addressing 방법을 사용 Chaining 충돌이 발생하면 연결리스트로 연결한다. 충돌이 많지 않으면 대부분의 탐색은 $O(1)$ 최악은 $O(n)$ Open addressing 충돌이 일어나면 그 뒤의 가장 가까운 다음 빈 위치를 탐사 (linear probing 방법) linear probing, quadratic probing, double hashing … 연산 set(key, value) 해시테이블에서 key를 찾아서 있으면 key update, 없으면 key와 value 삽입한다. search(key) 찾았는데 없으면 다음칸에 빈칸이 나올 때까지 찾는다. remove(key) 충돌이 일어나서 이어지는 경우 중간에 빈칸이 없도록 해야한다. 평균적으로 50% 이상 빈슬롯이면 위의 연산 모두 $O(1)$이다. 성능평가 cluster size : 해시테이블에서 뭉쳐진 cluster가 최소 충돌비율 등등 ","date":"2021-12-01","objectID":"/ds-05/:4:0","tags":["해시테이블"],"title":"[자료구조] 해시 테이블","uri":"/ds-05/"},{"categories":["자료구조"],"content":"Python 예시 Link 해시맵 디자인 chaining 방식 직접 해시함수를 구현 collections.defaultdict 사용 보석과 돌 A문자열이 B문자열에 얼마나 등장하는지 중복 문자 없는 가장 긴 부분 문자열 상위 K빈도 요소 Python에서 zip, * 의 사용법 zip은 제너레이터를 리턴 zip은 2개 이상의 시퀀스를 짧은 길이를 기준으로 일대일 대응하는 새로운 튜플 시쿼스를 만든다. ","date":"2021-12-01","objectID":"/ds-05/:5:0","tags":["해시테이블"],"title":"[자료구조] 해시 테이블","uri":"/ds-05/"},{"categories":["자료구조"],"content":"Reference 파이썬 알고리즘 인터뷰 (박상길 지음) 신찬수, 한국외대, 컴퓨터전자시스템공학부, 자료구조 2020-1 ","date":"2021-12-01","objectID":"/ds-05/:6:0","tags":["해시테이블"],"title":"[자료구조] 해시 테이블","uri":"/ds-05/"},{"categories":["자료구조"],"content":"선형적인 자료구조 데크과 우선순위 큐에 대해 정리 ","date":"2021-12-01","objectID":"/ds-04/:0:0","tags":["deque","우선순위큐"],"title":"[자료구조] deque, 우선순위 큐","uri":"/ds-04/"},{"categories":["자료구조"],"content":"데크 양쪽 끝을 모두 추출할 수 있는, 큐를 일반화한 형태의 추상 자료형 Python에서 제공하는 collections.deque는 이중 연결 리스트로 구현되어 있다. ","date":"2021-12-01","objectID":"/ds-04/:1:0","tags":["deque","우선순위큐"],"title":"[자료구조] deque, 우선순위 큐","uri":"/ds-04/"},{"categories":["자료구조"],"content":"우선순위 큐 우선순위가 높은 요소가 추출되는 자료형 최단 경로를 탐색하는 다익스트라 알고리즘, 힙 자료구조 와도 관련이 깊다. Python에서는 heapq를 사용 최소 힙 파이썬의 보통 리스트를 마치 최소 힙처럼 다룰 수 있도록 도와준다. 최대 힙을 만들려면 각 값에 대한 우선 순위를 구한 후, (우선 순위, 값) 구조의 튜플(tuple)을 힙에 추가하거나 삭제 import heapq heap = [] heapq.heappush(heap, (-num, num)) # (우선 순위, 값) ","date":"2021-12-01","objectID":"/ds-04/:2:0","tags":["deque","우선순위큐"],"title":"[자료구조] deque, 우선순위 큐","uri":"/ds-04/"},{"categories":["자료구조"],"content":"Python Link 원형 데크 디자인 직접 deque를 구현 k개 정렬 리스트 병합 heapq ","date":"2021-12-01","objectID":"/ds-04/:3:0","tags":["deque","우선순위큐"],"title":"[자료구조] deque, 우선순위 큐","uri":"/ds-04/"},{"categories":["자료구조"],"content":"Reference 파이썬 알고리즘 인터뷰 (박상길 지음) ","date":"2021-12-01","objectID":"/ds-04/:4:0","tags":["deque","우선순위큐"],"title":"[자료구조] deque, 우선순위 큐","uri":"/ds-04/"},{"categories":["자료구조"],"content":"선형적인 자료구조 스택과 큐에 대해 정리 ","date":"2021-12-01","objectID":"/ds-03/:0:0","tags":["스택","큐"],"title":"[자료구조] 스택, 큐","uri":"/ds-03/"},{"categories":["자료구조"],"content":"스택 LIFO (Last In First Out) Python에서는 스택 자료형을 따로 제공하지는 않지만 리스트가 스택의 연산들을 모두 제공한다. 리스트에서 append, pop이 O(1)로 빠르기 때문에 리스트를 스택을 구현한다. ","date":"2021-12-01","objectID":"/ds-03/:1:0","tags":["스택","큐"],"title":"[자료구조] 스택, 큐","uri":"/ds-03/"},{"categories":["자료구조"],"content":"큐 FIFO (First In First Out) Python에서 리스트를 사용하면 된지만 큐 연산을 수행하기에는 효율적이지는 않다. 그래서 deque라는 별도의 자료형을 사용하면 더 좋은 성능을 이용할 수 있다. ","date":"2021-12-01","objectID":"/ds-03/:2:0","tags":["스택","큐"],"title":"[자료구조] 스택, 큐","uri":"/ds-03/"},{"categories":["자료구조"],"content":"Python Link 유효한 괄호 중복 문자 제거 일일 온도 큐를 이용한 스택 구현 deque 이용 스택을 이용한 큐 구현 두 개의 스택(리스트)을 이용 원형 큐 디자인 ","date":"2021-12-01","objectID":"/ds-03/:3:0","tags":["스택","큐"],"title":"[자료구조] 스택, 큐","uri":"/ds-03/"},{"categories":["자료구조"],"content":"Reference 파이썬 알고리즘 인터뷰 (박상길 지음) ","date":"2021-12-01","objectID":"/ds-03/:4:0","tags":["스택","큐"],"title":"[자료구조] 스택, 큐","uri":"/ds-03/"},{"categories":["자료구조"],"content":"선형적인 자료구조 연결리스트에 대해 정리 ","date":"2021-12-01","objectID":"/ds-02/:0:0","tags":["연결리스트"],"title":"[자료구조] 연결리스트","uri":"/ds-02/"},{"categories":["자료구조"],"content":"연결 리스트 선형 자료구조 동적으로 새로운 노드를 삽입하거나 삭제하기 간편하다. 메모리에 물리적인 순서대로 저장되지는 않는다. 단, 탐색에는 O(n)이 소요된다. ","date":"2021-12-01","objectID":"/ds-02/:1:0","tags":["연결리스트"],"title":"[자료구조] 연결리스트","uri":"/ds-02/"},{"categories":["자료구조"],"content":"deque python의 list에서 pop(0)을 통해 맨 앞의 원소를 뽑아내는 것은 비효율적이다. list의 원소들이 하나씩 shifting되기 때문이다. 따라서 collections.deque()를 이용하면 좋다. q.append(some value)를 하고 q.popleft(), q.pop() 이런식으로 앞뒤에서 빠르게 원소를 뽑아낼 수 있다. ","date":"2021-12-01","objectID":"/ds-02/:2:0","tags":["연결리스트"],"title":"[자료구조] 연결리스트","uri":"/ds-02/"},{"categories":["자료구조"],"content":"Python code 예시 Link 펠린드롬 연결 리스트 deque, 러너 이용 두 정렬 리스트의 병합 재귀 이용 역순 연결 리스트 1 반복 구조로 뒤집기 두 수의 덧셈 페어의 노드 스왑 홀짝 연결 리스트 역순 연결 리스트 2 ","date":"2021-12-01","objectID":"/ds-02/:3:0","tags":["연결리스트"],"title":"[자료구조] 연결리스트","uri":"/ds-02/"},{"categories":["자료구조"],"content":"Reference 파이썬 알고리즘 인터뷰 (박상길 지음) ","date":"2021-12-01","objectID":"/ds-02/:4:0","tags":["연결리스트"],"title":"[자료구조] 연결리스트","uri":"/ds-02/"},{"categories":["자료구조"],"content":"선형적인 자료구조 배열에 대해 정리 ","date":"2021-12-01","objectID":"/ds-01/:0:0","tags":["배열"],"title":"[자료구조] 배열","uri":"/ds-01/"},{"categories":["자료구조"],"content":"배열 메모리 공간 기반의 연속적인 방식의 가장 기본이 되는 자료형 파이썬의 동적 배열 자료형 : 리스트 Cpython의 내부 구현을 보면, 배열의 정해진 공간보다 추가적으로 원소가 들어오면 조금씩 용량을 늘린다. 정적 배열과 달리 크기를 지정할 필요가 없다. 크기가 꽉 차면 새로운 메모리 공간에 더 큰 크기의 배열을 할당하고 기존 데이터를 복사하는 작업이 필요해서 O(n)의 비용이 발생한다. ","date":"2021-12-01","objectID":"/ds-01/:1:0","tags":["배열"],"title":"[자료구조] 배열","uri":"/ds-01/"},{"categories":["자료구조"],"content":"Python code 예시 Link 두 수의 합 빗물 트래핑 투 포인터로 합 계산 짝수합 자신을 제외한 배열의 곱 주식을 사고팔기 가장 좋은 시점 ","date":"2021-12-01","objectID":"/ds-01/:2:0","tags":["배열"],"title":"[자료구조] 배열","uri":"/ds-01/"},{"categories":["자료구조"],"content":"Reference 파이썬 알고리즘 인터뷰 (박상길 지음) ","date":"2021-12-01","objectID":"/ds-01/:3:0","tags":["배열"],"title":"[자료구조] 배열","uri":"/ds-01/"},{"categories":["PRML"],"content":"Ensemble method에 대해 정리하였다. 14. Combining Models 말 그대로 모델들을 섞는 것이다. 머신러닝 예측 모델에서 가장 좋은 성능을 보이고 있다는 Boosting이 이 부분의 내용이다. ","date":"2021-11-29","objectID":"/prml-chap14-1/:0:0","tags":["Ensemble"],"title":"[PRML] Chapter14 - Combining Models","uri":"/prml-chap14-1/"},{"categories":["PRML"],"content":"14.1 Bayesian Model Averaging model combination methods 와 Bayesian model averaging 을 구분하는 것은 중요하다. Density estimation using a mixture of Gaussians 예시를 통해 살펴보자. model combination 각 data들은 iid, $X = {\\textbf{x}_1, \\textbf{x}_2,…,\\textbf{x}_n }$ $X$는 전체 dataset을 의미 $$p(X) = \\prod_{n=1}^{N}{p(\\textbf{x} _ n)} = \\prod_{n=1}^{N}{[\\sum_{z_n}p(\\textbf{x}_n, \\textbf{z}_n)]}$$ bayesian model averaging models indexed by $h=1,…,H$ with prior $$p(X) = \\sum_{h=1}^{H}{p(X|h)p(h)}$$ 이 둘의 차이점은 model combination의 경우 각 data point는 latent variable $z$로 부터 generated되고 bayesian model averaging은 single model이 전체 dataset을 generate하는 과정을 담는 것이다. ","date":"2021-11-29","objectID":"/prml-chap14-1/:1:0","tags":["Ensemble"],"title":"[PRML] Chapter14 - Combining Models","uri":"/prml-chap14-1/"},{"categories":["PRML"],"content":"14.2 Committees bootstrap으로 M개의 data sets을 만들었고 각각 $y_m(\\textbf{x})$ 모델을 훈련시켰다고 가정 $$y_{COM}(\\textbf{x}) = \\frac{1}{M}\\sum_{m}^{M}{y_m(\\textbf{x})}$$ 이를 bagging 이라고 한다. (bagging은 variance를 줄이는 방법론) 우리가 구하고 싶은 true regression predict function을 $h(\\textbf{x})$ 라고 하면 $$y_m(\\textbf{x}) = h(\\textbf{x}) + \\epsilon_m(\\textbf{x})$$ average sum-of-squares error는 $$E_{\\textbf{x}}[{y_m(\\textbf{x}) - h(\\textbf{x}) }^2]$$ 따라서 average error는 $$E_{AV} = \\frac{1}{M}\\sum_{m=1}^{M}{E_x[\\epsilon_m(\\textbf{x})^2]}$$ Committees의 expected error는 $$E_{COM} = E_{\\textbf{x}} [{ \\frac{1}{M}\\sum_{m=1}^{M}{y_m(\\textbf{x}) - h(\\textbf{x})} }^2]=E_{\\textbf{x}}[{ \\frac{1}{M}{\\sum_{m=1}^{M}{\\epsilon_m(\\textbf{x})}} }^2]$$ 여기서 error term에 대한 가정은 $E[\\epsilon_m(\\textbf{x})] = 0$ $E[\\epsilon_m(\\textbf{x})\\epsilon_n(\\textbf{x})]=0, m \\neq n$ 따라서 우리는 $E_{COM} = \\frac{1}{m}E_{AV}$ 라는 결과를 얻는다. 하지만 현실에서는 error term의 가정이 지켜지기 어렵다. error term이 highly correlated되어 있기 때문이다. 그래도 COM의 E가 AV 이하라는 것은 변하지 않는다. $${ \\frac{1}{M}{\\sum_{m=1}^{M}{\\epsilon_m(\\textbf{x})}} }^2 \\le \\frac{1}{M}\\sum_{m=1}^{M}\\epsilon_m(\\textbf{x})^2;;\\because \\text{Cauchy’s inequality}$$ ","date":"2021-11-29","objectID":"/prml-chap14-1/:2:0","tags":["Ensemble"],"title":"[PRML] Chapter14 - Combining Models","uri":"/prml-chap14-1/"},{"categories":["PRML"],"content":"14.3 Boosting 간단히 말하자면 weak learner 모델을을 순차적으로 학습하는 것이다. PRML에서는 Adaboost만 다루고 있다. ","date":"2021-11-29","objectID":"/prml-chap14-1/:3:0","tags":["Ensemble"],"title":"[PRML] Chapter14 - Combining Models","uri":"/prml-chap14-1/"},{"categories":["PRML"],"content":"AdaBoost Intialize the data weighting coefficients by setting $w_n^{(1)} = 1/N$, n=1,…,N For m=1,…,M (a) Fit a Classifer $y_m(\\textbf{x})$ to the training data by minimizing the weighted error function $$J_m = \\sum_{n=1}^{N}w_n^{(m)} I (y_m (\\textbf{x}_n)\\neq t_n)$$ (b) Evaluate the quantities $$\\epsilon_m = \\frac{\\sum_{n=1}^{N}{w_n^{(m)}I(y_m(\\textbf{x}) \\neq t_n)}}{\\sum_{n=1}^{N}{w_n^{(m)}}}$$ and then use these to evaluate $$\\alpha_m = \\ln { \\frac{1-\\epsilon_m}{\\epsilon_m} }$$ (c) Update the data weighting coefficients $$w_n^{(m+1)} = w_n^{(m)} \\exp { \\alpha_m I(y_m(\\textbf{x}_n) \\neq t_n) }$$ Make prediction using the final model, which is given by $$Y_M(x) = \\text{sign}(\\sum_{m=1}^{M}{\\alpha_m y_m (x)})$$ 위의 과정을 다시 한 번 정리해보자. 일단 각 data point는 uniform한 가중치를 갖는다. weak model과 해당 시점의 가중치를 이용하여 train한다. 해당 model과 가중치를 이용하여 해당 model의 error $\\epsilon_m$을 구한다. $\\epsilon_m$을 이용하여 해당 model의 가중치를 의미하는 $\\alpha_m$을 구한다. 여기서 해당 model의 error가 작을수록 $\\alpha_m$은 큰 값을 가진다. 다음 시점의 각 data point별 가중치를 update한다. $w_n^{(m+1)} = w_n^{(m)} \\exp { \\alpha_m I(y_m(\\textbf{x}_n) \\neq t_n) })$ 좋은 model ($\\alpha_m$가 큰)이 틀린 data point는 다음 시점에서 더 큰 가중치를 갖는다. 나쁜 model이 틀린 data point의 경우 가중치는 더 커지지만 위의 경우보다는 작다. 맞춘 data point는 동일한 가중치를 갖는다. ","date":"2021-11-29","objectID":"/prml-chap14-1/:3:1","tags":["Ensemble"],"title":"[PRML] Chapter14 - Combining Models","uri":"/prml-chap14-1/"},{"categories":["PRML"],"content":"14.3.1 Minimizing exponential error Friedman이 2000년에 논문을 통해 boosting에 대한 다른 시점을 발표했다. boosting을 sequential minimization of an exponential error function으로 바라보는 과정을 알아보자. exponential error function $$E = \\sum_{n=1}^{N}{\\exp { -t_n f_m(\\textbf{x} _ n)}} \\\\ \\text{where}\\; f_m(\\textbf{x}) = \\frac{1}{2} \\sum_{l=1}^{m}{\\alpha_l y_l (\\textbf{x})} \\text{: linear combination of base classifiers}$$ 우리의 목적은 parameter $\\alpha_l, y_l (x)$ 에 대해 E를 최소화하는 것이다. global error function minimization 대신에 $\\alpha_m, y_m (x)$를 제외한 나머지 값들을 fixed시키고 진행한다. 그러면 $$E = \\sum_{n=1}^{N}{\\exp { -t_n f_{m-1}(\\textbf{x} _ n) - \\frac{1}{2}t_n \\alpha_m y_m (\\textbf{x} _ n) }} \\\\ = \\sum_{n=1}^{N}{w_n^{(m)} \\exp { -\\frac{1}{2} t_n \\alpha_m y_m (\\textbf{x}_n) }}$$ $T_m$을 잘 분류한 data point라고 하고 $M_m$을 틍린 data point라고 하면 $$E = e^{-\\alpha_m / 2}\\sum_{n \\in T_m}{w_n^{(m)}} + e^{\\alpha_m / 2} \\sum_{n \\in M_m}{w_n^{(m)}} $$ $$ = (e^{\\alpha_m / 2} - e^{- \\alpha_m / 2}) \\sum_{n=1}^{N}{w_n^{(m)} I(y_m (\\textbf{x} _ n) \\neq t_n)} + e^{-\\alpha_m / 2} \\sum_{n=1}^{N}{w_n^{(m)}}$$ $y_m (x)$에 대해 최소화하면 두번째 term은 constant가 된다. 그래서 2-(a)가 나온것 $\\alpha_m$에 대해서 계산하면 2-(b)가 나온것 $w_n$ 의 update도 이렇게 나온 것 ","date":"2021-11-29","objectID":"/prml-chap14-1/:3:2","tags":["Ensemble"],"title":"[PRML] Chapter14 - Combining Models","uri":"/prml-chap14-1/"},{"categories":["PRML"],"content":"14.3.2 Error functions for boosting Expected error는 $$E_{\\textbf{x},t}[\\exp { -ty(\\textbf{x}) }]=\\sum_t \\int \\exp { -ty(\\textbf{x}) }p(t|\\textbf{x})p(\\textbf{x})d\\textbf{x}$$ 위의 식을 variational minimization으로 $y(\\textbf{x})$을 구하면 $$y(\\textbf{x}) = \\frac{1}{2}{ \\frac{p(t=1|\\textbf{x})}{p(t=-1|\\textbf{x})} }$$ 임을 알 수 있다. 이를 통해 AdaBoost is seeking the best approximation to the log odds ratio, within the space of functions represented by the linear combination of base classifiers, subject to the constrained minimization resulting from the sequential optimization. exponential loss는 cross-entropy보다 outiler에 덜 robust하다. error에 대한 가중치가 더 크다. exponential loss는 cross-entropy와 다르게 $K\u003e2$ class의 경우로 일반화할 수 없다. ","date":"2021-11-29","objectID":"/prml-chap14-1/:3:3","tags":["Ensemble"],"title":"[PRML] Chapter14 - Combining Models","uri":"/prml-chap14-1/"},{"categories":["PRML"],"content":"14.4 Tree-based Models 이 부분은 이미 알고 있는 내용이여서 자세히 정리하지는 않을 것이다. 어떤 변수를 나눌 것인가? 나눈다면 그 threshlod는? 이에 대해서는 greedy 하게 최적점을 찾는다. optimal한 기준을 찾는 기준은 regression에서는 sum of square error, classification에서는 gini index, cross entropy 일 것이다. node를 몇 개까지 만들것인지도 정해야 한다. 이는 model complexity를 정하게 해주므로 cross validation과 같은 방법으로 찾는다. ","date":"2021-11-29","objectID":"/prml-chap14-1/:4:0","tags":["Ensemble"],"title":"[PRML] Chapter14 - Combining Models","uri":"/prml-chap14-1/"},{"categories":["PRML"],"content":"14.5 Conditional Mixture Models standard decision trees are restricted by hard, axis-aligned splits of the input space. 그래서 이를 완화하는 방법으로 soft, probabilistic splits that can be functions of all of the input variables ! ","date":"2021-11-29","objectID":"/prml-chap14-1/:5:0","tags":["Ensemble"],"title":"[PRML] Chapter14 - Combining Models","uri":"/prml-chap14-1/"},{"categories":["PRML"],"content":"14.5.1 Mixtures of linear regression models $K$개의 linear model을 이용한다. GMM과 비슷한 맥락을 가진다. $$p(t | \\theta) = \\sum_{k=1}^{K}{\\pi_k N(t | w_k^T \\phi, \\beta^{-1})}$$ 이를 통해 parameter를 구하기 위해 이전에 배웠던 GMM에서의 EM과 같은 방법을 이용하여 구하면 된다. $$\\ln p(\\textbf{t}, \\textbf{Z} | \\theta) = \\sum_{n=1}^{N}\\sum_{k=1}^{K}{z_{nk}\\ln{ \\pi_k N(t_n | w_k^T\\phi_n, \\beta^{-1}) }}$$ 결과는 아래의 사진을 참고하자. ","date":"2021-11-29","objectID":"/prml-chap14-1/:5:1","tags":["Ensemble"],"title":"[PRML] Chapter14 - Combining Models","uri":"/prml-chap14-1/"},{"categories":["PRML"],"content":"14.5.2 Mixtures of logistic models 위와 같은 방법인데 logistic의 경우에 해당한다. ","date":"2021-11-29","objectID":"/prml-chap14-1/:5:2","tags":["Ensemble"],"title":"[PRML] Chapter14 - Combining Models","uri":"/prml-chap14-1/"},{"categories":["PRML"],"content":"14.5.3 Mixtures of experts 위의 방법들보다 조금 더 advanced한 방법론이다. mixing coefficients를 input의 함수로 정의한다. $$p(t | \\theta) = \\sum_{k=1}^{K}{\\pi_k(x) p_k(t | x)}$$ ","date":"2021-11-29","objectID":"/prml-chap14-1/:5:3","tags":["Ensemble"],"title":"[PRML] Chapter14 - Combining Models","uri":"/prml-chap14-1/"},{"categories":["PRML"],"content":"distribution을 구하는 sampling method에 대해 정리하였다. probabilistic model에서 exact inference는 intractable한 경우가 많아서 approximation한다. 이번에는 approximate inference 방법 중 Monte carlo 라고 알려진 numerical sampling에 기반을 하는 방법을 공부할 것이다. 우리는 posterior 자체에도 관심이 있지만 주로 expectation에 관심이 있다 (for prediction). 왜? expectation으로 어떤 probability도 구할 수 있다. $P(X \\in A) = E [I(X \\in A)]$ intractable한 sum, integral을 계산할 수 있다. 구제적으로 아래의 값을 analytical 하게 계산이 어려운 경우 Sampling을 통해 approximation한다. $$E[f] = \\int f(z)p(z)dz$$ $p(z)$에서 iid하게 sample $z_i$ 들을 뽑아서 평균에 대해 근사 $$\\hat{f} = \\frac{1}{n}\\sum_{i=1}^{n}{f(z_i)}$$ 여기서 발생 할 수 있는 문제는 sampling한 data들이 independent 하지 않는 경우 존재 그래서 effective sample size가 apparent sample size보다 훨씬 작을 수도 있다 $p(z), f(z)$에 따라 data가 많이 필요한 경우 존재 normal 분포같은 경우는 괜찮은데 Gaussian mixture같이 분포가 왔다갔다하는 경우는 sample에 따라 expectation값이 천차만별 ","date":"2021-11-29","objectID":"/prml-chap11-1/:0:0","tags":["Approximate Inference"],"title":"[PRML] Chapter11 - Sampling Method","uri":"/prml-chap11-1/"},{"categories":["PRML"],"content":"+ Monte carlo approximation Goal approximate $E[f(X)]$ where $X \\sim P$ Define if $X_1, X_2,…,X_n \\overset{iid}{\\sim} P$ then $\\hat{\\mu}_n = \\frac{1}{n}\\sum f(X_i)$ is a monte carlo estimator of $E[f(X)]$ Remark $E[\\hat{\\mu}_n] = E[f(X)]$ : unbiased estimator $\\hat{\\mu}_n \\overset{p}{\\rightarrow}E[f(X)]$ : consistent estimator (by WLLN) $V[\\hat{\\mu}_n] = \\frac{1}{n^2}V[\\sum f(X_i)] = \\frac{1}{n}V[f(X)] \\rightarrow 0;\\text{as};n\\rightarrow\\infty$ ","date":"2021-11-29","objectID":"/prml-chap11-1/:0:1","tags":["Approximate Inference"],"title":"[PRML] Chapter11 - Sampling Method","uri":"/prml-chap11-1/"},{"categories":["PRML"],"content":"11.1 Basic Sampling Algorithms forward sampling, regection sampling, importance sampling은 이제 별로 쓰이지 않는다고 한다. 뒤에서 배울 MCMC기법들에 조금 더 집중하자. ","date":"2021-11-29","objectID":"/prml-chap11-1/:1:0","tags":["Approximate Inference"],"title":"[PRML] Chapter11 - Sampling Method","uri":"/prml-chap11-1/"},{"categories":["PRML"],"content":"11.1.2 Rejection sampling complex한 분포에서 sampling하게 도와준다. $p(z)$에서 바로 sampling하기는 어려운 상태 단, $z$를 넣어을 때 $p(z)$의 값은 알 수 있는 상황이다. 이를 위해 sampling이 쉬운 $q(z)$를 정한다. $p(z)$를 다 포함하는 (envelop하는) 분포 $kq(z)$를 만든다. $$kq(z) \\ge p(z)$$ $q(z)$ 에서 sampling한다 : $z_0$ $unif[0, kq(z_0)]$ 에서 숫자를 generate 한다. 해당 숫자가 $p(z_0)$ 보다 크면 reject, 아니면 sampling 한다. 따라서 $p(z)$를 잘 envelop하는 적절한 분포를 찾으면 위의 과정을 반복하여 우리가 원하는 sample들을 얻을 수 있다. ","date":"2021-11-29","objectID":"/prml-chap11-1/:1:1","tags":["Approximate Inference"],"title":"[PRML] Chapter11 - Sampling Method","uri":"/prml-chap11-1/"},{"categories":["PRML"],"content":"11.1.4 Importance sampling expectation을 approximation하는 방법을 제안하다. $$E[f] \\approx \\frac{1}{n}\\sum f(z_i) ; \\text{where} ; z_i \\sim p(z)$$ 하지만 $p(z)$에서 directly sampling하기 어려운 경우가 있다. so how? draw the samples from a proposal distribution(sampling할 수 있는), say $q(z)$ approximation where $w_i= \\frac{p(z_i)}{q(z_i)}, z_i \\sim q(z)$ $$E[f] = \\int f(z)\\frac{p(z)}{q(z)}q(z)dz \\approx \\frac{1}{n}\\sum w_i f(z_i) $$ rejection sampling과는 다르게 sampling한 모든 data들은 버려지지 않고 사용된다. 하지만 단점도 명확하다. 위의 식에서 $q(z)$가 매우 작은 값을 갖는 경우 가중치가 너무 커질수도 있다. ","date":"2021-11-29","objectID":"/prml-chap11-1/:1:2","tags":["Approximate Inference"],"title":"[PRML] Chapter11 - Sampling Method","uri":"/prml-chap11-1/"},{"categories":["PRML"],"content":"11.1.6 Sampling and the EM algorithm Monte carlo를 이용하여 MLE를 구할 수도 있다. EM algorithm의 E step에서 sampling methods를 통해 approximation해보자. complete-data log likelihood $$Q({\\pmb \\theta}, {\\pmb \\theta}^{old}) = \\int p(\\textbf{Z}|\\textbf{X}, {\\pmb \\theta}^{old}) \\ln p(\\textbf{Z},\\textbf{X}|{\\pmb \\theta})d\\textbf{Z}$$ $\\textbf{Z}^{(l)}$ drawn from the current estimate for the posterior distribution $p(\\textbf{Z}|\\textbf{X},{\\pmb \\theta}^{old})$ $$Q({\\pmb \\theta}, {\\pmb \\theta}^{old}) \\approx \\frac{1}{L}\\sum_{l=1}^{L} \\ln p(\\textbf{Z}^{(l)}, \\textbf{X}| {\\pmb \\theta})$$ 이후에 똑같이 M-step으로 optimize한다. 이런 과정을 Monte Carlo EM algorithm 이라고 한다. ","date":"2021-11-29","objectID":"/prml-chap11-1/:1:3","tags":["Approximate Inference"],"title":"[PRML] Chapter11 - Sampling Method","uri":"/prml-chap11-1/"},{"categories":["PRML"],"content":"11.2 Markov Chain Monte Carlo 지금까지 살펴본 sampling 방법들은 high dimension에서 한계점을 갖고 있다. 이제 더 좋은 방법인 MCMC에 대해 공부해보고자 한다. 이전의 방법들과 마찬가지로 proposal distribution에서 sampling한다. proposal distribution : $q(\\textbf{z}|\\textbf{z}^{(\\tau)})$ 다른점은 current state $\\textbf{z}^{(\\tau)}$ 를 given으로 하는 것이다. 이런 통해 만들어진 sample들은 Markov chain을 형성한다. $p(\\textbf{z}) = \\tilde{p}(\\textbf{z})/Z_p$ 에서 $Z_p$는 모르는 상태여도 상관없고 $\\tilde{p}(\\textbf{z})$의 값은 구할 수 있다고 가정한다. $Z_p$는 unknown constant $p(\\textbf{z})$에서 directly sampling은 어려운 상태이다. proposal distribution에서 sample을 뽑고 적절한 기준으로 이를 sample로 인정할지 말지 결정한다. 위와 같은 과정을 하는 basic Metropolis algorithm에 대해 살펴보자. proposal distribution은 symmetric하게 지정한다. 뒤에서 알게 되겠지만 symmetric하면 Markov chain이 time reversible하게 되고 이를 통해 stationary distribution ($p(\\textbf{z})$을 의미) 이 존재한다. $$q(\\textbf{z}_A | \\textbf{z}_B) = q(\\textbf{z}_B | \\textbf{z}_A)$$ 확률적으로 sample로 인정한다, 아래의 식이 accept 확률이다. 딱 봤을때 적절하다는 생각이 든다. 이렇게 반복하다 보면 우리가 원하는 $p(\\textbf{z})$의 모양으로 sampling이 될 것이다. $\\frac{p(\\textbf{z}^{ * })}{p(\\textbf{z}^{(\\tau)})} = \\frac{\\tilde{p}(\\textbf{z}^{ * })}{\\tilde{p}(\\textbf{z}^{(\\tau)})} \\frac{Z_p}{Z_p} = \\frac{\\tilde{p}(\\textbf{z}^{ * })}{\\tilde{p}(\\textbf{z}^{(\\tau)})}$ 라서 정확한 $p(\\textbf{z})$의 값을 몰라도 합리적인 acceptance probability를 구할 수 있다. $$A(\\textbf{z}^{ * }, \\textbf{z}^{(\\tau)} ) = min (1, \\frac{\\tilde{p}(\\textbf{z}^{ * })}{\\tilde{p}(\\textbf{z}^{(\\tau)})})$$ unif(0,1)에서 random number $u$를 뽑는다. $A(\\textbf{z}^{ * }, \\textbf{z}^{(\\tau)} ) \u003e u$이면 sample을 accept한다. candidate sample이 accpet되면 그 sample을 sample list에 저장한다. 그리고 그 sample을 given한 상태로 다시 알고리즘을 진행한다. 만약 reject되면 그 때 당시의 given sample을 sample list에 추가하고 다시 알고리즘을 진행한다. 각 sequence sample은 independent한 sample이 아니다. highly correlated되어 있다면 sample list에서 띄엄띄엄 사용하던가 초반 sample을 버리면 된다. ","date":"2021-11-29","objectID":"/prml-chap11-1/:2:0","tags":["Approximate Inference"],"title":"[PRML] Chapter11 - Sampling Method","uri":"/prml-chap11-1/"},{"categories":["PRML"],"content":"11.2.1 Markov chains 대표적인 MCMC 알고리즘을 살펴보기 전에 Markov chain에 대해 공부해보자. 각 state에 해당하는 random variable $\\textbf{z}^{(1)}, \\textbf{z}^{(2)} ,…,\\textbf{z}^{(M)}$ 가 있다. 이들이 아래와 같은 conditional independence property를 갖을 때, 이러한 stochastic process를 Markov chain이라고 한다. $$p(\\textbf{z}^{(m+1)}|\\textbf{z}^{(1)}, \\textbf{z}^{(2)} ,…,\\textbf{z}^{(m)}) = p(\\textbf{z}^{(m+1)}|\\textbf{z}^{(m)}),; m \\in {1,..,M-1}$$ transition probability $$T(\\textbf{z}^{(m)}, \\textbf{z}^{(m+1)}) \\equiv p(\\textbf{z}^{(m+1)}| \\textbf{z}^{(m)}) \\equiv T_{\\textbf{z}^{(m)}, \\textbf{z}^{(m+1)}}$$ 이제 Markov chain의 몇 가지 특징들에 대해 살펴보자. accesible $i \\rightarrow j$ : state $j$ is accessible from $i$ if $T_{i,j}^m \u003e 0$ 즉 state $i$에서 언젠가는 state $j$에 방문한다는 의미 $i \\leftrightarrow j$ : state $i, j$ communicate if $i \\rightarrow j$ and $j \\rightarrow i$ reducibility 모든 state $i,j$가 communicate하다면 그 Markov chain은 irreducible 하다고 한다. periodicity state $i$ has peoriod d if $d = gcd{n:T_{i,j}^m \u003e0}$ if d = 1, state $i$ is aperiodic transience state $j$ is recurrent if $j$에서 시작해서 언젠가는 다시 $j$를 방문할 확률이 1인 경우 state which is not recurrent is transient positive recurrent : expected time until the process starting in state $i$ returns to $i$ is finite ergodicity irreducible, aperiodic, positive recurrent Markov chain on a countable state space is called ergodic 참고로 irreducible가 성립하면 자동으로 positive recurrent가 성립한다. 따라서 어떤 책에는 ergodic의 조건으로 irreducible, aperiodic 만을 언급하기도 한다. countable state space가 아닌 general한 경우는 ergodicity를 확인하기 복잡하다. (어떤 책에는) For countable state spaces, an irreducible, aperiodic Markov chain having a stationary distribution is ergodic. ergodic Markov chain은 unique stationary distribution을 갖고 있다. Stationary distribution regular MC는 limiting probability distribution ${\\pmb \\pi} = (\\pi_0,…,\\pi_N)$을 갖는다. transition matrix $\\textbf{T}^{(m)}$의 모든 원소가 0보다 크면 MC가 regular 하다고 한다. $\\pi_j = lim_{n \\rightarrow \\infty}T_{i,j}^{(n)}$ stationary distribution은 존재하지 않을 수도 있고 여러 개일 수도 있다. 아래와 같은 식을 만족하는 limiting distribution을 stationary distribution이라고 부른다. $$\\pi_j = \\sum_{k=0}^K \\pi_k T_{k,j}$$ detailed balance condition Markov chain이 아래와 같은 식을 만족하면 time reversible 하다고 한다. $P(\\textbf{z}^{(n)} = j| \\textbf{z}^{(n+1)} = i) = P(\\textbf{z}^{(n+1)} = j| \\textbf{z}^{(n)} = i)$ time reversibility의 조건은 아래와 같이도 표현할 수 있는데 이를 detailed balance condition 이라고 한다. (detailed balance condition $\\Leftrightarrow$ reversibility) $$\\pi_i T_{i,j} = \\pi_j T_{j,i}$$ detailed balance condition을 만족하면 stationary distribution을 갖는다. (unique한지는 확신할 수 없다) proof $$\\pi_i T_{i,j} = \\pi_j T_{j,i} \\ \\sum_i \\pi_i T_{i,j} =\\sum_i \\pi_j T_{j,i} \\ \\sum_i \\pi_i T_{i,j} =\\pi_j \\sum_i T_{j,i} \\ \\sum_i \\pi_i T_{i,j} =\\pi_j$$ 지금까지 Markov chain에 대해 알아보았다. 이 특성들을 이용하여 우리는 MCMC algorithm을 진행한다. 일단 전통적인 Markov chain 이론과 MCMC의 구별되는 특징에 대해 알아보면 In the traditional Markov chain theory, Given a transition rule, $P(\\textbf{z}^{n+1} = j | \\textbf{z}^{(n)} = i)$ Interested in finding its stationary distribution $\\pi$ In the MCMC, Given a target stationary distribution $\\pi$ Interested in prescribing and efficient transition rule to reach $\\pi$ 이 내용을 위에서 봤던 Metropolis algorithm과 잘 연결시켜서 이해하도록 하자. ergodic MC는 unique stationary distribution을 갖고 있다. 하지만 종종 ergodic 여부를 판단하기 어려운 상황이 발생한다. in practice, reversible MC는 detailed balance condition을 만족하고 이는 stationary distribution가 존재함을 위미한다. 따라서 reversible MC를 주로 이용하고 starting value를 여러가지로 진행하여 unique함을 확인한다. ","date":"2021-11-29","objectID":"/prml-chap11-1/:2:1","tags":["Approximate Inference"],"title":"[PRML] Chapter11 - Sampling Method","uri":"/prml-chap11-1/"},{"categories":["PRML"],"content":"11.2.2 The Metropolis-Hastings algorithm 이전에 Metropolis algorithm에서는 proposal distribution(= transition kernel)이 symmetric했다. 하지만 이제는 그렇지 않다. 단, $q(\\textbf{z}_A | \\textbf{z}_B) \u003e0 \\Leftrightarrow q(\\textbf{z}_B | \\textbf{z}_A) \u003e 0$ 을 만족해야 한다. 현재 state는 $\\textbf{z}^{(\\tau)}$ distribution $q(\\textbf{z} | \\textbf{z}^{(\\tau)})$로부터 sample $\\textbf{z}^{ * }$을 뽑는다. normal 분포를 주로 사용한다. 단, 분산을 적절하게 선택해야 한다. 아래의 확률에 따라 accept한다. $$A(\\textbf{z}^{ * }, \\textbf{z}^{(\\tau)} ) = min (1, \\frac{\\tilde{p}(\\textbf{z}^{ * })q(\\textbf{z}^{(\\tau)} | \\textbf{z}^{ * })}{\\tilde{p}(\\textbf{z}^{(\\tau)})q(\\textbf{z}^{ * } | \\textbf{z}^{(\\tau)})})$$ Metropolis-Hastings은 detailed balance condition을 만족한다. $$p(\\textbf{z}) T_{\\textbf{z},\\textbf{z}’} $$ $$= p(\\textbf{z})q(\\textbf{z}’|\\textbf{z})A(\\textbf{z}’ , \\textbf{z}) $$ $$ = \\min {p(\\textbf{z})q(\\textbf{z}’|\\textbf{z}), p(\\textbf{z}’)q(\\textbf{z}|\\textbf{z}’) }$$ $$= \\min { p(\\textbf{z}’)q(\\textbf{z}|\\textbf{z}’),p(\\textbf{z})q(\\textbf{z}’|\\textbf{z}) }$$ $$= p(\\textbf{z}’)q(\\textbf{z}|\\textbf{z}’)A(\\textbf{z} , \\textbf{z}’) $$ $$= p(\\textbf{z}’) T_{\\textbf{z}’,\\textbf{z}} $$ detailed balance condition을 만족하기에 우리가 sampling하여 만들어지는 MC가 stationary distribution을 갖게 된다. 따라서 stationary distribution으로 수렴하기전의 sampling 초반의 sample들은 버리고 (해당 구간을 burn-in period 라고 한다) 뒷부분의 sample들을 이용한다. 해당 sample list는 stationary distribution의 형태를 갖고 있을 것이다. 결국 우리가 구하고자하는 (unormalized) density를 구할 수 있는 것이다. 주로 posterior distribution을 구하는 것이 목적인 경우가 많다. ","date":"2021-11-29","objectID":"/prml-chap11-1/:2:2","tags":["Approximate Inference"],"title":"[PRML] Chapter11 - Sampling Method","uri":"/prml-chap11-1/"},{"categories":["PRML"],"content":"11.3 Gibbs sampling Metropolis-Hastings algorithm의 특별한 케이스이다. 우리가 sample을 뽑고 싶어하는 $p(\\textbf{z}) = p(z_1,z_1,…,z_M)$ distribution이 있다. 이전에 우리는 proposal distribution을 따로 정해서 사용하였지만 Gibbs sampling에서는 그렇지 않다. 먼저 1부터 순서대로 $z_i$를 distribution $p(z_i|\\textbf{z}_{-i})$에서 뽑는다. 이를 M까지 반복한다. Initialize ${z_i : i=1,…,M}$ For $\\tau = 1,…,T:$ Sample $z_1^{(\\tau+1)} \\sim p(z_1 | z_2^{(\\tau)}, z_3^{(\\tau)},…, z_M^{(\\tau)})$ Sample $z_2^{(\\tau+1)} \\sim p(z_2 | z_1^{(\\tau+1)}, z_3^{(\\tau)},…, z_M^{(\\tau)})$ … Sample $z_M^{(\\tau+1)} \\sim p(z_M | z_1^{(\\tau+1)}, z_2^{(\\tau+1)},…, z_{M-1}^{(\\tau+1)})$ 즉, Gibbs sampling에서는 acceptance probability를 사용하지 않는다. 모든 sample을 그대로 사용한다. 그렇게 해도 detailed balance condition을 만족하는지 살펴보자. 즉, 특정한 distribution으로 수렴하는지 확인. Gibbs sampling에서 $q(\\textbf{z}|\\textbf{z}’) = p(z_i | \\textbf{z}_{-i}’)$ 이고 $p(\\textbf{z}’)q(\\textbf{z} | \\textbf{z}’) = p(\\textbf{z})q(\\textbf{z}’ | \\textbf{z})$ 임을 확인해보자. $$p(\\textbf{z}’)q(\\textbf{z} | \\textbf{z}’) = p(z_i’, \\textbf{z} _ {-i}’)p(z_i| \\textbf{z} _ {-i}’)$$ $$=p(z_i’|\\textbf{z} _ {-i}’)p(\\textbf{z} _ {-i}’)p(z_i| \\textbf{z} _ {-i}’) $$ $$= p(z_i’|\\textbf{z} _ {-i}’) p(z_i , \\textbf{z} _ {-i}’) = q(\\textbf{z}’| \\textbf{z})p(\\textbf{z})$$ 항상 detailed balance condition이 성립한다. 더 advanced한 MCMC 알고리즘으로는 Hamilton이 있는 것 같다. MCMC가 주 관심분야는 아니기 때문에 여기까지만 정리하기로 한다. ","date":"2021-11-29","objectID":"/prml-chap11-1/:3:0","tags":["Approximate Inference"],"title":"[PRML] Chapter11 - Sampling Method","uri":"/prml-chap11-1/"},{"categories":["PRML"],"content":"VI, EP 에 대한 정리 (예시 제외) probabilistic model의 중요 목표는 posterior distribution $p(\\textbf{Z}|\\textbf{X})$ of the latent variable $\\textbf{Z}$ given the observed data $\\textbf{X}$ 추정 posterior distribution을 이용한 expectation 추정 라고 할 수 있다. In practice 에서는 posterior와 expectation을 구하기가 infeasible한 경우가 존재한다. 이는 latent space가 too high dimension이라 directly 어려운 경우 posterior distribution이 너무 복잡하여 expectation이 analytically intractable한 경우 때문이다. 따라서 우리는 approximation을 해야 한다. 이 방법으로는 크게 두 가지로 나누어서 생각할 수 있다. Stochastic 방법 : MCMC Deterministic 방법 : (analytical approximations to the posterior distribution) variational inference(or Bayes) ","date":"2021-11-29","objectID":"/prml-chap10-2/:0:0","tags":["Approximate Inference"],"title":"[PRML] Chapter10 - Approximate Inference (2)","uri":"/prml-chap10-2/"},{"categories":["PRML"],"content":"10.1 Variational Inference functional : mapping that takes a function as the input and that returns the value of the functional as the output 우리는 이런 functional을 optimize해서 목표를 이룰 것이다. fully Bayesian model 을 가정해보자. 즉, 모든 parameter들이 prior 존재한다고 가정하는 것이다. model은 latent variable, latent parameter 가 존재한다. 이들은 모두 $\\textbf{Z}$ 로 표현하고 observed variables는 $\\textbf{X}$로 표현한다. 우리의 목표는 find approximation for the posterior distribution $p(\\textbf{Z} | \\textbf{X})$ and model evidence $p(\\textbf{X})$ log marginal probability를 분해하면 $$\\ln p(\\textbf{X}) = L(q) - KL(q||p)$$ $$L(q) = \\int q(\\textbf{Z}) \\ln { \\frac{p(\\textbf{X},\\textbf{Z})}{q(\\textbf{Z})} } d \\textbf{Z} \\ KL(q||p) = \\int q(\\textbf{Z}) \\ln { \\frac{p(\\textbf{Z}|\\textbf{X})}{q(\\textbf{Z})} }$$ 이전의 EM과 다른 부분은 parameter vector ${\\pmb \\theta}$가 안보인다는 점이다. 이는 parameter가 이제 stochastic variable이기 때문에 $\\textbf{Z}$에 흡수되서 그렇다. 이제 우리가 할 일은 알다시피 KL을 0으로 만들어주는 과정이 필요하다. 이전에는 latent의 posterior와 동일한 분포를 가정하면 됐지만 지금은 해당 분포가 intractable하다고 가정하고 있다. 그렇다면 제약적이지만 최대한 flexible한 분포를 통해 approximation 해야 한다. 그래서 family of approximation distribution을 parametric distribution으로 제한한다. parameter $\\omega$로 $p(\\textbf{Z}|\\omega)$를 이용하는 것이다. Lower bound가 $\\omega$에 대한 식이 되고 이를 optimization하는 problem을 해결한다. ","date":"2021-11-29","objectID":"/prml-chap10-2/:1:0","tags":["Approximate Inference"],"title":"[PRML] Chapter10 - Approximate Inference (2)","uri":"/prml-chap10-2/"},{"categories":["PRML"],"content":"10.1.1 Factorized distributions $\\textbf{Z}$의 각 element들을 disjoint하게 나눈다. $$q(\\textbf{Z}) = \\prod_{i=1}^{M} q_i (\\textbf{Z}_i)$$ 이를 바로 이용해보자! $$L(q) = \\int \\prod_i q_i(\\textbf{Z}_i) \\ln { \\frac{p(\\textbf{X},\\textbf{Z})}{\\prod_i q_i(\\textbf{Z}_i)}} d \\textbf{Z}$$ $$ = \\int q_j(\\textbf{Z} _ j ) { \\int \\ln p(\\textbf{X},\\textbf{Z})\\prod_{i \\neq j}q_i(\\textbf{Z}_i) d \\textbf{Z}_i } d \\textbf{Z}_j - \\int q_j(\\textbf{Z}_j) \\ln q_j (\\textbf{Z}_j) + const $$ $$= \\int q_j (\\textbf{Z}_j) \\ln \\tilde{p} (\\textbf{X},\\textbf{Z}_j) d \\textbf{Z}_j - \\int q_j(\\textbf{Z}_j) \\ln q_j (\\textbf{Z}_j) d\\textbf{Z}_j + const$$ $$\\text{where}\\; \\ln \\tilde{p} (\\textbf{X},\\textbf{Z} _ j) = E_{i \\neq j}[\\ln p(\\textbf{X,Z})]+const $$ $$ E_{i \\neq j}[\\ln p(\\textbf{X,Z})] = \\int \\ln p(\\textbf{X},\\textbf{Z})\\prod_{i \\neq j}q_i(\\textbf{Z}_i) d \\textbf{Z}_i $$ negative KL divergence의 형태가 나오고 lower bound $L(q)$를 최대로 올리기 위해서는 $$q_j(\\textbf{Z} _ j) = \\tilde{p}(\\textbf{X,Z})$$ general expression for the optimal solution $q_j (\\textbf{Z}_j)$는 $$ \\ln q_j(\\textbf{Z} _ j) = E_{i \\neq j}[\\ln p(\\textbf{X,Z})]+const$$ 위에서 const는 normalizing const이다. log를 지워보면서 아래와 같은 식이 나오는데 실제로 사용할때는 위의 식이 더 편하다고 한다. $$q_j(\\textbf{Z} _ j) = \\frac{\\exp(E_{i \\neq j}[\\ln p(\\textbf{X,Z})])}{\\int \\exp(E_{i \\neq j}[\\ln p(\\textbf{X,Z})])d\\textbf{Z}_j}$$ 이 식의 값을 구하기 위해서는 iterative하게 반복해야 한다. $\\textbf{Z}$의 모든 element에 적절한 초깃값으로 시작한다. $j$를 제외한 나머지 값들로 $q_j$를 구한다. 이 과정을 모든 element에 반복하면 된다. convergence를 이미 증명되어 있다. ","date":"2021-11-29","objectID":"/prml-chap10-2/:1:1","tags":["Approximate Inference"],"title":"[PRML] Chapter10 - Approximate Inference (2)","uri":"/prml-chap10-2/"},{"categories":["PRML"],"content":"10.1.2 Properties of factorized approximations minimization of $KL(q||p)$ : tend to find one of modes minimization of $KL(p||q)$ : resulting approximations would average across all of the modes ","date":"2021-11-29","objectID":"/prml-chap10-2/:1:2","tags":["Approximate Inference"],"title":"[PRML] Chapter10 - Approximate Inference (2)","uri":"/prml-chap10-2/"},{"categories":["PRML"],"content":"예시들 10.1.3 Example : The univariate Gaussian 10.1.4 Model comparison 10.2 Illustration: Variational Mixture of Gaussians 10.3 Variational Linear Regression 10.4 Exponential Family Distributions 10.5 Local Variational Methods 10.6 Variational Logistic Regression ","date":"2021-11-29","objectID":"/prml-chap10-2/:1:3","tags":["Approximate Inference"],"title":"[PRML] Chapter10 - Approximate Inference (2)","uri":"/prml-chap10-2/"},{"categories":["PRML"],"content":"10.7 Expectation Propagation deteministic한 또 다른 방법을 알아보자. 아래의 KL-Divergence를 최소화해야 하는 상황이다. $$KL(p||q)$$ $p(\\textbf{z})$ is fixed $q(\\textbf{z})$ is exponential family $$q(\\textbf{z}) = h(\\textbf{z})g({\\pmb \\eta})\\exp{ {\\pmb \\eta}^T u(\\textbf{z}) }$$ $\\eta$에 대한 함수인 KL을 구하면 $$KL(p||q) = - \\ln q({\\pmb \\eta}) - {\\pmb \\eta}^T E_p [u(\\textbf{z})] + const$$ 이를 최소화하기 위해 $\\eta$에 대해 미분하여 0으로 하면 $$- \\nabla \\ln g({\\pmb \\eta}) = E_p [u(\\textbf{z})]$$ 임을 알 수 있다. 그런데 우리가 2장에서 공부했던 내용을 이용하면 ($q(z)$를 parameter에 대해 미분) 아래와 같은 사실을 알 수 있다. $$- \\nabla \\ln g({\\pmb \\eta}) = E_q [u(\\textbf{z})]\\ \\therefore E_q [u(\\textbf{z})] = E_p [u(\\textbf{z})]$$ 따라서 KL를 최소화하는 optimum solution은 충분통계량의 expectation을 이용하는 것이다. 예를 들어, $q(\\textbf{z}) \\sim N(\\mu, \\Sigma)$ 이면 KL을 최소화하기 위해 $p(\\textbf{z})$의 mean과 covariance와 같아지면 된다. 이를 moment matching 이라고 한다. 이제 approximation을 해보자. 많은 probabilistic model들은 joint distribution of data $D$ and hidden variables $\\theta$ comprises a product of fators in the form 예를 들면, 각 data들은 iid $f_n({\\pmb \\theta}) = p(\\textbf{x}_n | {\\pmb \\theta})$ $f_0({\\pmb \\theta})$는 prior $$p(D, {\\pmb \\theta}) = \\prod_i f_i ({\\pmb \\theta})$$ 우리의 관심은 예측을 위한 posterior distrbution $p({\\pmb \\theta} | D)$, model comparison을 위한 model evidence $p(D)$ 이다. $$p({\\pmb \\theta}|D) = \\frac{1}{p(D)} \\prod_i f_i ({\\pmb \\theta}) \\ p(D) = \\int \\prod_i f_i({\\pmb \\theta}) d {\\pmb \\theta}$$ Expectation propagation은 posterior distribution을 아래와 같이 approximation하는 것이다. $\\tilde{f}_i$는 각각 이에 해당하는 $f_i$를 approximate $Z$는 normalizing constant $$q({\\pmb \\theta}) = \\frac{1}{Z} \\prod_i \\tilde{f}_i ({\\pmb \\theta})$$ $\\tilde{f}_i({\\pmb\\theta})$를 exponential family로 제한할 것이다. 그래서 충분통계량을 이용할 것이다. 지금까지를 통해 KL을 구하면 $$KL(p||q) = KL(\\frac{1}{p(D)} \\prod_i f_i ({\\pmb \\theta}) ||\\frac{1}{Z} \\prod_i \\tilde{f}_i ({\\pmb \\theta}))$$ 그런데 KL에 true distribution이 있기에 intractable하다. 이를 위해 우리는 전체가 아닌 개별의 factor에 대해 KL을 최소화할 것이다. 이는 훨씬 간단해졌다. 또한 noniterative하다. 하지만 개별 factor를 approximation하다보니 이들을 다 product하면 좋지 않은 결과가 나올 수도 있다. factor $\\tilde{f}_j({\\pmb \\theta})$를 구해보자. 먼저 j factor와 나머지 factor로 나누어서 생각한다. $$q^{new}({\\pmb \\theta}) \\propto \\tilde{f} _ j ({\\pmb \\theta}) \\prod_{i \\neq j} \\tilde{f}_i ({\\pmb \\theta})$$ 위의 식은 아래의 식과 최대한 비슷하게 만든다. $$f_j ({\\pmb \\theta}) \\prod_{i \\neq j} \\tilde{f}_i ({\\pmb \\theta})$$ 이를 위해 approximation $q({\\pmb \\theta})$에서 j를 제외하여 unnormalized distribution을 만들면 $$q^{-j}({\\pmb \\theta}) = \\frac{q({\\pmb \\theta})}{\\tilde{f}_j ({\\pmb \\theta})}$$ 이를 기존 factor와 결합하여 $Z_j = \\int f_j ({\\pmb \\theta}) q^{-j} ({\\pmb \\theta}) d{\\pmb \\theta}$ : normalizing const $$\\frac{1}{Z_j} f_j ({\\pmb \\theta}) q^{-j} ({\\pmb \\theta})$$ 이를 이용하여 KL을 최소화하여 우리가 구하고자하는 $\\tilde{f}_j$를 구해보자. $$KL( \\frac{f_j({\\pmb \\theta}) q^{-j}({\\pmb \\theta})}{Z_j} || q^{new}({\\pmb \\theta}) )$$ 이는 $q^{new}({{\\pmb \\theta}})$가 exponetial family로 만들어졌고 따라서 parameter들이 $\\frac{f_j({\\pmb \\theta}) q^{-j}({\\pmb \\theta})}{Z_j}$와 expected sufficient statistic을 맞춤으로 구할 수 있다. (moment matching) exponential family에서 expected statistic은 normalization coefficient의 derivative와 관련이 되어 있기에 더 쉽게 구할 수 있다. 이전에 구했던 식을 이용하면 아래와 같이 구할 수 있다. $$\\tilde{f}_j ({\\pmb \\theta}) = K \\frac{q^{new}({\\pmb \\theta})}{q^{-j}({\\pmb \\theta})}$$ $q^{new}({\\pmb \\theta})$가 normalized되었다는 사실을 이용하면 $$K = \\int \\tilde{f}_j ({\\pmb \\theta}) q^{-j}({\\pmb \\theta}) d {\\pmb \\theta}$$ 그리고 $K$의 값은 matching zeroth-order moments를 통해 $K=Z_j$라는 것을 알 수 있다. 따라서 $$\\tilde{f}_j ({\\pmb \\theta}) = Z_j \\frac{q^{new}({\\pmb \\theta})}{q^{-j}({\\pmb \\theta})}$$ 이렇게 approximation factor를 적절한 값으로 초기화하고 converge할 때까지 반복한다. EP의 단점은 converge한다는 보장이 없다. mixture의 경우는 EP가 적절하지 않다. variational inference는 $KL(q||p)$ EP는 $KL(p||q)$ $p({\\theta})$가 multimodal인 경우 EP는 approximation이 잘 안된다. 하지만 logistic-type models 에서는 EP가 좋다고 한다. ","date":"2021-11-29","objectID":"/prml-chap10-2/:2:0","tags":["Approximate Inference"],"title":"[PRML] Chapter10 - Approximate Inference (2)","uri":"/prml-chap10-2/"},{"categories":["PRML"],"content":"PRML chapter10 에 대한 카이스트 문일철 교수님 강의 정리하였다. ","date":"2021-11-29","objectID":"/prml-chap10-1/:0:0","tags":["Approximate Inference"],"title":"[PRML] Chapter10 - Approximate Inference (1)","uri":"/prml-chap10-1/"},{"categories":["PRML"],"content":"Variational transform concave한 $y = \\ln (x)$ 를 조금 더 간단한 함수(linear)로 근사하고자 한다. (특정 $x$에서) linear model $f(x) = \\lambda x + b(\\lambda)$ 으로 근사하자. How? $\\min_x (\\lambda x + b(\\lambda) -\\ln x)$ 이를 위해 $x$에 대해 미분한다. 미분해서 구하면 $\\lambda= \\frac{1}{x}$ 이를 이용하면 $b(\\lambda) = -\\ln \\lambda -1$ $f(x) = \\lambda x - \\ln \\lambda -1$ 의 결과가 나온다. $x$에 대해서 선형인 결과이다. 하지만 optimization하기에 non linear한 $\\lambda$가 다시 생긴다. 그렇다면 logistic function에서는 variation transform이 가능할까? s curve라 concave하지도 convex하지도 않다. 이런 경우 log 을 취해준다. $$\\log \\frac{1}{1+e^{x}} = -\\log(1+e^x)$$ 이렇게 하면 log함수의 형태이므로 linear approximation(variational transform)이 가능하다. 그리고 linear model을 다시 exp를 취해주면 될 것이다. ","date":"2021-11-29","objectID":"/prml-chap10-1/:0:1","tags":["Approximate Inference"],"title":"[PRML] Chapter10 - Approximate Inference (1)","uri":"/prml-chap10-1/"},{"categories":["PRML"],"content":"Convex duality 그렇다면 위와 같은 경우를 좀 더 systematic variational transform할 수 없을까? Utilize the convex duality 우리는 log같은 concave(or convex) function의 형태만 되면 선형으로 근사할 수 있다. Dual function(=Conjugate function) : $f^{ * }(\\lambda)$ $$f(x)=\\min_{\\lambda}{ \\lambda^T x - f^{* }(\\lambda) } \\Leftrightarrow f^{* }(\\lambda)=\\min_{x}{ \\lambda^T x - f(x)}$$ 위에서 봤듯이 복잡한 함수를 approximate했지만 그 복잡성은 사라지는 것이 아니고 $\\lambda$와 같이 파라미터의 형태로 존재하게 된다. 앞에서 배운 내용을 확률모델에서 생각해보자. probability distribution function도 결국 function이니까 그대로 이용할 수 있다. (variational transform) 아래 식에서 $\\pi (i)$는 $i$의 given을 의미 eg. $P(S) = P(S_1)P(S_2|P_1,P_3)P(S_3)$ 에서 $\\pi(2)={1,3}$ variational parameter $\\lambda_i^U$ $$P(S) = \\prod P(S_i | S_{\\pi(i)}) = \\min_{\\lambda}P^U (S_i | S_{\\pi(i)}, \\lambda^U_i )$$ ","date":"2021-11-29","objectID":"/prml-chap10-1/:0:2","tags":["Approximate Inference"],"title":"[PRML] Chapter10 - Approximate Inference (1)","uri":"/prml-chap10-1/"},{"categories":["PRML"],"content":"Variables of E and H $E$ is observed, fixed $H$ is estimated, infered $E \\cup H = S$ (전체) 라고 할 때 $P(E) = \\sum_H P(H,E) = \\sum_H P(S) = \\sum_H \\prod_i P(S_i | S_{\\pi(i)})$ 우리가 구하고자 하는 것은 $P(H|E) = P(H,E) / P(E)$ 이다. variational inference를 통해 $P(E)$를 approximate해야 한다. (바로 구하기 어려운 경우) ","date":"2021-11-29","objectID":"/prml-chap10-1/:0:3","tags":["Approximate Inference"],"title":"[PRML] Chapter10 - Approximate Inference (1)","uri":"/prml-chap10-1/"},{"categories":["PRML"],"content":"Setting the minimum criteria $$\\ln P(E) = \\ln \\sum_H P(H,E) = \\ln \\sum_H Q(H|E) \\frac{P(H,E)}{Q(H|E)}$$ log는 concave(위로 볼록) 하기에 $$\\ln \\sum_H Q(H|E) \\frac{P(H,E)}{Q(H|E)} \\ge \\sum_H Q(H|E) \\ln \\frac{P(H,E)}{Q(H|E)} \\ = \\sum_H Q(H|E)[{ \\ln P(E|H) + \\ln P(H) } - \\ln Q(H|E)] \\= E_{Q(H|E)}\\ln P(E|H) - KL(Q(H|E) || P(H))$$ ","date":"2021-11-29","objectID":"/prml-chap10-1/:0:4","tags":["Approximate Inference"],"title":"[PRML] Chapter10 - Approximate Inference (1)","uri":"/prml-chap10-1/"},{"categories":["PRML"],"content":"Optimizing the Lower Bound $Q(H | E,\\lambda)$ : variational function(distribution) $\\lambda$ : variational parameter $\\theta$는 model parameter $$\\ln P(E | \\theta) \\ge E_{Q(H|E)}\\ln P(E|H,\\theta) - KL(Q(H|E) || P(H|\\theta))$$ ELBO(evidence lower bound) $$L(\\theta, \\lambda) = \\sum_H Q(H|E,\\lambda)\\ln P(H,E | \\theta) - Q(H|E,\\lambda)\\ln Q(H|E,\\lambda)$$ 이를 최적화하기 위해서 (9장에서 공부한 EM과 거의 유사) KL을 0으로 만들고 $Q(H|E,\\lambda)=P(H|E,\\theta)$으로 만든다. $\\lambda^{t+1} = \\arg\\max_{\\lambda}L(\\theta^t, \\lambda^t)$ 그리고 $\\theta$를 optimization한다. (미분해서) $\\theta^{t+1} = \\arg\\max_{\\theta}L(\\theta^t, \\lambda^{t+1})$ 그렇다면 어떻게 Q를 구할까? ","date":"2021-11-29","objectID":"/prml-chap10-1/:0:5","tags":["Approximate Inference"],"title":"[PRML] Chapter10 - Approximate Inference (1)","uri":"/prml-chap10-1/"},{"categories":["PRML"],"content":"Factorizing Q Q를 안다는 것은 좋은 $\\lambda$와 Q의 distribution 형태를 골라야하는 것이다. 이전에는 Q가 $P(H|E,\\theta)$이 되도록 하였지만 이를 쉽게 구하기 어려운 경우도 존재한다. 그렇다면 Q를 approximate 해보자. Mean field approximation hidden variable들이 독립이라는 가정 given variational parameter simple, easier to hadle strong assumption $$Q(H) = \\prod_{i \\le |H|}q_i(H_i | \\lambda_i)$$ ","date":"2021-11-29","objectID":"/prml-chap10-1/:0:6","tags":["Approximate Inference"],"title":"[PRML] Chapter10 - Approximate Inference (1)","uri":"/prml-chap10-1/"},{"categories":["PRML"],"content":"Focusing on Single Variable in Q 이번에는 Factorizing한 Q에서 하나의 variable에 대해 살펴보자. $$L(\\theta, \\lambda) = \\sum_H [ \\prod_{i \\le |H|}q_i(H_i |E, \\lambda_i)\\ln P(H,E | \\theta) \\\\ - \\prod_{i \\le |H|}q_i(H_i |E, \\lambda_i)\\ln \\prod_{i \\le |H|}q_i(H_i | E,\\lambda_i) ]$$ 위에서 single variable에 대해 정리하면 (j와 관련없으면 constant C로 처리) $$L(\\lambda_j) = \\sum_H [ \\prod_{i \\le |H|}q_i(H_i |E, \\lambda_i)\\ln P(H,E | \\theta) \\\\ - \\prod_{i \\le |H|}q_i(H_i |E, \\lambda_i)\\ln \\prod_{i \\le |H|}q_i(H_i | E,\\lambda_i) ]$$ $$= \\sum_H [ \\prod_{i \\le |H|}q_i(H_i |E, \\lambda_i) { \\ln P(H,E | \\theta) - \\ln \\prod_{i \\le |H|}q_i(H_i | E,\\lambda_i)} ] $$ $$= \\sum_{H_j} q_j (H_j | E, \\lambda_j) \\sum_{H_{-j}} \\prod_{i \\le |H|, i \\neq j} q_i(H_i |E,\\lambda_i) \\ln P(H,E|\\theta) \\\\ -\\sum_{H_j} q_j (H_j|E,\\lambda_j) \\ln q_j (H_j|E,\\lambda_j)+C$$ 이제 새로운 P function을 정의하면 $$\\ln \\tilde{P}(H,E | \\theta) = \\sum_{H_{-j}}\\prod_{i\\le |H|, i \\neq j}q_i(H_i | E,\\lambda_i) \\ln P(H,E | \\theta) $$ $$ = E_{q_{i \\neq j} }[\\ln P(H,E | \\theta)]+C$$ 이 새로운 P function을 $L(\\lambda_j)$ 에 대입하면 이전에 우리가 봤던 형태가 나온다. 그렇다 KL divergence! 이를 최적화하기 위해서는 KL divergence = 0 을 만드는 분포를 이용하면 된다. 따라서 $$\\ln q_j (H_j | E, \\lambda_j) = \\ln \\tilde{P}(H,E | \\theta)=E_{q_{i \\neq j}}[\\ln P(H,E | \\theta)] + C$$ ","date":"2021-11-29","objectID":"/prml-chap10-1/:0:7","tags":["Approximate Inference"],"title":"[PRML] Chapter10 - Approximate Inference (1)","uri":"/prml-chap10-1/"},{"categories":["PRML"],"content":"예시 $\\mu \\sim N(\\mu_0, \\frac{1}{\\lambda_0 \\tau})$ $\\tau \\sim Gamma(a_0, b_0)$ $x_i \\sim N(\\mu, \\frac{1}{\\tau})$ H : $\\mu, \\tau$ E : x 먼저 joint 부터 구하면 $$p(H,E | \\theta) = p(X,\\mu,\\tau | \\mu_0, \\lambda_0, a_0, b_0)$$ $$ =p(X| \\mu, \\tau)p(\\mu | \\tau, \\mu_0, \\lambda_0)p(\\tau | a_0, b_0)$$ $$=\\prod_i p(x_i | \\mu, \\tau)p(\\mu | \\tau, \\mu_0, \\lambda_0)p(\\tau | a_0, b_0)$$ 우리는 2개의 variational parameter가 필요하다. by mean field approximation $$Q(H|E,\\lambda) = Q(\\mu,\\tau | X,\\mu’, \\tau’) = q(\\mu | X,\\mu’)q(\\tau | X,\\tau’)$$ 그럼 이제 optimal variational parameter를 구해보자. 일단 $\\mu$에 관하여 진행 $$\\ln q(\\mu | X,\\mu’) = E_{\\tau}[\\ln p(X,\\mu, \\tau | \\mu_0,\\lambda_0, a_0, b_0)]+C_1 $$ $$ = E_{\\tau}[\\ln \\prod_i p(x_i | \\mu, \\tau)p(\\mu | \\tau, \\mu_0, \\lambda_0)p(\\tau | a_0, b_0)]+C_1 \\\\ = E_{\\tau}[\\sum(\\frac{1}{2}(\\ln \\tau - \\ln 2\\pi) - \\frac{(x_i-\\mu)^2 \\tau}{2})] \\\\ + E_{\\tau}[\\frac{1}{2}(\\ln \\lambda_0 + \\ln \\tau - \\ln 2 \\pi) - \\frac{(\\mu - \\mu_0)^2 \\lambda_0 \\tau}{2}]+C_2 \\\\ = - \\frac{E_{\\tau}[\\tau]}{2}{ \\sum (x_i - \\mu)^2 + (\\mu - \\mu_0)^2 \\lambda_0 }+C_3$$ $$ = - \\frac{1}{2}{ (\\lambda_0+N)E_{\\tau}[\\tau] (\\mu - \\frac{\\lambda_0 \\mu_0 + \\sum x_i}{\\lambda_0 + N})^2 } + C_4$$ 그렇다면 이제 $q(\\mu | X,\\mu’)$를 normal이라고 가정해보면 (우리는 $q(\\mu;i;p)$에 대한 아무런 가정이 없기 때문에 이렇게 접근하는 것) $$q(\\mu | X,\\mu’) \\sim N(\\frac{\\lambda_0 \\mu_0 + \\sum x_i}{\\lambda_0 + N},\\frac{1}{(\\lambda_0 +N)E_{\\tau}[\\tau]})$$ 위에서 우리가 모르는 부분은 $E_{\\tau}[\\tau]$ 이므로 위와 똑같은 과정을 반복해서 모르는 부분에 대해 찾아야 한다. $$\\ln q(\\tau | X,\\tau’) = E_{\\mu}[\\ln p(X,\\mu,\\tau | \\mu_0, \\lambda_0, a_0, b_0)]+C_1$$ $$= -\\tau{ b_0 + \\frac{1}{2}E_{\\mu}[\\sum(x_i - \\mu)^2 + (\\mu-\\mu_0)^2 \\lambda_0]} + (a_0 + \\frac{N+1}{2}-1)\\ln \\tau + C_2$$ 이를 잘 보면 $q(\\tau | X,\\tau’)$ 는 Gamma 꼴이라고 생각할 수 있다. $$q(\\tau | X,\\tau’) \\sim Gamma(a_0 + \\frac{N+1}{2}, b_0 + \\frac{1}{2}E_{\\tau}[\\sum(x_i - \\mu)^2 + (\\mu - \\mu_0)^2\\lambda_0])$$ 이를 통해 우리가 구해야 하는 모든 것을 구했다. 정리하면 $E_{\\tau}[\\tau] : E_{\\mu}[\\mu],E_{\\mu}[\\mu^2]$ 이 필요하다 $E_{\\mu}[\\mu]$ 는 바로 구할 수 있음 $E_{\\mu}[\\mu^2] : E_{\\tau}[\\tau]$ 필요 $\\lambda$ 는 임의의 수로 시작 interlocked 된 상태이기에 iterative하게 구하면 된다. ","date":"2021-11-29","objectID":"/prml-chap10-1/:0:8","tags":["Approximate Inference"],"title":"[PRML] Chapter10 - Approximate Inference (1)","uri":"/prml-chap10-1/"},{"categories":["PRML"],"content":"기타 예시 prof.Moon Latent Dirichlet Allocation ","date":"2021-11-29","objectID":"/prml-chap10-1/:0:9","tags":["Approximate Inference"],"title":"[PRML] Chapter10 - Approximate Inference (1)","uri":"/prml-chap10-1/"},{"categories":["PRML"],"content":"GMM과 EM 알고리즘에 대해 정리하였다.GMM과 EM 알고리즘에 대해 정리하였다. observed variable와 latent variable에 대한 joint distribution을 정의한다고 해보자. 이 때 observed variable에 대한 확률 분포를 구하고 싶은 경우 latent variable의 marginalization을 진행하면 된다. 이 의미는 복잡한 형태의 분포를 가진 observed variable에 대한 분포를 다룰 때, 좀 더 다루기 쉬운 observed variable와 latent variable의 joint distribution을 이용할 수 있다는 것이다. 즉, latent variable을 도입함으로서 복잡한 분포 모델을 좀 더 쉬운 형태의 분포들의 조합으로 변경할 수 있다. 여기서는 K-mean, Gaussian mixture model, EM algorithm 에 대해 공부할 것이다. discrete latent variable의 경우에 해당한다. (continuous latent는 12장에서 공부한다) ","date":"2021-11-29","objectID":"/prml-chap09-1/:0:0","tags":["GMM","EM Algorithm"],"title":"[PRML] Chapter9 - Mixture Models and EM","uri":"/prml-chap09-1/"},{"categories":["PRML"],"content":"9.1 K-means Clustering D 차원의 데이터가 N개 있다 우리는 이 데이터들을 K개의 cluster로 분류하고자 한다. 각 cluster의 중심점을 ${\\pmb \\mu}_k$ 라고 하자. $r_{nk} \\in {0,1}$ : data가 k cluster에 속하면 1, 나머지는 0 object function (distortion measure 라고 부른다) : $$J = \\sum_{n=1}^{N}{ \\sum_{k=1}^{K}{r_{nk}| \\textbf{x}_n -{\\pmb \\mu}_k |^2} }$$ 각 cluster에 속하는 data들과 중심점의 거리를 더한식이다. 우리는 이 식을 최소화하는 $r_{nk},{\\pmb \\mu}_k$ 를 iterative 하게 찾으면 된다. 먼저, ${\\pmb \\mu}_k$의 초깃값을 설정한다. 그리고 $r_{nk}$에 대해 object function을 최소화 한다. (E-step) 다음 $r_{nk}$를 고정하고 object function을 ${\\pmb \\mu}_k$에 대해 최소화 한다. (M-step) converge할때까지 반복한다. 단, global이 아닌 local minimum으로 converge할수 있다. $r_{nk}$의 경우 쉽게 말해 데이터가 각 k개의 중심점들 중에 가장 가까운 k 에 1의 값을 가진다. ${\\pmb \\mu}_k$의 경우 J에서 quadratic 형태이므로 미분하여 그 값을 구한다. J를 미분하면 ${\\pmb \\mu}_k = \\frac{\\sum{r _{nk} \\textbf{x} _n}}{\\sum{r _{nk}}}$ 의 값을 가지고 이는 해당 k cluster에 속하는 data들의 평균값을 의미한다. 그래서 K-means 알고리즘이라고 불린다. K-means 알고리즘의 몇 가지 특징을 살펴보자. 유클리디안 기법을 사용하기 때문에 각 변수별로 scale을 맞출 필요가 있다. 모든 data별로 거리를 계산하기 때문에 속도가 느릴 수 있고 이를 해결하기 위한 논문이 많이 나와 있다.(tree, sequential update…) cluster 갯수를 직접 정해야 한다. Bayesian 접근법으로 문제를 해결할 수 있다. Hard clustering이다. 확률적인 접근이 없다. data와 중심점을 유클리디안으로 계산하기 때문에 categorical 변수에는 적합하지 않고 outlier에 취약하다. 이에 대해 data point간의 dissimilarity를 다르게 계산(유클리디안 거리이외의 다른 방법)하는 K-medoids 알고리즘이 있다. (써봤는데 그닥 좋은지 모르겠다) ","date":"2021-11-29","objectID":"/prml-chap09-1/:1:0","tags":["GMM","EM Algorithm"],"title":"[PRML] Chapter9 - Mixture Models and EM","uri":"/prml-chap09-1/"},{"categories":["PRML"],"content":"9.2 Mixtures of Gaussians PRML 2장에서는 GMM을 Gaussian component의 linear 조합으로 생각했지만 이번에는 latent variable의 개념을 추가해서 이해해보자. Gaussian mixture distribution $\\pi_k$는 weight의 역할을 하며 multinomial distribution에서의 확률이고 뒤의 mixture component $N$은 multivariate gaussian distribution이다. $$p(\\textbf{x}) = \\sum_{k=1}^{K}{\\pi_k N( \\textbf{x} | {\\pmb \\mu}_k, \\Sigma_k)}$$ $\\textbf{z}$ 는 discrete latent variable이다. K 차원의 binary random variable이며 하나의 원소만 1을 가지며 나머지는 0을 갖는다. $z_k \\in {1,0}$ 인 것이다. 이는 multinomial distribution의 확률변수라는 것을 알 수 있다. marginal distribution of z $$p(z_k=1) = \\pi_k$$ $0 \\le \\pi_k \\le 1$ $\\sum_{k=1}^{K}{\\pi_k}=1$ $$p(\\textbf{z}) = \\prod_{k=1}^{K}{\\pi_k^{z_{k} } }$$ conditional distribution of x $$p(\\textbf{x}|\\textbf{z}) = \\prod_{k=1}^{K}{N(\\textbf{x}| {\\pmb \\mu}_k,\\Sigma_k)^{z_k}}$$ 위의 식들을 이용하여 우리는 처음에 보았던 Gaussian mixture distribution을 구할 수 있다 $$p(\\textbf{x}) = \\sum_{\\textbf{z}}{p(\\textbf{z})p(\\textbf{x}|\\textbf{z})} = \\sum_{k=1}^{K}{\\pi_k N(\\textbf{x} | {\\pmb \\mu}_k, \\Sigma_k)}$$ Conditional probability of z given x it can be viewd as the responsibility the component k takes for ’explaning’ the observation x posterior 로 이해할 수 있다. $$\\gamma(z_{nk}) = p(z_k = 1 | \\textbf{x} _ n) = \\frac{p(z_k=1) p(\\textbf{x} _ n |z_k=1)}{\\sum_{j=1}^{K}{p(z_j=1)p(\\textbf{x} _ n|z_j=1)}} \\\\ = \\frac{\\pi_k N(\\textbf{x} _ n| {\\pmb \\mu} _ k,\\Sigma_k)}{\\sum_{j=1}^{K}{\\pi_j N(\\textbf{x} _ n|{\\pmb \\mu}_j,\\Sigma_j)}}$$ ","date":"2021-11-29","objectID":"/prml-chap09-1/:2:0","tags":["GMM","EM Algorithm"],"title":"[PRML] Chapter9 - Mixture Models and EM","uri":"/prml-chap09-1/"},{"categories":["PRML"],"content":"9.2.1 Maximum likelihood N * D data set X N * K latent matrix Z Log likelihood $$\\ln p(\\textbf{X} | \\pi, \\mu, \\Sigma) = \\sum_{n=1}^{N}{\\ln{ \\sum_{k=1}^{K}{\\pi_k N(\\textbf{x}_n | {\\pmb \\mu}_k, \\Sigma_k)}}}$$ 이를 maximize 하려고 하는데 문제가 생긴다. log안에 summation이 있어서 미분을 하여 closed form의 형태로 구할 수 없다. sigularity : 특정 점이 어떠한 평균값과 같은 값을 가지고 그 분포의 분산이 0으로 가면 그 점에서의 확률값이 무한으로 가고 logL도 무한으로 간다. identifiability : K! 개의 같은 solution이 생긴다. ","date":"2021-11-29","objectID":"/prml-chap09-1/:2:1","tags":["GMM","EM Algorithm"],"title":"[PRML] Chapter9 - Mixture Models and EM","uri":"/prml-chap09-1/"},{"categories":["PRML"],"content":"9.2.2 EM for Gaussian mixtures log likelihood 를 각 parameter($\\mu, \\Sigma, \\pi$)에 대해 미분하면 $$0 = - \\sum_{n=1}^{N}{\\frac{\\pi_k N(\\textbf{x} _ n | {\\pmb \\mu} _ k, \\Sigma_k)}{\\Sigma_{j}\\pi_j N(\\textbf{x} _ n | {\\pmb \\mu}_j,\\Sigma_j)} \\Sigma_k^{-1} (\\textbf{x}_n - {\\pmb \\mu}_k)}$$ $${\\pmb \\mu} _ k = \\frac{1}{N_k}\\sum_{n=1}^{N}{\\gamma(z_{nk}) \\textbf{x} _ n} \\\\ \\text{where}\\; N_k = \\sum_{n=1}^{N}{\\gamma(z_{nk})}$$ mean은 각 data에 posterior 가중치로서 곱해져 구해진다. covariance도 미분해서 구하면 아래와 같은 값을 가진다. $$\\Sigma_k = \\frac{1}{N_k}\\sum_{n=1}^{N}{\\gamma(z_{nk})(\\textbf{x}_n-{\\pmb \\mu}_k)(\\textbf{x}_n - {\\pmb \\mu}_k)^T}$$ mixing coefficient $\\pi$ 는 제약식이 있기에 Lagrange로 풀면 $$\\text{argmax} _ {\\pi} \\;\\ln p({\\bf X}|{\\bf \\pi}, {\\bf \\mu}, \\Sigma)+\\lambda\\left(\\sum _ {k=1}^K \\pi_k-1\\right)$$ $$0 = \\sum_{n=1}^{N} \\frac{N({\\bf x}_n|{\\pmb \\mu}_k, \\Sigma_k)}{\\sum_j \\pi_j N({\\bf x}_n|{\\pmb \\mu}_j, \\Sigma_j)}+\\lambda$$ $$\\pi_k = \\frac{N_k}{N}$$ $\\gamma(z_{nk})$ 값이 다른 parameter에 depend하기 때문에 iterative하게 구해야 한다. k-means보다 많은 iteration을 해야되기 때문에 초기값을 k-means를 통해 정하면 좋다. 또한 likelihood function이 여러 개의 max 봉우리를 가지면 EM을 통해 구한 값이 local maximum일 수도 있다. EM for GM 정리 parameter들$(\\mu_k, \\Sigma_k, \\pi_k)$의 초깃값을 설정한다. E-step : $\\gamma(z_{nk})$ 구하기 $$\\gamma(z_{nk})=\\frac{\\pi_k N({\\bf x}_n|{\\bf \\mu}_k, \\Sigma_k)}{\\sum_j \\pi_j N({\\bf x}_n|{\\bf \\mu}_j, \\Sigma_j)}$$ M-step : 주어진 responsibility로 $\\mu, \\Sigma, \\pi$ 구하기 $${\\bf \\mu} _ k^{new} = \\frac{1}{N_k}\\sum_{n=1}^N \\gamma(z _ {nk}){\\bf x} _ n \\\\ \\Sigma_k^{new} = \\frac{1}{N_k}\\sum_{n=1}^N \\gamma(z_{nk})({\\bf x} _ n-{\\bf \\mu}_k)({\\bf x} _ n-{\\bf \\mu} _ k)^T \\\\ \\pi_k^{new} = \\frac{N_k}{N} \\N_k = \\sum _ {n=1}^N \\gamma(z _ {nk})$$ log likelihood 구해서 converge할 때까지 반복 $$\\ln p({\\bf X}|{\\bf \\mu}, \\Sigma, {\\bf \\pi}) = \\sum_{n=1}^N \\{\\sum_{k=1}^K \\pi_k N({\\bf x}_n|{\\bf \\mu}_k, \\Sigma_k)\\}$$ ","date":"2021-11-29","objectID":"/prml-chap09-1/:2:2","tags":["GMM","EM Algorithm"],"title":"[PRML] Chapter9 - Mixture Models and EM","uri":"/prml-chap09-1/"},{"categories":["PRML"],"content":"9.3 An Alternative view of EM $$\\ln p(\\textbf{X} | \\pi, \\mu, \\Sigma)$$ 위의 식을 보면 log 안에 있는 summation(intergral) 때문에 maximum likelihood solution을 구하기 어렵다. 이를 해결하기 위해 latent variable을 추가하여 사용한다. maximization of complete-data log likelihood function은 상대적으로 쉽다고 가정하자. 하지만 latent variable 때문에 complete log likelihood를 그대로 이용하기 어렵고 대신에 Expectation을 취해서(posterior distribution for latent variable을 통해) 이를 최대로 만드는 parameter를 구하고 반복한다. E-step 현재 우리가 알고 있는 parameter $\\theta^{old}$를 이용하여 latent variable의 posterior $p(\\textbf{Z}|\\textbf{X},\\theta^{old})$를 구한다. 이를 이용하여 expectation of the complete-data log likelihood를 구한다. 원래는 $\\ln p(\\textbf{X} | \\theta)$를 maximize해야 하지만 어려우니까 $$Q({\\bf \\theta}, {\\bf \\theta}^{old}) = \\sum_{\\bf Z} p({\\bf Z}|{\\bf X}, {\\bf \\theta}^{old}) \\ln p({\\bf X}, {\\bf Z}|{\\bf \\theta})$$ M-step 이 식을 최대화하는 $\\theta^{new}$를 구한다. $${\\bf \\theta}^{new} = \\arg\\max_{\\theta} Q({\\bf \\theta}, {\\bf \\theta}^{old})$$ ","date":"2021-11-29","objectID":"/prml-chap09-1/:3:0","tags":["GMM","EM Algorithm"],"title":"[PRML] Chapter9 - Mixture Models and EM","uri":"/prml-chap09-1/"},{"categories":["PRML"],"content":"9.3.1 Gaussian mixture revisited 위에서 설명한 대로 GM을 모델링해보자. complete likelihood $$p({\\bf X}, {\\bf Z}|{\\bf \\mu}, \\Sigma, {\\bf \\pi}) = \\prod_{n=1}^N\\prod_{k=1}^K \\pi_k^{z_{nk}} N({\\bf x}_n|{\\bf \\mu} _ k, \\Sigma_k)^{z _ {nk}}$$ posterior of latent Z $$p({\\bf z})=\\prod_{k=1}^{K} \\pi^{z_k} \\ p({\\bf x}|{\\bf z}) = \\prod_{k=1}^{K} N({\\bf x}|{\\bf \\mu}_k, \\Sigma_k)^{z_k}$$ $$\\rightarrow p({\\bf Z}|{\\bf X}, {\\bf \\mu}, \\Sigma, {\\bf \\pi}) \\propto \\prod_{n=1}^{N}\\prod_{k=1}^{K}[\\pi_k N({\\bf x}_n|{\\bf \\mu} _ k, \\Sigma_k)]^{z _ {nk}}$$ 이를 이용하여 expectation of complete-data likelihood function을 구해보자. $$E_{\\bf Z}[\\ln p({\\bf X}, {\\bf Z}|\\theta)] = E_{\\bf Z}[\\sum_n\\ln p({\\bf x} _ n, {\\bf z} _ n|\\theta)] = \\sum_n E_{\\bf Z}[\\ln p({\\bf x}_n, {\\bf z}_n|\\theta)]$$ $$= \\sum_{n=1}^N E_{\\bf Z}[\\ln { p({\\bf z} _ n) p({\\bf x} _ n|{\\bf z} _ n, \\theta) } ] = \\sum_{n=1}^N E_{\\bf Z}[\\ln[\\prod_{k=1}^K (\\pi_k N({\\bf x}_n|{\\bf \\mu} _ k, \\Sigma_k))^{z _ {nk}}]]$$ $$=\\sum_{n=1}^N \\sum_{k=1}^K E_{z}[z_{nk}\\ln { \\pi_k N({\\bf x}|{\\bf \\mu} _ k, \\Sigma_k) } ] = \\sum_{n=1}^N \\sum_{k=1}^K E_{z}[z_{nk}] \\ln { \\pi_k N({\\bf x}_n|{\\bf \\mu}_k, \\Sigma_k })$$ $$=\\sum_{n=1}^N \\sum_{k=1}^K \\gamma(z_{nk}){\\ln\\pi_k+\\ln N({\\bf x}_n|{\\bf \\mu_k}, \\Sigma_k)}$$ $$E[z_{nk}] = \\frac{\\sum{z_{nk}[ \\pi_k N(\\textbf{x} _ n | \\mu_k, \\Sigma_k)]^{z_{nk} } } }{ \\sum{[ \\pi_k N(\\textbf{x} _ n | \\mu_k, \\Sigma_k)]^{z_{nj}} }} = \\frac{\\pi_k N(\\textbf{x} _ n | \\mu_k,\\Sigma_k)}{\\sum_{j=1}^{K}{\\pi_j N(\\textbf{x} _ n | \\mu_j,\\Sigma_j)}} = \\gamma(z_{nk})$$ 이제 차례대로 E-step, M-step을 진행하면 된다. ","date":"2021-11-29","objectID":"/prml-chap09-1/:3:1","tags":["GMM","EM Algorithm"],"title":"[PRML] Chapter9 - Mixture Models and EM","uri":"/prml-chap09-1/"},{"categories":["PRML"],"content":"9.3.2 Relation to K-means k-means를 GM의 특별한 케이스라고 생각할 수 있다. covariance matrices를 추정해야되는 것이 아니라 고정된 $\\epsilon I$ 라고 생각하고 이 값이 0으로 가는 경우 이는 k-means와 같은 결과를 낸다. responsibility $$\\gamma(z_{nk}) = \\frac{\\pi_k \\exp{-|{\\bf x}_n-{\\bf \\mu}_k|^2/2\\epsilon}}{\\sum_j \\pi_j \\exp{-|{\\bf x}_n-{\\bf \\mu}_j|^2/2\\epsilon}}$$ 위의 식에서 $\\epsilon$이 0으로 간다고 가정하자. $|{\\bf x}_n-{\\bf \\mu}_k|^2$ 값이 가장 작은 cluster를 k라고 하자. k 이외의 $\\exp{-|{\\bf x}_n-{\\bf \\mu}_j|^2/2\\epsilon}$ 값들은 더 빠르게 0으로 수렴한다. (exponentially) 즉, $\\gamma(z_{nk})$ 값이 k에서만 1이고 나머지는 0의 값을 가지는 것이다. (binary indicator) $\\gamma(z_{nk})$이 이전의 K-means에서 봤던 $\\gamma_{nk}$이 되는 것이다. 이제 $\\epsilon$이 0으로 간다고 가정하고 expected complete-data log likelihood 값을 보면 $$E_{\\bf Z}[\\ln p({\\bf X}, {\\bf Z}|{\\bf \\mu}, \\Sigma, {\\bf \\pi})] \\rightarrow -\\frac{1}{2}\\sum_{n=1}^N\\sum_{k=1}^K r_{nk}|{\\bf x}_n-{\\bf \\mu}_k|^2+const$$ expected complete-data log likelihood를 최대화하는 것은 결국 K-means에서 object function을 최소화하는 것과 같아졌다. wow! ","date":"2021-11-29","objectID":"/prml-chap09-1/:3:2","tags":["GMM","EM Algorithm"],"title":"[PRML] Chapter9 - Mixture Models and EM","uri":"/prml-chap09-1/"},{"categories":["PRML"],"content":"9.3.3 Mixtures of Bernoulli distribution latent class analysis의 예시이다. (구제적인 내용은 skip) ","date":"2021-11-29","objectID":"/prml-chap09-1/:3:3","tags":["GMM","EM Algorithm"],"title":"[PRML] Chapter9 - Mixture Models and EM","uri":"/prml-chap09-1/"},{"categories":["PRML"],"content":"9.3.4 EM for Bayesian linear regression $\\textbf{w}$를 marginalization했었는데 이를 latent variable로 취급하고 EM algorithm을 사용하는 예시이다. (구체적인 내용은 skip) ","date":"2021-11-29","objectID":"/prml-chap09-1/:3:4","tags":["GMM","EM Algorithm"],"title":"[PRML] Chapter9 - Mixture Models and EM","uri":"/prml-chap09-1/"},{"categories":["PRML"],"content":"9.4 The EM Algorithom in General 우리의 목표는 maximize the likelihood function that is given by $$p(X | \\theta) = \\sum_{Z}{p(X,Z | \\theta)}$$ 이다. (Z는 discrete, continuous 다 가능 intergral로 바꾸면 됨) 하지만 이를 바로 optimization하기는 힘들지만 complete likelihood function 를 optimization하는 것이 더 간단하자고 가정하자. 그러면 우리는 아래와 같은 decomposition을 생각할 수 있다. (임의의 $q(Z)$는 pdf라고 생각할 수 있다 defined over the latent variables) log likelihood는 $$\\ln p(\\textbf{X}|\\theta) = \\ln \\sum_{z}q(\\textbf{Z})\\frac{p(\\textbf{X},\\textbf{Z}|\\theta)}{q(\\textbf{Z})}$$ by Jansen’s inequality $$\\ln p(\\textbf{X}|\\theta) \\ge \\sum_{z}q(\\textbf{Z}) \\ln \\frac{p(\\textbf{X},\\textbf{Z}|\\theta)}{q(\\textbf{Z})} = L(\\theta, q)$$ 여기서 $L(\\theta, q)$는 log likelihood function의 Lower Bound (ELBO) 라고 할 수 있으며 우리는 이를 높여가면서 log likelihood를 최대화하는 $\\theta$를 찾고자 한다. (ELBO는 $\\theta,q$ 두 가지에 depend하는 식임을 기억하자) 그런데 지금 $q(Z)$에 대해 optimization를 할 수 없는 상황(임의의 q를 구할만한 정보가 없음)이고 이를 위해 추가적인 접근법이 필요하다. $$L(\\theta, q) = \\sum_{z}q(\\textbf{Z}) \\ln \\frac{p(\\textbf{X},\\textbf{Z}|\\theta)}{q(\\textbf{Z})}$$ $$= \\sum_{z}q(\\textbf{Z}) \\ln \\frac{p(\\textbf{Z} | \\textbf{X},\\theta)p(\\textbf{X}| \\theta)}{q(\\textbf{Z})} $$ $$= \\sum_{z}{ q(\\textbf{Z})\\ln \\frac{p(\\textbf{Z}|\\textbf{X},\\theta)}{q(\\textbf{Z})} + q(\\textbf{Z})\\ln p(\\textbf{X}|\\theta) }$$ $$ = \\ln p(\\textbf{X}|\\theta)+ \\sum_{z}q(\\textbf{Z})\\ln \\frac{p(\\textbf{Z}| \\textbf{X}, \\theta)}{q(\\textbf{Z})} $$ $$= \\ln p(\\textbf{X}|\\theta) - \\sum_{z}q(\\textbf{Z})\\ln \\frac{q(\\textbf{Z})}{p(\\textbf{Z}| \\textbf{X}, \\theta)}$$ 여기서 first term은 log likelihood이고 second term이 KL-divergence이다. $$KL(q||p) = -\\sum_{z}{q(\\textbf{Z}) \\ln { \\frac{p(\\textbf{Z}|\\textbf{X},\\theta)}{q(\\textbf{Z})} }}= \\sum_{z}{q(\\textbf{Z}) \\ln { \\frac{q(\\textbf{Z})}{p(\\textbf{Z}|\\textbf{X},\\theta)} }}\\ge 0$$ KL-divergence는 항상 0이상의 값을 가지기 때문에 Lower Bound를 최대화하기 위해서는 KL 을 0 의 값을 갖게 해야한다. 여기서 우리는 $q(Z)$에 대한 정보를 찾을 수 있다. 즉, t 시점에서 $$q(Z) = p(Z | X, \\theta^t)$$ 로 하면 된다. 이후 $q$를 고정시키고 우리는 다시 $\\theta^{t+1} = \\text{argmax} L(\\theta, q^t)$ 를 찾는다. 계속 iterative하게 반복하여 MLE parameter (with latent variable)의 값을 구할 수 있다. E-step lower bound L 은 $\\theta^{old}$는 고정한채로 $q(Z)$에 대해 최대화한다. 하지만 $\\ln p(X|\\theta)$는 $q(Z)$와 상관이 없기 때문에 Lower Bound의 최대값은 KL값이 0을 가져야한다. KL = 0 을 위해서는 $q(Z) = p(Z | X, \\theta^{old})$ (posterior)의 조건을 만족해야한다. 그러면 lower bound랑 log likelihood가 같아진다. (Lower Bound가 최대화되며) M-step 위의 과정에 따라 $q(Z)$는 posterior로 fixed 되고 L을 최대화하는 새로운 $\\theta^{new}$를 구한다. 이 새로운 값 때문에 KL은 non zero가 되고 log likelihood는 lower bound보다 더 큰 값을 가진다. converge할 때까지 iterative하게 반복한다. 또 다른 표현으로는 $$L(q, \\theta) = \\sum_\\textbf{Z} p(\\textbf{Z}|\\textbf{X}, \\theta^{old})\\ln p(\\textbf{X}, \\textbf{Z}|\\theta) - \\sum_\\textbf{Z} p( \\textbf{Z}|\\textbf{X}, \\theta^{old})\\ln p(\\textbf{Z} |\\textbf{X}, \\theta^{old}) $$ $$= Q(\\theta, \\theta^{old}) + const$$ 첫번째 항이 expectation of the complete-data log likelihood joint distribution이 exponential family인 경우, log를 취했을 때 쉽게 maximize할 수 있다. 두번째 항은 $\\theta$에 independent하기에 const 따라서 lower bound를 높이는 것이 expectation of the complete-data log likelihood를 최대화하는 것 이다. 한줄결론 : observed log likelihood를 최대화하는 parameter(MLE)를 구하고 싶다. latent variable에 대한 posterior distribution으로 E[complete log likelihood]를 최대로 하게 만드는 $\\theta$를 구하면 된다. ","date":"2021-11-29","objectID":"/prml-chap09-1/:4:0","tags":["GMM","EM Algorithm"],"title":"[PRML] Chapter9 - Mixture Models and EM","uri":"/prml-chap09-1/"},{"categories":["PRML"],"content":"+ EM for MAP MLE를 구하는 과정과 거의 비슷하다. 단지 prior만 추가될뿐이다! E-step $$R(\\theta, \\theta_{t-1}) = E_{\\theta_{t-1}}[\\ln p(\\textbf{X},\\textbf{Z}|\\theta)|\\textbf{X}=\\textbf{x}]+\\ln p(\\theta)$$ M-step $$\\theta_t = \\text{argmax} R(\\theta, \\theta_{t-1})$$ ","date":"2021-11-29","objectID":"/prml-chap09-1/:4:1","tags":["GMM","EM Algorithm"],"title":"[PRML] Chapter9 - Mixture Models and EM","uri":"/prml-chap09-1/"},{"categories":["PRML"],"content":"graphical model에서 inference하는 방법에 대해 정리하였다. (미완성) ","date":"2021-11-29","objectID":"/prml-chap08-2/:0:0","tags":["Grphical Model"],"title":"[PRML] Chapter8 - Graphical Models (2)","uri":"/prml-chap08-2/"},{"categories":["PRML"],"content":"8.4 Inference in Graphical Models node들에 대한 posterior를 계산하고 싶다고 하자. 이번 장에서는 exact inference에 대해 집중해서 알아보자. ","date":"2021-11-29","objectID":"/prml-chap08-2/:1:0","tags":["Grphical Model"],"title":"[PRML] Chapter8 - Graphical Models (2)","uri":"/prml-chap08-2/"},{"categories":["PRML"],"content":"8.4.1 Inference on a chain chain의 모습을 갖는 undirected의 joint distribution에 대해 살펴보자. 각 variable들은 $K$개의 states를 갖는 discrete variable이라고 가정한다. 그러면 joint disribution은 $(N-1)K^2$개의 parameter들을 갖고 있다. $$p(\\textbf{x})=\\frac{1}{Z}\\psi_{1,2}(x_1,x_2)\\psi_{2,3}(x_2,x_3)…\\psi_{N-1,N}(x_{N-1},x_N)$$ 이제 marginal distribution $p(x_n)$를 inference해보려고 한다. 가장 쉽게 보이지만 복잡하고 시간이 오래걸리는 방법은 아래처럼 다 summation하는 것이다. $$p(x_n) = \\sum_{x_1}…\\sum_{x_{n-1}}\\sum_{x_{n+1}}…\\sum_{x_{N}}p(\\textbf{x})$$ joint는 K개의 state를 갖는 N개의 variable이 있기 때문에 $K^N$개의 값이 존재하고 이를 계산하는 것은 비효율적이다. 그렇다면 chain의 특징을 이용해서 조금 더 효율적인 방법을 이용해보자. $$p(x_n)=\\frac{1}{Z}[\\sum_{x_{n-1}}\\psi_{n-1,n}(x_{n-1},x_n)…[\\sum_{x_2}\\psi_{2,3}(x_2,x_3)[\\sum_{x_1}\\psi_{1,2}(x_1,x_2)]]…] \\\\ [\\sum_{x_{n+1}}\\psi_{n,n+1}(x_n,x_{n+1})…[\\sum_{x_N}\\psi_{N-1,N}(x_{N-1},x_N)]…]$$ 위의 방법으로 구하면 total cost는 $O(NK^2)$이다. chain처럼 conditional independence를 찾아서 이용하는 것의 장점을 느낄 수 있다. 위와 같은 방법은 local messages를 보내는 것으로 해석할 수 있다. 크게 보면 marginal $p(x_n)$은 두 개의 factor로 나누어서 생각할 수 있다. $$p(x_n) = \\frac{1}{Z}\\mu_{\\alpha}(x_n)\\mu_{\\beta}(x_n)$$ 각각 $x_n$의 앞, 뒤에서 흘러오는 message로 이해할 수 있다. ","date":"2021-11-29","objectID":"/prml-chap08-2/:1:1","tags":["Grphical Model"],"title":"[PRML] Chapter8 - Graphical Models (2)","uri":"/prml-chap08-2/"},{"categories":["PRML"],"content":"8.4.2 Trees graph에서 tree는 어떤 두 개의 node를 선택했을 때 오직 하나의 path만 존재하는 것을 의미한다. 그리고 모든 node는 하나의 parent node를 갖고 가장 위에 있는 node는 root라고 부른다. local message passing을 이용한 inference를 이 tree에 이용하는 sum-product algorithm에 대해 배울 것이다. ","date":"2021-11-29","objectID":"/prml-chap08-2/:1:2","tags":["Grphical Model"],"title":"[PRML] Chapter8 - Graphical Models (2)","uri":"/prml-chap08-2/"},{"categories":["PRML"],"content":"8.4.3 Factor graphs graph에 node를 추가하여서 decomposition을 explicit하게 하는 것이다. $x_s$를 subset of the variable이라고 하면 joint를 아래와 같이 나타낼 수 있다. $$p(\\textbf{x}) = \\prod_s f_s (\\textbf{x}_s)$$ 여기서 $f_s$는 a function of a corresponding set of variables 이다. 각 factor $f_s(\\textbf{x}_s)$는 directed의 경우 local conditional distribution의 역할과 같고 undirected의 경우 potential function이라고 할 수 있다. undirected, directed 모두 factor graph로 일반화가 가능해지는 것으로 이해할 수 있을 것 같다. ","date":"2021-11-29","objectID":"/prml-chap08-2/:1:3","tags":["Grphical Model"],"title":"[PRML] Chapter8 - Graphical Models (2)","uri":"/prml-chap08-2/"},{"categories":["PRML"],"content":"8.4.4 The sum-product algorithm tree-structured graph에서 exact inference를 하기 위한 방법을 알아보자. variable들은 discrete이라고 가정하기에 summation으로 계산을 진행한다. (물론 continuous도 동일하게 가능) loop없는 directed graph에서 exact inference하는 알고리즘은 belief propagation이라 하고 이는 sum-product algorithm의 특별한 경우에 해당한다. original graph는 undirected tree, directed tree, polytree 이고 이에 대응되는 factor graph는 tree structure를 가진다. original graph는 factor graph로 바꾸는 과정을 통해 undirected, directed에 동일한 방법을 적용할 수 있게 된다. 우리는 이런 과정을 통해 최종적으로 얻고자 하는 바는 아래와 같다. to obtain an efficient, exact inference algorithm for finding marginals in situations where several marginals are required to allow computations to be shared efficiently 먼저 marginal을 구하는 것부터 시작해보자. $$p(x) = \\sum_{\\textbf{x}-x}p(\\textbf{x})$$ 우리는 tree structure를 다루고 있고 이를 통해 joint distribution의 factor들을 그룹으로 partition할 수 있다. $$p(\\textbf{x})=\\prod_{s\\in ne(x)}F_s(x,X_s)$$ $ne(x)$ : 이웃 variable을 의미 $X_s$ : factor node $f_x$를 통해 $x$와 연결된 subtree에 있는 set of all variables $F_s(x,X_s)$ : the product of all the factors in the group associated with factor $f_s$ 이를 통해 marginal식을 살펴보면 $$p(x) = \\sum_{\\textbf{x}-x}\\prod_{s\\in ne(x)}F_s(x,X_s)\\\\ =\\prod_{s\\in ne(x)}\\sum_{\\textbf{x}-x}F_s(x,X_s) \\\\ =\\prod_{s\\in ne(x)}\\mu_{f_s \\rightarrow x}(x)$$ 여기서 우리는 새로운 a set of functions $\\mu_{f_s \\rightarrow x}(x) = \\sum_{\\textbf{x}-x}F_s(x,X_s)$을 만나게 된다. 이는 factor nodes $f_s$에서 $x$를 향하는 messages라고 볼 수 있다. 그래서 marginal은 node $x$에 도착하는 message들의 product라고 이해할 수 있다. $F_s(x,X_s)$을 조금 더 factorize해보자. $$F_s(x,X_s) = f_s (x,x_1,…,x_M)G_1(x_1, X_{s1})…G_M(x_M, X_{sM})$$ $$\\mu_{f_s \\rightarrow x}(x) =\\sum_{x_1}…\\sum_{x_M}f_s(x,x_1,…,x_M) \\prod_{m \\in ne(f_s)-x}[\\sum_{X_{sm}}G_m(x_m, X_{sm})] \\\\ =\\sum_{x_1}…\\sum_{x_M}f_s(x,x_1,…,x_M) \\prod_{m \\in ne(f_s)-x}\\mu_{x_m \\rightarrow f_s}(x_m)$$ 이번에는 $\\mu_{x_m \\rightarrow f_s}(x_m) = \\sum_{X_{sm}}G_m(x_m,X_{sm})$ 이번에는 variable에서 factor로 가는 message를 의미한다. 이처럼 message를 보내는 flow를 이용하여 marginal distribution을 구할 수 있다. 구체적인 예시는 PRML책 409page를 보면 된다. 내용이 꽤 길어서 일부 생략하기로 한다. ","date":"2021-11-29","objectID":"/prml-chap08-2/:1:4","tags":["Grphical Model"],"title":"[PRML] Chapter8 - Graphical Models (2)","uri":"/prml-chap08-2/"},{"categories":["PRML"],"content":"8.4.5 The max-sum algorithm 이번에는 high probability를 갖는 latent variable을 구하고 싶은 경우를 생각해보자. $$\\textbf{x}^{\\text{max}} = \\arg \\max_{\\textbf{x}} p(\\textbf{x}) \\ p(\\textbf{x}^{\\text{max}}) = \\max_{\\textbf{x}}p(\\textbf{x})$$ 이를 구하기 위해 먼저 chain 예시를 한 번 살펴보자. 아래 식을 전개하는데 이용한 식 $\\max_{\\textbf{x}}p(\\textbf{x}) = \\max_{x_1}…\\max_{x_M}p(\\textbf{x})$ $\\max (ab,ac) = a \\max (b,c),;\\text{where};a\u003e0$ $$\\max_{\\textbf{x}}p(\\textbf{x}) = \\frac{1}{Z}\\max_{x_1}…\\max_{x_N}[\\psi_{1,2}(x_1, x_2)…\\psi_{N-1,N}(x_{N-1}, x_N)]\\\\ =\\frac{1}{Z} \\max_{x_1}[\\psi_{1,2}(x_1,x_2)[…\\max_{x_N}\\psi_{N-1, N}(x_{N-1},x_N)]]$$ 이는 이전의 sum-product algorithm처럼 message를 전달하는 것으로 이해할 수 있다. 이제는 tree-structured factor graph를 통해 일반적인 경우로 알아보자. sum-product algorithm과 거의 비슷하다. sum이 max로 바뀐 경우라고 이해할 수 있다. 거기에 추가로 product를 log를 씌워서 sum으로 implement한다. $$\\mu_{f \\rightarrow x}(x) = \\max_{x_1,…,x_M}[\\log f(x,x_1,…,x_M)+\\sum_{m\\in ne(f_s)-x}\\mu_{x_m\\rightarrow f}(x_m)]\\\\mu_{x \\rightarrow f}(x)=\\sum_{l \\in ne(x)-f}\\mu_{f_l\\rightarrow x}(x)$$ ","date":"2021-11-29","objectID":"/prml-chap08-2/:1:5","tags":["Grphical Model"],"title":"[PRML] Chapter8 - Graphical Models (2)","uri":"/prml-chap08-2/"},{"categories":["PRML"],"content":"8.4.6 Exact inference in general graphs ","date":"2021-11-29","objectID":"/prml-chap08-2/:1:6","tags":["Grphical Model"],"title":"[PRML] Chapter8 - Graphical Models (2)","uri":"/prml-chap08-2/"},{"categories":["PRML"],"content":"8.4.7 Loopy belief propagation ","date":"2021-11-29","objectID":"/prml-chap08-2/:1:7","tags":["Grphical Model"],"title":"[PRML] Chapter8 - Graphical Models (2)","uri":"/prml-chap08-2/"},{"categories":["PRML"],"content":"8.4.8 Learning the graph structures","date":"2021-11-29","objectID":"/prml-chap08-2/:1:8","tags":["Grphical Model"],"title":"[PRML] Chapter8 - Graphical Models (2)","uri":"/prml-chap08-2/"},{"categories":["PRML"],"content":"graphical model에 대해 정리하였다. probabilistic graphical models 의 장점 probabilistic model의 구조를 시각화하기 좋다. model에 대한 insight를 얻을 수 있다. 복잡한 modeling을 graphical적인 방법으로 다룰 수 있다. probabilistic graphical model에서 각 node는 random variable을 의미하고 link는 그들의 관계를 의미한다. joint distribution이 각 factor들의 product로 decomposed되는 모습을 주로 나타낸다. Bayesian network (directed graphical model) : link가 특정한 방향을 가르키는 경우 Markov random field (undirecte graphical model) : 방향이 없는 경우 ","date":"2021-11-29","objectID":"/prml-chap08-1/:0:0","tags":["Grphical Model"],"title":"[PRML] Chapter8 - Graphical Models (1)","uri":"/prml-chap08-1/"},{"categories":["PRML"],"content":"8.1 Bayesian Networks 먼저 간단한 예시를 보자. $$p(a,b,c) = p(c|a,b)p(b|a)p(a)$$ 위의 식처럼 우리는 joint distribution을 분해할 수 있다. 이때 node a는 node b의 parent node라고 부른다. 반대로 node b는 node a의 child node이다. 그리고 link의 방향은 given에서 출발한다. 즉, node a에서 node b로 화살표가 그려지는 것이다. 그리고 이와 같이 (특정순서대로) 모든 node에게서 link를 받으면 이 graph를 fully conneted 하다고 한다. 이를 일반화하면 $$p(\\textbf{x}) = \\prod_{k=1}^{K}{p(x_k|pa_k)}$$ 의 형태이다. $pa_k$는 parent node들을 의미한다. 우리가 다루는 directed graph는 no direted cycle 이라는 제약이 있다. 이는 directed acyclic graph라는 의미로 parent node로 다시 돌아가는 link가 없다는 의미이다. ","date":"2021-11-29","objectID":"/prml-chap08-1/:1:0","tags":["Grphical Model"],"title":"[PRML] Chapter8 - Graphical Models (1)","uri":"/prml-chap08-1/"},{"categories":["PRML"],"content":"8.1.1 Example : Polynomial regression polynomial regression에서 prediction을 graphical model로 나타내면 색이 칠해진 $t_n$ 부분은 given의 의미이다. ","date":"2021-11-29","objectID":"/prml-chap08-1/:1:1","tags":["Grphical Model"],"title":"[PRML] Chapter8 - Graphical Models (1)","uri":"/prml-chap08-1/"},{"categories":["PRML"],"content":"8.1.2 Generative models 주어진 probability distribution에서 sampling을 해야하는 경우가 있다. 다양한 방법들 중에 여기서는 graphical model과 관련있는 ancestral sampling 에 대해 알아보자. joint distribution $p(x_1,…x_k)$에 sampling을 하고자 한다. 우리는 이를 적절한 directed acyclic graph로 factorization할 것이다. 그리고 높은 숫자 node에서 낮은 숫자 node로의 link는 없다고 가정한다. 따라서 먼저 $p(x_1)$에서 sampling을 하고 $\\hat{x}_1$이 parent로 있는 conditional distribution에서 sampling을 한다. 이를 반복해서 $p(x_i|pa_i)$을 구하다보면 결국 우리가 원하는 joint distribution에서 sample을 얻는 것과 동일한 결과를 만들 수 있다. 특정 변수의 marginal distribution을 얻고 싶으면 필요한 sample만 쓰면 된다. probabilistic model에서 주로 higher-numbered node는 observation을 나타내고 lower-numbered node는 주로 latent variable에 해당한다. 이러한 구조를 이용하여 observed data가 만들어지는 과정을 해석할 수 있다. graphical model는 observed data가 만들어진 causal 과정을 잡을 수 있다. 이러한 이유로 그런 model를 generative model이라고 한다. 앞에서 본 polynomial regression같은 경우는 generative model이 아니다. input $x$과 관련한 probability distribution이 없기 때문이다. ","date":"2021-11-29","objectID":"/prml-chap08-1/:1:2","tags":["Grphical Model"],"title":"[PRML] Chapter8 - Graphical Models (1)","uri":"/prml-chap08-1/"},{"categories":["PRML"],"content":"8.1.3 Discrete variables discrete variable들의 joint distribution을 DAG로 표현해보자. probability distribution $p(\\textbf{x}|{\\pmb \\mu})$ for a single variable $\\textbf{x}$이 있다. K개의 states를 가질 수 있다고 하면 $$p(\\textbf{x} | {\\pmb \\mu}) = \\prod_{k=1}^{K}{\\mu_k^{x_k}}$$ 이번에는 2개의 discrete variable의 joint distribution을 modeling한다고 하자. $$p(\\textbf{x} _ 1, \\textbf{x} _ 2 | {\\pmb \\mu}) = \\prod_{k=1}^{K} \\prod_{l=1}^{K} \\mu_{kl}^{x_{1k} x_{2l}}$$ 여기서 $\\sum_k \\sum_l \\mu_{kl}=1$이라는 제약식이 있다. 따라서 이 distribution에서 parameter는 $K^2-1$개 이다. M개의 variable의 경우는 $K^M-1$이 될 것이고 이는 상당히 많은 양(exponentially)의 parameter를 요구하는 것이다. 만약 variable들이 서로 independent하다면 $M(K-1)$개의 parameter가 필요하다. link를 drop하여 더 간단한 model이 되는 것이다. 대신에 제한적인 distribution을 얻는다. markov chain과 같은 형태라고 가정하면 필요한 parameter는 $K-1+(M-1)K(K-1)$개 이다. parameter의 수를 줄이는 또 다른 방법은 parameter를 sharing하는 방법이다. 예를 들어 $p(x_i | x_{i-1})$의 conditional distribution이 모두 동일한 $K(K-1)$개의 parameter를 공유한다고 하면 전체 parameter는 $K-1 + K(K-1)$개가 된다. 또 다른 방법은 parameterized model을 이용하는 것이다. 예를 들어, $p(y=1|x_1,…,x_M)=\\sigma(\\textbf{w}^T\\textbf{x})$와 같은 형태를 이용하면 필요한 parameter는 $M$에 linear한 갯수가 필요하게 된다. 위의 방법들은 probabilistic modeling에서 parameter의 갯수를 줄일 수 있는 방법들이다. ","date":"2021-11-29","objectID":"/prml-chap08-1/:1:3","tags":["Grphical Model"],"title":"[PRML] Chapter8 - Graphical Models (1)","uri":"/prml-chap08-1/"},{"categories":["PRML"],"content":"8.1.4 Linear-Gaussian models 각 node i는 single continuous random variable $x_i$ (Gaussian distribution) 를 나타낸다. 해당 분포의 mean은 parent node들의 linear combination으로 이루어져있다. $$p(x_i|pa_i) = N(x_i|\\sum_{j \\in pa_i} w_{ij}x_j + b_i, v_i)$$ log of joint distribution은 log of product of all conditional node 이고 이를 전개하면 $$\\ln p(\\textbf{x}) = \\sum_{i=1}^{D} \\ln p(x_i|pa_i) \\ = - \\sum_{i}^{D} \\frac{1}{2v_i} (x_i - \\sum_{j \\in pa_i}w_{ij}x_j - b_i)^2 + \\text{const}$$ 여기서 $\\textbf{x}$의 quadratic form이라는 것을 알 수 있고 따라서 joint distribution $p(\\textbf{x})$은 multivariate gaussian이라는 것을 알 수 있다. 우리는 joint distribution의 mean과 covariance를 recursively 구할 수 있다. 각 variable $x_i$는 아래와 같은 형태를 갖고 있는데 $$x_i = \\sum_{j \\in pa_i} w_{ij}x_j + b_i + \\sqrt{v_i}\\epsilon_i$$ $$E[x_i] = \\sum_{j \\in pa_i} w_{ij} E[x_j] + b_i \\ E[\\textbf{x}] = (E[x_1], E[x_2],…,E[x_D])^T$$ 따라서 우리는 lowest numbered node에서 시작하여 recusively mean을 구할 수 있다. 이제 covariance를 구해보면 $$cov[x_i, x_j] = E[(x_i-E[x_i])(x_j-E[x_j])]$$ $$=E[(x_i-E[x_i]){ \\sum_{k \\in pa_j} w_{jk}(x_k-E[x_k])+\\sqrt{v_j}\\epsilon_j}]$$ $$=\\sum_{k \\in pa_j}w_{jk}cov[x_i,x_j]+I_{ij}v_j$$ 여기서도 똑같이 recusively 구할 수 있다. 따라서 위에서 discrete에서 공부한 것처럼 parameter의 갯수를 줄이는 방법들을 여기에서도 동일하게 적용할 수 있다. ","date":"2021-11-29","objectID":"/prml-chap08-1/:1:4","tags":["Grphical Model"],"title":"[PRML] Chapter8 - Graphical Models (1)","uri":"/prml-chap08-1/"},{"categories":["PRML"],"content":"8.2 Conditional Independence $$p(a|b,c) = p(a|c)$$ 위와 같은 경우 a is conditionally independent of b given c 라고 한다. 이는 아래와 같은 경우도 해당한다. $$p(a,b|c)=p(a|b,c)p(b|c) = p(a|c)p(b|c)$$ 두 가지 버전의 conditional independence 정의이다. 또 다른 notation으로는 $$a \\bot b | c $$ conditional independence는 probabilistic model에서 model의 structure와 computation을 단순화한다. joint distribution에서 conditional independence의 특징을 graphical한 차원에서 바로 파악할 수 있다. 이 방법을 d-seperation 이라고 한다. ","date":"2021-11-29","objectID":"/prml-chap08-1/:2:0","tags":["Grphical Model"],"title":"[PRML] Chapter8 - Graphical Models (1)","uri":"/prml-chap08-1/"},{"categories":["PRML"],"content":"8.2.1 Three example graphs 총 3가지의 경우에 대해 살펴 볼 것이다. tail-to-tail $$p(a,b,c) = p(a|c)p(b|c)p(c)$$ 여기서 모든 변수들이 observed되지 않았고 a,b의 independent를 보기 위해 c에 대해 marginalize하면 $$p(a,b) = \\sum_c p(a|c)p(b|c)p(c)$$ 이는 $p(a)p(b)$로 factorize되지 않는다. 즉 independent하지 않다는 의미이다. 그렇다면 이번에는 c가 given인 상황을 가정해보자. $$p(a,b|c) = \\frac{p(a,b,c)}{p(c)} = \\frac{p(a|c)p(b|c)p(c)}{p(c)} = p(a|c)p(b|c)\\ \\therefore a \\bot b | c $$ 여기서 node c는 tail-to-tail 이라고 한다. link가 node c에서 node a,b로 간다. 이를 통해 node a와 node b사이의 path가 생긴다. 이는 두 node가 dependent하다는 의미이다. 하지만 node c가 observed되는 순간 (conditioned on c) a와 b사이의 path를 block한다. 그래서 a와 b는 conditionally independent해진다. head-to-tail $$p(a,b,c) = p(a)p(c|a)p(b|c) \\\\ p(a,b) = p(a)\\sum_c p(c|a)p(b|c)=p(a)p(b|a)$$ 여기서도 마찬가지로 independent하지 않다. 하지만 c가 given이면 $$p(a,b|c) = \\frac{p(a,b,c)}{p(c)} = \\frac{p(a)p(c|a)p(b|c)}{p(c)}=p(a|c)p(b|c)$$ 여기서 node c는 head-to-tail 이라고 한다. node a에서 b로 가는 사이에 존재한다. 이는 두 node가 dependent하다는 것이다. 하지만 node c가 given되는 순간 두 node의 path는 block된다. 그래서 a와b는 conditionally independent해진다. heat-to-head $$p(a,b,c) = p(a)p(b)p(c|a,b) \\\\ p(a,b) = p(a)p(b)$$ 이번에는 위에 나왔던 내용들과 반대이다. c가 given이 아닌 경우, a와b가 independent하다. 오히려 c가 given이면 independent가 아닌 상태가 된다. $$p(a,b|c) = \\frac{p(a,b,c)}{p(c)} = \\frac{p(a)p(b)p(c|a,b)}{p(c)}$$ 여기서 node c는 head-to-head 이라고 한다. node a,b에서 node c로 화살표가 향하는 형태이다. node c가 unobserved되면 이는 path를 block한다. 그래서 a와 b는 independent하다. 오히려 c가 observed되면 dependent해진다. ","date":"2021-11-29","objectID":"/prml-chap08-1/:2:1","tags":["Grphical Model"],"title":"[PRML] Chapter8 - Graphical Models (1)","uri":"/prml-chap08-1/"},{"categories":["PRML"],"content":"8.2.2 D-seperation 위에서 살펴본 3가지의 종류에 따라서 joint distribution을 factorization한다. D-seperation이 특별한 방법론은 아니고 graphical적인 접근으로 conditional independent를 효율적으로 파악하고 이용한다. 책에서는 예시를 통해 이 과정을 설명한다. 책에서는 directed graph를 filter처럼 생각하라고 한다. joint distribution을 filter를 거치게 되면 d-seperation에 따라 conditional independent를 확인하고 factorization까지 한다. ","date":"2021-11-29","objectID":"/prml-chap08-1/:2:2","tags":["Grphical Model"],"title":"[PRML] Chapter8 - Graphical Models (1)","uri":"/prml-chap08-1/"},{"categories":["PRML"],"content":"8.3 Markov Random Fields Markov random fields (markov network, undirected graphical model)는 link에 방향성이 없는 것이다. 똑같이 각 node들은 a variable or group of variable을 의미하며 link에는 화살표가 없다. 마찬가지로 conditional independence와 fatorization과 관련하여 공부할 것이다. ","date":"2021-11-29","objectID":"/prml-chap08-1/:3:0","tags":["Grphical Model"],"title":"[PRML] Chapter8 - Graphical Models (1)","uri":"/prml-chap08-1/"},{"categories":["PRML"],"content":"8.3.1 Conditional independence properties 위에서 d-seperation을 통해 conditional independence에 대해 파악할 수 있었다. 그런데 head-to-head 때문에 다소 개념이 헷갈리는 부분이 분명 존재한다. 이에 대한 수요로 undirected graphical model이 나오게 되었다. A,B,C 라는 set of nodes들이 있다고 가정하자. 우리가 궁금한 conditional independence는 아래와 같다. $$A \\bot B | C $$ A에서 C를 거쳐서 B로 가는 모든 길이 block되면 conditional independence가 성립한다. 하나 이상의 길이 존재하면 이는 성립하지 않는다. 즉, 이 조건을 만족하지 않는 어떤 random variable의 분포가 하나라도 있다면 conditional independence라고 할 수 없는 것이다. 다른 시각으로는 C의 모든 node를 없애면서 이와 연결된 link도 없앤 후에 A와 B사이의 path가 존재하지 않는다면 conditional independence하고 할 수 있다. ","date":"2021-11-29","objectID":"/prml-chap08-1/:3:1","tags":["Grphical Model"],"title":"[PRML] Chapter8 - Graphical Models (1)","uri":"/prml-chap08-1/"},{"categories":["PRML"],"content":"8.3.2 Factorization properties 이제 undirected graph에서 factorization rule에 대해 알아보자. two node $x_i,x_j$가 연결되지 않았다고 가정하자. 해당 변수들은 conditionally independent given all other nodes 즉, 두 node끼리의 direct path는 없고 indirect path가 지나는 변수들은 observed된 것이다. $$p(x_i,x_j|\\textbf{x} _ {-(i,j)})=p(x_i|\\textbf{x} _ {-(i,j)})p(x_j|\\textbf{x} _ {-i,j})$$ 따라서 joint distribution을 factorization하면 두 node i, j는 같은 factor에 속하지 않을 것이다. 여기서 clique의 개념이 나온다. clique subset of the nodes in a graph 이고 모든 node들이 directly 연결되어 있다. (fully connected) 따라서 joint distribution을 decomposition할 때 각 factor들이 clique의 변수들로 이루어진 함수들이다. clique를 $C$라고 하고 $\\textbf{x}_C$를 해당 clique에 속하는 variable이라고 하자. joint distribution은 아래와 같이 decomposition할 수 있다. potential functions $\\psi_C (\\textbf{x}_C)$의 곱으로 이루어져있다. $\\psi_C(\\textbf{x}_C) \\ge 0$ $Z$ 는 normalization constant 아래식은 discrete이라 summation이고 continuous의 경우 integral $$p(\\textbf{x}) = \\frac{1}{Z} \\prod_C \\psi_C(\\textbf{x} _ C)\\\\ Z=\\sum_{\\textbf{x}} \\prod_C \\psi_C (\\textbf{x}_C)$$ directed graph에서는 각 factor들이 conditional distribution given parents의 형태였다. 하지만 여기서 potential function을 선택하는데 있어 제약이 없다. 하지만 그에 반해 normalization constant의 존재가 undirected graph의 가장 큰 한계점이라고 할 수 있다. factorization과 conditional independence의 관계를 알아보기 위해서는 potential function은 strictly positive한 값을 가진다고 가정한다. 그래서 exponential form을 이용한다. $$\\psi_C(\\textbf{x}_C) = \\exp{-E(\\textbf{x}_C)}$$ $E(\\textbf{x}_C)$ : energy function 위의 식처럼 exponential한 표현을 Boltzmann distribution이라고 한다. joint distribution은 각 potential function의 곱으로 이루어져있으므로 따라서 joint distribution은 각 clique의 energy function의 합으로 이루어지는 것을 의미한다. directed graph에서의 joint distribution과 다르게 확률적인 해석을 하기 어렵다. 하지만 potential function을 자유롭게 선택할 수 있으며 이는 domain마다 적절하게 선택해야 한다. ","date":"2021-11-29","objectID":"/prml-chap08-1/:3:2","tags":["Grphical Model"],"title":"[PRML] Chapter8 - Graphical Models (1)","uri":"/prml-chap08-1/"},{"categories":["PRML"],"content":"8.3.3 Image de-noising binary image에서 noise removal을 하는 예시를 살펴보자. noise-free image가 binary pixel $x_i \\in {-1,1}$ (unknown) pixel 일부를 random하게 반대로 바꾸면 noise image의 binary pixel $y_i \\in {-1,1}$ (known) 이를 통해 clique를 정하여 energy function을 찾아보자. energy function을 작게 만들어야 joint distribution을 커지게 할 수 있다. 각 pixel별로 clique를 만들수 있을 것이다. ${x_i, y_i}$로 만들 수 있다. $-\\eta x_i y_i$ : 두 변수가 같은 값이면 lower energy, 반대부호이면 higher energy $\\eta \u003e 0$ 이번에는 pixel의 바로 옆 neighborhood의 경우 ${x_i,x_j}$ $-\\beta x_i x_j$ : 두 변수가 같은 값이면 lower energy, 반대부호이면 higher energy $\\beta \u003e 0$ 마지막으로 biasing the model toward one particular sign 위해 $h x_i$ : pixel i in the noise-free image 이를 통해 complete energy function과 joint distribution을 구하면 $$E(\\textbf{x},\\textbf{y}) = h \\sum_i x_i - \\beta \\sum_{{i,j}} x_i x_j -\\eta \\sum_i x_i y_i$$ $$p(\\textbf{x},\\textbf{y}) = \\frac{1}{Z} \\exp{-E(\\textbf{x},\\textbf{y})}$$ $\\textbf{y}$는 observed value이고 따라서 conditional distribution $p(\\textbf{x}|\\textbf{y})$을 define할 수 있다. 여기서 우리는 확률을 높이는 $\\textbf{x}$를 구해야 할 것이다. 이를 위해 iterative한 방법을 사용할 것인데 iterated conditional modes 라는 방법이다. $x_i = y_i$로 시작한다. 각 $x_i$ 마다 (-1 or 1로) 값을 바꿔가면서 lower energy를 갖는 값을 선택한다. 하나의 $x_i$값을 계산하기 때문에 빠르게 진행할 수 있다. 특정 criterion을 만족할 때까지 반복한다. 뒤에서 high probability를 찾는 max-product algorithm에 대해 살펴볼 것이다. ","date":"2021-11-29","objectID":"/prml-chap08-1/:3:3","tags":["Grphical Model"],"title":"[PRML] Chapter8 - Graphical Models (1)","uri":"/prml-chap08-1/"},{"categories":["PRML"],"content":"8.3.4 Relation to directed graphs 예시를 통해 둘의 관계에 대해 알아보자. 먼저, MC형태의 directed graph의 joint distribution이 아래와 같다. $$p(\\textbf{x}) = p(x_1)p(x_2 | x_1)…p(x_N | x_{N-1})$$ 이를 undirected graph로 나타내보자. (maximal) clique를 고려하여 joint distribution을 나타내면 $$p(\\textbf{x}) = \\frac{1}{Z} \\psi_{1,2}(x_1, x_2)\\psi_{2,3}(x_2, x_3)…\\psi_{N-1,N}(x_{N-1}, x_N)$$ 그렇다면 어렵지 않게 $$\\psi_{1,2}(x_1, x_2)= p(x_1)p(x_2 | x_2)\\ \\psi_{2,3}(x_2, x_3)=p(x_3 | x_2) \\\\ … \\\\ \\psi_{N-1,N}(x_{N-1}, x_N) = p(x_N | x_{N-1})$$ 로 나타낼 수 있을 것이다. conditional distribution에 관련한 variable들을 같은 clique의 멤버로 하면 된다. 또 다른 예시를 보자. $$p(\\textbf{x})=p(x_1)p(x_2)p(x_3)p(x_4 | x_1,x_2,x_3)$$ 위와 같은 경우를 undirected graph로 나타내기 위해서는 마지막항으로 인해 원래는 directed graph에는 없던 link를 만들어야한다. (같은 clique에 속하게 해야하니까) 이렇게 ‘marrying parents’ 하는 과정을 moralization이라고 하며 link를 만들고 arrow를 없애는 과정으로 만들어진 graph를 moral graph라고 한다. 이처럼 directed를 undirected로 바꾸는 과정에서 conditional property를 많이 잃게 된다. 그래서 최대한 이를 지켜주면서 바꾸는게 중요한 듯 하다. 그리고 반대로 undirected에서 directed로 바꾸는 경우는 많지 않다고 한다. 그 이유중 하나는 normalization constant 때문이라고 할 수 있다. ","date":"2021-11-29","objectID":"/prml-chap08-1/:3:4","tags":["Grphical Model"],"title":"[PRML] Chapter8 - Graphical Models (1)","uri":"/prml-chap08-1/"},{"categories":["PRML"],"content":"Sparse kernel machine (SVM)에 대해 정리하였다. 이번 장에서는 SVM에 대해 공부할 것이다. SVM은 classification, regression, novelty detection에 사용한다. decision machine이기 때문에 posterior probability를 알수는 없다. model parameter를 구하는데 있어 convex optimization problem이기에 any local solution이 global optimum이 된다. high dimension에서 분류할 때 좋은 generalization 성능을 보인다 train이 quadratic programmin problem이다 train data에 대해 fit하지만 generalization의 성능이 좋다. statistical learning theory라는 탄탄한 이론에 기반하여 만들어졌다. ","date":"2021-11-29","objectID":"/prml-chap07-1/:0:0","tags":["SVM"],"title":"[PRML] Chapter7 - Sparse Kernel Machine","uri":"/prml-chap07-1/"},{"categories":["PRML"],"content":"7.1 Maximum Margin Classifiers (hard margin) 일단 몇 가지 가정을 하고 공부를 시작해보자. two class classification problem using linear model $$y(\\textbf{x}) = \\textbf{w}^T \\phi (\\textbf{x}) + b$$ train data가 linearly separable in feature space라고 가정 따라서 최소한 하나의 오류없이 100% 분류가능한 $\\textbf{w}, b$가 존재 training data $(\\textbf{x}_1,…,\\textbf{x}_n),(t_1,…,t_n), t_n \\in {-1,1}$ decision boundary : $y(\\textbf{x})=0$ $y(\\textbf{x}_n) \u003c 0 \\rightarrow t_n = -1,;y(\\textbf{x}_n) \u003e 0 \\rightarrow t_n = 1$ $\\therefore y(\\textbf{x}_n) t_n \u003e 0$ for all train data new data are classified by the sign of $y(\\textbf{x})$ train data가 lineary separable하므로 우리의 목표는 이를 나누는 hyperplane을 찾는 것이다. 그렇다면 가장 좋은 hyperplane을 어떻게 찾을까? SVM에서 hyperplane (decision boundary)는 margin 을 최대화하도록 한다. margin : smallest distance between the decision boundary and any of the samples 이에 해당하는 그림을 찾아보면 이해하기 쉬울 것이다. train set에서 margin 최대화 = generalization error 최소화 = good prediction hyperplane과 data point $\\textbf{x}$의 거리는 $$\\frac{\\left| y(\\textbf{x})\\right|}{ \\left| \\textbf{w} \\right|}$$ 인데 가정에 따라 모든 data point는 잘 분류되어 있다. (그 중에서 best hyperplane을 찾기). 따라서 $t_n y(\\textbf{x}_n)\u003e0$ 인 상황이므로 $$\\frac{t_n y(\\textbf{x}_n)}{\\left| \\textbf{w} \\right|}$$ 으로 나타낼 수 있다. 따라서 maximize margin solution은 $$\\arg\\max_{w,b}{ \\frac{1}{\\left| \\textbf{w}\\right|} \\min_{n} [t_n (\\textbf{w}^T \\phi(\\textbf{x}_n)+b)] }$$ 이를 바로 풀기는 어려움이 있어서 약간의 변화를 준다. Let $t_n(\\textbf{w}^T \\phi(x_n) + b) = 1$ for the point that is closest to the decision boundary. 따라서 $t_n(\\textbf{w}^T \\phi(x_n) + b) \\ge 1$ 의 제약이 생긴다. 대신 $\\min$ 뒷 부분을 제외하고 optimization이 가능하다. (constraint가 생기지만) 이를 통해 우리는 (convex) optimization problem을 아래와 같이 정의할 수 있다. constraint : $t_n(\\textbf{w}^T \\phi(x_n) + b) \\ge 1$ $$\\arg\\min_{w,b} \\frac{1}{2} \\left| \\textbf{w} \\right|^2_2$$ ","date":"2021-11-29","objectID":"/prml-chap07-1/:1:0","tags":["SVM"],"title":"[PRML] Chapter7 - Sparse Kernel Machine","uri":"/prml-chap07-1/"},{"categories":["PRML"],"content":"+ 위 내용을 다른 방법으로 접근 고려대학교 김성범 교수님의 유투브 참조 위의 margin을 찾는 과정에 대해 조금 다른 derivation을 소개한다. $y(\\textbf{x})=1, y(\\textbf{x})=-1$ 위의 점을 각각 $\\textbf{x}^+, \\textbf{x}^-$ 라고 하자 : support vector, 즉 decision boundary와 가장 가까운 각 class의 점들을 의미 $\\textbf{x}^-$을 움직여서 반대편 class $y(\\textbf{w})=-1$ 위의 점으로 만들 수 있다. $\\textbf{x}^+ = \\textbf{x}^- + \\alpha \\textbf{w}$ $$\\textbf{w}^T \\textbf{x}^+ + b = 1 \\ \\textbf{w}^T (\\textbf{x}^- + \\alpha \\textbf{w}) + b = 1 \\ \\textbf{w}^T \\textbf{x}^- +b + \\alpha \\textbf{w}^T \\textbf{w} = 1 \\ \\therefore \\alpha = \\frac{2}{\\textbf{w}^T \\textbf{w}}$$ margin = distance($\\textbf{x}^+, \\textbf{x}^-$) / 2 $$ = \\left| \\textbf{x}^+ - \\textbf{x}^- \\right|_ 2 /2 \\ = \\left | \\alpha \\textbf{w} \\right |_ 2 /2 \\ = \\alpha \\sqrt{\\textbf{w}^T \\textbf{w}}/2 \\ = \\frac{1}{\\sqrt{\\textbf{w}^T \\textbf{w}}} = \\frac{1}{\\left | \\textbf{w} \\right |_ 2}$$ 이렇게 약간 다른 과정을 통해 같은 결과를 얻을 수 있다. 이를 quadratic programming problem이라고 한다. quadratic programming : minimize a quadratic function subject to a set of linear inequality constraints 이를 통해 Lagrange function을 만들어 parameter를 구해보자. 제약식이 있는 maximum margin problem을 Lagrangian Primal문제로 변환 시킨 것이다. Lagrangian Primal $\\max_{a} \\min_{w,b} L(\\textbf{w},b,\\textbf{a})$ Lagrange multipliers $a_n \\ge 0$ $$L(\\textbf{w}, b, \\textbf{a}) = \\frac{1}{2} \\left| \\textbf{w} \\right|^2_2 - \\sum_{n=1}^{N}{a_n{ t_n(\\textbf{w}^T \\phi(\\textbf{x}_n)+b)-1 }}$$ 이 식을 각 parameter $\\textbf{w}, b$ 로 미분하면 $$\\textbf{w} = \\sum_{n=1}^{N}{a_n t_n \\phi (\\textbf{x}_n)}$$ $$0 = \\sum_{n=1}^{N}{a_n t_n}$$ 이를 통해 maximum margin problem을 dual representation 으로 나타낼 수 있다. 첫번째 항 $$\\frac{1}{2} \\left| \\textbf{w} \\right|^2_2 = \\frac{1}{2}\\textbf{w}^T\\textbf{w} $$ $$= \\frac{1}{2}\\textbf{w}^T \\sum_{n=1}a_n t_n \\phi(\\textbf{x} _ n)$$ $$ = \\frac{1}{2} \\sum_{n=1}a_n t_n \\textbf{w}^T \\phi(\\textbf{x} _ n) $$ $$ = \\frac{1}{2} \\sum_{n=1}a_n t_n\\sum_{m=1}a_m t_m \\phi(\\textbf{x} _ m)^T \\phi(\\textbf{x} _ n) $$ $$ =\\frac{1}{2} \\sum_{n=1}\\sum_{m=1}a_n t_na_m t_m \\phi(\\textbf{x}_m)^T \\phi(\\textbf{x}_n) $$ 두번째 항 $$- \\sum_{n=1}^{N}{a_n{ t_n(\\textbf{w}^T \\phi(\\textbf{x} _ n)+b)-1 }} $$ $$ = -\\sum_{n=1}a_n t_n \\textbf{w}^T \\phi(\\textbf{x} _ n) - b\\sum_{n=1} a_n t_n + \\sum_{n=1}a_n $$ $$ = -\\sum_{n=1}\\sum_{m=1}a_n a_m t_n t_m \\phi(\\textbf{x} _ m)^T \\phi(\\textbf{x} _ n) + \\sum_{n=1}a_n$$ 따라서 최종적으로 Lagrangian dual constraint (제약식) $a_n \\ge 0$ $\\sum_{n=1}^{N}{a_n t_n} = 0$ $$L(\\textbf{a}) = \\sum_{n=1}^{N}{a_n} - \\frac{1}{2}\\sum_{n=1}^{N} \\sum_{m=1}^{N}{a_n a_m t_n t_m \\phi(\\textbf{x}_m)^T \\phi(\\textbf{x}_n)}$$ 위 식을 maximize하면 되고 이는 다시 $a$에 관한 quadratic problem이 된다. Lagrangian Dual problem으로 바뀐 것이다. objective function is quadratic \u0026 constraint is linear 따라서 여기서 Lagrangian Dual은 quadratic programming이 된다. 또한 kernel function을 사용할 수 있는 형태을 얻었다. (inner product) 우리는 $\\textbf{a}$를 구하여 $\\textbf{w},b$ 모두 알 수 있고 prediction도 할 수 있다. 새로운 데이터를 분류하기 위해 $y(\\textbf{x})$의 sign을 알면 된다. 그리고 prediction을 위해 굳이 $\\textbf{w},b$를 구하지 않고 아래의 식으로 prediction하면 된다. $$y(\\textbf{x}) = \\sum_{n=1}^{N}{a_n t_n \\phi(\\textbf{x})^T \\phi(\\textbf{x}_n)+b}$$ 그런데 $(\\textbf{w}, b, \\textbf{a})$가 Lagrangian dual problem의 최적해가 되기 위한 조건으로 KKT condition 을 만족해야 한다. KKT( Karuch-Kuhn-Tuker) condition Stationarity $\\frac{\\partial L(\\textbf{w},b,\\textbf{a})}{\\partial \\textbf{w}}=0, \\frac{\\partial L(\\textbf{w},b,\\textbf{a})}{\\partial \\textbf{b}}=0$ Primal feasibility $t_n y(\\textbf{x}_n) - 1 \\ge 0$ Dual feasibility $a_n \\ge 0$ Complementary slackness $a_n { t_n y(\\textbf{x}_n )- 1 } = 0$ 이를 통해 SVM에서 중요한 내용을 생각할 수 있는데 모든 점은 두 가지 경우에 해당한다. $a_n \u003e 0 ; \\text{and} ; t_n y(\\textbf{x}_n)-1=0$ $a_n = 0 ; \\text{and} ; t_n y(\\textbf{x}_n)-1\\neq 0$ 근데 $a_n$이 0인 경우는 decision boundary를 만드는 것과 prediction에 아무런 영향을 주지 않는다. 영향을 주는 점들은 support vector 라고 부른다. 이들은 $t_n y(\\textbf{x}_n) = 1$ 이고 maximum margin hyperplane의 위에 있는 점들이다. (각 class별로 decision boundary와 가장 가까운 점에 관한 hyperplane) support vector만으로 optimal hyperplane(decision boundary)를 구할 수 있다. 그래서 sparse kernel machine이라고 부르는 것이다. ","date":"2021-11-29","objectID":"/prml-chap07-1/:1:1","tags":["SVM"],"title":"[PRML] Chapter7 - Sparse Kernel Machine","uri":"/prml-chap07-1/"},{"categories":["PRML"],"content":"7.1.1 Overlapping class distributions (soft margin) 이전까지 우리는 완전히 separable이 가능한 경우에서 모델링하였다. 하지만 이런 경우는 드물다. overlap되는 경우에 우리는 penalty를 주고 misclassification이 된 경우가 존재하는 모델을 만드는 것이다. 이를 soft margin 이라고 부른다. 이 penalty를 위해 각 data point마다 slack variable을 생각한다. slack variable (penalty) $\\xi_n = 0$ : 데이터가 잘 분류되고 margin 밖에 위치 이외의 경우 : $\\xi_n = | t_n - y(x_n) |$ (틀린 거리만큼 penalty) $0 \u003c \\xi_n \u003c 1$ : 잘 분류되었지만 margin 범위 안에 위치 $\\xi_n = 1$ : data가 +, - boundary 위에 위치 $\\xi_n \u003e 1$ : 잘못 분류 이에 따라 $t_n y(\\textbf{x}_n) \\ge 1- \\xi_n$ 으로 constraint가 바뀐다(error를 허용하는). 따라서 우리는 minimize constraint : $t_n(\\textbf{w}^T \\phi(\\textbf{x}_n) + b) \\ge 1- \\xi_n$ $$C\\sum_{n=1}^{N}{\\xi_n + \\frac{1}{2}|\\textbf{w}|^2_2}$$ 하게 된다. 여기서 C는 trade-off 관계를 컨트롤하는 파라미터이다. C가 커지면 error를 많이 허용하지 않으므로 overfit C가 작으면 error를 많이 허용하므로 underfit 이 식을 위에서 했던 대로 Lagrange로 계산하면 위의 dual representation과 같은 결과가 나온다. 이번에는 Lagrange multiplyer가 두 개가 필요하다. 다른 점은 constraint, KKT 가 달라진다. Lagrangian Primal $\\max_{a,\\gamma} \\min_{w,b,\\xi} L(\\textbf{w},b,\\textbf{a}, \\xi, \\gamma)$ Lagrange multipliers $a_n \\gamma_n \\ge 0$ $$L(\\textbf{w},b,\\textbf{a}, \\xi, \\gamma)$$ $$ = \\frac{1}{2} \\| \\textbf{w} \\|^2_2 + C\\sum_{n=1}\\xi_n - \\sum_{n=1}{a_n{ t_n(\\textbf{w}^T \\phi(\\textbf{x} _ n)+b) - 1 + \\xi_n }} - \\sum_{n=1}\\gamma_n \\xi_n$$ 이 식을 각 parameter $\\textbf{w}, b, \\xi$ 로 미분하면 $$\\textbf{w} = \\sum_{n=1}^{N}{a_n t_n \\phi (\\textbf{x}_n)}$$ $$0 = \\sum_{n=1}^{N}{a_n t_n}$$ $$C - a_n - \\gamma_n = 0$$ Lagrange dual constraint (제약식) $a_n \\ge 0$ $\\sum_{n=1}^{N}{a_n t_n} = 0$ $$L(\\textbf{a}) = \\sum_{n=1}^{N}{a_n} - \\frac{1}{2}\\sum_{n=1}^{N} \\sum_{m=1}^{N}{a_n a_m t_n t_m k(\\textbf{x}_n,\\textbf{x}_m)}$$ KKT( Karuch-Kuhn-Tuker) condition $\\frac{\\partial L(\\textbf{w},b,\\textbf{a})}{\\partial \\textbf{w}}=0, \\frac{\\partial L(\\textbf{w},b,\\textbf{a})}{\\partial \\textbf{b}}=0$ $C - a_n- \\gamma_n = 0$ $a_n { t_n y(\\textbf{x}_n )- 1 + \\xi } = 0, \\gamma_n \\xi_n = 0$ 이번에도 마찬가지로 solution의 특징을 보면 $a_n { t_n y(\\textbf{x}_n )- 1 + \\xi } = 0,; \\gamma_n \\xi_n = 0,; a_n = C-\\gamma_n$ $a_n = 0 \\Rightarrow \\gamma_n = C \\Rightarrow \\xi_n=0 \\Rightarrow t_n y(\\textbf{x}_n )- 1\\neq 0$ $\\textbf{x}_n$ 이 +,- boundary 보다 멀리 잘 분류되었다. $0 \u003c a_n \u003c C \\Rightarrow \\gamma_n \u003e 0 \\Rightarrow \\xi_n=0, \\gamma_n\\xi_n=0 \\Rightarrow t_n y(\\textbf{x}_n )- 1=0$ $\\textbf{x}_n$ 이 +,- boundary 위에 있다. (support vector) $a_n = C \\Rightarrow \\gamma_n = 0 \\Rightarrow \\xi_n\u003e0 \\Rightarrow t_n y(\\textbf{x}_n )- 1 = -a_n \\xi_n \\neq 0$ $\\textbf{x}_n$ 이 +,- boundary 과 decision boundary 사이에 존재한다. (margin의 범위에 존재, 이들도 support vector라고 함) 이제 kernel method for nonlinear classification에 대해 살펴보자. 우리의 위에서 dual problem을 통해 kernel function의 사용가능성을 파악할 수 있었다. kernel을 사용함으로서 nonlinear decision boundary를 만드는데 있어서 inner product $\\phi(\\textbf{x}_n)^T \\phi(\\textbf{x}_m)$이 아니라 $k(\\textbf{x}_n, \\textbf{x}_m)$으로 계산할 수 있다. 예시를 통해 kernel의 유용성을 알아보자. $\\textbf{x},\\textbf{z}$는 2차원 vector kernel function : $k(\\textbf{x},\\textbf{z}) = (1+\\textbf{x}^T\\textbf {z})$ 라고 하자. $$\\phi(\\textbf{x})^T \\phi(\\textbf{z}) = (1\\;\\sqrt{2}x_1\\;\\sqrt{2}x_2\\;x_1^2\\;\\sqrt{2}x_1x_2;x_2^2)(1\\;\\sqrt{2}z_1\\;\\sqrt{2}z_2\\;z_1^2\\;\\sqrt{2}z_1 z_2\\;z_2^2)^T $$ $$ = (1+x_1z_1+x_2z_2)^2 = (1 + \\textbf{x}^T \\textbf{z})^2$$ 이처럼 kernel을 통해 기존의 $\\textbf{x}$을 nonlinear하게 만들어서 decision boundary를 만들 수 있어서 classification을 더 잘 할 수 있는 것이다. (여기서는 처음부터 $\\phi(\\textbf{x})$를 사용하였지만 지금까지의 모든 과정을 $\\textbf{x}$ 라고 생각하면 kernel을 통해 nonlinear하게 만들었다고 이해할 수 있다.) 기존의 data를 explicit하게 $\\phi(\\textbf{x})$ (nonlinear하게) 으로 만든 뒤에 inner product로 계산하는 것이 아니라 kernel function을 통해 같은 결과를 만들 수 있기에 explicit하게 몰라도 되고 상당히 computationally 좋다. 가장 많이 쓰이는 kernel은 Gaussian Kernel (Radial basis function Kernel) $$k(\\textbf{x}, \\textbf{z}) = \\exp(\\frac{- \\left| \\textbf{x} - \\textbf{z} \\right|^2_2}{2 \\sigma^2})$$ ","date":"2021-11-29","objectID":"/prml-chap07-1/:1:2","tags":["SVM"],"title":"[PRML] Chapter7 - Sparse Kernel Machine","uri":"/prml-chap07-1/"},{"categories":["PRML"],"content":"7.1.2 Comparison to logistic regression 그림을 찾아보는 것을 추천한다. SVM loss function : Hinge loss $\\xi_j = (1-(wx_j + b)y_j)_ {+}$ logistic loss function : Log loss $\\xi_j = -\\log (1+\\exp(wx_j+b)y_j)$ $$\\because \\theta_{MLE} = \\arg\\max {\\sum{log(P(T_i \\ X_i;\\theta))}} $$ $$ = \\arg\\max {\\sum { Y_i X_i \\theta - \\log (1+\\exp(X_i \\theta) ) }}$$ Hinge loss는 correct한 경우 penalty가 0이 되지만 log loss는 corret한 경우에도 0이 되지 않는다. log loss가 좀 덜 극단적인 것 같다. ","date":"2021-11-29","objectID":"/prml-chap07-1/:1:3","tags":["SVM"],"title":"[PRML] Chapter7 - Sparse Kernel Machine","uri":"/prml-chap07-1/"},{"categories":["PRML"],"content":"7.1.3 Multiclass SVM 다양한 방법이 있다. 하지만 다들 한계점이 있는 것으로 보인다. ","date":"2021-11-29","objectID":"/prml-chap07-1/:1:4","tags":["SVM"],"title":"[PRML] Chapter7 - Sparse Kernel Machine","uri":"/prml-chap07-1/"},{"categories":["PRML"],"content":"7.1.4 SVMs for regression 어렵지 않다. 정리는 생략하고자 한다. $\\epsilon$-insensitive error function $$E_\\epsilon((y(\\textbf{x})-t)) = \\begin{Bmatrix} 0 ,\\; if\\;|y(\\textbf{x})-t|\u003c\\epsilon \\\\ |y(\\textbf{x})-t|-\\epsilon,\\; \\text{otherwise} \\end{Bmatrix}$$ 아래의 식을 최소화한다. $$C\\sum_{n=1}^{N}{E_\\epsilon((y(x)-t)) + \\frac{1}{2}|\\textbf{w}|^2}$$ ","date":"2021-11-29","objectID":"/prml-chap07-1/:1:5","tags":["SVM"],"title":"[PRML] Chapter7 - Sparse Kernel Machine","uri":"/prml-chap07-1/"},{"categories":["PRML"],"content":"7.2 Relevance vector machines SVM은 확률적인 요소가 없다. 이를 위해 Bayesian SVM이라고 할 수 있는 RVM이 있다. 하지만 나중에 필요하면 다시 공부하고자 한다. ","date":"2021-11-29","objectID":"/prml-chap07-1/:2:0","tags":["SVM"],"title":"[PRML] Chapter7 - Sparse Kernel Machine","uri":"/prml-chap07-1/"},{"categories":["PRML"],"content":"khan academy의 강의를 듣고 간략하게 정리해보았다. ","date":"2021-11-29","objectID":"/prml-chap07-0/:0:0","tags":["Optimization"],"title":"[PRML] Chapter7 - Constrained Optimization","uri":"/prml-chap07-0/"},{"categories":["PRML"],"content":"gradient store all partial derivative information of a multivariate function vector-valued function $$\\nabla f = [\\frac{\\partial f}{\\partial x};\\frac{\\partial f}{\\partial y};\\frac{\\partial f}{\\partial z}…]^T$$ 특징 gradient vector $\\nabla f (x_0, y_0,…)$는 함수식 $f$ 위의 점 $(x_0, y_0,…)$에서 $f$ 에 perpendicular 하다. $\\nabla f (x_0, y_0,…)$는 해당 점에서 $f$ 가 가장 빠르게 커지게하는 방향을 의미한다. ","date":"2021-11-29","objectID":"/prml-chap07-0/:1:0","tags":["Optimization"],"title":"[PRML] Chapter7 - Constrained Optimization","uri":"/prml-chap07-0/"},{"categories":["PRML"],"content":"문제상황 maximize $f(x,y) = x^2 y$ constraint : $x^2 + y^2 = 1$ 두 함수가 만나는 지점에서 $f$를 최대로 하는 점을 찾아야한다. 여기서 우리는 gradient를 이용한다. 해당 점을 $x_m, y_m$ 라고 하자. $g(x,y) = x^2 + y^2$ 라고 하자. $\\lambda$ : Lagrange multiplier $$\\nabla f(x_m, y_m) = \\lambda \\nabla g(x_m, y_m)$$ 해당 점에서 각 함수의 gradient는 어떤 상수배($\\lambda$)를 통해 같아질 수 있다. 해당함수(targent)에 perpendicular하기 때문이다. 그래프를 머리속으로 그려서 생각해보자! $$\\nabla f = [2xy; x^2]^T, \\nabla g = [2x;2y]^T$$ 이므로 우리는 식 3개와 변수 3개 $2xy = \\lambda 2x$ $x^2 = \\lambda 2y$ $x^2 + y^2 = 1$ (제약식) 를 얻을 수 있고 이를 통해 $x_m, y_m$ 을 구할 수 있다. ","date":"2021-11-29","objectID":"/prml-chap07-0/:2:0","tags":["Optimization"],"title":"[PRML] Chapter7 - Constrained Optimization","uri":"/prml-chap07-0/"},{"categories":["PRML"],"content":"Lagrange method Lagrangian optimize $f$ constraint $g = C$ $$L(x,y,\\lambda) = f(x,y) - \\lambda (g(x,y) - C)$$ 이를 미분해서 0이 되는 $x^* ,y^* ,\\lambda^*$ 를 구하면 된다. Lagrange multiplier의 의미 $M^* = f(x^* , y^* )$라고 하자. 그런데 이 식은 $C$에 따라 달라지기에 $$M^* (C) = f(x^* (C) , y^* (C) )$$ 이를 이용하여 $\\lambda^*$에 대해 정리하면 (증명 생략) $$\\lambda^* = \\frac{d M^* }{d C }$$ ","date":"2021-11-29","objectID":"/prml-chap07-0/:3:0","tags":["Optimization"],"title":"[PRML] Chapter7 - Constrained Optimization","uri":"/prml-chap07-0/"},{"categories":["PRML"],"content":"Bayesian Optimization으로 모델의 성능을 올려보자. ","date":"2021-11-29","objectID":"/prml-chap06-3/:0:0","tags":["Bayesian Optimization"],"title":"[PRML] Bayesian Optimization","uri":"/prml-chap06-3/"},{"categories":["PRML"],"content":"Bayesian Optimization with Gaussian Process 어떤 sequence of experiments를 한다고 생각해보자. 다음은 몇 가지 가정사항이다. Interested in finding a global maximizer(minimizer) of $f(\\bf{x})$ 우리는 experiments result를 만드는 underlying function $f(\\bf{x})$를 모른다. input은 우리가 다 알고 조절할 수 있다. result have a stochastic element $y_t \\sim N(f,\\sigma^2_{noise})$ results and input are continuous 일반적인 경우는 continous를 고려하지만 discrete, hybrid의 경우도 존재한다. 다양한 task에서 사용할 수 있지만 우리는 주로 hyperparameter tuning을 할 때 사용하게 된다. Grid search no learning of underlying function Binary search learning of constraints, not the function 위와 같은 방법들이 많이 사용되었다. 이와 다르게 BOP는 learning underlying function with surrogate model selecting the next sampling input 같은 task를 통해서 최적의 결과를 얻어내고자 하는 것이다. 그렇다면 어떤 과정으로 최적의 결과를 얻어낼까? GPR은 모든 data point에서 predicted mean, predicted std를 알려준다. input을 넣고 underlying function을 만든다 (GPR을 fitting하는 것). 그 후에 mean과 variance를 통해 exploitation or exploration를 결정하여 next sampling input을 결정한다. (그리고 다시 underlying function을 만든다. 이를 반복한다.) Exploitation : result값이 높은 곳(underlying function mean이 큰) 탐색 Exploration : 관측지가 적은 곳(variance가 큰) 탐색 이떄, 이에 대한 판단 기준이 필요하다. acquisition function을 이용한다. 이에 대해 한번 더 정리하자면 Surrogate model : Compute $p(f|D_{1})$, yielding $\\mu_{1}({\\bf x})$ and $\\sigma_{1}({\\bf x})$. Acquisition function: Choose ${\\bf{x}} _ {2}$ such that ${\\bf x} _ {2}=argmax_{ {\\bf x} \\in \\mathcal{X} } a ({\\bf x}|\\mathcal{M}_{1})$ Augment data, $D_2 = D_1 \\cup \\{ ({\\bf x}_{2}, y _ {2}) \\}$ Surrogate model : Compute $p(f|D_2)$, yielding $\\mu_{2}({\\bf x})$ and $\\sigma_{2}({\\bf x})$. Acquisition function: Choose ${\\bf x} _ 3$ such that ${\\bf x} _ {3}=argmax_{ {\\bf x} \\in \\mathcal{X} }a({\\bf x}|\\mathcal{M}_{3})$ Augment data, $D_ 3 = D_2 \\cup \\{ ({\\bf x} _ {3},y _ {3}) \\}$ Repeat theses till the final round T, to compute $\\mu_{T}({\\bf x})$ ${\\bf x}^{*} = argmax_{ {\\bf x} \\in {\\bf x}_1,…,{\\bf x} _ T } \\mu _ {T}({\\bf x})$ ","date":"2021-11-29","objectID":"/prml-chap06-3/:1:0","tags":["Bayesian Optimization"],"title":"[PRML] Bayesian Optimization","uri":"/prml-chap06-3/"},{"categories":["PRML"],"content":"surrogate model 다양한 모델을 사용할 수 있다. 하지만 해당 point의 mean, variance를 알 수 있는 stochastic한 모델이여야 할 것이다. Random Forest Empirical하게 mena, variance를 구할 수 있다. scable, faster continuous, discrete 변수 모두 handle 가능하다. (GP는 kernel을 따로 design해야 한다고 함) extrapolation을 잘 못한다. GP regression Nonparameteric Bayesian Regression Not scalable 10dim이 넘어가면 standard GP로는 힘들다. sample dsata의 수가 많아져도 힘들다. ","date":"2021-11-29","objectID":"/prml-chap06-3/:1:1","tags":["Bayesian Optimization"],"title":"[PRML] Bayesian Optimization","uri":"/prml-chap06-3/"},{"categories":["PRML"],"content":"Acquisition Function Acquisition Function은 다양하다. 몇 가지만 간단히 알아보고 코드를 통해 실습을 진행해보자. Maximum Probability of Improvement (PI) 현재 optimized value $y_{max}$를 어떤 margin m 이상으로 올려줄 확률이 가장 높은 input을 sampling한다. grid search처럼 value를 계산하는 것이 아니라 확률만 계산하여 진행한다. $D$는 기존 data, 이를 통해 GPR을 만들수 있겠다. $y \\sim N(\\mu, \\sigma^2)$ 이는 GPR로 만들어진 것이다. $$MPI(x|D) = \\argmax_x P(y \\ge (1+m)y_{max} | x, D)$$ $$y\\sim N(\\mu, \\sigma^2) = \\argmax_x P(\\frac{y-\\mu}{\\sigma} \\ge \\frac{(1+m)y_{max}-\\mu}{\\sigma})$$ $$= \\argmax_x \\Phi (\\frac{\\mu - (1+m)y_{max}}{\\sigma})$$ 그런데 PI는 잘 안쓴다고 한다. Maximum Expected Improvement (EI) MPI를 조금 더 디벨롭시킨 것이다. MPI에서는 m을 고려해야했다. 그렇게 하지 말고 0부터 infinite으로 고려하면 되지 않을까? 라는 접근을 한다. 구체적으로 식을 구하는 과정은 생략한다. expected improvement w.r.t. the best observed objective value $y_{b}$ so far is defined as $$EI = E _ y [ \\max (y - y_{b} ,0) ]$$ $$=\\int \\max (y-y_{b}) N (y | \\bar{y}, \\sigma^{2})dy$$ $$=(\\bar{y} - y_b) \\Phi ( \\frac{\\bar{y}-y_b}{\\sigma} ) + \\sigma \\phi ( \\frac{\\bar{y} - y_b}{\\sigma} )$$ Gaussian Process-Upper Confidence Bound (GP-UCB) posterior mean과 variance의 적절한 trade-off를 고려하여 data point를 선택한다. 아래의 수식에 따라서 point를 선택한다. $\\beta_t$ : appropriate constants $\\nu$ : hyperparameter involving the degree of exploration $$\\bf{x} _ t = \\argmax_{\\bf{x}} ( \\mu_{t-1}(\\bf{x}) + \\sqrt{\\nu \\beta_t} \\sigma_{t-1}(\\bf{x}))$$ Thompson Sampling posterior에서 function을 sampling하는 방법이다. ","date":"2021-11-29","objectID":"/prml-chap06-3/:1:2","tags":["Bayesian Optimization"],"title":"[PRML] Bayesian Optimization","uri":"/prml-chap06-3/"},{"categories":["PRML"],"content":"이해를 위한 코드 # NHN cloud # https://www.youtube.com/watch?v=PTxqPfG_lXY import numpy as np from scipy.stats import norm from sklearn.gaussian_process import GaussianProcessRegressor from sklearn.gaussian_process.kernels import RBF # Acquisition function def expected_improvement(mean, std, max): z = (mean - max) / std return (mean - max) * norm.cdf(z) + std * norm.pdf(z) # Objective function def f(x): return x * np.sin(x) # hyperparameter space min_x, max_x = -2, 10 # Observation data X = np.random.uniform(min_x, max_x, 3).reshape(-1, 1) y = f(X).ravel() # GP model gp_model = GaussianProcessRegressor(kernel=RBF(1.0)) for i in np.arange(10): # surrogate model fit gp_model.fit(X, y) # predict -\u003e mean, std 계산 xs = np.random.uniform(min_x, max_x, 10000) mean, std = gp_model.predict(xs.reshape(-1, 1), return_std=True) # acq 계산 acq = expected_improvement(mean, std, y.max()) # acq가 가장 큰 값 선택 x_new = xs[acq.argmax()] y_new = f(x_new) # 데이터에 추가 X = np.append(X, np.array([x_new])).reshape(-1, 1) y = np.append(y, np.array([y_new])) ","date":"2021-11-29","objectID":"/prml-chap06-3/:1:3","tags":["Bayesian Optimization"],"title":"[PRML] Bayesian Optimization","uri":"/prml-chap06-3/"},{"categories":["PRML"],"content":"Reference 문일철 교수님 강의 NHN cloud 발표 paper Taking the Human Out of the Loop: A Review of Bayesian Optimization (2016) A tutorial on Bayesian optimization (2018) ","date":"2021-11-29","objectID":"/prml-chap06-3/:2:0","tags":["Bayesian Optimization"],"title":"[PRML] Bayesian Optimization","uri":"/prml-chap06-3/"},{"categories":["PRML"],"content":"Gaussian Process에 대해 정리하였다. ","date":"2021-11-29","objectID":"/prml-chap06-2/:0:0","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"6.4 Gaussian Processes 이 부분은 카이스트 문일철 교수님의 유투브영상을 보고 정리하였습니다. ","date":"2021-11-29","objectID":"/prml-chap06-2/:1:0","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Continuous Domain Data GP는 continuous domain data 분석에 유용하다. Time, Space, Spatio-Temporal… 어떻게 분석, 모델링? Estimating on the underlying function (ex. Autoregression) Prediction on the unexpected point (ex. extrapolation with autoregression) ","date":"2021-11-29","objectID":"/prml-chap06-2/:1:1","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Underlying Function and Observations $Y = sinc(x)$ 라는 함수를 underlying function이라고 하자. 여기서 gaussian noise를 추가하여 observation들을 생성했다. 지금 그림은 없지만 그림1은 x에 따라 분산이 동일하고 그림2는 x에 따라 분산이 변화(x가 클수록 분산이 커짐)한다. underlying function을 구해야하므로 mean function을 찾는 것은 당연하고 추가로 variance(or precision) function도 중요하다. $$\\mu(t), \\sigma(t)^2$$ ","date":"2021-11-29","objectID":"/prml-chap06-2/:1:2","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Simple Analyses without Domain Correlation mean function을 domain correlation없이 estimate한다고 하자. 즉, 특정 1개의 point에서 mean과 variance를 계산하는 것이다. 그런데 continuous domain에서 사실 같은 $x(t)$에 대해 multiple obsevation이 나올 수 없다. 약간의 discretize라고 할 수 있다. 해당 domain point에서 observation이 많으면 어느 정도 smooth하게 mean function을 구할 수 있다. 하지만 반대의 경우 좋은 estimation이 어렵다. 그래서 우리는 주위의 다른 domain data point도 사용하는게 좋지 않을까 라는 생각을 할 수 있다. ","date":"2021-11-29","objectID":"/prml-chap06-2/:1:3","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Simple Analyses with Domain Correlation Moving average time window(특정 구간)를 설정하고 평균 급격하게 변화하는 구간은 잘 안 맞을 수도 있다. time window에 따라 변화 window가 커질수록 smooth해진다. $$MA(x) = \\frac{1}{N} \\sum_{x \\in W} y_i$$ 그런데 모든 data point에 동일한 가중치를 주는게 다르게 주면 어떨까? 예를 들면, Squared Exponential $L$이 커지면 window가 커지는 역할 위에서 window 크기처럼 $L$을 적절히 선택해야한다. $$k(x,x_i;L) = exp(-\\frac{|x-x_i|^2}{L^2})$$ 위처럼 domain correlation을 다르게 생각하고 거리에 따라 가중치를 다르게 주는 것이다. 가까울수록 큰 가중치! $$MA(x) = \\frac{1}{\\sum_{x_i \\in D} k(x,x_i)}\\sum_{x_i \\in D} k(x,x_i) y_i$$ ","date":"2021-11-29","objectID":"/prml-chap06-2/:1:4","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Random Process Random process(=Stochastic process) An infinite indexed collection of random variables ${ X(w,t) , t \\in T }$ index paramter : $t$ (time, space…) A function $X(t,\\omega), t \\in T ;\\text{and}; \\omega \\in \\Omega$ outcome : $\\omega$ Fixed $t \\rightarrow X(t,\\omega)$ is a random variable over $\\Omega$ Fixed $\\omega \\rightarrow X(t,\\omega)$ is a deterministic function of $t$ ; sample function ","date":"2021-11-29","objectID":"/prml-chap06-2/:2:0","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Gaussian Process GP는 Random Process의 한 종류 For any set S, a GP on S is a set of random variable ($z_t : t \\in S$) such that vector $[z_{t_1}, z_{t_2},…,z_{t_n}]$ is multivariate gaussian $$P(T) = N(0, (\\beta I_N)^{-1} + K) \\ K_{nm} = k(x_n, x_m) = \\theta_0 \\exp(-\\frac{\\theta_1}{2}||x_n - x_m||^2) + \\theta_2 + \\theta_3 x_n^T x_m$$ ","date":"2021-11-29","objectID":"/prml-chap06-2/:3:0","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Derivation of Gaussian Process 일단 linear regression으로 접근하고 GP에 대해 알아본다. gaussian process regression : a nonparametric bayesian regression method using the properties of Gaussian processes ","date":"2021-11-29","objectID":"/prml-chap06-2/:4:0","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Mapping Functions non-linearly separable data set이 있다고 가정하자. 이를 위해 basis space를 증가시키면 될 것이다. mapping function $\\phi$를 통해 확장시킨다. ","date":"2021-11-29","objectID":"/prml-chap06-2/:4:1","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Linear regression with basis function $$y(x) = w^T \\phi (x)$$ 여기서 $w$를 deterministic value가 아니라 probabilistically distributed value라고 생각하자. (Bayesian linear regression의 방법론) $$P(w) = N(0, \\alpha^{-1} I)$$ Y의 확률분포(joint distribution)에 대해 생각해보자. ($w$가 확률분포가 있으니까) $Y$도 normal 이겠구나 (multivariate gaussian) $$Y = (y_1, y_2,…,y_n)$$ $K$ : Gram matrix $$E[Y] = E[\\Phi w] = \\Phi E[w] = 0$$ $$cov(Y) = E[YY^T] = E[\\Phi w w^T \\Phi^T]$$ $$= \\Phi E[ww^T]\\Phi^T = \\frac{1}{\\alpha} \\Phi \\Phi^T$$ $$K_{nm} = k(x_n,x_m) = \\frac{1}{\\alpha} \\phi (x_n)^T \\phi (x_m)$$ $$\\therefore P(Y) = N(0,K)$$ 분산이 kernel function을 이용한다는 점을 기억하자 이제 $Y$에 대한 분포를 파악했으니 이를 통해 prediction을 해보자. ","date":"2021-11-29","objectID":"/prml-chap06-2/:4:2","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Modeling Noise with Gaussian distribution $t_n$ : observed value with noise $y_n$ : Latent, error-free value $e_n$ : Error term distributed by following the gaussian distribution $$t_n = y_n + e_n \\ (t_n = f(x_n)+e_n)$$ $$P(T|Y) = N(Y, \\beta^{-1} I)$$ $\\beta$ : hyperparameter of the error precision error term들이 independent라고 가정하기에 variance 부분에 $I$이 된다. $$P(T) = \\int P(T|Y)P(Y) dY = \\int N(Y,\\beta^{-1} I) N(0,K) dY$$ 위의 곱해지는 두 분포 모두 multivariate gaussian distribution 이므로 이를 이용하여 구할 것이다. $$P(T|Y)P(Y) = P(T,Y) = P(Z)$$ $$\\ln P(Z) = \\ln P(T|Y) + \\ln P(Y) \\ = - \\frac{1}{2} Y^TK^{-1}Y - \\frac{1}{2}(T-Y)^T \\beta I (T-Y) + const$$ 여기서 변수는 $T,Y$이다. 여기서 second order term을 보면 (second order term을 찾으면 covariance를 찾을 수 있기에) $$ = \\frac{1}{2} \\begin{pmatrix} Y \\\\ T \\end{pmatrix}^T \\begin{pmatrix} K^{-1} + \\beta I \u0026 -\\beta I \\\\ - \\beta I \u0026 \\beta I \\end{pmatrix} \\begin{pmatrix} Y \\\\ T \\end{pmatrix} = \\frac{1}{2}Z^T R Z$$ $R$은 precision matrix가 된다. 이를 inverse 하면 (공식이용) $$R^{-1} = \\begin{pmatrix} K \u0026 K \\\\ K \u0026 (\\beta I)^{-1} + K \\end{pmatrix}$$ $\\ln (Z)$의 first order term은 없다. mean이 0라는 것을 알 수 있다. 따라서 최종 결과는 $$P(Z) = N(0, R^{-1})$$ 이제 PRML chapter 2에서 봤었던 공식을 이용하면 marginal distribution을 구할 수 있다. $$P(T) = N(0, (\\beta I)^{-1} + K)$$ 이제 우리가 관찰한 N개의 data를 통해 $P(T)$를 알게 되었다. 그렇다면 이제 prediction해보자. $t_{N+1}$을 알아내야 한다. $$P(t_{N+1}|T_N)$$ 이를 구하기 위해 N+1의 joint를 구하고 conditional disribution을 만들면 된다. ","date":"2021-11-29","objectID":"/prml-chap06-2/:4:3","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Sampling of $P(T)$ Sampling T of 101 dimension when points $x_n = [-1,-0.98,…,1]$ : 101개의 data point mean $0$ : 101 dim zero vector cov $(\\beta I_N)^{-1} + K$ : 101 * 101 dim cov $$P(T) = N(0, (\\beta I_N)^{-1} + K)$$ kernel의 parameter와 $\\beta$값에 따라서 sampling data들이 이루는 모습이 달라진다. ","date":"2021-11-29","objectID":"/prml-chap06-2/:4:4","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Mean and Covariance of $P(t_{N+1} | T_N)$ $$P(t_{N+1}|T_N) = P(T_{N+1}) / P(T_N)$$ $$P(T_{N+1}) = N(0, cov_{N+1})$$ mean은 1차원이 늘어난 zero vector이고 cov는 행과 열이 하나씩 들어간 형태일 것이다. 이는 kernel function과 $\\beta$를 통해 어렵지 않게 구할 수 있다. $$cov_{N+1} = \\begin{pmatrix} cov_N \u0026 k \\\\ k^T \u0026 K_{(N+1)(N+1)}+\\beta^{-1} \\end{pmatrix}$$ 이제 joint distribution을 구했으니 conditional distribution을 구할 수 있다. (공식 PRML chap2에 나온다) $$P(t_{N+1}|T_N) = N(0+k^T cov_N^{-1}(T_N-0),K_{(N+1)(N+1)}+\\beta^{-1} -k^Tcov_N^{-1} k )$$ 이는 결국 regression을 한 것이다. predictive distribution을 구한 것이다. 평균과 분산 모두 new data $x_{N+1}$에 depend하다. 분산에서 inverse가 computationally 오래걸려서 approximation하는 방법들이 있다고 한다. $$\\mu_{t_{N+1}} = k^T cov_N^{-1} T_N \\ \\sigma^2_{t_{N+1}} = K_{(N+1)(N+1)}+\\beta^{-1} -k^Tcov_N^{-1} k$$ 우리가 알고 있는 일반적인 regression과는 조금 다른 형태이다. 각 feature들의 weight들이 어디있는지 궁금할 수 있는데 kernel function안의 parameter로 들어갔다. ","date":"2021-11-29","objectID":"/prml-chap06-2/:4:5","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Hyperparameter of Gaussian Process Regression 위에서 linear regression에서 parameter optimization을 하는 방법을 알아보자. 아래의 kernel hyperparameter를 추정해야 하는 것이다. $$ K_{nm} = k(x_n, x_m) = \\theta_0 \\exp(-\\frac{\\theta_1}{2}||x_n - x_m||^2) + \\theta_2 + \\theta_3 x_n^T x_m$$ $$P(T;\\theta) = N(0, (\\beta I_N)^{-1} + K)$$ $\\theta$를 추정하기 위해 likelihood를 최대한 높이는 방법을 택한다. $\\theta$에 대해 미분하여 구하면 된다. $$\\frac{\\partial}{\\partial \\theta_i} \\log P(T;\\theta) \\overset{let}{=}0$$ 그런데 closed form은 존재하지 않는다. 그래서 approximation해야 한다. (너무 복잡해서 derivation 생략) 우리는 pytorch와 같은 framework의 도움을 받아서 구한다. ","date":"2021-11-29","objectID":"/prml-chap06-2/:4:6","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Gaussian Process Classifier 아래와 같이 일반적인 logistic regression과 거의 동일하다. Gaussian process classifier : sigmoid function + Gaussian process Gaussian process : $f(x;\\theta)$ Gaussian process classifier : $y=\\sigma (f(x;\\theta))$ if $t \\in {0,1}$, objective function to optimize : $$P(t | \\theta) = \\sigma (f(x;\\theta))^t (1-\\sigma (f(x;\\theta)))^{1-t}$$ ","date":"2021-11-29","objectID":"/prml-chap06-2/:5:0","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"PRML에서 Naive bayes 와 Logistic regression에 대해 공부하였는데 이 둘의 관계에 대해 간단히 정리해보고자 한다. (문일철 교수님의 강의에 대해 정리하였습니다.) 몇 가지 가정(constraint)가 더해지면 Naive bayes와 Logistic regression이 같아진다. ","date":"2021-11-26","objectID":"/prml-chap04-3/:0:0","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (3)","uri":"/prml-chap04-3/"},{"categories":["PRML"],"content":"Gaussian Naive Bayes Naive Bayes에 대해서는 이전에 공부하였다. 이번에는 거기에 조금 더 추가하여 각 conditional distribution들이 Gaussian distribution이라고 가정해보자. $$f_{NB} = \\arg\\max_{Y=y}P(Y=y)\\prod_{i=1}^{D}P(X_i=x_i|Y=y)$$ $$P(Y=k) = \\pi_k$$ $$P(X_i=x_i|Y=y) = \\frac{1}{c \\sigma_k^i } \\exp(- \\frac{1}{2}(\\frac{x_i - \\mu_k^i}{\\sigma_k^i})^2)$$ 이제 Naive bayes classifier이 Logistic regression의 형태가 되는 과정을 살펴볼 것이다. Logistic regression : $P(Y=k | X)$ Naive Bayes : $\\frac{P(X|Y=k)P(Y=k)}{P(X)}$ generative 방법의 Naive bayes로 부터 Discriminative한 Logistic regression으로 가보자 $$ = \\frac{p(Y=k)\\prod_{i=1}^D P(X_i|Y=y)}{p(Y=k)\\prod_{i=1}^D P(X_i|Y=k) + p(Y=k^C)\\prod_{i=1}^D P(X_i|Y=k^C)}$$ $$= 1/[1 + \\frac{\\pi_2 \\prod \\frac{1}{c \\sigma_{not;k}^i } \\exp(- \\frac{1}{2}(\\frac{x_i - \\mu_{\\text{not};k}^i}{\\sigma_{\\text{not};k}^i})^2) }{\\pi_1 \\prod \\frac{1}{c \\sigma_{k}^i } \\exp(- \\frac{1}{2}(\\frac{x_i - \\mu_{k}^i}{\\sigma_{k}^i})^2) }]$$ 여기서 $\\sigma_{not ; k} = \\sigma_{k}= \\sigma$라고 가정하면 $$=1/[1+\\frac{\\pi_2 \\prod \\exp(- \\frac{1}{2}(\\frac{x_i - \\mu_{not;k}^i}{\\sigma^i})^2) }{\\pi_1 \\prod \\exp(- \\frac{1}{2}(\\frac{x_i - \\mu_{k}^i}{\\sigma^i})^2) }] $$ $$ = 1/[1+exp(-\\frac{1}{2 {\\sigma^i}^2} \\sum { 2(\\mu_{not;k}^i-\\mu_k^i)x_i + {\\mu_{not; k}^i}^2 - {\\mu_k^i}^2 + \\log\\pi_2 - \\log\\pi_1 }] $$ 최종식을 보면 sigmoid function에 $w^T x$가 들어가있는 형태이다. 즉, Logistic regression이 되는 것이다. Naive Bayes의 conditional independent 가정 conditional한 상황에서 각 feature들이 Gaussian이고 분산이 같다는 가정 ","date":"2021-11-26","objectID":"/prml-chap04-3/:1:0","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (3)","uri":"/prml-chap04-3/"},{"categories":["PRML"],"content":"Classification에 대해 알아보자. ","date":"2021-11-26","objectID":"/prml-chap04-2/:0:0","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (2)","uri":"/prml-chap04-2/"},{"categories":["PRML"],"content":"4.3 Probabilistic Discriminative Models 이전과 다르게 parameter 추정을 $p(C_k|x)$에서 Maximum likelihood 를 이용하여 directly 하고자 한다. 이전에 본 generative한 방법에 비해 parameter가 더 적다 class-conditional density 가정이 잘못되면 성능이 좋지 않을 수 있다 ","date":"2021-11-26","objectID":"/prml-chap04-2/:1:0","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (2)","uri":"/prml-chap04-2/"},{"categories":["PRML"],"content":"4.3.1 Fixed basis functions 이제부터는 basis function $\\phi ({\\bf x})$을 사용할 것이다. basis function이 비선형이라 decision boudary는 original space에 linear하지 않을 것이다. basis function에는 $\\phi ({\\bf x})=1$ bias를 기본적으로 넣는다. original이 아닌 basis function을 사용했다고 항상 결과가 좋은 것은 아니다. ","date":"2021-11-26","objectID":"/prml-chap04-2/:1:1","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (2)","uri":"/prml-chap04-2/"},{"categories":["PRML"],"content":"4.3.2 Logistic regression 2-class의 경우로 시작해보자. 이전에 공부했듯이 일반적인 가정하에서 posterior는 sigmoid에 linear function of $\\phi$ (feature vector) 가 들어간 형태이다. $$p(C_1 | \\phi) = y(\\phi) = \\sigma ({\\bf w}^T \\phi)$$ logistic regression 의 장점 (2 class) M 차원이라고 가정하면 M개의 parameter가 있을 것이다. 반면에 generative한 상황을 생각하면 Gaussian class conditional density 의 경우 2M개의 평균, M(M+1) / 2개의 covariance matrix, prior 까지 총 M(M+5)/2+1 개의 parameter가 필요하다. interpretable하다. parameter estimation에 있어 computationally efficient 하다. multiclass도 가능하다. 단점 prediction performance가 좋은 편은 아니다. basis가 fixed되어 있다. likelihood로 parameter를 추정하는 과정을 살펴보자. Given : $D = [({\\bf x}_1,y_1),({\\bf x}_2,y_2),..,({\\bf x}_n,y_n)]$ model : $t_i \\sim^{iid} \\text{Bern}[\\sigma({\\bf w}^T \\phi({\\bf x}_i))]$ $$y_n = p(C_1 | \\phi_n)=\\sigma({\\bf w}^T \\phi({\\bf x}_n))$$ $$p(\\textbf{t}|{\\bf w}) = \\prod_{n=1}^{N}{y_n^{t_n}(1-y_n)^{1-t_n}}$$ $\\textbf{t} = (t_1,…t_N)^T$ : true target cross-entropy error function : $$E({\\bf w}) = - \\ln p(\\textbf{t} | {\\bf w}) = - \\sum{ { t_n \\log y_n + (1-t_n)\\log(1-y_n) } }$$ ${\\bf w}$에 대해 미분하면 $$\\bigtriangledown E({\\bf w}) = \\sum_{n=1}^{N}{(y_n - t_n)\\phi_n}$$ 이를 구하는 방법은 chain rule을 사용한다. 아래의 값들을 곱하면 위의 식이 나온다. $$\\frac{\\partial E}{\\partial y_n} = \\frac{1-t_n}{1-y_n} - \\frac{t_n}{y_n} = \\frac{y_n-t_n}{y_n(1-y_n)}$$ $$\\frac{\\partial y_n}{\\partial a_n} = \\frac{\\partial \\sigma(a_n)}{\\partial a_n} = \\sigma(a_n)(1-\\sigma(a_n)) = y_n(1-y_n)$$ $$ \\frac{\\partial a_n}{\\partial {\\bf w}} = \\phi_n$$ 이전에 linear regression과는 다르게 MLE가 closed form으로 존재하지 않는다. 따라서 approximation하는 방법이 필요하다. 이를 Gradient descent 방법을 통해 답을 구할 수도 있다. 하지만 뒤에서는 약간 다른 방법으로 해결해본다. (전통적인 통계방법) ","date":"2021-11-26","objectID":"/prml-chap04-2/:1:2","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (2)","uri":"/prml-chap04-2/"},{"categories":["PRML"],"content":"4.3.3 Iterative reweighted least squares +일단은 교재의 내용을 보기 전에 이해를 돕기 위해 추가 설명을 한다. 우리는 logL를 미분했을 때, 이를 0으로 만드는 MLE를 찾고싶다. $g’(x)$ 는 미분가능 $g’’(x) \\neq 0$ 위의 조건을 만족하는 경우 taylor expansion을 이용하여 (1차 근사) $$0 = g’(x) \\approx g’(x^{t}) + (x-x^t)g’’(x^t)$$ 이를 정리하면 $$x = x^t - \\frac{g’(x^t)}{g’’(x^t)}$$ 이제 교재의 내용을 살펴보자. logisitc regression은 sigmoid function의 non-linearlity 때문에 closed-form의 해를 구할 수 없다. 그래서 우리는 error function의 최소화하는 방법으로 Newton-Raphson iterative opimization algorithm을 사용한다. $${\\bf w}^{new} = {\\bf w}^{old} - {\\bf H}^{-1} \\bigtriangledown E({\\bf w})$$ ${\\bf H}$ : hessian matrix whose elements comprise the second derivatives of $E({\\bf w})$ with respect to the component of ${\\bf w}$ $$\\bigtriangledown E({\\bf w}) = \\sum_{n=1}^{N}{(y_n - t_n)\\phi_n} = \\Phi ^T (\\textbf{y}-\\textbf{t})$$ $${\\bf H} = \\bigtriangledown \\bigtriangledown E({\\bf w}) = \\sum_{n=1}^{N}{y_n(1-y_n)\\phi_n \\phi_n^T} = \\Phi^T\\textbf{R}\\Phi$$ $\\Phi^T\\textbf{R}^{1/2} \\textbf{R}^{1/2} \\Phi =(\\textbf{R}^{1/2} \\Phi)^T (\\textbf{R}^{1/2} \\Phi)$ 이기에 positive semi definite이고 이를 통해 $E({\\bf w})$가 convex하다는 것을 알 수 있다. $\\textbf{R}$ : N*N diagonal matrix with elements $R_{nn} = y_n(1-y_n)$ $y_n$의 식이므로 parameter ${\\bf w}$에 dependent하다. 따라서 ${\\bf R}$에 대해서도 iterative하게 업데이트가 필요하다. 아래처럼 iterative하게 parameter를 업데이트 한다. $${\\bf w}^{(new)} = {\\bf w}^{(old)} - (\\Phi^T{\\bf R}\\Phi)^{-1}\\Phi^T({\\bf y}-{\\bf t})$$ $$= (\\Phi^T{\\bf R}\\Phi)^{-1}\\{\\Phi^T{\\bf R}\\Phi{\\bf w}^{(old)}-\\Phi^T({\\bf y}-{\\bf t})\\}$$ $$= (\\Phi^T{\\bf R}\\Phi)^{-1}\\Phi^T{\\bf R}{\\bf z}$$ $${\\bf z} = \\Phi{\\bf w}^{(old)} - {\\bf R}^{-1}({\\bf y}-{\\bf t})$$ 마지막 줄을 보면 이 형태는 weighted least-square 문제에서의 normal equation의 형태이다. 하지만 ${\\bf R}$이 상수가 아니기에 iterative하게 답을 구해야 하고 이러한 이유로 iterative reweighted least square 라고 부른다. ${\\bf R}$의 대각성분을 variance라고 해석할 수도 있다. 대각성분이 $y_n(1-y_n)$ 인데 이는 $t_n$의 variance이기 때문이다. ","date":"2021-11-26","objectID":"/prml-chap04-2/:1:3","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (2)","uri":"/prml-chap04-2/"},{"categories":["PRML"],"content":"4.3.4 Multiclass logistic regression 위에서 본 binary와 똑같이 할 수 있다. multiclass에서는 softmax function을 이용한다. $$p(C_k|\\phi) = y_k(\\phi) = \\frac{\\exp(a_k)}{\\sum_j \\exp(a_j)}$$ likelihood function을 구하면 $$p({\\bf T}|{\\bf w} _ 1,…{\\bf w} _ K) = \\prod_{n=1}^{N}\\prod_{k=1}^{K} p(C_k|\\phi_n)^{t_{nk}} = \\prod_{n=1}^{N}\\prod_{k=1}^{K}y_{nk}^{t_{nk}}$$ negative log를 취하면 $$E({\\bf w} _ 1, …, {\\bf w} _ K) = -\\ln p({\\bf T}|{\\bf w} _ 1, …,{\\bf w} _ K) = - \\sum_{n=1}^{N} \\sum_{k=1}^{K} t_{nk} \\ln(y_{nk})$$ 똑같이 미분을 취하고 Gradient descent나 IRLS 방법을 통해 parameter를 추정한다. $$\\nabla_{ {\\bf w} _ j } E({\\bf w} _ 1, …, {\\bf w} _ K) = \\sum_{n=1}^{N} (y _ {nj} - t _ {nj}) \\phi_n $$ ","date":"2021-11-26","objectID":"/prml-chap04-2/:1:4","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (2)","uri":"/prml-chap04-2/"},{"categories":["PRML"],"content":"4.3.5 Probit regression 이전과 마찬가지로 generalized linear model의 형태 $$p(t=1|a)=f(a)=f({\\bf w}^T \\phi)$$ 를 유지하지만 조금 다른 activation function을 알아보자. link function으로 noisy threshold model을 생각해보면 $t_n = 1 \\text{ if } a_n\\ge \\theta $ $t_n=0 \\text{ otherwise}$ $\\theta$는 random variable이고 probability density가 $p(\\theta)$라고 하자. 이에 따라 activation function을 CDF형태 $$f(a) = \\int_{-\\infty}^{a}p(\\theta)d\\theta$$ 로 표현할 수 있다. probability density를 $N(0,1)$로 가정하면 $$\\Phi(a) = \\int_{-\\infty}^{a}N(0, 1)d\\theta $$ 이고 이를 probit function이라고 한다. 모양은 sigmoid function과 거의 유사하다. 이를 모델에서 사용할 때는 약간 다른 모습을 이용한다. (계산의 편리함 때문인듯) erf function 은 $$erf(a) = \\frac{2}{\\sqrt{\\pi}} \\int_{0}^{a} \\exp(-\\theta^2) d\\theta$$ 이를 통해 탄생한 generalized linear model을 probit regression 이라고 한다. $$\\Phi(a) = \\frac{1}{2} \\{1+erf\\left(\\frac{a}{\\sqrt{2}}\\right)\\}$$ probit은 뒤에 나올 Bayesian logistic regression에서 사용된다. logistic, probit regression 모두 outlier에 취약한 편이다. 근데 probit은 $exp(-x^2)$이 있어서 더 취약하다. data가 mislabelling된 경우, 새로운 probability $\\epsilon$을 추가하여 사용할 수 있다. $$p(t|{\\bf x}) = (1-\\epsilon)\\sigma({\\bf x}) + \\epsilon(1-\\sigma({\\bf x})) = \\epsilon + (1-2\\epsilon)\\sigma({\\bf x})$$ ","date":"2021-11-26","objectID":"/prml-chap04-2/:1:5","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (2)","uri":"/prml-chap04-2/"},{"categories":["PRML"],"content":"4.4 The Laplace Approximation 4.5장에서 logistic regression에 Bayesian 방법을 사용하고자 한다. 근데 ${\\bf w}$의 posterior가 더 이상 Gaussian이 아니기 때문에 integrate하기가 어렵다. 따라서 특정 범위에 있는 함수를 Gaussian으로 approximation하는 방법을 이용하고자 한다. 먼저 single variable의 경우부터 살펴보자. Suppose the distribution $p(z)$ is defined by $$p(z) = \\frac{1}{Z}f(z),;; Z = \\int f(z)dz$$ 우리의 목표는 $p(z)$의 mode를 중앙(평균)으로 갖는 Gaussian distribution을 approximation하는 것이다. 먼저, mode를 찾아야한다. $$p’(z_0) = 0$$ Taylor expansion $$\\ln f(z) \\simeq \\ln f(z_0) - \\frac{1}{2}A(z-z_0)^2$$ $$A=-\\left.\\dfrac{d^2}{dz^2}\\ln f(z)\\right|_ {z=z_0} $$ 따라서 $$f(z) \\simeq f(z_0) \\exp { - \\frac{A}{2}(z-z_0)^2}$$ $$q(z) = (\\frac{A}{2\\pi})^{1/2} \\exp { -\\frac{A}{2}(z-z_0)^2 }$$ 우리는 $p(z)$를 approximate한 Gaussian $q(z)$를 찾을 수 있다! 이 과정이 Laplace approximation 이다. Gaussian approximation에서 ($f(z)$를 두 번 미분하여 $z_0$를 대입) precision $A$는 양수이다. 따라서 $z_0$는 local maximum이다. 이제 다차원의 형태로 살펴보자. Hessian Matrix $\\textbf{A} = - \\bigtriangledown \\bigtriangledown \\ln f(\\textbf{z}_0)$ $f(\\textbf{z}) \\simeq f(\\textbf{z}_0) \\exp { -\\frac{1}{2} (\\textbf{z} - \\textbf{z}_0)^T \\textbf{A} (\\textbf{z}-\\textbf{z}_0) }$ $$q({\\bf z}) = \\dfrac{|{\\bf A}|^{1/2}}{(2\\pi)^{M/2}}\\exp\\{-\\dfrac{1}{2}({\\bf z}-{\\bf z}_0)^T{\\bf A}({\\bf z}-{\\bf z}_0)\\} = N( {\\bf z}_0, {\\bf A}^{-1})$$ Laplace approximation 특징 Mutimodal인 distribution은 다양한 Laplace approximation이 생길 수 있다. CLT에 의해 Laplace approximation은 data가 많을수록 좋다. 위에서 알 수 있는이 $Z$에 대해 알 필요가 없다. Gaussian에 기반하므로 실수 변수에만 사용이 가능하다. global한 특징을 잡기 어렵다. ","date":"2021-11-26","objectID":"/prml-chap04-2/:2:0","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (2)","uri":"/prml-chap04-2/"},{"categories":["PRML"],"content":"4.4.1 Model comparison and BIC normalization constraint $Z$에 대해 approximation해보자. $$Z = \\int f({\\bf z})d{\\bf z} \\simeq f({\\bf z}_0)\\int\\exp\\{\\dfrac{1}{2}({\\bf z}-{\\bf z}_0)^T{\\bf A}({\\bf z}-{\\bf z}_0)\\}d{\\bf z}=f({\\bf z}_0)\\dfrac{(2\\pi)^{M/2}}{|{\\bf A}|^{1/2}}$$ 우리는 이 결과를 통해 이전에 공부했던 Bayesian model comparison에서 model evidence를 approximation해볼 것이다. model evidence $p(D|M_i)$ $M_i$ 생략 $$p(D)=\\int p(D|{\\pmb \\theta})p({\\pmb \\theta})d{\\pmb \\theta}$$ 아래와 같이 정의하고 우리는 model evidence를 approximation하면 $f({\\pmb \\theta}) = p(D|{\\pmb \\theta})p({\\pmb \\theta})$ $Z = p(D)$ $$\\ln p(D)\\simeq \\ln p(D|{\\pmb \\theta} _ {MAP}) + \\ln p({\\pmb \\theta} _ {MAP}) + \\dfrac{M}{2}\\ln(2\\pi) - \\dfrac{1}{2}\\ln|{\\bf A}| $$ 첫번째 term은 log likelihood evaluated using the optimized parameters 두번째 term부터 마지막 term까지 Occam factor 라고 부른다. penalizes model complexity ${\\pmb \\theta}_{MAP}$ : mode of posterior distribution ${\\bf A}$ : Hessian matrix $${\\bf A} = - \\nabla\\nabla p(D|{\\pmb \\theta} _ {MAP})p({\\pmb \\theta} _ {MAP}) = -\\nabla\\nabla\\ln p({\\pmb \\theta} _ {MAP}|D)$$ model evidence를 approximation한 식에서 Gaussian prior가 broad하고 Hessian이 full rank이면 우리는 해당 식을 더 간단하게 (의미없는 상수 생략) $$\\ln p(D) \\simeq \\ln p(D|{\\bf \\theta}_{MAP}) - \\frac{1}{2}M\\ln N$$ 이는 BIC(Baysian Information Criterion) 이다. $M$은 parameter의 갯수, $N$은 data의 수를 의미한다. AIC보다 더 간단한 모델을 추구한다. BIC를 쉽게 계산할 수 있지만 full rank라는 가정이 만족하기 쉽지 않아서 한계가 존재한다. ","date":"2021-11-26","objectID":"/prml-chap04-2/:2:1","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (2)","uri":"/prml-chap04-2/"},{"categories":["PRML"],"content":"4.5 Bayesian Logistic Regression Logistic regression에 Bayesian적으로 접근해보자. ","date":"2021-11-26","objectID":"/prml-chap04-2/:3:0","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (2)","uri":"/prml-chap04-2/"},{"categories":["PRML"],"content":"4.5.1 Laplace approximation 일단 prior는 Gaussian으로 가정한다. $$p({\\bf w}) = N( \\textbf{m}_0 , \\textbf{S}_0)$$ 이제 posterior를 구해보자. $$p(\\textbf{w}| \\textbf{t}) \\propto p(\\textbf{w})p(\\textbf{t}|\\textbf{w})$$ 양변에 log를 취하면 $$\\ln p(\\textbf{w} | \\textbf{t}) = - \\frac{1}{2}(\\textbf{w}-\\textbf{m} _ 0)^T \\textbf{S} _ 0^{-1} (\\textbf{w} - \\textbf{m} _ 0 )$$ $$+ \\sum_{n=1}^{N}{\\{ t_n \\ln y_n + (1-t_n)\\ln (1-y_n) \\}+ const}$$ posterior에 대한 Gaussian approximation하였다고 가정하자. maximize하는 parameter를 ${\\bf w}_{MAP}$라고 하고 covariance는 $${\\bf S}_N^{-1} = -\\nabla\\nabla \\ln p({\\bf w}|{\\bf t}) = {\\bf S} _ 0^{-1} + \\sum _ {n=1}^{N} y_n(1-y_n)\\phi_n\\phi_n^T$$ 따라서 Gaussian approximation한 posterior distribution의 form은 $$q(\\textbf{w}) = N(\\textbf{w}_{MAP} , \\textbf{S}_N)$$ 이제 approximation하여 구한 posterior로 Predictive를 구해보자. ","date":"2021-11-26","objectID":"/prml-chap04-2/:3:1","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (2)","uri":"/prml-chap04-2/"},{"categories":["PRML"],"content":"4.5.2 Predictive distribution 2-class의 경우라고 가정하자. predictive distribution은 $$p(C_1 | \\phi, \\textbf{t} ) = \\int p(C_1 | \\phi, \\textbf{w})p(\\textbf{w} | \\textbf{t}) \\simeq \\int \\sigma (\\textbf{w}^T\\phi) q(\\textbf{w})d\\textbf{w}$$ Funtion $\\sigma ({\\bf w}^T \\phi)$ depends on w only through tis projection onto $\\phi$ (교재에 설명이 다소 빈약) 그냥 아래처럼 변형 $$\\sigma({\\bf w}^T\\phi) = \\int \\delta(a-{\\bf w}^T\\phi)\\sigma(a)da$$ 이를 predictive distribution에 대입하면 $$\\int \\sigma({\\bf w}^T\\phi)q({\\bf w})d{\\bf w} = \\int \\sigma(a)p(a)da$$ $$p(a) = \\int \\delta(a-{\\bf w}^T\\phi)q({\\bf w})d{\\bf w}$$ $p(a)$는 Gaussian distribution이 되는데 delta function ($\\delta$) imposes a linear constraint on ${\\bf w}$이고 $q({\\bf w})$ 는 정의에 의해 Gaussian distribution Gaussian의 marginal도 Gaussian $$\\mu_a = E[a] = \\int p(a)a da = \\int q({\\bf w}){\\bf w}^T \\phi d{\\bf w} = {\\bf w}_{MAP}^T\\phi$$ $$\\sigma_a^2 = var[a] = \\int p(a){ a^2 - E[a]^2 }da $$ $$= \\int q({\\bf w}) {({\\bf w}^T\\phi)^2 - ({\\bf m}_N^T\\phi)^2 }d{\\bf w} = \\phi^T{\\bf S}_N\\phi$$ 따라서 predictive distribution은 $$p(C_1|{\\bf t}) = \\int \\sigma(a)p(a)da = \\int \\sigma(a)N(\\mu_a, \\sigma_a^2)da$$ sigmoid-gaussian을 analytically 구할 수 없기 때문에 이 또한 approximation을 해야한다. sigmoid와 비슷한 모양을 가지는 Probit function을 이용한다. ($\\sigma(a) \\approx \\Phi(\\lambda a) ,\\lambda^2 = \\pi / 8$) probit function을 이용한 approximation의 장점은 Gaussian과 만나서 analytically 또 probit function으로 아래와 같은 결과가 나온다. $$\\int \\Phi (\\lambda a )N ( \\mu, \\sigma^2)da = \\Phi (\\frac{\\mu}{( \\lambda^{-2}+\\sigma^2 ) ^{1/2}})$$ $$\\int \\sigma(a) N(\\mu,\\sigma^2)da \\simeq \\sigma (k(\\sigma^2)\\mu)$$ $k(\\sigma^2) = (1+\\pi \\sigma^2 / 8)^{-1/2}$ 최종 결과 approximate predictive distribution은 $$p(C_1 | \\phi, \\textbf{t}) = \\sigma (k(\\sigma^2_a)\\mu_a)$$ ","date":"2021-11-26","objectID":"/prml-chap04-2/:3:2","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (2)","uri":"/prml-chap04-2/"},{"categories":["PRML"],"content":"Classification에 대해 알아보자. input space는 decision regions 로 나눠지는데 이는 decision boundaries(decision surfaces) 에 의해 나눠진다. 이번 챕터에서는 분류 선형모델에 대해 공부하는데 이는 decision surfaces가 input x의 linear function 이라는 것을 의미한다. D차원의 input space가 D-1 차원의 hyperplane으로 나눠지는 것이다. 크게 3가지로 나누어서 공부한다. Discriminant function generative Discriminative classification에서는 discrete class labels 이나 각 class가 될 probability를 target으로 예측한다. 후자의 경우 (0,1) 사이의 값을 가질 것이다. 따라서 우리는 linear function of ${\\bf w}$를 nonlinear function을 이용하여 transform한다. $$y({\\bf x}) = f({\\bf w}^T {\\bf x} + w_0)$$ machine learning에서는 $f$를 activation function 이라고 부른다. 통계학에서는 inverse of link function 으로 부른다. 따라서 이전에 봤던 regression model과는 다르게 더이상 parameter에 linear하지 않는 성질을 가진다. ","date":"2021-11-26","objectID":"/prml-chap04-1/:0:0","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (1)","uri":"/prml-chap04-1/"},{"categories":["PRML"],"content":"4.1 Discriminant Functions discriminant : a function that takes an input vector ${\\bf x}$ and assigns it to one of $K$ class 이번 chapter에서는 linear discriminant ( : decision surfaces are hyperplane) 로 한정지어 공부할 것이다. ","date":"2021-11-26","objectID":"/prml-chap04-1/:1:0","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (1)","uri":"/prml-chap04-1/"},{"categories":["PRML"],"content":"4.1.1 two classes 가장 간단한 linear discriminant function을 보면 $$y({\\bf x}) = {\\bf w}^T {\\bf x} + w_0$$ $y({\\bf x}) \\ge 0$ 이면 class 1이고 반대면 class 2 이다. 따라서 decision boundary는 $y({\\bf x}) = 0$ 이고 $(D-1)$차원의 hyperplane이다. decision surface 위에 두 점 ${\\bf x}_A , {\\bf x}_B$ 이 있다고 가정하면 ${\\bf w}^T({\\bf x}_A - {\\bf x}_B)=0$ 이므로 vector ${\\bf w}$는 decision surface에 있는 모든 점들과 orthogonal하다. 이는 ${\\bf w}$가 decision surface의 orientation을 결정한다는 의미이다. 똑같이 ${\\bf x}$가 decision surface 위의 점이라고 하고 원점과 decision surface의 거리를 계산하면 아래와 같다. 여기서 ${\\bf w}_0$는 decision surface의 위치를 결정한다. $$\\frac{\\textbf{w}^T \\textbf{x}}{\\left|| \\textbf{w} \\right||} = - \\frac{ \\textbf{w}_0}{\\left|| \\textbf{w} \\right||}$$ ","date":"2021-11-26","objectID":"/prml-chap04-1/:1:1","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (1)","uri":"/prml-chap04-1/"},{"categories":["PRML"],"content":"4.1.2 Multiple classes $K$ 가 2보다 큰 multiple class를 분류하는 상황을 생각해보자. linear discriminant로 분류하는 방법은 크게 두 가지로 나눌 수 있다. one vs the rest one vs one 두 방법 모두 class를 결정하는데 있어 애매한 상황이 발생한다. hyperplane이라는 제약때문에 그 어떤 class에도 속하지 못하는 지역이 발생한다. (PRML figure 4.2 에 잘 보여줌) 이를 해결하기 위해 아래와 같은 $K$개의 linear function을 $K$-class discriminant로 사용한다. $$y_k(x) = w^T_kx + w_{k0}$$ $y_k({\\bf x}) \\ge y_j ({\\bf x})$ 인 경우, ${\\bf x}$는 $k$로 분류한다. 즉, 큰 값을 가지는 쪽으로! 여기서 만들어지는 decision region은 항상 singly connected and convex하다. decision region $R_k$에 들어있는 두 점 ${\\bf x}_A, {\\bf x}_B$ 이 두 점을 연결한 선 위에 점 $\\hat{ {\\bf x} }$이 있다고 가정하자. 이를 표현하면 ($0 \\le \\lambda \\le 1$) $$\\hat{\\bf x}=\\lambda{\\bf x}_A + (1-\\lambda){\\bf x}_B$$ 따라서 discriminant function은 다음을 만족한다. $$y_k(\\hat{ {\\bf x} })={\\lambda}y_k({\\bf x}_A) + (1-\\lambda)y_k({\\bf x}_B) $$ $y_k({\\bf x}_A) \u003e y_j({\\bf x}_A) , y_k({\\bf x}_B) \u003e y_j({\\bf x}_B)$ 을 만족하기에 $y_k({\\hat {\\bf x}}) \u003e y_j({\\hat {\\bf x}})$ 도 성립한다. 따라서, ${\\hat {\\bf x}}$은 항상 $R_k$에 속한다. 이제 linear discriminant function의 parameter를 학습하는 방법에 대해 배울 것이다. least square Fisher’s linear discriminant perceptron algorithm ","date":"2021-11-26","objectID":"/prml-chap04-1/:1:2","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (1)","uri":"/prml-chap04-1/"},{"categories":["PRML"],"content":"4.1.3 Least squares for classification 이전의 sum of squares error function을 그대로 이용한다. target은 1-of-K binary coding하여 vector ${\\bf t}$ 이다. (해당하는 class는 1 나머지 class는 0으로 표현) 각 class 마다 $y_k({\\bf x}) = {\\bf w}_k^T {\\bf x} + w _ {k0}$ , 이를 합쳐서 표현하면 $$\\textbf{y} (\\textbf{x}) = \\widetilde{ \\textbf{W} }^T \\widetilde{ {\\bf x} }$$ $\\widetilde{\\textbf{W}}$ : 각 컬럼이 $\\widetilde{\\textbf{w}}_k = ({\\bf w} _ {k0}, {\\bf w}_k^T)$ $\\widetilde{\\textbf{W}}_k^T \\widetilde{ {\\bf x}}$가 가장 큰 값(class)에 input ${\\bf x}$를 할당한다. normal equation으로 parameter를 구하면 $$\\widetilde{\\textbf{W}}=(\\widetilde{\\textbf{W}}^T \\widetilde{\\textbf{W}})^{-1}\\widetilde{\\textbf{W}}^T\\widetilde{\\textbf{T}}=\\widetilde{\\textbf{W}}^{\\dagger}\\widetilde{\\textbf{T}}$$ 특징 exact closed-form의 solution이 나온다. output이 확률의 범위 (0,1) 을 넘어가는 경우가 존재한다. (우리는 output이 확률값이길 원한다) least square의 단점인 outlier에 취약하다. input data에 따라서 decision이 급변하다. ","date":"2021-11-26","objectID":"/prml-chap04-1/:1:3","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (1)","uri":"/prml-chap04-1/"},{"categories":["PRML"],"content":"4.1.4 Fisher’s linear discriminant 차원 축소의 역할로 많이 쓰이는데 classification으로도 사용가능하다. 일단은 2-class의 경우만 고려해보자. $D$ 차원의 input vector $\\textbf{W}$를 1차원에 project한다고 생각하자. $$y = \\textbf{w}^T \\textbf{x}$$ 이렇게 할 수 있다. 하지만 overlapping되니까 class seperation을 최대화하는 projection을 하는 것이다. 각 class의 평균을 $\\textbf{m}_1, \\textbf{m}_2$이라고 하면 아래의 값을 최대로 하는 ${\\bf w}$를 찾아야 한다. ${\\bf m_1}=1 / N_1\\sum_{n \\in C_1}\\textbf{x}_n$ ${\\bf m_2}=1 / N_2\\sum_{n \\in C_2}\\textbf{x}_n$ $$m_2 - m_1 = \\textbf{w}^T (\\textbf{m}_1 - \\textbf{m}_2),\\quad where; m_k = \\textbf{w}^T \\textbf{m}_k$$ ${\\bf w}$를 계속 키우면 커지기 때문에 제약식 $\\sum {\\bf w}_i^2 = 1$을 두고 라그랑지로 풀면 $${\\bf w} \\propto (\\textbf{m}_2 - \\textbf{m}_1)$$ 의 결론을 얻는다. 이에 추가적으로 Fisher는 within class의 varinace를 최소화 하고자 했다. 반면에 between class의 variance는 최대화 한다. class $C_k$의 within variance는 $y_n = {\\bf w}^T {\\bf x}_n$ $m_k = {\\bf w}^T {\\bf m}_k$ $$s_k^2=\\sum_{n \\in C_k}(y_n-m_k)^2$$ 전체 class의 within variance는 $s_1^2+s_2^2$ 이를 통해 Fisher criterion (ratio of the between-class variance to the within-class variance)은 $$J(\\textbf{w}) = \\frac{(m_2 - m_1)^2}{s_1^2+s_2^2}$$ Fisher criterion을 다시 쓰면 $$J(\\textbf{w}) = \\frac{\\textbf{w}^T {\\bf S}_B \\textbf{w}}{\\textbf{w}^T {\\bf S}_W \\textbf{w}}$$ $${\\bf S}_B = (\\textbf{m}_2 - \\textbf{m}_1)(\\textbf{m}_2 - \\textbf{m}_1)^T$$ 이 값은 between-class covariance matrix이다. $$\\textbf{S} _ W = \\sum_{n \\in C_1} (\\textbf{x} _ n - \\textbf{m} _ 1)(\\textbf{x} _ n - \\textbf{m} _ 1)^T + \\sum_{n \\in C_2} ({\\bf x}_n - \\textbf{m}_2)({\\bf x}_n-\\textbf{m}_2)^T$$ 이 값은 total within-class covariance matrix이다. w에 대해 미분하고 위의 값을 최대화하는 값을 찾으면 $\\textbf{w} \\propto {\\bf S}_W^{-1} (\\textbf{m}_2 - \\textbf{m}_1)$ . 이 결과를 Fisher’s linear discriminant 라고 한다. 1차원에 projection한 뒤에 특정 threshold값을 정해 classification할 수 있다. ","date":"2021-11-26","objectID":"/prml-chap04-1/:1:4","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (1)","uri":"/prml-chap04-1/"},{"categories":["PRML"],"content":"4.1.5 Relation to least squares Fisher criterion은 least square의 특별한 경우이다. target을 1-of-K encoding의 방법이 아닌 class 1은 $N / N_1$ class 2는 $-N / N_2$ 으로 encoding 하면 된다. 이렇게 한 뒤에 least square의 방법대로 parameter를 구하면 Fisher criterion이 나온다. (과정은 생략) ","date":"2021-11-26","objectID":"/prml-chap04-1/:1:5","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (1)","uri":"/prml-chap04-1/"},{"categories":["PRML"],"content":"4.1.6 Fisher’s discriminant for multiple classes skip ","date":"2021-11-26","objectID":"/prml-chap04-1/:1:6","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (1)","uri":"/prml-chap04-1/"},{"categories":["PRML"],"content":"4.1.7 The perceptron algorithm perceptron 특징 2 class에서만 사용가능하다. based on linear combination of fixed basis function target을 이전에는 주로 1,0 으로 했는데 여기서는 -1, 1 로 코딩한다. perceptron criterion (error function) $$E_p ({\\bf w}) = -\\sum_{n \\in M}{\\textbf{w}^T \\phi_n t_n}$$ $M$은 잘못분류한 케이스를 의미한다. 우리는 이 criterion을 최소화 하고자 한다. $\\textbf{w}^T \\phi_n \u003e 0$ 이면 1로 분류 $\\textbf{w}^T \\phi_n \u003c 0$ 이면 -1로 분류 따라서 분류를 잘못하면 ${\\textbf{w}^T \\phi_n t_n} \u003c 0$ 이고 error가 커지는 것이다. 위 perceptron criterion을 SGD로 iterative하게 계산하면 $${\\bf w}^{(\\tau+1)}={\\bf w}^{(\\tau)}-\\eta\\triangledown E_p({\\bf w})={\\bf w}^{(\\tau)}+\\eta\\phi_n{t_n}$$ ($\\eta$는 learning rate) 이다. 이를 쉽게 해석하면 분류가 맞으면 놔두고 틀리면 그 $\\phi_n$ 만큼 더하고 빼고 하는 것이다. 양변에 $-\\phi_n t_n$을 곱하면 에러가 줄어듬(parameter가 converge)을 알 수 있다. $$-{\\bf w}^{(\\tau+1)T}{\\phi}_n{t_n} = -{\\bf w}^{(\\tau)T}{\\phi_n}{t_n}-(\\phi_n{t_n})^T\\phi_n{t_n} \u003c -{\\bf w}^{(\\tau)T}\\phi_n{t_n}$$ perceptron convergence theorem training data set is linearly separable 하면 perceptron algorithm수렴한다 (반드시 해당하는 decision boundary를 찾을 수 있다) . 아니면 수렴이 안된다. 수렴하기 전까지 이게 non separable 문제인지 아니면 수렴이 천천히 되는 건지 파악하기 어렵다. ","date":"2021-11-26","objectID":"/prml-chap04-1/:1:7","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (1)","uri":"/prml-chap04-1/"},{"categories":["PRML"],"content":"4.2 Probabilistic Generative Models data의 분포에 대한 가정을 갖는 decision boundary에 대해 공부해보자. $p(x|C_k), p(C_k)$로 베이즈정리를 이용하여 posterior를 계산한다. (일단 binary classification의 경우) posterior probability for class 1 : $$p(C_1 | {\\bf x}) = \\frac{p({\\bf x}|C_1)p(C_1)}{p({\\bf x}|C_1)p(C_1)+p({\\bf x}|C_2)p(C_2)}$$ $$ = \\frac{1}{1+\\frac{p({\\bf x}|C_2)p(C_2)}{p({\\bf x}|C_1)p(C_1)}} = \\frac{1}{1+exp(-a) } = \\sigma (a)$$ $$\\text{where}\\; a = \\ln \\frac{p(x|C_1)p(C_1)}{p(x|C_2)p(C_2)}$$ $\\sigma (x) = \\frac{1}{1+exp(-x) }$ 이 식은 logistic sigmoid function 이다. 이의 inverse는 $x=\\ln (\\frac{\\sigma}{1-\\sigma})$ 이고 logit function이라고 한다. 이번에는 일반적인 경우에 대해 살펴보자. multi class의 경우 $$p(C_k | {\\bf x}) = \\frac{p({\\bf x}|C_k)p(C_k)}{\\sum p({\\bf x}|C_j)p(C_j)} = \\frac{exp(a_k)}{\\sum_j exp(a_j)}$$ $$\\text{where}\\; a_k = \\ln p({\\bf x}|C_k)p(C_k)$$ 이를 normalized exponential or softmax function 이라고 한다. ","date":"2021-11-26","objectID":"/prml-chap04-1/:2:0","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (1)","uri":"/prml-chap04-1/"},{"categories":["PRML"],"content":"4.2.1 Continuous inputs class-conditional density를 Gaussian이라고 가정하고 posterior를 살펴보자. 단 모든 class는 같은 covariance matrix를 가진다. (2-class) $$p({\\bf x}|C_k) = \\dfrac{1}{(2\\pi)^{D/2}|\\Sigma|^{1/2}}\\exp \\{-\\dfrac{1}{2}({\\bf x} - {\\pmb \\mu}_k)^T\\Sigma^{-1}({\\bf x} - {\\pmb \\mu}_k)\\} $$ 이므로 이를 이용해 위에서 구한 posterior를 계산하면 $a = \\ln \\frac{p(x|C_1)p(C_1)}{p(x|C_2)p(C_2)}$ $$p(C_1 | {\\bf x}) =\\sigma (a) = \\sigma ({\\bf w}^T {\\bf x} + w_0)$$ $${\\bf w} = \\Sigma^{-1}({\\pmb \\mu_1}-{\\pmb \\mu_2})$$ $$w_0 = -\\frac{1}{2}{\\pmb \\mu_1}^T\\Sigma^{-1}{\\pmb \\mu_1} + \\frac{1}{2}{\\pmb \\mu_2}^T\\Sigma^{-1}{\\pmb\\mu_2} + \\ln{\\frac{p(C_1)}{p(C_2)}}$$ 의 형태가 나온다. class-conditional density를 Gaussian이라고 가정하였기 때문에 logistic sigmoid안에서 ${\\bf x}$ 의 linear function의 형태가 나온다. K-class의 경우 $$a_k({\\bf x})=\\ln(p({\\bf x}|C_k)p(C_k)) = {\\bf w}^T_k {\\bf x}+w_0$$ $${\\bf w}_k = \\Sigma^{-1}{\\pmb \\mu}_k$$ $$w_{k0} = -\\frac{1}{2}{\\pmb \\mu}_{k}^{T} \\Sigma^{-1}{\\pmb \\mu}_k + \\ln p(C_k)$$ posterior의 decision boundary는 input space에 linear하다. (공분산이 동일하다는 가정하에서) 공분산을 각 class마다 다르다고 가정하면 우리는 quadratic function of ${\\bf x}$를 얻게 되고 이는 quadratic discriminant 이다. 이처럼 posterior probability는 $$p({\\bf x}|C_k) = f(\\text{linear of}\\;{\\bf x})$$ 의 형태가 된다. ","date":"2021-11-26","objectID":"/prml-chap04-1/:2:1","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (1)","uri":"/prml-chap04-1/"},{"categories":["PRML"],"content":"4.2.2 Maximum likelihood solution MLE를 통해 prameter들을 추정해보자. class-conditional에서 Gaussian을 가정하였는데 그에 해당하는 parameter들 이다. prior : $p(C_1) = \\pi , p(C_2) = 1- \\pi$ $p(x_n,C_1) = p(C_1)p({\\bf x}_n|C_1) = \\pi N({\\bf x}_n | {\\pmb \\mu}_1,{\\pmb \\Sigma})$ $p(x_n,C_2) = p(C_2)p({\\bf x}_n|C_2) =(1- \\pi) N({\\bf x}_n | {\\pmb \\mu}_2,{\\pmb \\Sigma})$ Class 1은 1, Class 2는 0 으로 target coding likelihood function : $$p(\\textbf{t} | \\pi, {\\pmb \\mu}_1,{ \\pmb \\mu}_2, {\\pmb \\Sigma} ) = \\prod [\\pi N({\\bf x}_n | {\\pmb \\mu}_1, {\\pmb \\Sigma})]^{t_n}[(1-\\pi)N({\\bf x}_n | {\\pmb \\mu}_2, {\\pmb \\Sigma})]^{1-t_n}$$ 이를 log 취하고 미분하여 MLE를 구하면 (K-class도 동일한 방법으로 구할 수 있다) $$\\pi = \\frac{1}{N} \\sum_{n=1}^{N}{t_n} = \\frac{N_1}{N_1 + N_2}$$ $${\\pmb \\mu} _ 1 = \\frac{1}{N_1} \\sum_{n=1}^{N}t_n {\\bf x} _ n, {\\pmb \\mu} _ 2 = \\frac{1}{N_2}\\sum_{n=1}^{N}(1-t_n){\\bf x}_n$$ $${\\pmb \\Sigma} = {\\bf S} = \\frac{N_1}{N}{\\bf S}_1 + \\frac{N_2}{N}{\\bf S}_2$$ ","date":"2021-11-26","objectID":"/prml-chap04-1/:2:2","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (1)","uri":"/prml-chap04-1/"},{"categories":["PRML"],"content":"4.2.3 Discrete features 각 input data feature가 2가지의 값을 갖는 discrete feature들이라고 가정해보자. 그러면 총 $2^D$의 경우 수가 생긴다. 이를 추정하기에는 너무 복잡하다. 따라서 naive bayes의 가정을 이용하면 $$p({\\bf x}|C_k) = \\prod_{i=1}^{D}\\mu_{ki}^{x_i}(1-\\mu_{ki})^{1-x_i} $$ $$a_k({\\bf x})=\\ln(p({\\bf x}|C_k)p(C_k))$$ $$a_k({\\bf x})=\\sum_{i=1}^{D}\\{x_i\\ln \\mu_{ki}+(1-x_i)\\ln(1-\\mu_{ki})\\}+\\ln p(C_k)$$ 이 또한 linear한 형태이다. ","date":"2021-11-26","objectID":"/prml-chap04-1/:2:3","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (1)","uri":"/prml-chap04-1/"},{"categories":["PRML"],"content":"4.2.4 Exponential Family 위에서 알 수 있듯이 input이 Gaussian이던 discrete이던지 우리에게 가장 중요한 posterior class probability는 generalized linear model과 sigmoid, softmax activation function에 의해 결정된다. 이러한 특징은 class-conditional density가 exponential family의 경우 해당한다. $$p({\\bf x};|\\lambda_k) = h({\\bf x})g(\\lambda_k)\\exp(\\lambda_k^T u({\\bf x})) $$ 여기서 제약을 위한 parameter $s$를 추가하고 (잘 이해못함) $$p({\\bf x};|\\lambda_k, s) = \\dfrac{1}{s}h\\left(\\dfrac{1}{s}{\\bf x}\\right)g\\left(\\lambda_k\\right)\\exp \\left(\\dfrac{1}{s}\\lambda_k^T u({\\bf x})\\right)$$ linear function을 구할 수 있다. $$a({\\bf x})=\\dfrac{1}{s}(\\lambda_1-\\lambda_2)^T{\\bf x}+\\ln g(\\lambda_1) - \\ln g(\\lambda_2) + \\ln p(C_1) - \\ln p(C_2)$$ $$a_k({\\bf x}) = \\dfrac{1}{s}\\lambda_k^T{\\bf x}+\\ln g(\\lambda_k) + \\ln p(C_k)$$ link function과 exp fam의 관계 EX) Bernoulli dist $$L(\\theta) = \\prod \\theta^{x_i}(1-\\theta)^{1-x_i}= \\exp {\\sum{x_i \\log \\theta}+ \\sum{(1-x_i)\\log (1-\\theta)} } $$ $$=\\exp { \\sum{x_i} \\log(\\frac{\\theta}{1-\\theta}) }(1-\\theta)^n$$ 위의 식에서 $\\log (\\frac{\\theta}{1-\\theta})$ 가 link function이다. $\\log (\\frac{\\theta}{1-\\theta}) = \\beta_0 + \\beta_1 x_1+…+\\beta_n x_n$ 이 이제 배울 logistic regression 이다. ","date":"2021-11-26","objectID":"/prml-chap04-1/:2:4","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (1)","uri":"/prml-chap04-1/"},{"categories":["PRML"],"content":"Regression에 대해 알아보자. ","date":"2021-11-26","objectID":"/prml-chap03-2/:0:0","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (2)","uri":"/prml-chap03-2/"},{"categories":["PRML"],"content":"3.3 Bayesian Linear Regression 이전에 우리는 maximum likelihood 방법을 통해 linear regression 의 parameter를 구하는 방법을 공부했다. 이는 몇 가지 특징(단점)이 있는데 MLE 는 overfitting의 위험이 있다. 적절한 model complexity를 정해야 한다. by basis function의 수 regularization coefficient 우리는 한정적인 dataset을 갖고 있기에 적절한 model complexity를 정하기 위해서는 cross validation과 같은 computationally expensive한 방법을 사용해야한다. 위와 같은 단점들을 해결하기 위해 우리는 Bayesian 방법론을 사용할 것이다. MAP는 uncertainty를 표현할 수 없기 때문에 distribution을 이용한다. ","date":"2021-11-26","objectID":"/prml-chap03-2/:1:0","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (2)","uri":"/prml-chap03-2/"},{"categories":["PRML"],"content":"3.3.1 Parameter distribution 이전에 likelihood function $p(t|{\\bf w})$ 이 Gaussian 이었다. 이에 대한 conjugate prior로 Gaussian을 가정한다. prior distribution은 $$p({\\bf w}) = N({\\bf m}_0, {\\bf S}_0) $$ likelihood function과 prior를 곱해 posterior를 계산하면 (계산과정은 생략, monk영상을 보면 된다) $$p({\\bf w}|{\\bf t}) = N({\\bf m}_N, {\\bf S}_N)$$ ${\\bf m}_N = {\\bf S}_N({\\bf S}_0^{-1} {\\bf m}_0 + \\beta { \\bf \\Phi}^T {\\bf t})$ ${\\bf S}_N^{-1} = {\\bf S}_0^{-1}+\\beta {\\bf \\Phi}^T {\\bf \\Phi}$ $\\beta$ : (target error term) noise precision parameter (assume known) Gaussian은 mean과 mode(최빈값)가 같은 값을 갖기 때문에 ${\\bf w}_{MAP} = {\\bf m}_N$ 이다. 만약 infinite broad prior인 경우 (${\\bf S}_0 = \\alpha^{-1}{\\bf I},\\alpha \\rightarrow 0$) 수식을 전개해보면 ${\\bf m}_N \\rightarrow {\\bf m} _ {ML}$ 반대로 $N \\rightarrow 0$ 이면 posterior 는 prior로 가까워진다. 복잡해 보이는 prior를 다소 간단한 형태로 정하면 $p({\\bf w}|\\alpha) = N(0, \\alpha^{-1}I)$ 으로 생각할 수 있다. 이 prior에서 posterior의 mean, precision은 $${\\bf m}_N = \\beta {\\bf S}_N {\\bf \\Phi}^T {\\bf t}$$ $${\\bf S}_N^{-1} = \\alpha {\\bf I} + \\beta {\\bf \\Phi}^T {\\bf \\Phi}$$ log of posterior distribution (log of likelihood function과 log of prior의 합) 은 $$\\ln p({\\bf w}|{\\bf t}) = -\\frac{\\beta}{2}\\sum_{n=1}^{N}{t_n-{\\bf w}^T\\phi({\\bf x}_n)}^2 - \\frac{\\alpha}{2}{\\bf w}^T{\\bf w}+const$$ 이는 결국 minimization of the sum of square with quadratic regulrarization($\\lambda = \\frac{\\alpha}{\\beta}$) 과 같은 수식이다. ","date":"2021-11-26","objectID":"/prml-chap03-2/:1:1","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (2)","uri":"/prml-chap03-2/"},{"categories":["PRML"],"content":"3.3.2 Predictive distribution 우리의 최종 목표는 predictive distribution 이다. $$p(t|{\\bf t}, \\alpha, \\beta) = \\int p(t|{\\bf w}, \\beta)p({\\bf w}|{\\bf t}, \\alpha, \\beta)d{\\bf w} $$ predictive distribution을 보면 target의 conditional distribution $p(t | w,\\beta)=N(t | y(w,x), \\beta^{-1})$ 와 weight parameter ${\\bf w}$의 posterior distribution으로 만들어졌다. 이를 토대로 정리하면 $$p(t|{\\bf t}, \\alpha, \\beta) = N({\\bf m}_N^T\\phi({\\bf x}), \\sigma_N^2({\\bf x})) $$ variance : $\\sigma_N^2({\\bf x}) = \\frac{1}{\\beta} + \\bf \\phi({\\bf x})^T {\\bf S}_N\\phi({\\bf x})$ 이 variance에서 첫번째 항은 data의 noise이고 (앞부분을 찾아보자) 뒷부분이 ${\\bf w}$의 uncertainty를 나타낸다. noise와 ${\\bf w}$ distribution은 independent하기에 두 값을 더한게 variance가 된것이다. N이 커질수록 posterior는 narrow해지므로 뒷부분은 0으로 간다. ","date":"2021-11-26","objectID":"/prml-chap03-2/:1:2","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (2)","uri":"/prml-chap03-2/"},{"categories":["PRML"],"content":"3.3.3 Equivalent kernel 위에 $w$에 대해 구한 값을 토대로 mean of predictive distribution은 $$y({\\bf x}, {\\bf m} _ N) = {\\bf m} _ N^T\\phi({\\bf x}) = \\beta \\phi({\\bf x})^T {\\bf S} _ N \\Phi^T {\\bf t} \\\\ = \\sum_{n=1}^N \\beta \\phi({\\bf x})^T {\\bf S}_N \\phi({\\bf x}_n)t_n $$ 특정 ${\\bf x}$에 대한 mean of predictive dist 은 결국 training set target t의 linear combination 이다. 이를 다르게 표현하면 $$y({\\bf x}, {\\bf m} _ N) = \\sum_{n=1}^N k({\\bf x}, {\\bf x}_n)t_n$$ $k({\\bf x}, {\\bf x}’) = \\beta \\phi({\\bf x})^T {\\bf S}_N \\phi({\\bf x}’)$ : 이 식을 smoother matrix or equvalent kernel 라고 부른다. 따라서 mean of predictive distribution at $x$ 은 $x$와 (비슷한)가까운 data에 해당하는 $t$에 높은 가중치를 준다. equvalent kernel에 대해서 covariance의 측면으로 살펴보자. $$cov[y({\\bf x}), y({\\bf x}’)] = cov[\\phi({\\bf x})^T{\\bf w}, {\\bf w}^T\\phi({\\bf x}’)] = \\phi({\\bf x})^T{\\bf S}_N\\phi({\\bf x}’)=\\beta^{-1}k({\\bf x}, {\\bf x}’) $$ equvalent kernel의 형태에서 근처의 points들의 predictive mean는 상관관계가 높다는 것을 알 수 있다. ","date":"2021-11-26","objectID":"/prml-chap03-2/:1:3","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (2)","uri":"/prml-chap03-2/"},{"categories":["PRML"],"content":"3.4 Bayesian Model Comparison Bayesian의 입장에서 model selection을 바라보고자 한다. 모델을 선택하는 과정에 있어서 확률적인 내용을 많이 사용한다. maximum likelihood와 관련한 overfitting 문제는 marginalizing over the model parameters instead of making point estimates of their values 로 해결 할 수 있다. 모델은 training data를 통해 바로 정할 수 있으므로 validation set이 필요없다. 따라서 모든 데이터를 학습시킬 수 있고 불필요한 검증과정을 없앨 수 있다. 이제 L개의 ${M_i}$ model이 있다고 하자. 이제 이 model들을 random variable으로 생각하고 model에 대한 uncertainty는 확률로 표현한다. $$p(M_i | D) \\propto p(M_i)p(D | M_i) $$ 일단 model에 대한 prior는 다 같다고 가정하자. 따라서 우리의 주 관심은 model evidence(=marginal likelihood) : $p(D/M_i)$ model을 이루는 parameter들이 marginalized out 되었기에 marginal likelihood라고도 부름 (뒷 부분에 나옴) Bayes factor ratio of model evidence s $p(D|M_i)p(D|M_j)$ model의 posterior를 알고 이를 이용하여 predictive distribution을 구하면 $$p(t|{\\bf x}, D) = \\sum_{i=1}^{L} p(t|{\\bf x}, M_i, D)p(M_i|D)$$ 이다. (mixture distribution의 모습) 이는 model posterior를 가중치로 하여 평균을 낸 것으로 볼 수 있다. 위와 같은 model averaging의 값과 가장 근사하는 좋은 model 하나를 찾고자 한다. 이를 model selection 이라고 한다. model evidence (${\\bf w}$는 model에 관한 parameter) 이를 sampling 측면에서 바라보면, marginal likelihood는 data set D를 생성하는 probability로 볼 수 있는데 여기서 D는 prior로 부터 random하게 뽑힌 parameter들로 이루어진 model에서 만들어진 것이다. 또한, evidence는 Bayes’ Them에서 분모에 해당하는 normalizing term을 의미하기도 한다 : $p({\\bf w}| D, M_i) = \\frac{p(D | {\\bf w}, M_i) p({\\bf w} | M_i)}{p(D | M_i)}$ $$p(D|M_i) = \\int p(D|{\\bf w}, M_i)p({\\bf w}|M_i)d{\\bf w}$$ 이제 model evidence에 대해 더 알아보자. model이 single parameter $w$ 를 갖고 있다고 가정 notation $M_i$는 생략 $w$의 posterior는 $p(D|w)p(w)$에 비례 posterior는 $w_{MAP}$ 에서 peaked 된 상태이고 그 때 width는 $\\vartriangle w_{posterior}$ 라고 가정 prior는 flat with width $\\vartriangle w_{prior}$, 따라서 $p(w) = 1/\\vartriangle w_{prior}$ $$p(D) = \\int p(D | w)p(w)dw \\simeq p(D | w_{MAP}) \\frac{1}{\\vartriangle w_{prior}} \\vartriangle w_{posterior}$$ log를 씌우면 $$\\ln p(D) \\simeq \\ln p(D|w_{MAP}) + \\ln (\\frac{\\vartriangle w_{posterior}}{\\vartriangle w_{prior}})$$ 첫번째 항 : 이 data를 가장 잘 표현하는 파라미터에 대한 확률값으로 log likelihood 의미 두번째 항 : model complexity에 대한 penalty 항 우리는 $\\ln p(D|M_i)$ 가 가장 큰 model($M_i$)을 찾는 것이 목표이다. complex가 높은 model를 구하면 첫번째 항이 커질 것이지만 두번째 항은 $\\vartriangle w_{posterior}$ 이 narrow 해지면서 음수가 되고 점점 작아진다. trade-off 관계인 것이다. 따라서 적절한 complexity가 있는 model을 선택하게 된다. $\\ln p(D | M_i) = accuracy(M_i) - complexity(M_i)$ 느낌 AIC, BIC를 예시로 생각할 수 있다. M 개의 parameter가 있을 경우 위에서 설명한 부분과 같다. 뒷 부분에 M이 추가되어 M이 커지면서 더 penalty를 준다. $$\\ln p(D | \\textbf{w} _ {MAP}) + M \\ln (\\frac{\\vartriangle w_{posterior}}{\\vartriangle w_{prior}})$$ optimal model complexity (model selection) 는 maximum evidence 으로 정해진다는 것 을 기억하자. ","date":"2021-11-26","objectID":"/prml-chap03-2/:2:0","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (2)","uri":"/prml-chap03-2/"},{"categories":["PRML"],"content":"3.5 The Evidence Approximation linear basis model에서 완전한 Bayesian 접근법을 위해서 ${\\bf w}$에 대한 hyperparameter $\\alpha, \\beta$의 prior를 고려해보자. predictive distribution은 아래와 같이 구할 수 있다. (${\\bf x}$ 표시는 생략) $p(t|{\\bf w})$ : distribution of target ($=N(y(x,{\\bf w}), \\beta^{-1})$) $p({\\bf w}|{\\bf t}, \\alpha, \\beta)$ : posterior of ${\\bf w}$ $p(\\alpha, \\beta | {\\bf t})$ : posterior of $\\alpha, \\beta$ $$p(t|{\\bf t}) = \\iiint p(t|{\\bf w}, \\beta) p({\\bf w}|{\\bf t}, \\alpha, \\beta) p(\\alpha, \\beta | {\\bf t}) d{\\bf w}d\\alpha d\\beta $$ 하지만 여기서 문제가 발생한다. 위처럼 모든 변수에 대해 marginalize하는 것은 항상 가능한 것이 아니다 (analytically intractable). 그래서 우리는 hyperparameter를 특정한 값으로 approximation한다. 그 방법은 maximizing marginal likelihood function이다. 이러한 방법론을 evidence approximation (통계에서는 emprical Bayes, type 2 maximum likelihood, generalized maximum likelihood) 라고 부른다. 만약에 posterior distribution $p(\\alpha, \\beta | {\\bf t})$ 가 특정한 값 $\\hat{\\alpha}, \\hat{\\beta}$에서 가장 높은 값(peaked)을 가진다면 predictive distribution은 ${\\bf w}$에 대해서만 marginalize해서 구할 수 있을 것이다. $$p(t|{\\bf t}) \\simeq p(t|{\\bf t}, \\hat{\\alpha}, \\hat{\\beta}) = \\int p(t|{\\bf w}, \\hat{\\beta})p({\\bf w}|{\\bf t}, \\hat{\\alpha}, \\hat{\\beta})d{\\bf w}$$ posterior distribution for $\\alpha, \\beta$ 는 $$p(\\alpha, \\beta | {\\bf t}) \\propto p({\\bf t}|\\alpha, \\beta) p(\\alpha, \\beta) $$ prior는 flat 하다고 가정하자. 따라서 우리는 $\\hat{\\alpha}, \\hat{\\beta}$를 구하기 위해서 marginal likelihood function $p({\\bf t} | \\alpha, \\beta)$ 을 최대로 만드는 찾으면 된다. 이를 통해 우리는 cross validation과 같은 방법이 아니라 한 번에 hyperparameter를 찾을 수 있다. 찾는 방법은 미분을 이용하는 방법, EM 알고리즘을 이용하는 방법이 있다. 전자는 이제 살펴볼 것이고 후자는 9장에서 배운다. ","date":"2021-11-26","objectID":"/prml-chap03-2/:3:0","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (2)","uri":"/prml-chap03-2/"},{"categories":["PRML"],"content":"3.5.1 Evaluation of the evidence function marginal likelihood function은 parameter ${\\bf w}$를 marginalize해서 얻을 수 있다. $p({\\bf t}|{\\bf w}, \\beta)$ : likelihood function $p({\\bf w}|\\alpha)$ : prior of w $$p({\\bf t}|\\alpha, \\beta) = \\int p({\\bf t}|{\\bf w}, \\beta) p({\\bf w}|\\alpha) d{\\bf w}$$ 위의 식을 Gaussian의 형태를 이용하여 정리해보자. (과정은 생략, PRML 연습문제에 있다) $$p({\\bf t}|\\alpha, \\beta) = \\left(\\frac{\\beta}{2\\pi}\\right)^{N/2}\\left(\\frac{\\alpha}{2\\pi}\\right)^{M/2} \\int \\exp{-E({\\bf w})}d{\\bf w}$$ $$E({\\bf w}) = \\beta E_D({\\bf w}) + \\alpha E_w({\\bf w}) = \\frac{\\beta}{2}|{\\bf t} - \\Phi{\\bf w}|^2 + \\frac{\\alpha}{2}{\\bf w}^T{\\bf w} $$ $$E({\\bf w}) = E({\\bf m}_N)+\\frac{1}{2}({\\bf w}-{\\bf m}_N)^T {\\bf A} ({\\bf w} - {\\bf m}_N) $$ ${\\bf A} = \\alpha {\\bf I} + \\beta \\Phi^T\\Phi$ ${\\bf m}_N = \\beta {\\bf A}^{-1}\\Phi^T{\\bf t}$ 이제 이를 이용하면 $$\\int \\exp\\left(-E({\\bf w})\\right) d{\\bf w} = \\exp(-E({\\bf m}_N))\\int \\exp \\{ -\\frac{1}{2}({\\bf w}-{\\bf m}_N)^T {\\bf A} ({\\bf w}-{\\bf m}_N) \\} d { \\bf w} \\\\ = \\exp\\{-E({\\bf m}_N)\\}(2\\pi)^{M/2}|{\\bf A}|^{-1/2}$$ 이를 이용하여 최종적으로 log marginal likelihood function을 구하면 $$\\ln p({\\bf t}|\\alpha, \\beta) = \\frac{M}{2}\\ln \\alpha + \\frac{N}{2}\\ln \\beta - E({\\bf m}_n) - \\frac{1}{2}\\ln |{\\bf A}| - \\frac{N}{2}\\ln(2\\pi)$$ ","date":"2021-11-26","objectID":"/prml-chap03-2/:3:1","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (2)","uri":"/prml-chap03-2/"},{"categories":["PRML"],"content":"3.5.2 Maximizing the evidence function $\\ln p({\\bf t} | \\alpha, \\beta)$을 최대화하는 $\\alpha, \\beta$를 구하기 위해 미분을 이용해보자. $(\\beta \\Phi^T \\Phi) {\\bf \\mu}_i = \\lambda_i{\\bf \\mu}_i$ 라고 하면 ${\\bf A}$의 eigenvalue는 $\\alpha + \\lambda_i$ 이다. 따라서 $$\\frac{d}{d\\alpha}\\ln |{\\bf A}| = \\frac{d}{d\\alpha}\\ln \\prod_{i}(\\lambda_i+\\alpha) = \\frac{d}{d\\alpha}\\sum_i \\ln(\\lambda_i+\\alpha) = \\sum_i \\frac{1}{\\lambda_i + \\alpha}$$ $\\alpha$에 대해 미분 $$0 = \\frac{M}{2\\alpha} - \\frac{1}{2}{\\bf m}_N^T{\\bf m}_N - \\frac{1}{2}\\sum_i \\frac{1}{\\lambda_i+\\alpha}$$ $$\\alpha {\\bf m} _ N^T {\\bf m} _ N = M - \\alpha \\sum_{i=1}^{M} \\frac{1}{\\lambda_i+\\alpha} = \\gamma$$ 이를 다시 정리하면 $$\\gamma = \\sum_{i=1}^{M} \\frac{\\lambda_i}{\\alpha + \\lambda_i}$$ 최종적으로 $\\alpha$에 대해 정리하면 $$\\alpha = \\frac{\\gamma}{ {\\bf m}_N^T{\\bf m}_N} $$ 그런데 $\\gamma, {\\bf m}_N$ 모두 $\\alpha$에 depend한다. 따라서 이를 위해서 iterative한 방법을 사용한다. 임의의 수로 $\\alpha$를 시작하고 $\\gamma, {\\bf m}_N$을 구한다. 다시 이 두 값으로 $\\alpha$를 구한다. 이렇게 수렴할 때까지 반복하는 것이다. $\\beta$에 대해 미분 $$\\frac{d}{d\\beta} \\ln |{\\bf A}| = \\frac{d}{d\\beta}\\sum_i \\ln(\\lambda_i+\\alpha) = \\frac{1}{\\beta}\\sum_i\\frac{\\lambda_i}{\\lambda_i+\\alpha} = \\frac{\\gamma}{\\beta}$$ $$0 = \\frac{N}{2\\beta} - \\frac{1}{2}\\sum_{n=1}^N{t_n-{\\bf m}_N^T\\phi({\\bf x}_n)}^2 - \\frac{\\gamma}{2\\beta} $$ $$\\frac{1}{\\beta} = \\frac{1}{N-\\gamma}\\sum_{n=1}^N {t_n-{\\bf m}_N^T\\phi({\\bf x}_N)}^2 $$ 이도 마찬가지도 iterative하게 구한다. cross validation과 같은 추가적인 computation이 없이 한 번에 train data set을 모두 이용하여 model complexity를 정할 수 있다 는 점을 기억하자. ","date":"2021-11-26","objectID":"/prml-chap03-2/:3:2","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (2)","uri":"/prml-chap03-2/"},{"categories":["PRML"],"content":"3.5.3 Effective number of parameters 이 부분은 ridge regression의 내용 (data의 고윳값이 작은 방향의 parameter가 0에 가까워진다) 과 같다. ESL 책의 linear regression부분을 보면 알 수 있다. $\\alpha$에 대한 Bayesian의 접근에 대해 조금 더 살펴보자. $\\beta \\Phi^T \\Phi$는 positive definite matrix이므로 eigenvalue가 모두 0이상의 값을 갖는다. 따라서 $0 \\le \\lambda_i /(\\lambda_i + \\alpha) \\le 1$ $0 \\le \\gamma \\le 1$ 임을 알 수 있다. $\\lambda_i » \\alpha$ 인 경우는 이에 해당하는 parameter $w_i$가 maximum likelihood의 값과 가까워지고 $\\lambda_i /(\\lambda_i + \\alpha)$ 이 1에 가까워진다. 반대의 경우는 $w_i, \\lambda_i /(\\lambda_i + \\alpha)$ 모두 0에 가까워진다. 따라서 $\\gamma$는 measures the effective total number of well determined parameters 다음은 $\\beta$에 대해 알아보자. 위에서 보았듯이 effective number of parameter는 $\\gamma$이고 나머지 $M-\\gamma$개의 parameters 들이 prior에 의해 작은 값을 갖는다. 이것이 variance에서 $\\frac{1}{N-\\gamma}$로 나타나고 bias of maximum likelihood result를 바로 잡아준다. 만약에 $N » M$의 상황인 경우, 대부분의 parameter들이 well determined될 것이고 data size에 따라 eigenvalue도 커지게 된다. 그러면 $\\gamma = M$이 되고 evidence approximation도 아래 값을 이용해 간단해진다. (data 많은게 짱이다) $$\\alpha = \\frac{M}{2E_W({\\bf m}_N)}$$ $$\\beta = \\frac{N}{2E_D({\\bf m}_N)}$$ ","date":"2021-11-26","objectID":"/prml-chap03-2/:3:3","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (2)","uri":"/prml-chap03-2/"},{"categories":["PRML"],"content":"3.6 Limitations of Fixed Basis Functions 장점 nonlinear basis functions의 linear combination이니까 해석이 쉽다. closed form의 해가 존재한다. 단점 basis function이 training data를 보기 전에 이미 fixed되서 시작한다. 차원의 저주 input간의 correlation 때문에 보다 작은 차원에 nonlinear manifold에 데이터가 분포할 수 있다. ","date":"2021-11-26","objectID":"/prml-chap03-2/:4:0","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (2)","uri":"/prml-chap03-2/"},{"categories":["PRML"],"content":"Regression에 대해 알아보자. 목표는 predictive distribution $p(t|x)$를 찾는 것 주로 loss funciton은 squared loss를 사용하며 이 때 optimal solution은 conditional expectation of t : $E[t|x]$ ","date":"2021-11-26","objectID":"/prml-chap03-1/:0:0","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (1)","uri":"/prml-chap03-1/"},{"categories":["PRML"],"content":"3.1 Linear Basis Function Models 가장 기본적인 linear model for regression은 $$y(x,w) = w_0+w_1x_1+…+w_D x_D$$ 의 형태일 것이다. 하지만 basis function $\\phi_ j(\\textbf{x})$을 이용하여 nonlinear의 성질을 추가할 수 있다. basis function은 다양하다. gaussian distribution의 형태 polynomial의 형태 원래의 input data를 마음대로 변화가능 $$y(\\textbf{w},\\textbf{x}) = w_0 + \\sum_{j=1}^{M-1}{w_j \\phi_j(\\textbf{x})} = \\textbf{w}^T {\\pmb \\phi}( \\textbf{x})$$ 하지만 여전히 linear model이다. 여기서 linear의 의미는 계수 w에 linear하다는 의미이기 때문이다. 그렇기에 여전히 interpretation에 대한 장점은 갖고 있다. 단점은 너무 단순하다는 것이다. ","date":"2021-11-26","objectID":"/prml-chap03-1/:1:0","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (1)","uri":"/prml-chap03-1/"},{"categories":["PRML"],"content":"3.1.1 Maximum likelihood and least sqaures $t$ : target variable $y(\\textbf{x}, \\textbf{w})$ : deterministic funciton $\\epsilon \\sim N(0, \\beta^{-1})$ : noise $$t = y(\\textbf{x}, \\textbf{w})+ \\epsilon$$ $$p(t | \\textbf{x},\\textbf{w},\\beta) = N(y(\\textbf{x}, \\textbf{w}), \\beta^{-1})$$ 위의 gaussian 가정에서는 parameter $w$를 추정할 때, likelihood를 이용하는 것과 least square의 방법을 이용하는 것이 똑같다. (그 과정은 직접 해보면 쉽게 파악가능, chapter1에도 있다) optimal prediction은 conditional mean of the target variable 이므로 unimodal이라는 한계가 존재 $$E[t | {\\bf x}] = \\int tp(t | {\\bf x})dt = y({\\bf x}, {\\bf w}) $$ 이제 likelihood function을 통해 MLE를 구하는 과정을 간단히 살펴보자. $$\\ln{p({\\bf t}|{\\bf w}, \\beta)} = \\sum_{n=1}^{N}\\ln{N( {\\bf w}^T{\\pmb \\phi}(x_n), \\beta^{-1})}\\\\ =\\dfrac{1}{2}\\ln{\\beta}-\\dfrac{1}{2}\\ln{2\\pi}-\\beta{E_D({\\bf w})}$$ $$E_D({\\bf w})=\\dfrac{1}{2}\\sum_{n=1}^{N}{t_n-{\\bf w}^T {\\pmb \\phi}(x_n)}^2$$ 위의 식을 미분하고 정리하면 ($\\Phi$ : N*M design matrix) normal equation을 얻는다. $${\\bf w}_{ML} = (\\Phi^T\\Phi)^{-1}\\Phi^T{\\bf t} $$ bias : $w_0 = \\bar{t} - \\sum_{j=1}^{M-1}{w_j \\bar{\\phi}_j}$ 실제 얻어지는 샘플들의 타겟 값들의 평균과, 이 때 basis function에 parameter를 곱하여 얻어진 결과의 평균값의 차이를 보정하는 역할 noise precision : $\\frac{1}{\\beta_{ML}} = \\frac{1}{N}\\sum_{n=1}^{N}{{ t_n - w_{ML}^T \\phi(x_n)}^2}$ ","date":"2021-11-26","objectID":"/prml-chap03-1/:1:1","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (1)","uri":"/prml-chap03-1/"},{"categories":["PRML"],"content":"3.1.2 Geometry of least squares least square의 방법에서 우리가 prediction한 값의 의미를 기하학적으로 살펴보자. 증명의 과정은 ESL에 잘 나와있다. 물론 봐도 이해하기는 어렵다. 결론만 언급하자면 “input vector가 span하는 space에 true t의 값을 orthorgonal하게 projection한 값이 우리가 예측한 t의 값이다” 추가적으로 multicolinearity에 대한 해결책으로는 PCA, SVD와 같은 방법으로 input들을 orthorgonal하게 만들어주는 것과 ridge regression과 같이 regulrarization 항이 있는 모델을 쓰는 것이다. ","date":"2021-11-26","objectID":"/prml-chap03-1/:1:2","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (1)","uri":"/prml-chap03-1/"},{"categories":["PRML"],"content":"3.1.3 Sequential learning 이 부분에서는 parameter를 최적화하는 과정에 있어서 gradient descent의 방법을 말하고 있다. 그게 Sequential하게 update하는 것이라 그런 것 같다. 데이터의 크기가 크면 normal equation의 방법이 오래걸리는 단점을 보완할 수도 있다. $$\\textbf{w}^{\\tau+1}=\\textbf{w}^{(\\tau)}+{\\eta}(t_n-{\\bf w}^{(\\tau)T}{\\pmb \\phi}_n) {\\pmb \\phi}_n$$ ","date":"2021-11-26","objectID":"/prml-chap03-1/:1:3","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (1)","uri":"/prml-chap03-1/"},{"categories":["PRML"],"content":"3.1.4 Regularized least squares 기존의 error function에 regularization term을 추가하여서 parameter shrinkage를 하고자 한다. 이를 통해 overfitting을 완화시킨다. lasso 같은 경우 sparse한 model을 만들어서 feature selection의 역할도 한다. regularized error takes the form 아래 식에서 q가 1이면 lasso, 2이면 ridge regression이다. $\\lambda$가 커질수록 model complexity가 낮아진다. $$\\frac{1}{2}\\sum_{n=1}^{N}{{t_n - \\textbf{w}^T{\\pmb \\phi}(x_n)}^2}+ \\frac{\\lambda}{2}\\sum_{j=1}^{M}{ \\left| \\textbf{w}_j\\right|^q }$$ ridge의 경우 error function이 $\\textbf{w}$에 대해 quadratic form이라서 closed form으로 solution이 존재한다. $$w_{ridge} = (\\Phi^T \\Phi + \\lambda I)^{-1}\\Phi^T t$$ ","date":"2021-11-26","objectID":"/prml-chap03-1/:1:4","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (1)","uri":"/prml-chap03-1/"},{"categories":["PRML"],"content":"3.2 The Bias-Variance Decomposition 모델링을 할 때 overfitting을 피하기 위해 제약을 두면 complexity를 못 잡을 수도 있다. 너무 모델을 복잡하게 하면 overfitting이 될 수도 있다. 이는 상당히 어려운 문제이다. 이 부분에 있어서 frequentist의 입장에서 바라보는 bias-variance trade off 관계를 공부하고자 한다. 이해를 위해 square loss (regression)의 경우의 예시를 살펴보자. square loss function 에서 optimal solution : $$E[t | \\textbf{x}] = \\int t p(t | \\textbf{x})dt = h(\\textbf{x})$$ expected squared loss : $$E[L] = \\int { y(\\textbf{x}) - h(\\textbf{x})}^2 p(\\textbf{x})d\\textbf{x} + \\int {h(\\textbf{x}) - t}^2 p(\\textbf{x},t)d\\textbf{x}dt$$ 우리는 우항의 첫번째를 최대한 작게하는 $y(\\textbf{x})$을 만들고자 한다. 위의 식에서 우항의 두번째는 우리가 줄일 수 없는 intrinsic noise이다. 첫 번째 항을 decompose 해보자. 일단 ${ y(\\textbf{x};D) - h(\\textbf{x})}^2$ 값은 특정한 dataset $D$에 대한 값이다. 이제 dataset이 여러개가 있다고 가정하고 이에 대해 average한 경우를 생각해보자. $E_D[y(\\textbf{x};D)]$ 을 더하고 빼서 $$E_D[{ y(\\textbf{x};D)-h(\\textbf{x}) }^2] =\\ {E_D[y(\\textbf{x};D)] -h(\\textbf{x})}^2+ E_D[{ y(\\textbf{x};D) - E_D[y(\\textbf{x};D)]}^2]$$ 이렇게 나타낼 수 있다. 즉, expected loss = (bias)^2 + variance +noise 인 것이다. bias 의미 : average prediction over all datasets 이 우리가 알고 싶은 true (regression) function과 차이나는 정도 variance 의미 : 해당 하나의 dataset이 average 와 차이나는 정도, function $y(\\textbf{x};D)$이 특정한 dataset에 얼마나 민감한지 이 둘은 trade-off 관계 : 한쪽이 커지면 한쪽이 작아진다. 하지만 이런 bias-variance의 관계는 average에 기반을 한 개념이기 때문에(bias, variance의 계산하는 과정이 D에 대해 평균) 한계점이 분명 존재 한다. 우리가 가지고 있는 데이터는 한정적이기 때문이다. 독립적인 데이터가 여러 개이면 각 데이터로 복잡한 모델을 만들어서 평균을 내면 좋은 결과를 얻을 수 있지만 우리는 데이터가 부족하다. 그래서 저자는 Bayesian 접근법을 소개한다. ","date":"2021-11-26","objectID":"/prml-chap03-1/:2:0","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (1)","uri":"/prml-chap03-1/"},{"categories":["PRML"],"content":"+ monk의 설명 정의 MSE of an estimate $\\hat{\\theta} = f(D)$ for $\\theta$ is $$MSE(\\hat{\\theta}) = E[(\\hat{\\theta} - \\theta)^2 | \\theta]$$ $bias(\\hat{\\theta}) = E[\\hat{\\theta}] - \\theta$ $var(\\hat{\\theta}) = E[(\\hat{\\theta}-E[\\hat{\\theta}])^2]$ $$MSE(\\hat{\\theta}) = bias^2(\\hat{\\theta}) + var(\\hat{\\theta})$$ (proof) let $\\mu = E[\\hat{\\theta}]$ $$E[(\\hat{\\theta} - \\theta)^2] = E[(\\hat{\\theta} - \\mu + \\mu -\\theta)^2] \\\\ = E[(\\hat{\\theta} - \\mu)^2 + 2(\\hat{\\theta} - \\mu)(\\mu - \\theta) + (\\mu - \\theta)^2] \\\\ = (\\mu - \\theta)^2 + E[(\\hat{\\theta}-\\mu)^2] \\quad \\because E[(\\hat{\\theta} - \\mu)(\\mu - \\theta)] = 0 $$ 쉬운 예시 $X \\sim N(\\theta,1)$ $\\theta$는 non random, unknown $\\hat{\\theta}_1 = X \\rightarrow bias^2 = 0, var = 1, MSE = 1$ $\\hat{\\theta}_2 = 0 \\rightarrow bias^2 = \\theta^2, var = 0, MSE = \\theta^2$ ","date":"2021-11-26","objectID":"/prml-chap03-1/:2:1","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (1)","uri":"/prml-chap03-1/"},{"categories":["PRML"],"content":"+ 문일철 교수님의 설명 Sources of Error in ML 크게 두 가지로 나눌 수 있다 : Approximation and generalization $E_{out} \\le E_{in} + \\Omega$ $E_{out}$ : estimation error $E_{in}$ : error from approximation by the learning algorithm $\\Omega$ : error caused by the variance of the observations 뒤에서 사용할 notation에 대해 알아보자. $f$ : the target function to learn (true function) $g$ : the learning function of ML $g^{(D)}$ : the learned function by using a dataset $\\bar{g}$ : the average hypothesis of a given infinite numbers of D ( $\\bar{g}(x) = E_D [g^{(D) } (x)]$ ) 하나의 dataset D에 대한 Error는 $$E_{out}[g^{(D)}(x)] = E_x[(g^{(D)}(x) - f(x))^2]$$ 그렇다면 expected error of the infinite dataset은 $$E_D [E_{out}[g^{(D)}(x)] ] = E_D [E_x[(g^{(D)}(x) - f(x))^2]] = E_x [E_D[(g^{(D)}(x) - f(x))^2]]$$ 일단 안쪽에 있는 term부터 확인해보자. $$E_D[(g^{(D)}(x) - f(x))^2] = E_D [( g^{(D)}(x) - \\bar{g}(x) + \\bar{g}(x) - f(x) )^2]$$ $$= E_D [(g^{(D)}(x) - \\bar{g}(x) )^2] + (\\bar{g}(x) - f(x))^2$$ $$\\therefore E_D [E_{out}[g^{(D)}(x)] ] = E_D [(g^{(D)}(x) - \\bar{g}(x) )^2] + (\\bar{g}(x) - f(x))^2 $$ 여기서 우리는 variance와 bias를 정의할 수 있는데 $Var = E_D [(g^{(D)}(x) - \\bar{g}(x) )^2]$ $Bias^2 = (\\bar{g}(x) - f(x))^2$ 이들이 의미하는 바는 var는 제한적인 dataset 때문에 model을 average hypothesis로 훈련시킬 수 없는 부분을 의미 bias는 average hypothesis조차도 (true) real world hypothesis를 맞출수 없는 부분을 의미 그렇다면 var과 bias를 줄이기 위해서는? var를 줄이기 위해서는 data를 더 모은다. bias를 줄이기 위해서는 더 복잡한 model을 사용한다. 하지만 문제는 var와 bias는 trade-off 관계를 가진다. 예를 들어, 우리가 갖고 있는 dataset에 잘 맞는 복잡한 모델을 사용하면 평균적인 모델과는 차이가 커질 것이다. 간단한 model은 낮은 variance, 높은 bias를 갖는다. 복잡한 model은 높은 variance, 낮은 bias를 갖는다. 따라서 적잘한 model을 만드는 것이 관건이다. Occam’s Razor 같은 error를 갖는 모델이라면 둘 중 더 간단한 모델을 선택하라! ","date":"2021-11-26","objectID":"/prml-chap03-1/:2:2","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (1)","uri":"/prml-chap03-1/"},{"categories":["PRML"],"content":"Exponential Family와 Nonparametric 방법론에 대해 알아보자. ","date":"2021-11-26","objectID":"/prml-chap02-4/:0:0","tags":["Exponential Family","Non parametric"],"title":"[PRML] Chapter2 - Probability Distribution (4)","uri":"/prml-chap02-4/"},{"categories":["PRML"],"content":"2.4 The Exponential Family 우리가 이전에 공부했던 대부분의 distribution은 Exponential Family에 속한다. The exponential family of distribution over $x$, given parameters $\\eta$, is defined to be the set of distributions of the form $$p({\\pmb x} | {\\pmb \\eta}) = h({\\pmb x})g({\\pmb \\eta}) \\exp ({\\pmb \\eta}^T u({\\pmb x}))$$ pdf(pmf) $p({\\pmb x} | {\\pmb \\eta})$ 을 우항과 같이 표현할 수 있다면 exponential family에 속한다. ${\\pmb x}$는 스칼라, 벡터 둘 다 가능하고 discrete, continous 모두 가능하다. ${\\pmb \\eta}$ 는 natural parameter of the distribution 이라고 한다. $g(\\pmb \\eta)$는 distribution의 normalize coefficient (적분해서 1이 되도록 만들어주는) 라고 할 수 있다. $$g({\\pmb \\eta}) \\int h({\\pmb x})\\exp{ {\\pmb \\eta}^T{\\pmb u} ({\\pmb x}) } d {\\pmb x}=1 $$ Bernoulli distribution 예시 $p(x | \\mu) = Bern(x | \\mu)=\\mu^x(1-\\mu)^{1-x}$ 이를 exponential form으로 표현해보자. $f(x)=\\exp(\\ln{f(x)})$ 을 이용하여 $$p(x | \\mu) = \\exp {x \\ln \\mu + (1-x) \\ln (1-\\mu) } \\\\ = (1-\\mu) \\exp \\{ \\ln \\left( \\frac{\\mu}{1-\\mu} \\right) x \\} \\\\ \\therefore \\eta = \\ln\\left(\\frac{\\mu}{1-\\mu}\\right) $$ 위의 형태를 $\\mu$에 대한 식으로 바꿔보면 $$\\mu=\\sigma(\\eta)=\\dfrac{1}{1+\\exp(-\\eta)} $$ 위의 식과 같은 형태의 함수를 logistic sigmoid function이라고 부른다. Multinomial distribution 예시 $p({\\pmb x} | {\\pmb \\mu}) = \\prod_{k=1}^{M}\\mu_k^{x_k}= \\exp [\\sum_{k=1}^{M}x_k \\ln \\mu_k]$ $p({\\pmb x}|{\\pmb \\eta})=\\exp({\\pmb \\eta}^T{\\pmb x})$ $\\eta_k = \\ln \\mu_k$ ${\\pmb \\eta} = (\\eta_1, \\eta_2,…,\\eta_k)^T$ M개의 parameter가 있지만 $\\sum_{k=1}^{M}{\\mu_k}=1$ 이라는 제약때문에 M-1개의 값이 정해지면 마지막 M개는 저절로 정해진다. 이를 이용할 것이다. $$\\exp \\{\\sum_{k=1}^{M}x_k\\ln\\mu_k \\} = \\exp \\{\\sum_{k=1}^{M-1}x_k\\ln\\mu_k + \\left(1-\\sum_{k=1}^{M-1}x_k\\right)\\ln\\left(1-\\sum_{k=1}^{M-1}\\mu_k\\right) \\}\\\\ = \\exp\\{\\sum_{k=1}^{M-1}x_k\\ln\\left(\\frac{\\mu_k}{1-\\sum_{j=1}^{M-1}\\mu_j}\\right)+\\ln\\left(1-\\sum_{k=1}^{M-1}\\mu_k\\right)\\}$$ $$\\therefore \\eta_k = \\ln\\left(\\frac{\\mu_k}{1-\\sum_{j \\neq k} \\mu_j}\\right)$$ 똑같이 $$\\mu_k=\\dfrac{\\exp(\\eta_k)}{1+\\sum_{j \\neq k}\\exp(\\eta_j)}$$ 위의 식과 같은 형태의 함수를 softmax function (normalized exponential) 이라고 부른다. ","date":"2021-11-26","objectID":"/prml-chap02-4/:1:0","tags":["Exponential Family","Non parametric"],"title":"[PRML] Chapter2 - Probability Distribution (4)","uri":"/prml-chap02-4/"},{"categories":["PRML"],"content":"2.4.1 Maximum likelihood and sufficient statistics $\\eta$가 어떤 것인지 알았으니 이제 이를 MLE로 estimate해보자. exponential form을 $\\eta$에 대해 미분하면 $$\\nabla g({\\pmb \\eta})\\int h({\\pmb x})\\exp{ {\\pmb \\eta}^T {\\pmb u}({\\pmb x})}d{\\pmb x} + g({\\pmb \\eta})\\int h({\\pmb x})\\exp{ {\\pmb \\eta}^T{\\pmb u}({\\pmb x})}{\\pmb u}({\\pmb x})d{\\pmb x} = 0$$ $g({\\pmb \\eta}) \\int h({\\pmb x})\\exp{ {\\pmb \\eta}^T{\\pmb u} ({\\pmb x}) } d {\\pmb x}=1$ 을 이용하여 $$-\\frac{1}{g({\\pmb \\eta})} \\nabla g({\\pmb \\eta}) = g({\\pmb \\eta})\\int h({\\pmb x})\\exp{ {\\pmb \\eta}^T{\\pmb u}({\\pmb x})}{\\pmb u}({\\pmb x})d{\\pmb x}=E[{\\pmb u}({\\pmb x})]$$ 최종적으로는 $$-\\nabla \\ln g({\\pmb \\eta}) = E[{\\pmb u}({\\pmb x})] $$ 이제 iid인 data를 통해 likelihood function을 만들면 $$p({\\pmb X}|{\\pmb \\eta}) = \\left(\\prod_{n=1}^{N}h({\\pmb x} _ n)\\right) g({\\pmb \\eta})^N \\exp\\{ {\\pmb \\eta}^T\\sum_{n=1}^{N}{\\pmb u}({\\pmb x}_n)\\} $$ log를 취한 뒤에 $\\eta$에 대해 미분하여 0을 갖도록 하면 아래와 같은 식을 얻을 수 있다. $$-\\nabla \\ln g({\\pmb \\eta} _ {ML}) = \\frac{1}{N}\\sum_{n=1}^{N}{\\pmb u}({\\pmb x}_n)$$ 이를 통해 우리는 MLE solution이 오직 $\\sum_{n=1}^{N} \\textbf{u}(\\textbf{x}_n)$에 달려 있다는 것을 알 수 있다. 이는 sufficient statistics of the distribution 이라고 부른다. parameter에 대한 정보가 여기 다 들어 있어서 충분하다! 라고 이해할 수 있다. 따라서 우리는 MLE를 구하는 과정에 있어서 각 data를 모두 알고 있을 필요가 없이 충분통계량만 알면 된다. $N \\rightarrow \\infty$이면 우항은 $E[\\textbf{u}(\\textbf{x})]$이 되고 ${\\pmb \\eta}_{ML}$은 true값으로 수렴한다는 것을 알 수 있다. ","date":"2021-11-26","objectID":"/prml-chap02-4/:1:1","tags":["Exponential Family","Non parametric"],"title":"[PRML] Chapter2 - Probability Distribution (4)","uri":"/prml-chap02-4/"},{"categories":["PRML"],"content":"2.4.2 Conjugate priors exponential family인 prior distribution은 $$p({\\pmb \\eta} | {\\pmb \\chi}, v) = f({\\pmb \\chi}, v)g({\\pmb \\eta})^v \\exp\\{v{\\pmb \\eta}^T{\\pmb \\chi}\\}$$ 여기에 위에서 보았던 likelihood function을 곱하여 posterior distribution을 구하면 $$p({\\pmb \\eta}|{\\pmb X}, {\\pmb \\chi}, v) \\propto g({\\pmb \\eta})^{v+N}\\exp\\{ {\\pmb \\eta}^T\\left(\\sum_{n=1}^{N}{\\pmb u}({\\pmb x})+v{\\pmb \\chi}\\right)\\}$$ conjugacy를 확인할 수 있다. 또한 parameter $v$는 effective nunber of pseudo-observation 이라고 이해할 수 있다. ","date":"2021-11-26","objectID":"/prml-chap02-4/:1:2","tags":["Exponential Family","Non parametric"],"title":"[PRML] Chapter2 - Probability Distribution (4)","uri":"/prml-chap02-4/"},{"categories":["PRML"],"content":"2.4.3 Noninformative priors posterior를 만들기 위해 사전의 정보가 충분하면 상관없지만 그렇지 않은 경우, 우리는 prior의 영향을 최소화하고 싶을 것이다. 이런 prior를 Noninformative prior 라고 부른다. $p(x|\\lambda)$ distribution이 있을 때, prior distribution $p(\\lambda)=\\text{const}$ 가 적절한 prior가 될 것이다. 만약에 $\\lambda$가 $K$ states를 갖는 discrete이면 prior 는 $1/K$로 하면 된다. 하지만 continous하고 domain이 unbounded하면 prior distribution은 합이 1이 되지 않는다 (integral diverge, not correctly normalized). 이런 prior를 improper prior 라고 한다. 적분값이 1이 아닌 diverge하는 모든 분포에 해당하는 것은 아니다. prior는 improper해도 posterior는 적절한 pdf가 되어야 한다. ","date":"2021-11-26","objectID":"/prml-chap02-4/:1:3","tags":["Exponential Family","Non parametric"],"title":"[PRML] Chapter2 - Probability Distribution (4)","uri":"/prml-chap02-4/"},{"categories":["PRML"],"content":"2.5 Nonparametric Methods 말 그대로 비모수적인 방법들이다. 이전까지는 parameter를 추정하여 density를 추정하였다면 아래의 방법들은 parameter를 추정할 필요가 없는 data oriented한 방법이라고 생각할 수 있다. ","date":"2021-11-26","objectID":"/prml-chap02-4/:2:0","tags":["Exponential Family","Non parametric"],"title":"[PRML] Chapter2 - Probability Distribution (4)","uri":"/prml-chap02-4/"},{"categories":["PRML"],"content":"Histogram 주로 같은 크기의 bin으로 해당 data를 나눈 뒤에 해당 bin에 들어가는 data의 수를 통해 density를 파악한다. 기본적인 것으로 저차원에서 시각화용으로만 사용해야 할 것 같다. (Probability 식) : x를 크기 $\\Delta$로 나누고 각 bin i에 들어가는 data의 수를 $n_i$라고 하면 각 bin i의 확률값은 (각 bin의 넓이는 $\\frac{n_i}{N} * \\Delta$ 이고 histogram 전체 넓이는 1이라) $$p_i = \\frac{n_i}{N \\Delta}$$ density는 bin의 크기가 커질수록 smooth해지고 작아질수록 복잡해진다. ","date":"2021-11-26","objectID":"/prml-chap02-4/:2:1","tags":["Exponential Family","Non parametric"],"title":"[PRML] Chapter2 - Probability Distribution (4)","uri":"/prml-chap02-4/"},{"categories":["PRML"],"content":"Kernel density estimators D-dimension의 probability density $p({\\pmb x})$ 있고 우리는 이 값을 추정하려고 한다. data set은 이 분포에서 나온 $N$개의 observation $R$은 data가 들어있는 어떤 지역 이 지역의 probability mass는 $$P=\\int_R p({\\pmb x})d{\\pmb x}$$ 여기서 이 지역에 들어가는 data의 수는 $K$라고 하면 이는 binomial distribution을 따를 것이다. $$Bin(K/N, P) = \\dfrac{N!}{K!(N-K)!}P^K(1-P)^{1-K}$$ data의 수 $N$이 커지면 $K \\approx NP$일 것이다. $R$이 충분히 작아서 density $p({\\pmb x})$는 해당 지역에서 거의 constant하면 $P \\approx p({\\pmb x}) V$ 임을 알 수 있다. ($V$는 volume of $R$) 따라서 density estimate하면 $$p({\\pmb X}) = \\frac{K}{NV}$$ $V$를 fix : Kernel approach $K$를 fix : K-nearest-neighbour 조금 더 자세히 살펴보자. $R$을 우리가 구하고 싶은 probability density의 point ${\\pmb x}$가 가운데에 있는 작은 hypercube라고 하자. 해당 지역에 들어있는 data 수 $K$를 위해 다음과 같은 함수를 생각해보자. 이 함수는 kernel function 의 한 예시이다. 따라서 $$K = \\sum_{n=1}^{N}k\\left(\\frac{ {\\pmb x}-{\\pmb x}_n}{h}\\right) $$ 이를 이용하여 density at ${\\pmb x}$를 구하면 $$p({\\pmb x}) = \\frac{1}{N}\\sum_{n=1}^{N}\\frac{1}{h^D}k\\left(\\frac{ {\\pmb x}-{\\pmb x}_n}{h}\\right)$$ $v = h^D$ 위 식은 함수 $k({\\pmb u})$의 대칭성을 생각하여, single cube centered on ${\\pmb x}$가 아니라 N cubes centered on the N data point ${\\pmb x_n}$ 이라고 이해할 수 있다. 하지만 이는 여전히 불연속적인 단점이 있기에 좀 더 업그레이드해보자. kernel function을 Gaussian으로 정하면 $$p({\\pmb x}) = \\frac{1}{N}\\sum_{n=1}^N\\frac{1}{(2\\pi h^2)^{D/2}}\\exp\\{-\\frac{|{\\pmb x}-{\\pmb x}_n|^2}{2h^2}\\}$$ kernel function은 다양하게 정할 수 있다. 단, 조건은 $k(x) \\ge 0$ $\\int k(x)dx = 1$ density는 h가 커지면 smooth해지고 h가 작아지면 더 복잡해진다. 우리는 적절하나 h를 잘 찾아야 하는데 이미 최선의 h는 밝혀져 있다. 아울러 가장 좋은 kernel function도 이미 밝혀져있다. ","date":"2021-11-26","objectID":"/prml-chap02-4/:2:2","tags":["Exponential Family","Non parametric"],"title":"[PRML] Chapter2 - Probability Distribution (4)","uri":"/prml-chap02-4/"},{"categories":["PRML"],"content":"Nearest-neighbour methods 이번에는 $K$를 미리 정한 뒤에 이에 적절한 $V$를 찾는 것이다. density는 $K$가 커지면 smooth해지고 작아지면 복잡해진다. KNN classification이 잘 알려져있다. 지금까지 Nonparametric 방법론을 살펴보았다. 전체 data를 저장하고 있어야 하는 단점이 존재한다. data가 너무 많으면 계산에 어려움이 생기고 너무 적으면 다소 부정확한 근사치를 만들 수 있다. ","date":"2021-11-26","objectID":"/prml-chap02-4/:2:3","tags":["Exponential Family","Non parametric"],"title":"[PRML] Chapter2 - Probability Distribution (4)","uri":"/prml-chap02-4/"},{"categories":["PRML"],"content":"Gaussian Distribution과 관련한 내용을 알아보자. ","date":"2021-11-26","objectID":"/prml-chap02-3/:0:0","tags":["Gaussian Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (3)","uri":"/prml-chap02-3/"},{"categories":["PRML"],"content":"2.3.6 Bayesian inference for the Gaussian 이번에는 Bayesian의 방법으로 접근해보자. $\\sigma^2$ is known, inferring the mean $\\mu$ likelihood function은 $$p({\\bf x} | \\mu) = \\prod_{n=1}^{N}p(x_n | \\mu) = \\dfrac{1}{(2\\pi\\sigma^2)^{N/2}}\\exp \\{-\\frac{1}{2\\sigma^2}\\sum_{n=1}^{N}(x_n-\\mu)^2 \\}$$ Gaussian의 conjugate prior는 Gaussian이다. 따라서 prior distribution은 $$p(\\mu) = N(\\mu | \\mu_0, \\sigma_0^2)$$ posterior distribution은 $$p(\\mu |{\\bf x}) \\propto p({\\bf x}|\\mu)p(\\mu) = N(\\mu | \\mu_N, \\sigma_N^2)$$ $\\mu_N = \\frac{\\sigma^2}{N\\sigma_0^2+\\sigma^2}\\mu_0 + \\frac{N\\sigma_0^2}{N\\sigma_0^2+\\sigma^2}\\mu_{ML}$ $\\frac{1}{\\sigma_N^2}=\\frac{1}{\\sigma_0^2}+\\frac{N}{\\sigma^2}$ 위의 결론을 통해 평균과 분산에 대해 좀 더 살펴보자. posterior mean prior mean $\\mu_0$ 와 MLE solution $\\mu_{ML}$ 사이의 값을 갖는다. $N=0$이면 prior mean쪽으로 $N \\rightarrow \\infty$이면 MLE solution쪽을 가까워 진다. posterior variance 해석의 편의를 위해 precision으로 표현하였다. data의 수가 늘어날수록 precision이 커지고 따라서 posterior variance는 작아진다. $N=0$이면 prior variance의 값과 같다. $N \\rightarrow \\infty$이면 variance가 0으로 가까워진다. 이번에는 $\\mu$ is known, inferring the variance $\\sigma^2$ $$p({\\bf x} | \\lambda) = \\prod_{n=1}^{N} N(x_n | \\mu, \\lambda^{-1}) \\propto \\lambda^{N/2} \\exp \\{ -\\frac{\\lambda}{2} \\sum_{n=1}^{N}(x_n-\\mu)^2 \\}$$ precision의 posterior의 conjugate prior는 gamma distribution이다. $$Gam(\\lambda | a,b)=\\frac{1}{\\Gamma(a)}b^a\\lambda^{a-1}\\exp(-b\\lambda) $$ 이를 이용하여 posterior를 구하면 $$p({\\bf x} | \\lambda) \\propto \\lambda^{a_0-1}\\lambda^{N/2} \\exp \\{-b_0\\lambda-\\frac{\\lambda}{2}\\sum_{n=1}^{N}(x_n-\\mu)^2\\}$$ $a_N = a_0 + \\frac{N}{2}$ $b_N = b_0 + \\frac{1}{2}\\sum_{n=1}^{N}(x_n-\\mu)^2 = b_0 + \\frac{N}{2}\\sigma_{ML}^2$ precision이 아닌 covariance를 바로 이용하는 경우 gamma distribution이 아니라 inverse gamma distribution을 이용한다. 이번에는 $\\mu, \\sigma^2$ 둘 다 모른다고 하자 $$p({\\bf x} | \\mu, \\lambda) = \\prod_{n=1}^{N} (\\frac{\\lambda}{2\\pi} )^{1/2} \\exp \\{-\\frac{\\lambda}{2}(x_n-\\mu)^2\\} \\\\ \\propto [\\lambda^{1/2}\\exp (-\\frac{\\lambda\\mu^2}{2})]^N\\exp\\{\\lambda\\mu\\sum_{n=1}^{N}x_n-\\frac{\\lambda}{2}\\sum_{n=1}^{N}x_n^2\\} $$ parameter가 2개이기에 prior가 $p(\\mu, \\lambda)$일 것이다. likelihood function의 모양과 $p(\\mu, \\lambda) = p(\\mu |\\lambda)p(\\lambda)$를 이용하면 Normal-Gamma distribution $$p(\\mu, \\lambda) = N(\\mu|\\mu_0, (\\beta\\lambda)^{-1})Gam(\\lambda|a,b) $$ 을 구할 수 있다. independent한 두 식을 곱한게 아니다. Normal의 precision이 $\\lambda$에 dependent하다. D-dimension인 경우, Wishart distribution을 이용한다. ","date":"2021-11-26","objectID":"/prml-chap02-3/:0:1","tags":["Gaussian Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (3)","uri":"/prml-chap02-3/"},{"categories":["PRML"],"content":"2.3.7 Student’s t-distribution 위에서 gaussian precision과 관련하여 gamma prior을 이용했다. 이때 $x$에 대한 marginal distribution을 구해보자. $$p(x/\\mu,a,b) = \\int_{0}^{\\infty}N(x/\\mu, \\tau^{-1})Gam(\\tau/a,b)d\\tau \\\\ =\\int_{0}^{\\infty}\\frac{b^a e^{(-b\\tau)}\\tau^{(a-1)}}{\\Gamma(a)}(\\frac{\\tau}{2\\pi})^{1/2}\\exp \\{-\\frac{\\tau}{2}(x-\\mu)^2 \\}d\\tau \\\\ = \\frac{b^a}{\\Gamma(a)}(\\frac{1}{2\\pi})^{1/2}[b+\\frac{(x-\\mu)^2}{2}]^{-a-1/2}\\Gamma(a+1/2) $$ $z = \\tau[b+(x-\\mu)^2/2]$로 놓고 식을 전개하면 $$St(x/\\mu,\\lambda,v) = \\frac{\\Gamma(v/2+1/2)}{\\Gamma(v/2)}\\left(\\frac{\\lambda}{\\pi v}\\right)^{1/2}\\left[1+\\frac{\\lambda(x-\\mu)^2}{v}\\right]^{-v/2-1/2} $$ 이를 Student’s t-distribution 이라고 한다. $v$는 자유도이며 이 값이 무한대로 갈수록 gaussian distribution에 가까워진다. 이 분포의 특징 중 하나는 robustness 라는 것이다. 분포모양이 gaussian distribution과 비슷하지만 (좌우대칭) 더 긴 꼬리를 갖고 있다. 이 때문에 outlier(이상치)에 대해 덜 민감하다. ","date":"2021-11-26","objectID":"/prml-chap02-3/:0:2","tags":["Gaussian Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (3)","uri":"/prml-chap02-3/"},{"categories":["PRML"],"content":"2.3.8 Periodic variables skip ","date":"2021-11-26","objectID":"/prml-chap02-3/:0:3","tags":["Gaussian Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (3)","uri":"/prml-chap02-3/"},{"categories":["PRML"],"content":"2.3.9 Mixtures of Gaussians mixture distribution : linear combination of basic distribution K개의 gaussian distribution을 중첩하면 $$p({\\bf x}) = \\sum_{k=1}^{K}\\pi_k N({\\bf x} | {\\bf \\mu}_k, \\Sigma_k) $$ 이를 Mixture of Gaussian 이라고 부른다. 이 때 각 $N({\\bf x} | {\\bf \\mu}_k, \\Sigma_k)$ 는 component, $\\pi_k$는 mixing coefficients 라고 부른다. $\\pi_k$은 0과 1 사이의 값을 갖고 합이 1이다. 따라사 이를 확률로 이해할 수 있다. 이를 통해 다시 marginal distribution을 전개하면 $$p({\\bf x}) = \\sum_{k=1}^{K}p(k)p({\\bf x}|k)$$ 그렇다면 이제 parameter 추정을 해보자. prameter는 $\\pi, \\mu,\\Sigma$ $$\\ln p({\\bf X}|{\\bf \\pi}, {\\bf \\mu}, \\Sigma) = \\sum_{n=1}^{N}\\ln \\{\\sum_{k=1}^{K} \\pi_k N({\\bf x}_n|{\\bf \\mu}_k, \\Sigma_k) \\}$$ 위의 식에서 MLE를 구하기는 쉽지 않다. log 안에 summation이 있기 때문이다. (미분이 어려움) 이를 구하는 방법은 EM algorithm이다. 나중에 배운다. ","date":"2021-11-26","objectID":"/prml-chap02-3/:0:4","tags":["Gaussian Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (3)","uri":"/prml-chap02-3/"},{"categories":["PRML"],"content":"Gausisan distribution의 성질을 알아보자. ","date":"2021-11-26","objectID":"/prml-chap02-2/:0:0","tags":["Gaussian Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (2)","uri":"/prml-chap02-2/"},{"categories":["PRML"],"content":"2.3 Gaussian distribution Multivariate Gaussian distribution D 차원의 vector $\\textbf{x}$에 대한 distribution entropy가 가장 큰 분포가 gaussian이고 multivariate gaussian도 해당한다. ${\\Sigma}$ : D*D의 covariance matrix $$N(\\pmb{x} | \\pmb{\\mu}, \\pmb{\\Sigma}) = \\frac{1}{(2\\pi)^{D/2}} \\frac{1}{ | \\pmb{\\Sigma} |^{1/2} } \\exp{ -\\frac{1}{2}(\\pmb{x} - \\pmb{\\mu})^T \\pmb{\\Sigma}^{-1}(\\pmb{x} - \\pmb{ \\mu})}$$ Gaussian distribution은 상당히 중요한 특징들을 갖고 있다 하나씩 살펴보자. $$\\Delta^2 = ({\\bf x}-{\\pmb \\mu})^T{\\bf \\Sigma}^{-1}({\\bf x}-{\\pmb \\mu}) $$ $\\Delta$ : Mahalanobis distance from $\\pmb{\\mu}$ to $\\textbf{x}$ $\\pmb{\\Sigma}$가 identity이면 Euclidean distance $\\pmb{\\Sigma}$는 (실수)대칭행렬이므로 고윳값이 실수 고유벡터들은 orthonomal하게 가능 고유대각화가 가능하고 아울어 직교대각화가 가능하다. $${\\bf \\Sigma}=\\sum_{i=1}^{D}{\\pmb \\Lambda}_i{\\bf u}_i{\\bf u}_i^T = U{\\pmb \\Lambda} U^{-1}$$ $${\\bf \\Sigma}^{-1}=\\sum_{i=1}^{D}\\dfrac{1}{\\pmb \\Lambda}_i{\\bf u}_i{\\bf u}_i^T = U {\\pmb \\Lambda}^{-1} U^{-1}$$ 이를 위에 대입하면 $$\\Delta^2 = \\sum_{i=1}^{D}\\frac{y_i^2}{\\pmb \\Lambda}_i $$ $y_i={\\bf u}_i^T({\\bf x}-{\\pmb \\mu})$ 우리는 ${y_i}$를 orthonomal vector $\\textbf{u}_i$에 의해 새롭게 정의된 coordinate system이라고 이해할 수 있다. multivariate gaussian의 평균과 분산은 $E[\\textbf{x}] = {\\pmb \\mu}$ $cov[\\textbf{x}] = {\\pmb \\Sigma}$ : 공분산행렬 (covariance matrix) multivariate gaussian은 유용한 분포지만 한계점도 있다. 공분산행렬의 parameter 개수 공분산행렬의 parameter는 $D(D+3)/2$ 개 이다. 차원이 커짐에 따라 parameter가 quadratic하게 커진다. 이를 위한 해결책은 2가지가 있는데 공분산행렬은 대각행렬로 생각한다. 즉, ${\\pmb \\Sigma} = diag(\\sigma_i^2)$ 공분산행렬을 isotropic covariance로 만든다. 즉, ${\\pmb \\Sigma} = \\sigma^2{\\pmb I}$ 물론 이런 제약이 생기면 data간의 correlation을 못 잡는 경우가 발생한다. gaussian은 unimodal 하기에 multimodal distribution을 잘 approximation하기 어렵다. 이에 대해 해결책은 나중에 뒤에서 배운다. (Mixture 등등) ","date":"2021-11-26","objectID":"/prml-chap02-2/:1:0","tags":["Gaussian Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (2)","uri":"/prml-chap02-2/"},{"categories":["PRML"],"content":"2.3.1 Conditional Gaussian distributions conditional distribution의 경우를 살펴보자. $\\textbf{x}$는 Gaussian distribution $N(\\textbf{x} | {\\pmb \\mu, \\Sigma})$의 D-차원 vector이다. 이를 두 부분으로 나누어 $\\textbf{x}_a, \\textbf{x}_b$ 라고 하자. D*D covariance matrix는 대칭행렬이다. $$\\textbf{x} = \\begin{pmatrix} \\textbf{x}_a \\\\ \\textbf{x}_b \\end{pmatrix}, {\\pmb \\mu} = \\begin{pmatrix} {\\pmb \\mu}_a \\\\ {\\pmb \\mu}_b \\end{pmatrix}$$ $${\\pmb \\Sigma} = \\begin{pmatrix} \\Sigma_{aa} \u0026 \\Sigma_{ab} \\\\ \\Sigma_{ba} \u0026 \\Sigma_{bb} \\end{pmatrix}$$ precision matrix $${\\pmb \\Lambda} \\equiv {\\pmb \\Sigma}^{-1} = \\begin{pmatrix} {\\pmb \\Lambda} _ {aa} \u0026 {\\pmb \\Lambda} _ {ab} \\\\ {\\pmb \\Lambda} _ {ba} \u0026 {\\pmb \\Lambda}_{bb} \\end{pmatrix}$$ 이제 우리는 conditional distribution $p(\\textbf{x}_a | \\textbf{x}_b)$ 을 살펴보자. (gaussian은 quadratic form in the exponent를 주의깊게 살펴보자) $\\textbf{x}_b$는 fixed 되었으며 exp 안의 부분을 나눠서보면 $$-\\frac{1}{2}({\\bf x}-{\\pmb \\mu})^T\\Sigma^{-1}({\\bf x}-{\\pmb \\mu})=$$ $$ -\\frac{1}{2}({\\bf x}_a - {\\pmb \\mu}_a)^T{\\pmb \\Lambda} _ {aa}({\\bf x}_a-{\\pmb \\mu}_a) - \\frac{1}{2}({\\bf x}_a - {\\pmb \\mu}_a)^T {\\pmb \\Lambda} _ {ab}({\\bf x}_b-{\\pmb \\mu}_b)$$ $$-\\frac{1}{2}({\\bf x}_b-{\\pmb \\mu}_b)^T{\\pmb \\Lambda} _ {ba}({\\bf x}_a-{\\pmb \\mu}_a) - \\frac{1}{2}({\\bf x}_b - {\\pmb \\mu}_b)^T{\\pmb \\Lambda} _ {bb}({\\bf x}_b-{\\pmb \\mu}_b) $$ 위 식을 보면 $\\textbf{x}_a$ 에 대한 함수이고 quadratic form 임을 알 수 있다. 즉 conditional dist는 Gaussian인 것이다. 이제 평균과 분산을 구하는 과정을 살펴보자. 먼저, $\\textbf{x}_a$의 second order인 부분을 먼저보면 $$-\\frac{1}{2}\\textbf{x}^T_a {\\pmb \\Lambda}_{aa} \\textbf{x}_a$$ 따라서 우리는 conditional distribution $p(\\textbf{x}_a | \\textbf{x}_b)$의 covariance 가 $${\\pmb \\Sigma_{a|b} = {\\pmb \\Lambda}_{aa}^{-1}}$$ 임을 알 수 있다. 다음은 $\\textbf{x}_a$에 linear한 부분을 보면 $$\\textbf{x}_a^T { {\\pmb \\Lambda} _ {aa} {\\pmb \\mu}_a - {\\pmb \\Lambda} _ {ab}(\\textbf{x}_a - {\\pmb \\mu}_b)}$$ 이를 이용하여 우리는 평균을 구할 수 있다. $${\\pmb \\mu} _ {a|b} = {\\pmb \\Sigma}_{a|b} [ {\\pmb \\Lambda} _ {aa}{\\pmb \\mu}_a - {\\pmb \\Lambda} _ {ab}({\\bf x}_b-{\\pmb \\mu}_b) ] = {\\pmb \\mu}_a -{\\pmb \\Lambda} _ {aa}^{-1}{\\pmb \\Lambda} _ {ab}({\\bf x}_b-{\\pmb \\mu}_b) $$ 다음으로 공분산행렬을 구하면 $${\\pmb \\Sigma}_{a|b} = {\\pmb \\Sigma} _ {aa} - {\\pmb \\Sigma} _ {ab}{\\pmb \\Sigma} _ {bb}^{-1}{\\pmb \\Sigma} _ {ba} $$ [참고] 아래의 공식을 이용하여 구한다. $$\u003c![CDATA[\r\\left(\\begin{array}{cc}A \u0026 B \\\\ C \u0026 D \\end{array}\\right)^{-1} = \\left(\\begin{array}{cc} M \u0026 -MBD^{-1} \\\\ -D^{-1}CM \u0026 D^{-1}CMBD^{-1} \\end{array}\\right) %]]\u003e$$ $$M = (A-BD^{-1}C)^{-1} $$ 결론 : conditional distribution도 Gaussian distribution이다 mean은 linear function of $\\textbf{x}_b$ covariance은 independent of $\\textbf{x}_b$ ","date":"2021-11-26","objectID":"/prml-chap02-2/:1:1","tags":["Gaussian Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (2)","uri":"/prml-chap02-2/"},{"categories":["PRML"],"content":"2.3.2 Mariginal Gaussian distributions $$p({\\bf x}_a) = \\int p({\\bf x}_a, {\\bf x}_b)d{\\bf x}_b $$ joint distribution에서 integrate out $x_b$하면 된다. 이번에도 마찬가지로 quadratic form을 이용하여 문제를 해결한다. 위에서 봤던 joint distribution의 exp부분을 이번에는 $\\textbf{x}_b$에 대해 전개하면 $$-\\dfrac{1}{2}{\\bf x}_b^{T}{\\pmb \\Lambda} _ {bb}{\\bf x}_b + {\\bf x}_b^T{\\bf m} = -\\dfrac{1}{2}({\\bf x}_b- {\\pmb \\Lambda} _ {bb}^{-1}{\\bf m})^T {\\pmb \\Lambda} _ {bb}({\\bf x}_b- {\\pmb \\Lambda} _ {bb}^{-1}{\\bf m}) + \\dfrac{1}{2}{\\bf m}^T {\\pmb \\Lambda} _ {bb}^{-1}{\\bf m}$$ $$\\text{where}\\;{\\bf m} = {\\pmb \\Lambda}_{bb}{\\pmb \\mu} _ b - {\\pmb \\Lambda} _ {ba}({\\bf x}_a-{\\pmb \\mu}_a)$$ 위의 식 우항에서 첫번째 부분은 quadratic form으로 만들었다. integrate하면 exp부분을 제외한 Gaussian distribution의 normalization constant가 나온다. 이는 첫번째항의 covariance determinant만 관련이 있고 $\\textbf{x}_a$와 independent하다. 결국 중요한건 $\\textbf{x}_a$와 dependent한 뒷부분인데 이를 정리하면 ${\\bf x}_a$에 대한 marginal gaussian distribution가 된다. $$\\dfrac{1}{2}[{\\pmb \\Lambda} _ {bb}{\\pmb \\mu}_b-{\\pmb \\Lambda} _ {ba}({\\bf x}_a-{\\pmb \\mu}_a)]^T {\\pmb \\Lambda} _ {bb}^{-1}[{\\pmb \\Lambda} _ {bb}{\\pmb \\mu}_b-{\\pmb \\Lambda} _ {ba}({\\bf x}_a-{\\pmb \\mu}_a)]$$ $$- \\dfrac{1}{2}{\\bf x}_a^T{\\pmb \\Lambda} _ {aa}{\\bf x}_a + {\\bf x}_a^T({\\pmb \\Lambda} _ {aa}{\\pmb \\mu}_a+{\\pmb \\Lambda} _ {ab}{\\pmb \\mu}_b) + const$$ $$= - \\dfrac{1}{2}{\\bf x}_a^T({\\pmb \\Lambda} _ {aa}-{\\pmb \\Lambda} _ {ab}{\\pmb \\Lambda} _ {bb}^{-1}{\\pmb \\Lambda} _ {ba}){\\bf x}_a + {\\bf x}_a^T({\\pmb \\Lambda} _ {aa}-{\\pmb \\Lambda} _ {ab}{\\pmb \\Lambda} _ {bb}^{-1}{\\pmb \\Lambda} _ {ba}){\\pmb \\mu}_a+const $$ 이를 이용하여 marginal distribution을 구하면 된다. 먼저, covariance는 $${\\pmb \\Sigma}_a = ({\\pmb \\Lambda} _ {aa}-{\\pmb \\Lambda} _ {ab}{\\pmb \\Lambda} _ {bb}^{-1}{\\pmb \\Lambda} _ {ba})^{-1} = {\\pmb \\Sigma} _ {aa}$$ mean은 아래와 같다. $${\\pmb \\Sigma}_a({\\pmb \\Lambda} _ {aa}-{\\pmb \\Lambda} _ {ab}{\\pmb \\Lambda} _ {bb}^{-1}{\\pmb \\Lambda} _ {ba}){\\pmb \\mu}_a = {\\pmb \\mu}_a$$ 결론 : Marginal distribution도 Gaussian distribution이다. $E[\\textbf{x}_a] = {\\pmb \\mu}_a$ $cov[\\textbf{x}_a] = \\Sigma _{aa}$ 직관과 거의 일치한다. (partitioned한 부분) ","date":"2021-11-26","objectID":"/prml-chap02-2/:1:2","tags":["Gaussian Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (2)","uri":"/prml-chap02-2/"},{"categories":["PRML"],"content":"2.3.3 Bayes’ theorem for Gaussian variables Gaussian marginal distribution $p(\\textbf{x})$ , Gaussian conditional distribution $p(\\textbf{y} | \\textbf{x})$가 주어진 상태이다. (2.3.1과 2.3.2에서 알게된 사실을 토대로) $$p({\\bf x}) = N({\\bf x}|{\\pmb \\mu}, {\\pmb \\Lambda}^{-1}) $$ $$p({\\bf y}|{\\bf x}) = N({\\bf y}|{\\bf A} {\\bf x}+{\\bf b} , \\textbf{L}^{-1}) $$ 우리는 Gaussian marginal distribution $p(\\textbf{y})$ , Gaussian conditional distribution $p(\\textbf{x} | \\textbf{y})$를 구하고자 한다. 먼저 joint distribution을 구한 뒤에 구해보자. $${\\bf z} = \\dbinom{ {\\bf x} }{ {\\bf y} }$$ $$\\ln p({\\bf z}) = \\ln p({\\bf x}) + \\ln p({\\bf y}) \\\\ = -\\frac{1}{2}({\\bf x}-{\\pmb \\mu})^T{\\pmb \\Lambda}({\\bf x}-{\\pmb \\mu}) -\\frac{1}{2}({\\bf y}-{\\bf A}{\\bf x}-{\\bf b})^T {\\bf L}({\\bf y}-{\\bf A}{\\bf x}-{\\bf b})+const $$ 위의 식은 quadratic 형태의 함수라는 것을 알수 있고 따라서 Gaussian distribution의 함수일 것이다. 위의 식을 전개하여 이차항을 살펴보면 (for covariance) $$-\\frac{1}{2} {\\bf x}^T ({\\pmb \\Lambda} + {\\bf A}^T {\\pmb \\Lambda} {\\bf A}) {\\bf x} - \\frac{1}{2} {\\bf y}^T {\\bf L}{\\bf y} + \\frac{1}{2} {\\bf x}^T {\\bf A}{\\bf L}{\\bf y}$$ $$ = -\\frac{1}{2} \\dbinom{ {\\bf x} }{ {\\bf y} }^T \\left(\\begin{array}{cc}{\\pmb \\Lambda}+{\\bf A}^T{\\bf L}{\\bf A} \u0026 -{\\bf A}^T{\\bf L} \\\\ - {\\bf L}{\\bf A} \u0026 {\\bf L}\\end{array} \\right) \\dbinom{ {\\bf x} }{ {\\bf y} } = -\\frac{1}{2}{\\bf z}^T{\\bf R}{\\bf z}$$ 따라서 precision matrix는 $${\\bf R} = \\left(\\begin{array}{cc}{\\pmb \\Lambda}+{\\bf A}^T{\\bf L}{\\bf A} \u0026 -{\\bf A}^T{\\bf L}\\-{\\bf L}{\\bf A} \u0026 {\\bf L}\\end{array}\\right)$$ 임을 알 수 있다. 이를 inverse하여 covariance matrix를 구하면 $$cov[{\\bf z}]={\\bf R}^{-1} = \\left(\\begin{array}{cc}{\\pmb \\Lambda}^{-1} \u0026 {\\pmb \\Lambda}^{-1}{\\bf A}^T \\ {\\bf A}{\\pmb \\Lambda}^{-1} \u0026 {\\bf L}^{-1}+{\\bf A}{\\pmb \\Lambda}^{-1}{\\bf A}^T \\end{array}\\right)$$ 이전의 방법을 이용하여 mean을 구할 수 있다. $${\\bf x}^T{\\pmb \\Lambda}{\\pmb \\mu} - {\\bf x}^T{\\bf A}^T{\\bf L}{\\bf b} + {\\bf y}^T{\\bf L}{\\bf b} = \\dbinom{ {\\bf x} }{ {\\bf y} }^T \\dbinom {\\pmb \\Lambda}{\\pmb \\mu}-{\\bf A}^T{\\bf L}{\\bf b} {\\bf L}{\\bf b} $$ $$E[{\\bf z}] = {\\bf R}^{-1}\\dbinom{ {\\bf x} }{ {\\bf y} }^T\\dbinom {\\pmb \\Lambda}{\\pmb \\mu}-{\\bf A}^T{\\bf L}{\\bf b} {\\bf L}{\\bf b}$$ 전개하면 최종적으로 mean은 $$E[{\\bf z}] = \\dbinom{ {\\pmb \\mu} }{ {\\bf A} {\\pmb \\mu} - {\\bf b}}$$ 결과 $$E[{\\bf y}] = {\\bf A}{\\pmb \\mu} + {\\bf b}$$ $$cov[{\\bf y}] = {\\bf L}^T + {\\bf A}{\\pmb \\Lambda}^{-1}{\\bf A}^T $$ 다음은 conditional distribution $p(\\textbf{x}| \\textbf{y})$ 의 mean, covariance를 구하면 $$\\Sigma_{a|b}={\\pmb \\Lambda} _ {aa}^{-1} \\ {\\pmb \\mu}_{a|b}={\\pmb \\mu}_a - {\\pmb \\Lambda} _ {aa}^{-1}{\\pmb \\Lambda} _ {ab}({\\bf x}_b-{\\pmb \\mu}_b)$$ $$E[{\\bf x}|{\\bf y}] = ({\\pmb \\Lambda}+{\\bf A}^T{\\bf L}{\\bf A})^{-1}{ {\\bf A}^T{\\bf L}({\\bf y}-{\\bf b})+{\\pmb \\Lambda}{\\pmb \\mu}} $$ $$cov[{\\bf x}|{\\bf y}] = ({\\pmb \\Lambda}+{\\bf A}^T{\\bf L}{\\bf A})^{-1} $$ ","date":"2021-11-26","objectID":"/prml-chap02-2/:1:3","tags":["Gaussian Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (2)","uri":"/prml-chap02-2/"},{"categories":["PRML"],"content":"2.3.4 Maximum likelihood for the Gaussian Log likelihood $$\\ln p({\\bf X}|{\\pmb \\mu}, \\Sigma) = -\\frac{ND}{2}\\ln(2\\pi) - \\frac{N}{2}\\ln|\\Sigma|-\\frac{1}{2}\\sum_{n=1}^{N}({\\bf x}_n-{\\pmb \\mu})^T\\Sigma^{-1}({\\bf x}_n-{\\pmb \\mu})$$ (과정 생략) $${\\pmb \\mu} _ {ML} = \\frac{1}{N}\\sum_{i=1}^{N}{\\bf x}_i = \\bar{\\bf x}$$ $${ \\pmb \\Sigma} _ {ML} = \\frac{1}{N}\\sum_{i=1}^{N}({\\bf x}_i-\\mu)({\\bf x}_i-\\mu)^T$$ ","date":"2021-11-26","objectID":"/prml-chap02-2/:1:4","tags":["Gaussian Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (2)","uri":"/prml-chap02-2/"},{"categories":["PRML"],"content":"2.3.5 Sequential estimation data sample이 하나 들어오면 바로 계산하고 버린다. MLE를 구하는 예시를 살펴보자. $${\\pmb \\mu} _ {ML}^{(N)} = \\frac{1}{N} \\sum_{n=1}^{N}{\\bf x}_n = \\frac{1}{N}{\\bf x} _ N + \\frac{1}{N} \\sum _ {n=1}^{N-1}{\\bf x}_n$$ $$= \\frac{1}{N}{\\bf x}_N + \\frac{N-1}{N}{\\pmb \\mu} _ {ML}^{(N-1)}={\\pmb \\mu} _ {ML}^{(N-1)}+\\frac{1}{N}({\\bf x}_N-{\\pmb \\mu} _ {ML}^{(N-1)}) $$ 이전에 구한 parameter를 ’error signal’ $(\\textbf{x} _N - {\\pmb \\mu} _{ML}^{(N-1)})$ 쪽으로 1/N에 비례하도록 수정하여 parameter를 업데이트한다. $N$이 커질수록 새로운 data의 영향은 작아진다. 이번에는 이런 Sequential estimation에서 사용되는 일반적인 방법에 대해 살펴보자. 바로 Robbins-Monro algorithm이다. random variables $\\theta, z$가 있다. conditional expectation은 $$f(\\theta)\\equiv E[z|\\theta] = \\int zp(z|\\theta)dz $$ 이고 이러한 형태를 regression function이라고 부른다. 우리의 목표는 $f(\\theta^{ * }) = 0$을 만족하는 root $\\theta^{ * }$를 찾는 것이다. 몇가지 가정을 살펴보면 data가 많으면 한번에 regression function을 만들고 root를 estimation할 수 있겠지만 지금은 Sequential하게 data가 하나씩 구해진다고 가정한다. $E[(z-f)^2 | \\theta]\u003c\\infty$ : conditional variance는 finite하다고 가정한다. $\\theta \u003e \\theta^{ * } \\rightarrow f(\\theta) \u003e 0$ $\\theta \u003c \\theta^{ * } \\rightarrow f(\\theta) \u003c 0$ Robbins-Monro의 방법은 $$\\theta^{(N)} = \\theta^{(N-1)} - a_{N-1} z(\\theta^{N-1}) $$ 여기서 $z(\\theta^{(N)})$은 N번째의 $\\theta$가 들어왔을 때, $z$의 값을 의미한다. $a_N$은 양의 실수이며 다음과 같은 조건을 갖는다. $\\lim_{N\\rightarrow\\infty}a_N=0 $ : $\\theta$가 특정값에 수렴 $\\sum_{N=1}^{\\infty}a_N=\\infty $ : root를 찾기도 전에 다른 값에 수렵하지 않도록 $% \u003c![CDATA[\r\\sum_{N-1}^{\\infty}a_N^2\u003c\\infty %]]\u003e$ : 축적되는 noise가 finite하여 수렴을 방해하지 않는다. 이제 이 방법을 통해 이전에 구했던 MLE의 예시에 적용해보자. $$\\frac{\\partial}{\\partial\\theta}{-\\frac{1}{N}\\sum_{n=1}^{N}\\ln p(x_n|\\theta)}_ {\\theta_{MLE}}=0$$ MLE는 위처럼 log likelihood function을 미분하여 0으로 만드는 값니다. as $N \\rightarrow \\infty$ $$-\\lim_{n\\rightarrow\\infty}\\frac{1}{N}\\sum_{n=1}^{N}\\frac{\\partial}{\\partial\\theta}\\ln p(x_n|\\theta) = E_x\\left[-\\frac{\\partial}{\\partial\\theta}\\ln p(x|\\theta)\\right] $$ 이제 Robbins-Monro의 방법을 적용하면 $$\\theta^{(N)} = \\theta^{(N-1)} - a_{N-1}\\frac{\\partial}{\\partial\\theta^{(N-1)}}\\left[-\\ln p(x_N/\\theta^{(N-1)})\\right] $$ $$z=\\frac{\\partial}{\\partial\\mu_{ML}}[-\\ln p(x|\\mu_{ML}, \\sigma^2)]=-\\frac{1}{\\sigma^2}(x-\\mu_{ML}) $$ 따라서 $\\textbf{x}_N$을 대입하고 $a_N = \\sigma^1 / N$을 대입하면 처음에 구한 결과와 같다. ","date":"2021-11-26","objectID":"/prml-chap02-2/:1:5","tags":["Gaussian Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (2)","uri":"/prml-chap02-2/"},{"categories":["PRML"],"content":"이번 장은 주어진 데이터를 이용하여 Distribution을 만드는 것을 배울 것이다. density estimation을 하는 것이다. 이에 대한 방법으로 크게 parametric, nonparmetric 방법으로 나눌 수 있다. 추가로 몇가지 중요한 분포들에 대해 살펴볼 것이다. ","date":"2021-11-26","objectID":"/prml-chap02-1/:0:0","tags":["Bayesian","Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (1)","uri":"/prml-chap02-1/"},{"categories":["PRML"],"content":"2.1 Binary Variables 동전던지기와 같이 random variable이 딱 두가지의 값을 가지는 경우 ($x \\in {0,1}$) 에 대해 살펴보자. Bernoulli distribution $x=1$의 확률을 $p(x=1 | \\mu) = \\mu$ 라고 하자. ($0\\le \\mu \\le 1$) $E[x] = \\mu, Var[x] = \\mu(1-\\mu)$ parameter를 MLE로 추정하면 $\\mu_{ML} = \\frac{1}{N}\\sum_{n=1}^{N}{x_n}$ $$Bern(x | \\mu) = \\mu^x (1- \\mu)^{1-x}$$ MLE의 문제점을 여기서 볼 수 있다. 만약에 동전을 3번 던져서 모두 앞면이 나왔다고 하자. 이 data를 기반으로 동전이 앞면이 나올 확률을 MLE로 추정한다면 1일 것이다. 이처럼 극단적으로 overfitting이 되는 경우가 생길 수 있다. 이에 대한 해결책으로는 더 많은 data를 수집하거나 bayesian의 관점으로 접근해야 한다. Binomial distribution N번 중 $\\mu$의 확률로 사건이 $x$개 발생한 경우 (Bernoulli trial이 N번 발생) $$Bin(x | sN,\\mu) = \\begin{pmatrix} N \\ x \\end{pmatrix}\\mu^x (1-\\mu)^{N-x}$$ $$E[x] =N \\mu, Var[x] =N \\mu(1-\\mu)$$ ","date":"2021-11-26","objectID":"/prml-chap02-1/:1:0","tags":["Bayesian","Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (1)","uri":"/prml-chap02-1/"},{"categories":["PRML"],"content":"2.1.1 The beta distribution 위의 분포를 보고 bayesian의 접근방식을 생각해보자. parameter $\\mu$에 대한 prior를 만들어보자. conjugacy (prior와 posterior가 같은 분포를 갖는) 의 성질을 이용하면 Beta distribution을 생각할 수 있다. prior도 Beta이고 posterior도 Beta distribution의 모습을 보이도록 만들어준다. conjugacy를 이용하면 계산, 해석적인 측면에서 상당히 유용하다. $$Beta(\\mu | a,b) = \\frac{\\Gamma(a+b)}{\\Gamma (a) \\Gamma (b)}\\mu^{a-1}(1-\\mu)^{b-1}$$ $$E[\\mu] = \\frac{a}{a+b}, Var[\\mu] = \\frac{ab}{(a+b)^2(a+b+1)}$$ Binomial likelihood function과 Beta prior를 곱하여 posterior dist of $\\mu$ 를 만들면 $$p(\\mu | x,l,a,b) \\propto \\mu^{x+a-1} (1-\\mu)^{N-x+b-1}$$ 합이 1이 되게 constant를 만들지 않아도 posterior가 beta distribution임을 파악할 수 있다. posterior에서 $a$와 $b$는 각각 $x=1$, $x=0$ 인 data의 수와 같은 의미(역할)임을 알 수 있다. 우리는 prior를 beta로 이용했고 posterior가 beta로 나왔다. 그렇다면 나온 posterior를 다시 prior로 이용할 수 있을 것이다. 이처럼 sequential한 접근이 가능해진다. 우리의 목표는 predict이므로 predictive distribution을 구해보자. $$p(x=1 | D) = \\int_{0}^{1} p(x=1,\\mu | D)d\\mu$$ $$= \\int_{0}^{1} p(x=1 | \\mu)p(\\mu | D)d\\mu = \\int_{0}^{1}\\mu p(\\mu | D)d\\mu = E[\\mu | D]$$ 여기서 posterior dist의 평균을 구하면 $$p(x=1|D) = \\frac{x+a}{x+a+N-x+b}$$ 이고 데이터의 수가 많아지면 posterior mean은 MLE와 같아진다. 또한, uncertainty도 줄어들며 likelihood function의 모양과 가까워진다. 물론, 반대로 prior의 정보가 강하다면 prior와 비슷해진다. prior가 강하거나 data수가 많아 likelihood가 강해지면 uncertainty가 줄면서 posterior distribution의 모양이 뾰족해진다. 수리통계학에서 배웠던 공식을 이용하여 살펴보면 $E_{\\theta}[\\theta] = E_{D}[E_{\\theta}[\\theta|D]]$ D에 대해 averaged over된 posterior mean of $\\theta$ = prior mean of $\\theta$ $V_{\\theta}[\\theta] = E_{D}[V_{\\theta}[\\theta|D]]+V_{D}[E_{\\theta}[\\theta|D]]$ 평균적으로 posterior variance of $\\theta$가 prior variance보다 더 작다. ","date":"2021-11-26","objectID":"/prml-chap02-1/:1:1","tags":["Bayesian","Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (1)","uri":"/prml-chap02-1/"},{"categories":["PRML"],"content":"2.2 Multinomial Variables 이번에는 확률변수가 2가지의 값을 갖는게 아닌 K개의 값을 갖는 경우를 살펴보자. 이를 위해 우리는 vector로 확률변수를 표현한다. 예를 들어, 주사위를 던졌더니 3이란 수가 나왔다. $\\textbf{x} = (0,0,1,0,0,0)^T$ 이렇게 표현한다. 각 원소 $x_k$들의 합은 1이다. $x_k=1$인 확률을 parameter $\\mu_k$로 표현하면, $\\textbf{x}$의 distribution은 $$p(\\textbf{x} | {\\pmb \\mu}) = \\prod_{k=1}^{K}\\mu_{k}^{x_k}$$ $\\sum \\mu_k = 1, 0\\le\\mu_k\\le 1$ 이다. expectation은 $$E[{\\bf x}|{\\pmb \\mu}] = \\sum_{\\bf x}p({\\bf x}|{\\pmb \\mu}){\\bf x} = (\\mu_1, …, \\mu_K)^T = {\\pmb \\mu}$$ 으로 구할 수 있다. 그렇다면 이제 likelihood function을 구해보자. $$p(D|{\\pmb \\mu}) = \\prod_{n=1}^{N}\\prod_{k=1}^{K}\\mu_k^{x_{nk}} = \\prod_{k=1}^{K}\\mu_k^{\\sum_n x_{nk}}=\\prod_{k=1}^{K}\\mu_k^{m_k}$$ $m_k = \\sum_{n} x_{nk}$ : 전체 data에서 k값을 가지는 data 갯수 이 likelihood function을 이용하여 parameter ${\\pmb \\mu}$를 구해보자. constraint $\\sum_{k=1}^{K}{\\mu_k} = 1$ 에서 log likelihood 를 최대화 해야 한다. Lagrange multiplier $\\lambda$를 이용하여 아래 식을 최대화하면 된다. (Lagrange method) $$\\sum_{k=1}^{K}{m_k \\ln \\mu_k} + \\lambda (\\sum_{k=1}^{K}{\\mu_k}-1) $$ $\\mu_k$에 대해 미분하면 $\\mu_k = - m_k / \\lambda$ 이고 constraint때문에 $\\lambda = - N$ 이라는 것을 파악할 수 있다. 따라서 MLE는 $$\\mu_k = \\frac{m_k}{N}$$ Multinomial distribution $\\sum \\mu_k = 1, 0\\le\\mu_k\\le 1$ $\\sum m = N$ $$\\text{Multi}(m_1,m_2, … , m_K | \\mu, N) = \\frac{N!}{m_1! m_2! … m_K!}\\prod_{k=1}^{K}{\\mu_k^{m_k}}$$ ","date":"2021-11-26","objectID":"/prml-chap02-1/:2:0","tags":["Bayesian","Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (1)","uri":"/prml-chap02-1/"},{"categories":["PRML"],"content":"2.2.1 The Dirichlet distribution $$Dir(\\boldsymbol{\\mu} | \\boldsymbol{\\alpha}) = \\frac{\\Gamma (\\alpha_0)}{\\Gamma (\\alpha_1) \\Gamma(\\alpha_2)…\\Gamma(\\alpha_K)}\\prod_{k=1}^{K}{\\mu_k^{\\alpha_k - 1}}$$ $\\sum \\mu_k = 1, 0\\le\\mu_k\\le 1$ Multinomial의 conjugate prior K = 2이면 beta 분포이다. Binomial의 일반화된 분포가 Multinomial이듯 Beta의 일반화된 분포가 Dirichlet 분포라고 할 수 있다. posterior $$p({\\pmb \\mu}|D, {\\pmb \\alpha}) \\propto p(D|{\\pmb \\mu})p({\\pmb \\mu}|{\\pmb \\alpha}) \\propto \\prod_{k=1}^{K} \\mu_k^{\\alpha_k+m_k-1}$$ 이전에 봤듯이 prior의 $a_k$는 data에서 ‘observation of $x_k=1$’ 의 갯수와 같은 의미(역할)이라고 할 수 있다. ","date":"2021-11-26","objectID":"/prml-chap02-1/:2:1","tags":["Bayesian","Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (1)","uri":"/prml-chap02-1/"},{"categories":["PRML"],"content":"Information Theory에 대해 알아봅시다. ","date":"2021-11-26","objectID":"/prml-chap01-3/:0:0","tags":["Information Theory"],"title":"[PRML] Chapter1 - Introduction (3)","uri":"/prml-chap01-3/"},{"categories":["PRML"],"content":"1.6 Information Theory 일단 entropy에 대해 두 가지의 시선으로 살펴볼 예정이다. 일단 discrete random variable $x$와 이 variable의 specific value를 알아내면서 얻는 정보의 양이 얼마나 되는지로부터 시작한다. 어떤 사건이 일어날 확률이 큰 경우보다 일어날 확률이 작은 사건이 더 정보가 많다고 한다. 이에 따라 우리는 information content ($h(x)$ 라고 하자) 를 측정하는 방법이 필요하다. 그 방법의 조건은 확률 $p(x)$에 대해 monotonic function 두 개의 사건이 독립적이면 information gain은 두 information의 합으로 표현 이런 조건을 만족시키기 위해 우리는 logarithm을 이용한다. ($\\log_2$인 이유는 2진수 bit단위의 정보전달의 측면에서 접근하기 위해) $$h(x) = - \\log_2 p(x)$$ information은 0이상의 값을 갖기에 음수부호를 붙여서 사용한다. 이제 sender가 receiver에게 random variable의 값을 전달해야하는 상황이라고 가정하자. 그들이 전달하는 정보의 평균적인 양은 $$H[x] = - \\sum_{x}{p(x)\\log_2 p(x)}$$ 이를 우리는 entropy of the random variable x 라고 부른다. (예시는 생략) nonuniform distribution은 uniform distribution보다 더 작은 entropy값을 갖는다. entropy의 값을 정보전달의 측면 (bit단위라고 생각) 에서 생각해보자. 예를 들면, A집단의 entropy가 2, B집단의 entropy가 3의 값을 가진다. A의 내용을 전달하기 위해서는 최소 2bit, B는 최소 3bit가 필요한 것을 의미하고 이처럼 entropy는 the state of a random variable을 전달하기 위해 필요한 bits 수의 lower bound이다. 이번에는 entropy에 대해 다른 시각으로 살펴보자. N개의 물체를 bin에 나누어 담아야 한다. $i^{th}$ bin 에는 $n_i$개의 물체가 들어간다. 물체를 나누어 담는 경우의 수 $W$ 를 생각해보면 $$W = \\frac{N!}{\\prod_i n_i !}$$ 이를 multiplicity 라고 부른다. entropy를 만들기 위해 logarithm과 적절한 scaled 취하면 $$H = \\frac{1}{N}\\ln w = \\frac{1}{N} \\ln N! - \\frac{1}{N}\\sum_{i} \\ln n_i !$$ N이 무한대로 가고 $n_i / N$은 fixed 된다. 그리고 Stirling’s approximation을 이용하면 $\\ln N ! \\approx N \\ln N - N$ $\\ln n_i ! \\approx n_i \\ln n_i - n_i$ 이를 대입하면 $$H = - \\lim_{N \\rightarrow \\infty} \\sum_{i} \\frac{n_i}{N} \\ln \\frac{n_i}{N} = - \\sum_{i}{p_i \\ln p_i}$$ $\\sum_i n_i = N$ $p_i = \\lim_{N \\rightarrow \\infty} (n_i / N)$ : 물체가 i bin에 들어갈 확률 우리는 bin을 random variable X의 state $x_i$ 라고 할 수 있다. 따라서 random variable X의 entropy는 $$H[p] = - \\sum_{i}{p(x_i)\\ln p(x_i)}$$ 우리는 Lagrange를 이용하여 위의 식의 최댓값을 구할수 있고 최댓값은 Uniform distribution 일 때이다. 이제 continuos variable에서도 생각해보자. (과정 생략) continuos variable의 entropy는 아래 값을 가진다. $$H[x] = - \\int p(x) \\ln p(x) dx$$ 이를 differential entropy 라고 부른다. discrete의 경우에서와 마찬가지로 continuos에서는 어떤 distribution이 가장 큰 entropy를 가질까? (과정 생략, 똑같이 Lagrange 사용) 정답은 Gaussian distribution 인 경우이다. ","date":"2021-11-26","objectID":"/prml-chap01-3/:1:0","tags":["Information Theory"],"title":"[PRML] Chapter1 - Introduction (3)","uri":"/prml-chap01-3/"},{"categories":["PRML"],"content":"1.6.1 Relative entropy and mutual information 우리가 모르는 distribution $p(x)$가 있다고 가정해보자. 이를 approximation하는 $q(x)$를 모델링하였다. 이전에 정보전달에서의 측면에서 생각해보면 우리는 approximation 했기에 random variable 의 value 전달을 위해 추가적으로 리소스 bit가 더 필요하다. 더 필요한 정도는 $$KL(p| q) = - \\int p(\\textbf{x}) \\ln q(\\textbf{x})d\\textbf{x} - (- \\int p(\\textbf{x}) \\ln p(\\textbf{x})d\\textbf{x}) \\ = - \\int p(\\textbf{x})\\ln \\frac{p(\\textbf{x})}{q(\\textbf{x})}d\\textbf{x}$$ 이를 Kullbak-Leibler divergence (Relative entropy) between $p(\\textbf{x})$ and $q(\\textbf{x})$ 라고 부른다. 그리고 아래와 같은 특징을 갖는다. (이러한 특징을 통해 Kullbak-Leibler divergence는 measure of the dissimilarity of the two distributions $p(\\textbf{x}), q(\\textbf{x})$ 라고 할 수 있다.) $KL(p| q) \\ge 0$ $KL(p| q) = 0$, if and only if, $p(\\textbf{x}) = q(\\textbf{x})$ 증명은 Jensen’s inequality로 쉽게 할 수 있다. convex function $f(x)$는 $$f(\\sum_{i=1}^{M}{\\lambda_i x_i}) \\le \\sum_{i=1}^{M}{\\lambda_i f(x_i)}$$ $\\lambda \\ge 0$ $\\sum_i \\lambda_i = 1$ 의 특징을 갖는다. 위에서 $\\lambda_i$를 x의 확률분포라고 생각하면 $f(E[x]) \\le E[f(x)]$ 이다. 따라서 ($f$ 를 -log라고 생각하면 된다) $$KL[p|q] = - \\int p(\\textbf{x}) \\ln \\frac{q(\\textbf{x})}{p(\\textbf{x})}d\\textbf{x} \\ge - \\ln \\int q(\\textbf{x}) d\\textbf{x} = 0 $$ KL divergence를 최소화하는 것은 결국 likelihood function을 최대화하는 것과 같은데 이에 대해 살펴보자. 우리가 모르는 (approximation해야하는) 분포 $p(\\textbf{x})$에서 data가 generate되었다고 하자. 우리는 어떤 parametric distribution $q(\\textbf{x} | \\theta)$ 를 통해 approximation하고자 한다. $\\theta$를 정하는 방법은 $\\theta$에 대해 KL divergence를 최소화하는 것을 찾는 것이다. 그런데 우리는 $p(\\textbf{x})$를 모르는 상황이기에 directly할 수 없다. 대신 N개의 train data가 존재하므로 이를 이용하면 $$KL(p|q) \\approx \\sum_{n=1}^{N}{{ - \\ln q (\\textbf{x}_n | {\\bf \\theta}) + \\ln p(\\textbf{x}_n)} }$$ 우변의 두번째항은 parameter와 independent하다. 첫번째항은 negative log likelihood function for $\\theta$ of under the distribution $q(\\textbf{x} | \\theta)$ (train data를 통해 만들어진 분포) 이므로 KL divergence를 최소화하는 것은 likelihood function을 최대화하는 것이다. 이번에는 joint distribution을 생각해보자. 두 변수가 independent이면 $p(\\textbf{x}\\textbf{y}) = p(\\textbf{x})p(\\textbf{y})$ 이다. 하지만 independent가 아닌 경우, 우리는 KL divergence를 통해 얼마나 independent와 가까운지 생각해볼수 있다. $$I[\\textbf{x}, \\textbf{y}] \\equiv KL(p(\\textbf{x}, \\textbf{y}) | p(\\textbf{x})p(\\textbf{y})) = - \\int \\int p(\\textbf{x}, \\textbf{y}) \\ln \\frac{p(\\textbf{x})p(\\textbf{y})}{p(\\textbf{x}, \\textbf{y})}d\\textbf{x} d\\textbf{y}$$ 이를 mutual information between the variable x and y 라고 부른다. conditional entropy의 측면에서 $I[\\textbf{x}, \\textbf{y}] = H[\\textbf{x}] - H[\\textbf{x}|\\textbf{y}] = H[\\textbf{y}] - H[\\textbf{y}/\\textbf{x}]$ 따라서 MI는 y를 알고 난 뒤에 x의 uncertainty가 줄어든 정도 (반대도 성립) 라고 할 수 있다. Bayesian의 입장에서는 $p(\\textbf{x})$가 pior이고 $p(\\textbf{x} | \\textbf{y})$는 y data를 얻은 후의 posterior이다. 따라서 MI는 새로운 observation y의 등장으로 줄어든 x의 uncertainty라고 할 수 있다. ","date":"2021-11-26","objectID":"/prml-chap01-3/:1:1","tags":["Information Theory"],"title":"[PRML] Chapter1 - Introduction (3)","uri":"/prml-chap01-3/"},{"categories":["PRML"],"content":"Decision Theory에 대해 알아봅시다. ","date":"2021-11-26","objectID":"/prml-chap01-2/:0:0","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"1.5 Decision Theory Decision Theory는 크게 두 가지의 과정으로 이루어져 있다. Determining $p(x,t)$ from a training data set : inference 이를 통하여 새로운 데이터에 대해 결정(분류,회귀) : decision Decision Theory의 목표는 적절한 Probability들을 이용하여 optimal한 decision을 내리는 것이다. 2-class classification의 상황을 예시로 뒤의 내용을 진행한다. 우리는 input data를 통해 해당 data의 class를 구분하고 싶기에 $p(C_k / \\textbf{x})$를 구해야 한다. Bayes’ theorem을 생각해보면 posterior를 구해야 하는 것이다. $$p(C_k | \\textbf{x}) = \\frac{p(\\textbf{x} | C_k)p(C_k)}{p(\\textbf{x})}$$ 우리는 misclassfication을 최소화하기 위해서 둘 중 더 큰 posterior probability갖는 class에 input data를 분류한다. ","date":"2021-11-26","objectID":"/prml-chap01-2/:1:0","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"1.5.1 Minimizing the misclassfication rate 우리의 목표가 misclassfication을 최소화하는게 목표라고 하자. 각 $\\textbf{x}$를 class에 분류해야하고 이를 위해 rule이 필요하다. 그 rule에 따라 input space를 region $R_k$로 나눠야 한다. 이 region을 decision regions 라고 한다. ($R_k$에 속한 data는 class k라고 분류) decision region간의 경계선을 decision boundary, decision surface 라고 부른다. misclassfication의 확률은 $$P(mistake) = P(\\textbf{x} \\in R_1, C_2) + P(\\textbf{x} \\in R_2, C_1) = \\int_{R_1} p(\\textbf{x}, C_2)d\\textbf{x}+ \\int_{R_2} p(\\textbf{x}, C_1)d\\textbf{x}$$ mistake의 확률을 최소화하기 위해서는 각 integral의 값을 최소화해야 한다. 따라서 만약 $p(\\textbf{x}, C_1) \u003e p(\\textbf{x}, C_2)$의 경우, data를 class1으로 분류해야한다. $p(\\textbf{x}, C_k) = p(\\textbf{x}) p(C_k | \\textbf{x})$ 이고 우변의 $p(\\textbf{x})$는 공통된 부분이므로 우리는 $p(C_k | \\textbf{x})$만 고려하면 된다. ","date":"2021-11-26","objectID":"/prml-chap01-2/:1:1","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"1.5.2 Minimizing the expected loss 위에서 misclassfication rate를 줄이는 부분에 대해서 살펴봤다. 하지만 실제로 분류를 할 때는 이 접근으로는 부족하다. 예를 들어, 암환자를 분류하는 문제라고 생각해보자. 암이 걸리지 않은 환자를 걸렸다고 잘못 판단하는 것과 암이 걸렸는데 걸리지 않았다고 판단하는 것. 둘 중 후자가 훨씬 심각한 문제이다. 이런 경우 후자에 대해 더 가중치가 있어야 하지 않을까? loss function (cost function) : overall measure of loss incurred in taking any of the available decisions or actions $L_{kj}$ : (k인데 j로 분류한 경우) loss matrix의 element를 의미한다. misclassfication에 대한 loss라고 이해하면 된다. 예를 들면 암환자의 loss matrix는 아래와 같은 모양이다. $$\\begin{bmatrix} 0 \u0026 100 \\\\ 1 \u0026 0 \\end{bmatrix}$$ (inference가 끝난 뒤에 decision하는 과정에 해당) optimal solution은 loss function을 최소화하는 것이다. 하지만 loss function은 true class을 알아야 계산할 수 있다. 우리는 true class를 모른다. (예를 들어, 환자의 신상데이터가 있고 이를 통해 암환자인지 아닌지 찾아야하는 상황) 따라서 우리는 expected (average) loss를 최소화하는 방법을 선택한다. $$E[L] = \\sum_{k} \\sum_{j} \\int_{R_j} L_{kj} p(\\textbf{x}, C_k) d\\textbf{x}$$ 우리의 목표는 expected loss를 최소로 만드는 적절한 $R_j$를 찾는 것이고 이는 각 데이터 $\\textbf{x}$가 $\\sum_{k} L_{kj}p(\\textbf{x}, C_k)$를 최소화 한다는 것을 의미한다. 최종적으로 expected loss를 최소화 하기 위해서는 $\\textbf{x}$를 값 $$\\sum_{k}{L_{kj} p(C_k|\\textbf{x})}= E[L(C_k, \\hat{C}_k) | X=\\textbf{x}]$$ 이 최소가 되는 class $j$로 분류하는 것이다. ","date":"2021-11-26","objectID":"/prml-chap01-2/:1:2","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"1.5.3 The reject option class에 따라 posterior의 비교를 통해 결정하기 애매한 상황이 생긴다. 이런 경우에는 probability에 따라 결정하기 보다는 다른 방법을 사용하는 것이 적절할 수도 있다. (예를 들면, 해당 데이터를 model이 아니라 전문가가 판단하는 방법) 이런 경우 regect option 이 있다고 할 수 있는 것이다. ","date":"2021-11-26","objectID":"/prml-chap01-2/:1:3","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"1.5.4 Inference and decision decision 문제를 해결하는 방법을 3가지로 분류할 수 있다. 앞쪽의 방법일수록 복잡한 방법이다. generative model 아래 식에서 posterior를 구하기 위해서는 분자, 분모를 다 구해야 한다. 한마디로 approachs that explicitly or implicitly model the distribution of inputs as well as outputs. 다른 표현으로는, joint distribution $p(\\textbf{x}, C_k)$을 구해서 marginalize하여 분모도 구하여 posterior를 구한다. $$p(C_k | x) = \\frac{p(x | C_k)p(C_k)}{p(x)}$$ discriminative model approachs that model the posterior probabilities directly 예를 들면 SVM, Tree models, KNN 등등 discriminative function maps each input x directly onto a class label 따라서 확률을 고려하지 않는다. inference와 decision stage를 하나로 묶은 것이다. 각각 장단점이 존재한다. 예를 들면, 1번에서 prior $p(\\textbf{x})$를 구했으므로 해당 값이 너무 작은 새로운 data는 무시하는 판단을 할 수 있다. (outlier detection하는 것처럼) 그렇다면 이제 (1,2번 선호) posterior를 구하면 어떤 장점이 있는지 알아보자. Minimizing risk 이전에 봤던 loss matrix를 수정하여 decision criterion을 수정하기 쉽다. 확률의 threshold를 조정하여 decision criterion을 수정하기 쉽다. Reject option expected loss뿐만 아니라 misclassfication rate를 최소화하는 rejection criterion을 정할 수 있게 해준다. Compensating for class priors posterior는 prior에 비례하므로 prior를 적절하게 바꿔줌으로서 posterior를 보완할 수 있다. Combing models 특정 문제를 subproblem으로 나누어서 생각할 수 있다. 예를 들면, naive bayes model과 같이 independent를 이용하여 posterior를 나누어서 생각할 수 있는 장점이 생긴다. ","date":"2021-11-26","objectID":"/prml-chap01-2/:1:4","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"1.5.5 Loss functions for regression 이전까지 classification에 대해 살펴봤으므로 이번에는 regression에 대해 살펴보자. expected (average) loss는 $$E[L] = \\int \\int L(t, y(\\textbf{x})) p(\\textbf{x}, t) d\\textbf{x}dt$$ 이다. regression에서 주로 사용하는 loss function은 squared loss이고 이를 통해 다시 쓰면 $$E[L] = \\int \\int {y(\\textbf{x}) - t}^2 p(\\textbf{x}, t) d\\textbf{x} dt$$ 이다. 우리는 이를 최소화하는 $y(\\textbf{x})$를 찾는 것이 목표이므로 미분하여 구할 수 있다. $$\\frac{dE[L]}{dy(\\textbf{x})} = 2\\int { y(\\textbf{x}) - t}p(\\textbf{x}, t) dt = 0$$ $$y(\\textbf{x}) = \\frac{\\int t p(\\textbf{x}, t)dt}{p(\\textbf{x})} = \\int t p(t | \\textbf{x})dt = E_t [t | \\textbf{x}]$$ 이는 우리가 알고 있는 regression function의 모양이다. (conditional average of t conditioned on x) 이를 이용하여 추가적인 접근을 해보자면 $${y(\\textbf{x}) - t}^2 = {y(\\textbf{x}) - E[t | \\textbf{x}] + E[t | \\textbf{x}] - t }^2$$ $$E[L] = \\int {y(\\textbf{x}) - E[t | \\textbf{x}]}^2 p(\\textbf{x})d\\textbf{x} + \\int {E[t | \\textbf{x}] - t}^2 p (\\textbf{x}) d\\textbf{x} $$ 두번째 항은 variance of the distribution of t, averaged over x 이다. 따라서 이는 irreducible minumum value of the loss function을 의미한다. ","date":"2021-11-26","objectID":"/prml-chap01-2/:1:5","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"+ Decision Theory 추가 monk의 강의에서 decision theory를 다루는데 해당 내용을 추가하고자 한다. 일단, loss function은 “0-1 loss” 으로 생각하자. true = prediction : 0 true != prediction : 1 두 가지 상황으로 나누어서 살펴보자. 하지만 두 경우 모두의 공통적인 결론은 $p(y/x)$ 가 핵심이라는 것이다. ","date":"2021-11-26","objectID":"/prml-chap01-2/:2:0","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"1. Minimizing conditional expected loss : Given $x$, minimize $L(y, \\hat{y})$ … but don’t know true class $y$ $(X, Y) \\sim P$ : discrete $$E[L(Y, \\hat{y}) | X = x] = \\sum_{y} L(y, \\hat{y}) P(y | x) = \\sum_{y \\neq \\hat{y} } 1*P(y | x) = 1 - P(\\hat{y} | x)$$ $$\\therefore \\hat{y} = argmin_y E[L(Y,\\hat{y}) | x] = argmax_y P(y | x)$$ ","date":"2021-11-26","objectID":"/prml-chap01-2/:2:1","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"2. Choosing f to minimize expected loss : Choose $f(f(x) = y)$ to minimize $L(y, f(x))$ but don’t know $x$ or $y$ $$E[L(Y, \\hat{Y})] = E[L(Y, f(X))] = \\sum_{x,y}L(y, f(x))P(x,y)$$ $$ = \\sum_{x}{\\sum_y L(y, f(x))P(y | x)}P(x) = \\sum_{x}g(x,f(x))p(x) = E_x[g(x,f(x))]$$ suppose for some $x’, t$ $g(x’, f(x’)) \\ge g(x’, t)$ $f_0(x) =$ if $x \\neq x’, f(x)$ if $x = x’, t$ 모든 $x,; g(x,f(x)) \\ge g(x, f_0(x))$ $$\\therefore E_x [g(x, f(x))] \\ge E_x[g(x,f_0(x))]$$ Choose f to min $g(x,f(x))$ $$f(x) = argmin_t g(x,t)$$ ","date":"2021-11-26","objectID":"/prml-chap01-2/:2:2","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"Big picture ","date":"2021-11-26","objectID":"/prml-chap01-2/:2:3","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"Generative model estimate $p(x,y)$ using data and then $p(y|x) = \\frac{p(x,y)}{p(x)}$ parameter / latent : $\\theta$ 라고 하자 $\\theta$는 distribution에 관한 parameter / latent $D$는 random (new data) $$p(y|x,D) = \\int p(y|x,D,\\theta) p(\\theta | x,D) d\\theta$$ $p(y|x,D)$ : predictive distribution $p(\\theta |x,D)$ : posterior distribution $p(y|x,D,\\theta)$ 이 부분은 주로 closed form(eg. regression y=wx)으로 구해지며 어렵지 않다. 하지만 posterior 부분은 closed form으로 못 구하는 경우가 많다. 또한 integral 부분도 계산이 어려운 경우가 많다. 그렇다면 이를 어떻게 해결할까? 크게 4가지의 방법을 살펴보자. exact inference Multivariate Gaussian, Conjugate prior, Graphical model point estimate MLE, MAP (1.2.5를 보면 integral 없이 계산) optimization, EM deteministic approximation Laplace approximation, Variational method, Expectation propagation stochastic approximation Sampling 기법들 (eg. MCMC) ","date":"2021-11-26","objectID":"/prml-chap01-2/:2:4","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"Probability Theory에 대해 알아봅시다. ","date":"2021-11-26","objectID":"/prml-chap01-1/:0:0","tags":null,"title":"[PRML] Chapter1 - Introduction (1)","uri":"/prml-chap01-1/"},{"categories":["PRML"],"content":"1.1 Example : polynomial curve fitting 예를 들어, 회귀에서 error function이 quadratic function of w이면 w에 대한 미분은 w에 linear하고 unique한 closed form의 해를 구할 수 있다. 모델의 overfitting을 항상 조심하고 데이터의 수가 늘어날수록 그 정도는 약해진다. MLE 방법은 overfitting에 취약하며 Bayesian 모델링으로 보완할 수 있다. ridge와 같이 error function에 패널티항을 추가하여 overfitting을 막는 방법도 있다. 이를 shrinkage 방법이라 부른다. (딥러닝에서는 weight decay) 이런 모델의 복잡한 정도를 정하는 데에 validation data set을 만들기도 하는데 이는 다소 낭비이므로 다른 방법을 공부할 것이다. (아마 Bayesian approach일듯) ","date":"2021-11-26","objectID":"/prml-chap01-1/:1:0","tags":null,"title":"[PRML] Chapter1 - Introduction (1)","uri":"/prml-chap01-1/"},{"categories":["PRML"],"content":"1.2 Probability Theory 패턴인식에서 가장 중요한 컨셉은 uncertainty이다. Probability Theory는 이런 uncertainty을 quantification하고 manipulation하는 방법을 제시한다. (확률을 이용하여) The rules of Probability sum rule : $p(X) = \\sum_{Y}{p(X,Y)}$ product rule : $p(X,Y) = p(Y|X)p(X)$ Bayes’ Throrem (rule) $p(Y|X) = \\frac{p(X|Y)p(Y)}{p(X)}$ $p(Y)$ : prior probability $p(Y|X)$ : posterior probability ","date":"2021-11-26","objectID":"/prml-chap01-1/:2:0","tags":null,"title":"[PRML] Chapter1 - Introduction (1)","uri":"/prml-chap01-1/"},{"categories":["PRML"],"content":"1.2.1 Probability densities probability density : if the probability of a real-valued variable $x $ falling in the interval $(x, x+\\delta x )$ is given by $p(x)\\delta x$ for $\\delta x \\rightarrow 0$, then $p(x)$ is called the probability density 값은 항상 0 이상, 합하면 1을 가진다. ","date":"2021-11-26","objectID":"/prml-chap01-1/:2:1","tags":null,"title":"[PRML] Chapter1 - Introduction (1)","uri":"/prml-chap01-1/"},{"categories":["PRML"],"content":"1.2.2 Expectations and covariances expection of $f(x)$ : $E[f(x)] = \\int{p(x)f(x)dx}$ it can be approximated as $$E[f] \\approx \\frac{1}{N}\\sum_{n=1}^{N}{f(x_n)}$$ $E_x [f(x,y)]$는 y에 대한 함수이다. x에 대해 averaged over 된 것이다. conditional expection : $E[f(x)|y] = \\int{p(x|y)f(x)dx}$ variance of $f(x)$ : $var[f] = E[(f(x) - E[f(x)])^2]$ $f(x)$가 mean 주위에서 얼마나 variability가 있는지 보여준다. ","date":"2021-11-26","objectID":"/prml-chap01-1/:2:2","tags":null,"title":"[PRML] Chapter1 - Introduction (1)","uri":"/prml-chap01-1/"},{"categories":["PRML"],"content":"1.2.3 Bayesian probabilities 우리가 일반적으로 알고 있는 확률(probability)은 frequentist의 견해이다. bayesian은 frequentist와는 아예 다른 접근법을 갖는다. Frequentist 분모가 되는 전체 사건이 무한대로 일어나고 우리가 궁금한 사건이 그 중 몇번 일어나는지를 확률로 생각한다. parameter 추정이 목표이며 parameter는 fixed 되어 있다고 생각한다. 주로 estimator로서 likelihood function을 최대화하는 MLE로 사용한다. Bayesian 확률 : uncertainty를 quantification한 것으로 생각한다. parameter는 fixed 된 것이 아니라 (probability) distribution을 갖는 것이라고 생각한다. posterior distribution을 찾는 것이 목표이다. Bayes’ theorem $$p(\\textbf{w} | D) = \\frac{p(D | \\textbf{w})p(\\textbf{w})}{p(D)}$$ parameter에 대해 원래 갖고 있던 믿음을 data D에 대한 정보를 얻은 뒤에 posterior probability로 업데이트 한다. (분모는 posterior가 합이 1이 되기 위한 normalization constant) prior probability : $p(w)$ likelihood function : $p(D/w)$ posterior probability : $p(w/D)$ posterior $\\propto$ likelihood * prior ","date":"2021-11-26","objectID":"/prml-chap01-1/:2:3","tags":null,"title":"[PRML] Chapter1 - Introduction (1)","uri":"/prml-chap01-1/"},{"categories":["PRML"],"content":"1.2.4 The Gaussian distribution $$N(x | \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi \\sigma^2}}exp{ - \\frac{(x-\\mu)^2}{2 \\sigma^2} }$$ mean : $\\mu$ variance : $\\sigma^2$ standard deviation : $\\sigma$ precision : $\\beta = 1/ \\sigma^2$ normal (gaussian) 분포는 mode와 mean이 같다. i.i.d (independent and identically distributed : data point가 독립적이고 같은 분포에서 나왔다) 인 경우, likelihood function은 $$p(\\textbf{x} | \\mu, \\sigma^2) = \\prod_{n=1}^{N}{N(x_n | \\mu, \\sigma^2)}$$ 이고 이를 최대화하는 mean과 variance의 MLE는 sample mean, sample variance이다. MLE를 구하는 방법은 likelihood function에 log를 취한 후 미분하여 0을 만족하는 parameter를 찾으면 된다. 이때 단점은 maximum likelihood 접근법이 분포의 variance를 underestimate한다(bias 발생)는 점이다. N이 커지면 문제가 없지만 복잡한 모델에서는 이런 bias때문에 문제가 발생할 수 있다. (나중에 공부한다) ","date":"2021-11-26","objectID":"/prml-chap01-1/:2:4","tags":null,"title":"[PRML] Chapter1 - Introduction (1)","uri":"/prml-chap01-1/"},{"categories":["PRML"],"content":"1.2.5 Curve fitting re-visted data를 통해 polynomial curve를 fitting해보자. target t에 대한 uncertainty를 probability를 통해 표현하면 (under gaussian noise distribution) $$p(t | x, \\textbf{w}, \\beta) = N(t | y(x,\\textbf{w}), \\beta^{-1})$$ 위의 식을 이용하여 우리는 parameter $\\textbf{w}$ 추정한다. likelihood를 최대로 하는 MLE를 찾으면 되는 것이다. log likelihood function은 아래와 같은 모양을 갖는다. $$\\ln p(\\textbf{t} | \\textbf{x}, \\textbf{w}, \\beta) = - \\frac{\\beta}{2}\\sum_{n=1}^{N}{{ y(x_n, \\textbf{w}) - t_n }^2} + \\frac{N}{2}\\ln \\beta - \\frac{N}{2}\\ln (2 \\pi)$$ 위 값을 최대화 하는 $\\textbf{w}_{ML}$을 찾으면 된다. 이는 결국 least square 방법과 동일한 의미를 갖는다. (추정선과 target의 차이를 최소화해야되므로) parameter를 추정한 뒤에 이제 prediction을 해야한다. 우리는 확률모델을 갖고 있기에 t에 대한 point estimate만이 아니라 predictive distribution을 만들 수 있다. $$p(t | x, \\textbf{w} _ {ML}, \\beta _ {ML}) = N(y(x,\\textbf{w} _ {ML}), \\beta _ {ML}^{-1})$$ 지금까지는 frequentist의 영역이였다면 Bayesian들은 어떤 접근을 하는지 살펴보자. 일단 우리가 추정해야하는 parameter에 대한 prior를 갖고 있다. prior distribution를 gaussian 분포로 가정하면 아래와 같이 나타낼 수 있다. (Mth order의 polynomial) $$p(\\textbf{w} | \\alpha) = N(\\textbf{0}, \\alpha^{-1}\\textbf{I}) = (\\frac{\\alpha}{2\\pi})^{(M+1)/2} \\exp { -\\frac{\\alpha}{2} \\textbf{w}^T \\textbf{w}}$$ 이를 통해 우리는 posterior distribution를 구할 수 있다. posterior는 likelihood와 prior의 곱에 비례하므로 $$p(\\textbf{w} | \\textbf{x}, \\textbf{t}, \\alpha, \\beta) \\propto p(\\textbf{t} | \\textbf{x}, \\textbf{w}, \\beta)p(\\textbf{w} | \\alpha)$$ 위의 posterior distribution을 최대화로 만드는 parameter를 MAP (MLE에 대응되는 point estimate)라고 부른다. posterior distribution에 negative log를 취한다. posterior를 최대로 만드는 것은 아래를 최소화 하는 것과 같다. $$\\frac{\\beta}{2}\\sum_{n=1}^{N}{{ y(x_n, \\textbf{w}) - t_n }^2} + \\frac{\\alpha}{2}\\textbf{w}^T\\textbf{w}$$ 위 결과를 통해 posterior distribution를 maximizing하는 것은 regularized sum-of-squares error function을 minimizing하는 것과 동일하다는 것을 알 수 있다.. (L2 regularization, Ridge regression) ","date":"2021-11-26","objectID":"/prml-chap01-1/:2:5","tags":null,"title":"[PRML] Chapter1 - Introduction (1)","uri":"/prml-chap01-1/"},{"categories":["PRML"],"content":"1.2.6 Bayesian curve fitting 위의 Bayesian 접근법은 point estimate를 구했기 때문에 살짝 아쉽다. 좀 더 Bayesian적인 방법은 $\\textbf{w}$의 모든 값에 대해 integral over하는 것이다. $\\textbf{w}$에 대해 marginalize하면 되는데 이는 뒤에 자주 나오는 방법이므로 잘 기억하자. 이제 predictive distribution을 구해보자. training data : $\\textbf{x},\\textbf{t}$ new data : $x$ hyperparameter (assume we know) : $\\alpha, \\beta$ (아래식에서는 생략) $$p(t | x, \\textbf{x}, \\textbf{t}) = \\int p(t | x, \\textbf{w})p(\\textbf{w} | \\textbf{x}, \\textbf{t}) d\\textbf{w} = N(t| \\mu(x), s^2(x))$$ $$\\mu (x) = \\beta \\phi (x)^T \\textbf{S} \\sum_{n=1}^{N}{\\phi (x_n)} t_n $$ $$s^2 (x) = \\beta^{-1} + \\phi (x)^T \\textbf{S} \\phi (x)$$ $$\\textbf{S}^{-1} = \\alpha \\textbf{I} + \\beta \\sum_{n=1}^{N}{\\phi (x_n) \\phi (x)^T}$$ vector $\\phi (x)$ : element $\\phi_i (x) = x^i$ for $i = 0, … M$ ","date":"2021-11-26","objectID":"/prml-chap01-1/:2:6","tags":null,"title":"[PRML] Chapter1 - Introduction (1)","uri":"/prml-chap01-1/"},{"categories":["PRML"],"content":"1.3 Model Selection 여러 가지 모델을 선택할 때, train score로 model을 선택하는 것은 적절하지 않다. 그래서 validation set을 이용한다. 하지만 validation set에 overfitting하는 경우도 있기에 test set으로 최종 점검까지 하는 것이다. data가 제한적인 경우 cross validation의 방법을 사용한다. 하지만 이는 상당히 computationally expensive하다. ","date":"2021-11-26","objectID":"/prml-chap01-1/:3:0","tags":null,"title":"[PRML] Chapter1 - Introduction (1)","uri":"/prml-chap01-1/"},{"categories":["PRML"],"content":"1.4 The Curse of Dimensionalty 차원의 저주를 보여주는 몇가지 예시들 nearest neighborhood 알고리즘에 해당하는 부분 : sample space를 cubic형태로 나눈다고 생각했을 때, 차원이 커짐에 따라 지수적으로 cubic의 갯수가 많아진다. 따라서 cubic에 data가 텅 비지 않으려면 많은 양의 데이터가 필요하다. polynomial 의 경우 : Mth order의 polynomial 모델을 사용한다고 하면 $D^M$ 으로 parameter의 수가 증가한다. data를 sphere하게 생각해보자. 차원이 높아질수록 sphere의 표면쪽에 data가 몰려있다. 즉, 중심쪽이 sparse해지는 것이다. ","date":"2021-11-26","objectID":"/prml-chap01-1/:4:0","tags":null,"title":"[PRML] Chapter1 - Introduction (1)","uri":"/prml-chap01-1/"}]