[{"categories":["PRML"],"content":"Bayesian Optimization으로 모델의 성능을 올려보자. ","date":"2021-11-29","objectID":"/prml-chap06-3/:0:0","tags":["Bayesian Optimization"],"title":"[PRML] Bayesian Optimization","uri":"/prml-chap06-3/"},{"categories":["PRML"],"content":"Bayesian Optimization with Gaussian Process 어떤 sequence of experiments를 한다고 생각해보자. 다음은 몇 가지 가정사항이다. Interested in finding a global maximizer(minimizer) of $f(\\bf{x})$ 우리는 experiments result를 만드는 underlying function $f(\\bf{x})$를 모른다. input은 우리가 다 알고 조절할 수 있다. result have a stochastic element $y_t \\sim N(f,\\sigma^2_{noise})$ results and input are continuous 일반적인 경우는 continous를 고려하지만 discrete, hybrid의 경우도 존재한다. 다양한 task에서 사용할 수 있지만 우리는 주로 hyperparameter tuning을 할 때 사용하게 된다. Grid search no learning of underlying function Binary search learning of constraints, not the function 위와 같은 방법들이 많이 사용되었다. 이와 다르게 BOP는 learning underlying function with surrogate model selecting the next sampling input 같은 task를 통해서 최적의 결과를 얻어내고자 하는 것이다. 그렇다면 어떤 과정으로 최적의 결과를 얻어낼까? GPR은 모든 data point에서 predicted mean, predicted std를 알려준다. input을 넣고 underlying function을 만든다 (GPR을 fitting하는 것). 그 후에 mean과 variance를 통해 exploitation or exploration를 결정하여 next sampling input을 결정한다. (그리고 다시 underlying function을 만든다. 이를 반복한다.) Exploitation : result값이 높은 곳(underlying function mean이 큰) 탐색 Exploration : 관측지가 적은 곳(variance가 큰) 탐색 이떄, 이에 대한 판단 기준이 필요하다. acquisition function을 이용한다. 이에 대해 한번 더 정리하자면 Surrogate model : Compute $p(f|D_{1})$, yielding $\\mu_{1}({\\bf x})$ and $\\sigma_{1}({\\bf x})$. Acquisition function: Choose ${\\bf{x}} _ {2}$ such that ${\\bf x} _ {2}=argmax_{ {\\bf x} \\in \\mathcal{X} } a ({\\bf x}|\\mathcal{M}_{1})$ Augment data, $D_2 = D_1 \\cup \\{ ({\\bf x}_{2}, y _ {2}) \\}$ Surrogate model : Compute $p(f|D_2)$, yielding $\\mu_{2}({\\bf x})$ and $\\sigma_{2}({\\bf x})$. Acquisition function: Choose ${\\bf x} _ 3$ such that ${\\bf x} _ {3}=argmax_{ {\\bf x} \\in \\mathcal{X} }a({\\bf x}|\\mathcal{M}_{3})$ Augment data, $D_ 3 = D_2 \\cup \\{ ({\\bf x} _ {3},y _ {3}) \\}$ Repeat theses till the final round T, to compute $\\mu_{T}({\\bf x})$ ${\\bf x}^{*} = argmax_{ {\\bf x} \\in {\\bf x}_1,…,{\\bf x} _ T } \\mu _ {T}({\\bf x})$ ","date":"2021-11-29","objectID":"/prml-chap06-3/:1:0","tags":["Bayesian Optimization"],"title":"[PRML] Bayesian Optimization","uri":"/prml-chap06-3/"},{"categories":["PRML"],"content":"surrogate model 다양한 모델을 사용할 수 있다. 하지만 해당 point의 mean, variance를 알 수 있는 stochastic한 모델이여야 할 것이다. Random Forest Empirical하게 mena, variance를 구할 수 있다. scable, faster continuous, discrete 변수 모두 handle 가능하다. (GP는 kernel을 따로 design해야 한다고 함) extrapolation을 잘 못한다. GP regression Nonparameteric Bayesian Regression Not scalable 10dim이 넘어가면 standard GP로는 힘들다. sample dsata의 수가 많아져도 힘들다. ","date":"2021-11-29","objectID":"/prml-chap06-3/:1:1","tags":["Bayesian Optimization"],"title":"[PRML] Bayesian Optimization","uri":"/prml-chap06-3/"},{"categories":["PRML"],"content":"Acquisition Function Acquisition Function은 다양하다. 몇 가지만 간단히 알아보고 코드를 통해 실습을 진행해보자. Maximum Probability of Improvement (PI) 현재 optimized value $y_{max}$를 어떤 margin m 이상으로 올려줄 확률이 가장 높은 input을 sampling한다. grid search처럼 value를 계산하는 것이 아니라 확률만 계산하여 진행한다. $D$는 기존 data, 이를 통해 GPR을 만들수 있겠다. $y \\sim N(\\mu, \\sigma^2)$ 이는 GPR로 만들어진 것이다. $$MPI(x|D) = \\argmax_x P(y \\ge (1+m)y_{max} | x, D)$$ $$y\\sim N(\\mu, \\sigma^2) = \\argmax_x P(\\frac{y-\\mu}{\\sigma} \\ge \\frac{(1+m)y_{max}-\\mu}{\\sigma})$$ $$= \\argmax_x \\Phi (\\frac{\\mu - (1+m)y_{max}}{\\sigma})$$ 그런데 PI는 잘 안쓴다고 한다. Maximum Expected Improvement (EI) MPI를 조금 더 디벨롭시킨 것이다. MPI에서는 m을 고려해야했다. 그렇게 하지 말고 0부터 infinite으로 고려하면 되지 않을까? 라는 접근을 한다. 구체적으로 식을 구하는 과정은 생략한다. expected improvement w.r.t. the best observed objective value $y_{b}$ so far is defined as $$EI = E _ y [ \\max (y - y_{b} ,0) ]$$ $$=\\int \\max (y-y_{b}) N (y | \\bar{y}, \\sigma^{2})dy$$ $$=(\\bar{y} - y_b) \\Phi ( \\frac{\\bar{y}-y_b}{\\sigma} ) + \\sigma \\phi ( \\frac{\\bar{y} - y_b}{\\sigma} )$$ Gaussian Process-Upper Confidence Bound (GP-UCB) posterior mean과 variance의 적절한 trade-off를 고려하여 data point를 선택한다. 아래의 수식에 따라서 point를 선택한다. $\\beta_t$ : appropriate constants $\\nu$ : hyperparameter involving the degree of exploration $$\\bf{x} _ t = \\argmax_{\\bf{x}} ( \\mu_{t-1}(\\bf{x}) + \\sqrt{\\nu \\beta_t} \\sigma_{t-1}(\\bf{x}))$$ Thompson Sampling posterior에서 function을 sampling하는 방법이다. ","date":"2021-11-29","objectID":"/prml-chap06-3/:1:2","tags":["Bayesian Optimization"],"title":"[PRML] Bayesian Optimization","uri":"/prml-chap06-3/"},{"categories":["PRML"],"content":"이해를 위한 코드 # NHN cloud # https://www.youtube.com/watch?v=PTxqPfG_lXY import numpy as np from scipy.stats import norm from sklearn.gaussian_process import GaussianProcessRegressor from sklearn.gaussian_process.kernels import RBF # Acquisition function def expected_improvement(mean, std, max): z = (mean - max) / std return (mean - max) * norm.cdf(z) + std * norm.pdf(z) # Objective function def f(x): return x * np.sin(x) # hyperparameter space min_x, max_x = -2, 10 # Observation data X = np.random.uniform(min_x, max_x, 3).reshape(-1, 1) y = f(X).ravel() # GP model gp_model = GaussianProcessRegressor(kernel=RBF(1.0)) for i in np.arange(10): # surrogate model fit gp_model.fit(X, y) # predict -\u003e mean, std 계산 xs = np.random.uniform(min_x, max_x, 10000) mean, std = gp_model.predict(xs.reshape(-1, 1), return_std=True) # acq 계산 acq = expected_improvement(mean, std, y.max()) # acq가 가장 큰 값 선택 x_new = xs[acq.argmax()] y_new = f(x_new) # 데이터에 추가 X = np.append(X, np.array([x_new])).reshape(-1, 1) y = np.append(y, np.array([y_new])) ","date":"2021-11-29","objectID":"/prml-chap06-3/:1:3","tags":["Bayesian Optimization"],"title":"[PRML] Bayesian Optimization","uri":"/prml-chap06-3/"},{"categories":["PRML"],"content":"Reference 문일철 교수님 강의 NHN cloud 발표 paper Taking the Human Out of the Loop: A Review of Bayesian Optimization (2016) A tutorial on Bayesian optimization (2018) ","date":"2021-11-29","objectID":"/prml-chap06-3/:2:0","tags":["Bayesian Optimization"],"title":"[PRML] Bayesian Optimization","uri":"/prml-chap06-3/"},{"categories":["PRML"],"content":"Gaussian Process에 대해 정리하였다. ","date":"2021-11-29","objectID":"/prml-chap06-2/:0:0","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"6.4 Gaussian Processes 이 부분은 카이스트 문일철 교수님의 유투브영상을 보고 정리하였습니다. ","date":"2021-11-29","objectID":"/prml-chap06-2/:1:0","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Continuous Domain Data GP는 continuous domain data 분석에 유용하다. Time, Space, Spatio-Temporal… 어떻게 분석, 모델링? Estimating on the underlying function (ex. Autoregression) Prediction on the unexpected point (ex. extrapolation with autoregression) ","date":"2021-11-29","objectID":"/prml-chap06-2/:1:1","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Underlying Function and Observations $Y = sinc(x)$ 라는 함수를 underlying function이라고 하자. 여기서 gaussian noise를 추가하여 observation들을 생성했다. 지금 그림은 없지만 그림1은 x에 따라 분산이 동일하고 그림2는 x에 따라 분산이 변화(x가 클수록 분산이 커짐)한다. underlying function을 구해야하므로 mean function을 찾는 것은 당연하고 추가로 variance(or precision) function도 중요하다. $$\\mu(t), \\sigma(t)^2$$ ","date":"2021-11-29","objectID":"/prml-chap06-2/:1:2","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Simple Analyses without Domain Correlation mean function을 domain correlation없이 estimate한다고 하자. 즉, 특정 1개의 point에서 mean과 variance를 계산하는 것이다. 그런데 continuous domain에서 사실 같은 $x(t)$에 대해 multiple obsevation이 나올 수 없다. 약간의 discretize라고 할 수 있다. 해당 domain point에서 observation이 많으면 어느 정도 smooth하게 mean function을 구할 수 있다. 하지만 반대의 경우 좋은 estimation이 어렵다. 그래서 우리는 주위의 다른 domain data point도 사용하는게 좋지 않을까 라는 생각을 할 수 있다. ","date":"2021-11-29","objectID":"/prml-chap06-2/:1:3","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Simple Analyses with Domain Correlation Moving average time window(특정 구간)를 설정하고 평균 급격하게 변화하는 구간은 잘 안 맞을 수도 있다. time window에 따라 변화 window가 커질수록 smooth해진다. $$MA(x) = \\frac{1}{N} \\sum_{x \\in W} y_i$$ 그런데 모든 data point에 동일한 가중치를 주는게 다르게 주면 어떨까? 예를 들면, Squared Exponential $L$이 커지면 window가 커지는 역할 위에서 window 크기처럼 $L$을 적절히 선택해야한다. $$k(x,x_i;L) = exp(-\\frac{|x-x_i|^2}{L^2})$$ 위처럼 domain correlation을 다르게 생각하고 거리에 따라 가중치를 다르게 주는 것이다. 가까울수록 큰 가중치! $$MA(x) = \\frac{1}{\\sum_{x_i \\in D} k(x,x_i)}\\sum_{x_i \\in D} k(x,x_i) y_i$$ ","date":"2021-11-29","objectID":"/prml-chap06-2/:1:4","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Random Process Random process(=Stochastic process) An infinite indexed collection of random variables ${ X(w,t) , t \\in T }$ index paramter : $t$ (time, space…) A function $X(t,\\omega), t \\in T ;\\text{and}; \\omega \\in \\Omega$ outcome : $\\omega$ Fixed $t \\rightarrow X(t,\\omega)$ is a random variable over $\\Omega$ Fixed $\\omega \\rightarrow X(t,\\omega)$ is a deterministic function of $t$ ; sample function ","date":"2021-11-29","objectID":"/prml-chap06-2/:2:0","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Gaussian Process GP는 Random Process의 한 종류 For any set S, a GP on S is a set of random variable ($z_t : t \\in S$) such that vector $[z_{t_1}, z_{t_2},…,z_{t_n}]$ is multivariate gaussian $$P(T) = N(0, (\\beta I_N)^{-1} + K) \\ K_{nm} = k(x_n, x_m) = \\theta_0 \\exp(-\\frac{\\theta_1}{2}||x_n - x_m||^2) + \\theta_2 + \\theta_3 x_n^T x_m$$ ","date":"2021-11-29","objectID":"/prml-chap06-2/:3:0","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Derivation of Gaussian Process 일단 linear regression으로 접근하고 GP에 대해 알아본다. gaussian process regression : a nonparametric bayesian regression method using the properties of Gaussian processes ","date":"2021-11-29","objectID":"/prml-chap06-2/:4:0","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Mapping Functions non-linearly separable data set이 있다고 가정하자. 이를 위해 basis space를 증가시키면 될 것이다. mapping function $\\phi$를 통해 확장시킨다. ","date":"2021-11-29","objectID":"/prml-chap06-2/:4:1","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Linear regression with basis function $$y(x) = w^T \\phi (x)$$ 여기서 $w$를 deterministic value가 아니라 probabilistically distributed value라고 생각하자. (Bayesian linear regression의 방법론) $$P(w) = N(0, \\alpha^{-1} I)$$ Y의 확률분포(joint distribution)에 대해 생각해보자. ($w$가 확률분포가 있으니까) $Y$도 normal 이겠구나 (multivariate gaussian) $$Y = (y_1, y_2,…,y_n)$$ $K$ : Gram matrix $$E[Y] = E[\\Phi w] = \\Phi E[w] = 0$$ $$cov(Y) = E[YY^T] = E[\\Phi w w^T \\Phi^T]$$ $$= \\Phi E[ww^T]\\Phi^T = \\frac{1}{\\alpha} \\Phi \\Phi^T$$ $$K_{nm} = k(x_n,x_m) = \\frac{1}{\\alpha} \\phi (x_n)^T \\phi (x_m)$$ $$\\therefore P(Y) = N(0,K)$$ 분산이 kernel function을 이용한다는 점을 기억하자 이제 $Y$에 대한 분포를 파악했으니 이를 통해 prediction을 해보자. ","date":"2021-11-29","objectID":"/prml-chap06-2/:4:2","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Modeling Noise with Gaussian distribution $t_n$ : observed value with noise $y_n$ : Latent, error-free value $e_n$ : Error term distributed by following the gaussian distribution $$t_n = y_n + e_n \\ (t_n = f(x_n)+e_n)$$ $$P(T|Y) = N(Y, \\beta^{-1} I)$$ $\\beta$ : hyperparameter of the error precision error term들이 independent라고 가정하기에 variance 부분에 $I$이 된다. $$P(T) = \\int P(T|Y)P(Y) dY = \\int N(Y,\\beta^{-1} I) N(0,K) dY$$ 위의 곱해지는 두 분포 모두 multivariate gaussian distribution 이므로 이를 이용하여 구할 것이다. $$P(T|Y)P(Y) = P(T,Y) = P(Z)$$ $$\\ln P(Z) = \\ln P(T|Y) + \\ln P(Y) \\ = - \\frac{1}{2} Y^TK^{-1}Y - \\frac{1}{2}(T-Y)^T \\beta I (T-Y) + const$$ 여기서 변수는 $T,Y$이다. 여기서 second order term을 보면 (second order term을 찾으면 covariance를 찾을 수 있기에) $$ = \\frac{1}{2} \\begin{pmatrix} Y \\\\ T \\end{pmatrix}^T \\begin{pmatrix} K^{-1} + \\beta I \u0026 -\\beta I \\\\ - \\beta I \u0026 \\beta I \\end{pmatrix} \\begin{pmatrix} Y \\\\ T \\end{pmatrix} = \\frac{1}{2}Z^T R Z$$ $R$은 precision matrix가 된다. 이를 inverse 하면 (공식이용) $$R^{-1} = \\begin{pmatrix} K \u0026 K \\\\ K \u0026 (\\beta I)^{-1} + K \\end{pmatrix}$$ $\\ln (Z)$의 first order term은 없다. mean이 0라는 것을 알 수 있다. 따라서 최종 결과는 $$P(Z) = N(0, R^{-1})$$ 이제 PRML chapter 2에서 봤었던 공식을 이용하면 marginal distribution을 구할 수 있다. $$P(T) = N(0, (\\beta I)^{-1} + K)$$ 이제 우리가 관찰한 N개의 data를 통해 $P(T)$를 알게 되었다. 그렇다면 이제 prediction해보자. $t_{N+1}$을 알아내야 한다. $$P(t_{N+1}|T_N)$$ 이를 구하기 위해 N+1의 joint를 구하고 conditional disribution을 만들면 된다. ","date":"2021-11-29","objectID":"/prml-chap06-2/:4:3","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Sampling of $P(T)$ Sampling T of 101 dimension when points $x_n = [-1,-0.98,…,1]$ : 101개의 data point mean $0$ : 101 dim zero vector cov $(\\beta I_N)^{-1} + K$ : 101 * 101 dim cov $$P(T) = N(0, (\\beta I_N)^{-1} + K)$$ kernel의 parameter와 $\\beta$값에 따라서 sampling data들이 이루는 모습이 달라진다. ","date":"2021-11-29","objectID":"/prml-chap06-2/:4:4","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Mean and Covariance of $P(t_{N+1} | T_N)$ $$P(t_{N+1}|T_N) = P(T_{N+1}) / P(T_N)$$ $$P(T_{N+1}) = N(0, cov_{N+1})$$ mean은 1차원이 늘어난 zero vector이고 cov는 행과 열이 하나씩 들어간 형태일 것이다. 이는 kernel function과 $\\beta$를 통해 어렵지 않게 구할 수 있다. $$cov_{N+1} = \\begin{pmatrix} cov_N \u0026 k \\\\ k^T \u0026 K_{(N+1)(N+1)}+\\beta^{-1} \\end{pmatrix}$$ 이제 joint distribution을 구했으니 conditional distribution을 구할 수 있다. (공식 PRML chap2에 나온다) $$P(t_{N+1}|T_N) = N(0+k^T cov_N^{-1}(T_N-0),K_{(N+1)(N+1)}+\\beta^{-1} -k^Tcov_N^{-1} k )$$ 이는 결국 regression을 한 것이다. predictive distribution을 구한 것이다. 평균과 분산 모두 new data $x_{N+1}$에 depend하다. 분산에서 inverse가 computationally 오래걸려서 approximation하는 방법들이 있다고 한다. $$\\mu_{t_{N+1}} = k^T cov_N^{-1} T_N \\ \\sigma^2_{t_{N+1}} = K_{(N+1)(N+1)}+\\beta^{-1} -k^Tcov_N^{-1} k$$ 우리가 알고 있는 일반적인 regression과는 조금 다른 형태이다. 각 feature들의 weight들이 어디있는지 궁금할 수 있는데 kernel function안의 parameter로 들어갔다. ","date":"2021-11-29","objectID":"/prml-chap06-2/:4:5","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Hyperparameter of Gaussian Process Regression 위에서 linear regression에서 parameter optimization을 하는 방법을 알아보자. 아래의 kernel hyperparameter를 추정해야 하는 것이다. $$ K_{nm} = k(x_n, x_m) = \\theta_0 \\exp(-\\frac{\\theta_1}{2}||x_n - x_m||^2) + \\theta_2 + \\theta_3 x_n^T x_m$$ $$P(T;\\theta) = N(0, (\\beta I_N)^{-1} + K)$$ $\\theta$를 추정하기 위해 likelihood를 최대한 높이는 방법을 택한다. $\\theta$에 대해 미분하여 구하면 된다. $$\\frac{\\partial}{\\partial \\theta_i} \\log P(T;\\theta) \\overset{let}{=}0$$ 그런데 closed form은 존재하지 않는다. 그래서 approximation해야 한다. (너무 복잡해서 derivation 생략) 우리는 pytorch와 같은 framework의 도움을 받아서 구한다. ","date":"2021-11-29","objectID":"/prml-chap06-2/:4:6","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Gaussian Process Classifier 아래와 같이 일반적인 logistic regression과 거의 동일하다. Gaussian process classifier : sigmoid function + Gaussian process Gaussian process : $f(x;\\theta)$ Gaussian process classifier : $y=\\sigma (f(x;\\theta))$ if $t \\in {0,1}$, objective function to optimize : $$P(t | \\theta) = \\sigma (f(x;\\theta))^t (1-\\sigma (f(x;\\theta)))^{1-t}$$ ","date":"2021-11-29","objectID":"/prml-chap06-2/:5:0","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Regression에 대해 알아보자. ","date":"2021-11-26","objectID":"/prml-chap03-2/:0:0","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (2)","uri":"/prml-chap03-2/"},{"categories":["PRML"],"content":"3.3 Bayesian Linear Regression 이전에 우리는 maximum likelihood 방법을 통해 linear regression 의 parameter를 구하는 방법을 공부했다. 이는 몇 가지 특징(단점)이 있는데 MLE 는 overfitting의 위험이 있다. 적절한 model complexity를 정해야 한다. by basis function의 수 regularization coefficient 우리는 한정적인 dataset을 갖고 있기에 적절한 model complexity를 정하기 위해서는 cross validation과 같은 computationally expensive한 방법을 사용해야한다. 위와 같은 단점들을 해결하기 위해 우리는 Bayesian 방법론을 사용할 것이다. MAP는 uncertainty를 표현할 수 없기 때문에 distribution을 이용한다. ","date":"2021-11-26","objectID":"/prml-chap03-2/:1:0","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (2)","uri":"/prml-chap03-2/"},{"categories":["PRML"],"content":"3.3.1 Parameter distribution 이전에 likelihood function $p(t|{\\bf w})$ 이 Gaussian 이었다. 이에 대한 conjugate prior로 Gaussian을 가정한다. prior distribution은 $$p({\\bf w}) = N({\\bf m}_0, {\\bf S}_0) $$ likelihood function과 prior를 곱해 posterior를 계산하면 (계산과정은 생략, monk영상을 보면 된다) $$p({\\bf w}|{\\bf t}) = N({\\bf m}_N, {\\bf S}_N)$$ ${\\bf m}_N = {\\bf S}_N({\\bf S}_0^{-1} {\\bf m}_0 + \\beta { \\bf \\Phi}^T {\\bf t})$ ${\\bf S}_N^{-1} = {\\bf S}_0^{-1}+\\beta {\\bf \\Phi}^T {\\bf \\Phi}$ $\\beta$ : (target error term) noise precision parameter (assume known) Gaussian은 mean과 mode(최빈값)가 같은 값을 갖기 때문에 ${\\bf w}_{MAP} = {\\bf m}_N$ 이다. 만약 infinite broad prior인 경우 (${\\bf S}_0 = \\alpha^{-1}{\\bf I},\\alpha \\rightarrow 0$) 수식을 전개해보면 ${\\bf m}_N \\rightarrow {\\bf m} _ {ML}$ 반대로 $N \\rightarrow 0$ 이면 posterior 는 prior로 가까워진다. 복잡해 보이는 prior를 다소 간단한 형태로 정하면 $p({\\bf w}|\\alpha) = N(0, \\alpha^{-1}I)$ 으로 생각할 수 있다. 이 prior에서 posterior의 mean, precision은 $${\\bf m}_N = \\beta {\\bf S}_N {\\bf \\Phi}^T {\\bf t}$$ $${\\bf S}_N^{-1} = \\alpha {\\bf I} + \\beta {\\bf \\Phi}^T {\\bf \\Phi}$$ log of posterior distribution (log of likelihood function과 log of prior의 합) 은 $$\\ln p({\\bf w}|{\\bf t}) = -\\frac{\\beta}{2}\\sum_{n=1}^{N}{t_n-{\\bf w}^T\\phi({\\bf x}_n)}^2 - \\frac{\\alpha}{2}{\\bf w}^T{\\bf w}+const$$ 이는 결국 minimization of the sum of square with quadratic regulrarization($\\lambda = \\frac{\\alpha}{\\beta}$) 과 같은 수식이다. ","date":"2021-11-26","objectID":"/prml-chap03-2/:1:1","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (2)","uri":"/prml-chap03-2/"},{"categories":["PRML"],"content":"3.3.2 Predictive distribution 우리의 최종 목표는 predictive distribution 이다. $$p(t|{\\bf t}, \\alpha, \\beta) = \\int p(t|{\\bf w}, \\beta)p({\\bf w}|{\\bf t}, \\alpha, \\beta)d{\\bf w} $$ predictive distribution을 보면 target의 conditional distribution $p(t | w,\\beta)=N(t | y(w,x), \\beta^{-1})$ 와 weight parameter ${\\bf w}$의 posterior distribution으로 만들어졌다. 이를 토대로 정리하면 $$p(t|{\\bf t}, \\alpha, \\beta) = N({\\bf m}_N^T\\phi({\\bf x}), \\sigma_N^2({\\bf x})) $$ variance : $\\sigma_N^2({\\bf x}) = \\frac{1}{\\beta} + \\bf \\phi({\\bf x})^T {\\bf S}_N\\phi({\\bf x})$ 이 variance에서 첫번째 항은 data의 noise이고 (앞부분을 찾아보자) 뒷부분이 ${\\bf w}$의 uncertainty를 나타낸다. noise와 ${\\bf w}$ distribution은 independent하기에 두 값을 더한게 variance가 된것이다. N이 커질수록 posterior는 narrow해지므로 뒷부분은 0으로 간다. ","date":"2021-11-26","objectID":"/prml-chap03-2/:1:2","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (2)","uri":"/prml-chap03-2/"},{"categories":["PRML"],"content":"3.3.3 Equivalent kernel 위에 $w$에 대해 구한 값을 토대로 mean of predictive distribution은 $$y({\\bf x}, {\\bf m} _ N) = {\\bf m} _ N^T\\phi({\\bf x}) = \\beta \\phi({\\bf x})^T {\\bf S} _ N \\Phi^T {\\bf t} \\\\ = \\sum_{n=1}^N \\beta \\phi({\\bf x})^T {\\bf S}_N \\phi({\\bf x}_n)t_n $$ 특정 ${\\bf x}$에 대한 mean of predictive dist 은 결국 training set target t의 linear combination 이다. 이를 다르게 표현하면 $$y({\\bf x}, {\\bf m} _ N) = \\sum_{n=1}^N k({\\bf x}, {\\bf x}_n)t_n$$ $k({\\bf x}, {\\bf x}') = \\beta \\phi({\\bf x})^T {\\bf S}_N \\phi({\\bf x}')$ : 이 식을 smoother matrix or equvalent kernel 라고 부른다. 따라서 mean of predictive distribution at $x$ 은 $x$와 (비슷한)가까운 data에 해당하는 $t$에 높은 가중치를 준다. equvalent kernel에 대해서 covariance의 측면으로 살펴보자. $$cov[y({\\bf x}), y({\\bf x}')] = cov[\\phi({\\bf x})^T{\\bf w}, {\\bf w}^T\\phi({\\bf x}')] = \\phi({\\bf x})^T{\\bf S}_N\\phi({\\bf x}')=\\beta^{-1}k({\\bf x}, {\\bf x}') $$ equvalent kernel의 형태에서 근처의 points들의 predictive mean는 상관관계가 높다는 것을 알 수 있다. ","date":"2021-11-26","objectID":"/prml-chap03-2/:1:3","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (2)","uri":"/prml-chap03-2/"},{"categories":["PRML"],"content":"3.4 Bayesian Model Comparison Bayesian의 입장에서 model selection을 바라보고자 한다. 모델을 선택하는 과정에 있어서 확률적인 내용을 많이 사용한다. maximum likelihood와 관련한 overfitting 문제는 marginalizing over the model parameters instead of making point estimates of their values 로 해결 할 수 있다. 모델은 training data를 통해 바로 정할 수 있으므로 validation set이 필요없다. 따라서 모든 데이터를 학습시킬 수 있고 불필요한 검증과정을 없앨 수 있다. 이제 L개의 ${M_i}$ model이 있다고 하자. 이제 이 model들을 random variable으로 생각하고 model에 대한 uncertainty는 확률로 표현한다. $$p(M_i | D) \\propto p(M_i)p(D | M_i) $$ 일단 model에 대한 prior는 다 같다고 가정하자. 따라서 우리의 주 관심은 model evidence(=marginal likelihood) : $p(D/M_i)$ model을 이루는 parameter들이 marginalized out 되었기에 marginal likelihood라고도 부름 (뒷 부분에 나옴) Bayes factor ratio of model evidence s $p(D|M_i)p(D|M_j)$ model의 posterior를 알고 이를 이용하여 predictive distribution을 구하면 $$p(t|{\\bf x}, D) = \\sum_{i=1}^{L} p(t|{\\bf x}, M_i, D)p(M_i|D)$$ 이다. (mixture distribution의 모습) 이는 model posterior를 가중치로 하여 평균을 낸 것으로 볼 수 있다. 위와 같은 model averaging의 값과 가장 근사하는 좋은 model 하나를 찾고자 한다. 이를 model selection 이라고 한다. model evidence (${\\bf w}$는 model에 관한 parameter) 이를 sampling 측면에서 바라보면, marginal likelihood는 data set D를 생성하는 probability로 볼 수 있는데 여기서 D는 prior로 부터 random하게 뽑힌 parameter들로 이루어진 model에서 만들어진 것이다. 또한, evidence는 Bayes' Them에서 분모에 해당하는 normalizing term을 의미하기도 한다 : $p({\\bf w}| D, M_i) = \\frac{p(D | {\\bf w}, M_i) p({\\bf w} | M_i)}{p(D | M_i)}$ $$p(D|M_i) = \\int p(D|{\\bf w}, M_i)p({\\bf w}|M_i)d{\\bf w}$$ 이제 model evidence에 대해 더 알아보자. model이 single parameter $w$ 를 갖고 있다고 가정 notation $M_i$는 생략 $w$의 posterior는 $p(D|w)p(w)$에 비례 posterior는 $w_{MAP}$ 에서 peaked 된 상태이고 그 때 width는 $\\vartriangle w_{posterior}$ 라고 가정 prior는 flat with width $\\vartriangle w_{prior}$, 따라서 $p(w) = 1/\\vartriangle w_{prior}$ $$p(D) = \\int p(D | w)p(w)dw \\simeq p(D | w_{MAP}) \\frac{1}{\\vartriangle w_{prior}} \\vartriangle w_{posterior}$$ log를 씌우면 $$\\ln p(D) \\simeq \\ln p(D|w_{MAP}) + \\ln (\\frac{\\vartriangle w_{posterior}}{\\vartriangle w_{prior}})$$ 첫번째 항 : 이 data를 가장 잘 표현하는 파라미터에 대한 확률값으로 log likelihood 의미 두번째 항 : model complexity에 대한 penalty 항 우리는 $\\ln p(D|M_i)$ 가 가장 큰 model($M_i$)을 찾는 것이 목표이다. complex가 높은 model를 구하면 첫번째 항이 커질 것이지만 두번째 항은 $\\vartriangle w_{posterior}$ 이 narrow 해지면서 음수가 되고 점점 작아진다. trade-off 관계인 것이다. 따라서 적절한 complexity가 있는 model을 선택하게 된다. $\\ln p(D | M_i) = accuracy(M_i) - complexity(M_i)$ 느낌 AIC, BIC를 예시로 생각할 수 있다. M 개의 parameter가 있을 경우 위에서 설명한 부분과 같다. 뒷 부분에 M이 추가되어 M이 커지면서 더 penalty를 준다. $$\\ln p(D | \\textbf{w} _ {MAP}) + M \\ln (\\frac{\\vartriangle w_{posterior}}{\\vartriangle w_{prior}})$$ optimal model complexity (model selection) 는 maximum evidence 으로 정해진다는 것 을 기억하자. ","date":"2021-11-26","objectID":"/prml-chap03-2/:2:0","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (2)","uri":"/prml-chap03-2/"},{"categories":["PRML"],"content":"3.5 The Evidence Approximation linear basis model에서 완전한 Bayesian 접근법을 위해서 ${\\bf w}$에 대한 hyperparameter $\\alpha, \\beta$의 prior를 고려해보자. predictive distribution은 아래와 같이 구할 수 있다. (${\\bf x}$ 표시는 생략) $p(t|{\\bf w})$ : distribution of target ($=N(y(x,{\\bf w}), \\beta^{-1})$) $p({\\bf w}|{\\bf t}, \\alpha, \\beta)$ : posterior of ${\\bf w}$ $p(\\alpha, \\beta | {\\bf t})$ : posterior of $\\alpha, \\beta$ $$p(t|{\\bf t}) = \\iiint p(t|{\\bf w}, \\beta) p({\\bf w}|{\\bf t}, \\alpha, \\beta) p(\\alpha, \\beta | {\\bf t}) d{\\bf w}d\\alpha d\\beta $$ 하지만 여기서 문제가 발생한다. 위처럼 모든 변수에 대해 marginalize하는 것은 항상 가능한 것이 아니다 (analytically intractable). 그래서 우리는 hyperparameter를 특정한 값으로 approximation한다. 그 방법은 maximizing marginal likelihood function이다. 이러한 방법론을 evidence approximation (통계에서는 emprical Bayes, type 2 maximum likelihood, generalized maximum likelihood) 라고 부른다. 만약에 posterior distribution $p(\\alpha, \\beta | {\\bf t})$ 가 특정한 값 $\\hat{\\alpha}, \\hat{\\beta}$에서 가장 높은 값(peaked)을 가진다면 predictive distribution은 ${\\bf w}$에 대해서만 marginalize해서 구할 수 있을 것이다. $$p(t|{\\bf t}) \\simeq p(t|{\\bf t}, \\hat{\\alpha}, \\hat{\\beta}) = \\int p(t|{\\bf w}, \\hat{\\beta})p({\\bf w}|{\\bf t}, \\hat{\\alpha}, \\hat{\\beta})d{\\bf w}$$ posterior distribution for $\\alpha, \\beta$ 는 $$p(\\alpha, \\beta | {\\bf t}) \\propto p({\\bf t}|\\alpha, \\beta) p(\\alpha, \\beta) $$ prior는 flat 하다고 가정하자. 따라서 우리는 $\\hat{\\alpha}, \\hat{\\beta}$를 구하기 위해서 marginal likelihood function $p({\\bf t} | \\alpha, \\beta)$ 을 최대로 만드는 찾으면 된다. 이를 통해 우리는 cross validation과 같은 방법이 아니라 한 번에 hyperparameter를 찾을 수 있다. 찾는 방법은 미분을 이용하는 방법, EM 알고리즘을 이용하는 방법이 있다. 전자는 이제 살펴볼 것이고 후자는 9장에서 배운다. ","date":"2021-11-26","objectID":"/prml-chap03-2/:3:0","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (2)","uri":"/prml-chap03-2/"},{"categories":["PRML"],"content":"3.5.1 Evaluation of the evidence function marginal likelihood function은 parameter ${\\bf w}$를 marginalize해서 얻을 수 있다. $p({\\bf t}|{\\bf w}, \\beta)$ : likelihood function $p({\\bf w}|\\alpha)$ : prior of w $$p({\\bf t}|\\alpha, \\beta) = \\int p({\\bf t}|{\\bf w}, \\beta) p({\\bf w}|\\alpha) d{\\bf w}$$ 위의 식을 Gaussian의 형태를 이용하여 정리해보자. (과정은 생략, PRML 연습문제에 있다) $$p({\\bf t}|\\alpha, \\beta) = \\left(\\frac{\\beta}{2\\pi}\\right)^{N/2}\\left(\\frac{\\alpha}{2\\pi}\\right)^{M/2} \\int \\exp{-E({\\bf w})}d{\\bf w}$$ $$E({\\bf w}) = \\beta E_D({\\bf w}) + \\alpha E_w({\\bf w}) = \\frac{\\beta}{2}|{\\bf t} - \\Phi{\\bf w}|^2 + \\frac{\\alpha}{2}{\\bf w}^T{\\bf w} $$ $$E({\\bf w}) = E({\\bf m}_N)+\\frac{1}{2}({\\bf w}-{\\bf m}_N)^T {\\bf A} ({\\bf w} - {\\bf m}_N) $$ ${\\bf A} = \\alpha {\\bf I} + \\beta \\Phi^T\\Phi$ ${\\bf m}_N = \\beta {\\bf A}^{-1}\\Phi^T{\\bf t}$ 이제 이를 이용하면 $$\\int \\exp\\left(-E({\\bf w})\\right) d{\\bf w} = \\exp(-E({\\bf m}_N))\\int \\exp \\{ -\\frac{1}{2}({\\bf w}-{\\bf m}_N)^T {\\bf A} ({\\bf w}-{\\bf m}_N) \\} d { \\bf w} \\\\ = \\exp\\{-E({\\bf m}_N)\\}(2\\pi)^{M/2}|{\\bf A}|^{-1/2}$$ 이를 이용하여 최종적으로 log marginal likelihood function을 구하면 $$\\ln p({\\bf t}|\\alpha, \\beta) = \\frac{M}{2}\\ln \\alpha + \\frac{N}{2}\\ln \\beta - E({\\bf m}_n) - \\frac{1}{2}\\ln |{\\bf A}| - \\frac{N}{2}\\ln(2\\pi)$$ ","date":"2021-11-26","objectID":"/prml-chap03-2/:3:1","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (2)","uri":"/prml-chap03-2/"},{"categories":["PRML"],"content":"3.5.2 Maximizing the evidence function $\\ln p({\\bf t} | \\alpha, \\beta)$을 최대화하는 $\\alpha, \\beta$를 구하기 위해 미분을 이용해보자. $(\\beta \\Phi^T \\Phi) {\\bf \\mu}_i = \\lambda_i{\\bf \\mu}_i$ 라고 하면 ${\\bf A}$의 eigenvalue는 $\\alpha + \\lambda_i$ 이다. 따라서 $$\\frac{d}{d\\alpha}\\ln |{\\bf A}| = \\frac{d}{d\\alpha}\\ln \\prod_{i}(\\lambda_i+\\alpha) = \\frac{d}{d\\alpha}\\sum_i \\ln(\\lambda_i+\\alpha) = \\sum_i \\frac{1}{\\lambda_i + \\alpha}$$ $\\alpha$에 대해 미분 $$0 = \\frac{M}{2\\alpha} - \\frac{1}{2}{\\bf m}_N^T{\\bf m}_N - \\frac{1}{2}\\sum_i \\frac{1}{\\lambda_i+\\alpha}$$ $$\\alpha {\\bf m} _ N^T {\\bf m} _ N = M - \\alpha \\sum_{i=1}^{M} \\frac{1}{\\lambda_i+\\alpha} = \\gamma$$ 이를 다시 정리하면 $$\\gamma = \\sum_{i=1}^{M} \\frac{\\lambda_i}{\\alpha + \\lambda_i}$$ 최종적으로 $\\alpha$에 대해 정리하면 $$\\alpha = \\frac{\\gamma}{ {\\bf m}_N^T{\\bf m}_N} $$ 그런데 $\\gamma, {\\bf m}_N$ 모두 $\\alpha$에 depend한다. 따라서 이를 위해서 iterative한 방법을 사용한다. 임의의 수로 $\\alpha$를 시작하고 $\\gamma, {\\bf m}_N$을 구한다. 다시 이 두 값으로 $\\alpha$를 구한다. 이렇게 수렴할 때까지 반복하는 것이다. $\\beta$에 대해 미분 $$\\frac{d}{d\\beta} \\ln |{\\bf A}| = \\frac{d}{d\\beta}\\sum_i \\ln(\\lambda_i+\\alpha) = \\frac{1}{\\beta}\\sum_i\\frac{\\lambda_i}{\\lambda_i+\\alpha} = \\frac{\\gamma}{\\beta}$$ $$0 = \\frac{N}{2\\beta} - \\frac{1}{2}\\sum_{n=1}^N{t_n-{\\bf m}_N^T\\phi({\\bf x}_n)}^2 - \\frac{\\gamma}{2\\beta} $$ $$\\frac{1}{\\beta} = \\frac{1}{N-\\gamma}\\sum_{n=1}^N {t_n-{\\bf m}_N^T\\phi({\\bf x}_N)}^2 $$ 이도 마찬가지도 iterative하게 구한다. cross validation과 같은 추가적인 computation이 없이 한 번에 train data set을 모두 이용하여 model complexity를 정할 수 있다 는 점을 기억하자. ","date":"2021-11-26","objectID":"/prml-chap03-2/:3:2","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (2)","uri":"/prml-chap03-2/"},{"categories":["PRML"],"content":"3.5.3 Effective number of parameters 이 부분은 ridge regression의 내용 (data의 고윳값이 작은 방향의 parameter가 0에 가까워진다) 과 같다. ESL 책의 linear regression부분을 보면 알 수 있다. $\\alpha$에 대한 Bayesian의 접근에 대해 조금 더 살펴보자. $\\beta \\Phi^T \\Phi$는 positive definite matrix이므로 eigenvalue가 모두 0이상의 값을 갖는다. 따라서 $0 \\le \\lambda_i /(\\lambda_i + \\alpha) \\le 1$ $0 \\le \\gamma \\le 1$ 임을 알 수 있다. $\\lambda_i » \\alpha$ 인 경우는 이에 해당하는 parameter $w_i$가 maximum likelihood의 값과 가까워지고 $\\lambda_i /(\\lambda_i + \\alpha)$ 이 1에 가까워진다. 반대의 경우는 $w_i, \\lambda_i /(\\lambda_i + \\alpha)$ 모두 0에 가까워진다. 따라서 $\\gamma$는 measures the effective total number of well determined parameters 다음은 $\\beta$에 대해 알아보자. 위에서 보았듯이 effective number of parameter는 $\\gamma$이고 나머지 $M-\\gamma$개의 parameters 들이 prior에 의해 작은 값을 갖는다. 이것이 variance에서 $\\frac{1}{N-\\gamma}$로 나타나고 bias of maximum likelihood result를 바로 잡아준다. 만약에 $N » M$의 상황인 경우, 대부분의 parameter들이 well determined될 것이고 data size에 따라 eigenvalue도 커지게 된다. 그러면 $\\gamma = M$이 되고 evidence approximation도 아래 값을 이용해 간단해진다. (data 많은게 짱이다) $$\\alpha = \\frac{M}{2E_W({\\bf m}_N)}$$ $$\\beta = \\frac{N}{2E_D({\\bf m}_N)}$$ ","date":"2021-11-26","objectID":"/prml-chap03-2/:3:3","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (2)","uri":"/prml-chap03-2/"},{"categories":["PRML"],"content":"3.6 Limitations of Fixed Basis Functions 장점 nonlinear basis functions의 linear combination이니까 해석이 쉽다. closed form의 해가 존재한다. 단점 basis function이 training data를 보기 전에 이미 fixed되서 시작한다. 차원의 저주 input간의 correlation 때문에 보다 작은 차원에 nonlinear manifold에 데이터가 분포할 수 있다. ","date":"2021-11-26","objectID":"/prml-chap03-2/:4:0","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (2)","uri":"/prml-chap03-2/"},{"categories":["PRML"],"content":"Regression에 대해 알아보자. 목표는 predictive distribution $p(t|x)$를 찾는 것 주로 loss funciton은 squared loss를 사용하며 이 때 optimal solution은 conditional expectation of t : $E[t|x]$ ","date":"2021-11-26","objectID":"/prml-chap03-1/:0:0","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (1)","uri":"/prml-chap03-1/"},{"categories":["PRML"],"content":"3.1 Linear Basis Function Models 가장 기본적인 linear model for regression은 $$y(x,w) = w_0+w_1x_1+…+w_D x_D$$ 의 형태일 것이다. 하지만 basis function $\\phi_ j(\\textbf{x})$을 이용하여 nonlinear의 성질을 추가할 수 있다. basis function은 다양하다. gaussian distribution의 형태 polynomial의 형태 원래의 input data를 마음대로 변화가능 $$y(\\textbf{w},\\textbf{x}) = w_0 + \\sum_{j=1}^{M-1}{w_j \\phi_j(\\textbf{x})} = \\textbf{w}^T {\\pmb \\phi}( \\textbf{x})$$ 하지만 여전히 linear model이다. 여기서 linear의 의미는 계수 w에 linear하다는 의미이기 때문이다. 그렇기에 여전히 interpretation에 대한 장점은 갖고 있다. 단점은 너무 단순하다는 것이다. ","date":"2021-11-26","objectID":"/prml-chap03-1/:1:0","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (1)","uri":"/prml-chap03-1/"},{"categories":["PRML"],"content":"3.1.1 Maximum likelihood and least sqaures $t$ : target variable $y(\\textbf{x}, \\textbf{w})$ : deterministic funciton $\\epsilon \\sim N(0, \\beta^{-1})$ : noise $$t = y(\\textbf{x}, \\textbf{w})+ \\epsilon$$ $$p(t | \\textbf{x},\\textbf{w},\\beta) = N(y(\\textbf{x}, \\textbf{w}), \\beta^{-1})$$ 위의 gaussian 가정에서는 parameter $w$를 추정할 때, likelihood를 이용하는 것과 least square의 방법을 이용하는 것이 똑같다. (그 과정은 직접 해보면 쉽게 파악가능, chapter1에도 있다) optimal prediction은 conditional mean of the target variable 이므로 unimodal이라는 한계가 존재 $$E[t | {\\bf x}] = \\int tp(t | {\\bf x})dt = y({\\bf x}, {\\bf w}) $$ 이제 likelihood function을 통해 MLE를 구하는 과정을 간단히 살펴보자. $$\\ln{p({\\bf t}|{\\bf w}, \\beta)} = \\sum_{n=1}^{N}\\ln{N( {\\bf w}^T{\\pmb \\phi}(x_n), \\beta^{-1})}\\\\ =\\dfrac{1}{2}\\ln{\\beta}-\\dfrac{1}{2}\\ln{2\\pi}-\\beta{E_D({\\bf w})}$$ $$E_D({\\bf w})=\\dfrac{1}{2}\\sum_{n=1}^{N}{t_n-{\\bf w}^T {\\pmb \\phi}(x_n)}^2$$ 위의 식을 미분하고 정리하면 ($\\Phi$ : N*M design matrix) normal equation을 얻는다. $${\\bf w}_{ML} = (\\Phi^T\\Phi)^{-1}\\Phi^T{\\bf t} $$ bias : $w_0 = \\bar{t} - \\sum_{j=1}^{M-1}{w_j \\bar{\\phi}_j}$ 실제 얻어지는 샘플들의 타겟 값들의 평균과, 이 때 basis function에 parameter를 곱하여 얻어진 결과의 평균값의 차이를 보정하는 역할 noise precision : $\\frac{1}{\\beta_{ML}} = \\frac{1}{N}\\sum_{n=1}^{N}{{ t_n - w_{ML}^T \\phi(x_n)}^2}$ ","date":"2021-11-26","objectID":"/prml-chap03-1/:1:1","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (1)","uri":"/prml-chap03-1/"},{"categories":["PRML"],"content":"3.1.2 Geometry of least squares least square의 방법에서 우리가 prediction한 값의 의미를 기하학적으로 살펴보자. 증명의 과정은 ESL에 잘 나와있다. 물론 봐도 이해하기는 어렵다. 결론만 언급하자면 “input vector가 span하는 space에 true t의 값을 orthorgonal하게 projection한 값이 우리가 예측한 t의 값이다” 추가적으로 multicolinearity에 대한 해결책으로는 PCA, SVD와 같은 방법으로 input들을 orthorgonal하게 만들어주는 것과 ridge regression과 같이 regulrarization 항이 있는 모델을 쓰는 것이다. ","date":"2021-11-26","objectID":"/prml-chap03-1/:1:2","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (1)","uri":"/prml-chap03-1/"},{"categories":["PRML"],"content":"3.1.3 Sequential learning 이 부분에서는 parameter를 최적화하는 과정에 있어서 gradient descent의 방법을 말하고 있다. 그게 Sequential하게 update하는 것이라 그런 것 같다. 데이터의 크기가 크면 normal equation의 방법이 오래걸리는 단점을 보완할 수도 있다. $$\\textbf{w}^{\\tau+1}=\\textbf{w}^{(\\tau)}+{\\eta}(t_n-{\\bf w}^{(\\tau)T}{\\pmb \\phi}_n) {\\pmb \\phi}_n$$ ","date":"2021-11-26","objectID":"/prml-chap03-1/:1:3","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (1)","uri":"/prml-chap03-1/"},{"categories":["PRML"],"content":"3.1.4 Regularized least squares 기존의 error function에 regularization term을 추가하여서 parameter shrinkage를 하고자 한다. 이를 통해 overfitting을 완화시킨다. lasso 같은 경우 sparse한 model을 만들어서 feature selection의 역할도 한다. regularized error takes the form 아래 식에서 q가 1이면 lasso, 2이면 ridge regression이다. $\\lambda$가 커질수록 model complexity가 낮아진다. $$\\frac{1}{2}\\sum_{n=1}^{N}{{t_n - \\textbf{w}^T{\\pmb \\phi}(x_n)}^2}+ \\frac{\\lambda}{2}\\sum_{j=1}^{M}{ \\left| \\textbf{w}_j\\right|^q }$$ ridge의 경우 error function이 $\\textbf{w}$에 대해 quadratic form이라서 closed form으로 solution이 존재한다. $$w_{ridge} = (\\Phi^T \\Phi + \\lambda I)^{-1}\\Phi^T t$$ ","date":"2021-11-26","objectID":"/prml-chap03-1/:1:4","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (1)","uri":"/prml-chap03-1/"},{"categories":["PRML"],"content":"3.2 The Bias-Variance Decomposition 모델링을 할 때 overfitting을 피하기 위해 제약을 두면 complexity를 못 잡을 수도 있다. 너무 모델을 복잡하게 하면 overfitting이 될 수도 있다. 이는 상당히 어려운 문제이다. 이 부분에 있어서 frequentist의 입장에서 바라보는 bias-variance trade off 관계를 공부하고자 한다. 이해를 위해 square loss (regression)의 경우의 예시를 살펴보자. square loss function 에서 optimal solution : $$E[t | \\textbf{x}] = \\int t p(t | \\textbf{x})dt = h(\\textbf{x})$$ expected squared loss : $$E[L] = \\int { y(\\textbf{x}) - h(\\textbf{x})}^2 p(\\textbf{x})d\\textbf{x} + \\int {h(\\textbf{x}) - t}^2 p(\\textbf{x},t)d\\textbf{x}dt$$ 우리는 우항의 첫번째를 최대한 작게하는 $y(\\textbf{x})$을 만들고자 한다. 위의 식에서 우항의 두번째는 우리가 줄일 수 없는 intrinsic noise이다. 첫 번째 항을 decompose 해보자. 일단 ${ y(\\textbf{x};D) - h(\\textbf{x})}^2$ 값은 특정한 dataset $D$에 대한 값이다. 이제 dataset이 여러개가 있다고 가정하고 이에 대해 average한 경우를 생각해보자. $E_D[y(\\textbf{x};D)]$ 을 더하고 빼서 $$E_D[{ y(\\textbf{x};D)-h(\\textbf{x}) }^2] =\\ {E_D[y(\\textbf{x};D)] -h(\\textbf{x})}^2+ E_D[{ y(\\textbf{x};D) - E_D[y(\\textbf{x};D)]}^2]$$ 이렇게 나타낼 수 있다. 즉, expected loss = (bias)^2 + variance +noise 인 것이다. bias 의미 : average prediction over all datasets 이 우리가 알고 싶은 true (regression) function과 차이나는 정도 variance 의미 : 해당 하나의 dataset이 average 와 차이나는 정도, function $y(\\textbf{x};D)$이 특정한 dataset에 얼마나 민감한지 이 둘은 trade-off 관계 : 한쪽이 커지면 한쪽이 작아진다. 하지만 이런 bias-variance의 관계는 average에 기반을 한 개념이기 때문에(bias, variance의 계산하는 과정이 D에 대해 평균) 한계점이 분명 존재 한다. 우리가 가지고 있는 데이터는 한정적이기 때문이다. 독립적인 데이터가 여러 개이면 각 데이터로 복잡한 모델을 만들어서 평균을 내면 좋은 결과를 얻을 수 있지만 우리는 데이터가 부족하다. 그래서 저자는 Bayesian 접근법을 소개한다. ","date":"2021-11-26","objectID":"/prml-chap03-1/:2:0","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (1)","uri":"/prml-chap03-1/"},{"categories":["PRML"],"content":"+ monk의 설명 정의 MSE of an estimate $\\hat{\\theta} = f(D)$ for $\\theta$ is $$MSE(\\hat{\\theta}) = E[(\\hat{\\theta} - \\theta)^2 | \\theta]$$ $bias(\\hat{\\theta}) = E[\\hat{\\theta}] - \\theta$ $var(\\hat{\\theta}) = E[(\\hat{\\theta}-E[\\hat{\\theta}])^2]$ $$MSE(\\hat{\\theta}) = bias^2(\\hat{\\theta}) + var(\\hat{\\theta})$$ (proof) let $\\mu = E[\\hat{\\theta}]$ $$E[(\\hat{\\theta} - \\theta)^2] = E[(\\hat{\\theta} - \\mu + \\mu -\\theta)^2] \\\\ = E[(\\hat{\\theta} - \\mu)^2 + 2(\\hat{\\theta} - \\mu)(\\mu - \\theta) + (\\mu - \\theta)^2] \\\\ = (\\mu - \\theta)^2 + E[(\\hat{\\theta}-\\mu)^2] \\quad \\because E[(\\hat{\\theta} - \\mu)(\\mu - \\theta)] = 0 $$ 쉬운 예시 $X \\sim N(\\theta,1)$ $\\theta$는 non random, unknown $\\hat{\\theta}_1 = X \\rightarrow bias^2 = 0, var = 1, MSE = 1$ $\\hat{\\theta}_2 = 0 \\rightarrow bias^2 = \\theta^2, var = 0, MSE = \\theta^2$ ","date":"2021-11-26","objectID":"/prml-chap03-1/:2:1","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (1)","uri":"/prml-chap03-1/"},{"categories":["PRML"],"content":"+ 문일철 교수님의 설명 Sources of Error in ML 크게 두 가지로 나눌 수 있다 : Approximation and generalization $E_{out} \\le E_{in} + \\Omega$ $E_{out}$ : estimation error $E_{in}$ : error from approximation by the learning algorithm $\\Omega$ : error caused by the variance of the observations 뒤에서 사용할 notation에 대해 알아보자. $f$ : the target function to learn (true function) $g$ : the learning function of ML $g^{(D)}$ : the learned function by using a dataset $\\bar{g}$ : the average hypothesis of a given infinite numbers of D ( $\\bar{g}(x) = E_D [g^{(D) } (x)]$ ) 하나의 dataset D에 대한 Error는 $$E_{out}[g^{(D)}(x)] = E_x[(g^{(D)}(x) - f(x))^2]$$ 그렇다면 expected error of the infinite dataset은 $$E_D [E_{out}[g^{(D)}(x)] ] = E_D [E_x[(g^{(D)}(x) - f(x))^2]] = E_x [E_D[(g^{(D)}(x) - f(x))^2]]$$ 일단 안쪽에 있는 term부터 확인해보자. $$E_D[(g^{(D)}(x) - f(x))^2] = E_D [( g^{(D)}(x) - \\bar{g}(x) + \\bar{g}(x) - f(x) )^2]$$ $$= E_D [(g^{(D)}(x) - \\bar{g}(x) )^2] + (\\bar{g}(x) - f(x))^2$$ $$\\therefore E_D [E_{out}[g^{(D)}(x)] ] = E_D [(g^{(D)}(x) - \\bar{g}(x) )^2] + (\\bar{g}(x) - f(x))^2 $$ 여기서 우리는 variance와 bias를 정의할 수 있는데 $Var = E_D [(g^{(D)}(x) - \\bar{g}(x) )^2]$ $Bias^2 = (\\bar{g}(x) - f(x))^2$ 이들이 의미하는 바는 var는 제한적인 dataset 때문에 model을 average hypothesis로 훈련시킬 수 없는 부분을 의미 bias는 average hypothesis조차도 (true) real world hypothesis를 맞출수 없는 부분을 의미 그렇다면 var과 bias를 줄이기 위해서는? var를 줄이기 위해서는 data를 더 모은다. bias를 줄이기 위해서는 더 복잡한 model을 사용한다. 하지만 문제는 var와 bias는 trade-off 관계를 가진다. 예를 들어, 우리가 갖고 있는 dataset에 잘 맞는 복잡한 모델을 사용하면 평균적인 모델과는 차이가 커질 것이다. 간단한 model은 낮은 variance, 높은 bias를 갖는다. 복잡한 model은 높은 variance, 낮은 bias를 갖는다. 따라서 적잘한 model을 만드는 것이 관건이다. Occam’s Razor 같은 error를 갖는 모델이라면 둘 중 더 간단한 모델을 선택하라! ","date":"2021-11-26","objectID":"/prml-chap03-1/:2:2","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (1)","uri":"/prml-chap03-1/"},{"categories":["PRML"],"content":"Exponential Family와 Nonparametric 방법론에 대해 알아보자. ","date":"2021-11-26","objectID":"/prml-chap02-4/:0:0","tags":["Exponential Family","Non parametric"],"title":"[PRML] Chapter2 - Probability Distribution (4)","uri":"/prml-chap02-4/"},{"categories":["PRML"],"content":"2.4 The Exponential Family 우리가 이전에 공부했던 대부분의 distribution은 Exponential Family에 속한다. The exponential family of distribution over $x$, given parameters $\\eta$, is defined to be the set of distributions of the form $$p({\\pmb x} | {\\pmb \\eta}) = h({\\pmb x})g({\\pmb \\eta}) \\exp ({\\pmb \\eta}^T u({\\pmb x}))$$ pdf(pmf) $p({\\pmb x} | {\\pmb \\eta})$ 을 우항과 같이 표현할 수 있다면 exponential family에 속한다. ${\\pmb x}$는 스칼라, 벡터 둘 다 가능하고 discrete, continous 모두 가능하다. ${\\pmb \\eta}$ 는 natural parameter of the distribution 이라고 한다. $g(\\pmb \\eta)$는 distribution의 normalize coefficient (적분해서 1이 되도록 만들어주는) 라고 할 수 있다. $$g({\\pmb \\eta}) \\int h({\\pmb x})\\exp{ {\\pmb \\eta}^T{\\pmb u} ({\\pmb x}) } d {\\pmb x}=1 $$ Bernoulli distribution 예시 $p(x | \\mu) = Bern(x | \\mu)=\\mu^x(1-\\mu)^{1-x}$ 이를 exponential form으로 표현해보자. $f(x)=\\exp(\\ln{f(x)})$ 을 이용하여 $$p(x | \\mu) = \\exp {x \\ln \\mu + (1-x) \\ln (1-\\mu) } \\\\ = (1-\\mu) \\exp \\{ \\ln \\left( \\frac{\\mu}{1-\\mu} \\right) x \\} \\\\ \\therefore \\eta = \\ln\\left(\\frac{\\mu}{1-\\mu}\\right) $$ 위의 형태를 $\\mu$에 대한 식으로 바꿔보면 $$\\mu=\\sigma(\\eta)=\\dfrac{1}{1+\\exp(-\\eta)} $$ 위의 식과 같은 형태의 함수를 logistic sigmoid function이라고 부른다. Multinomial distribution 예시 $p({\\pmb x} | {\\pmb \\mu}) = \\prod_{k=1}^{M}\\mu_k^{x_k}= \\exp [\\sum_{k=1}^{M}x_k \\ln \\mu_k]$ $p({\\pmb x}|{\\pmb \\eta})=\\exp({\\pmb \\eta}^T{\\pmb x})$ $\\eta_k = \\ln \\mu_k$ ${\\pmb \\eta} = (\\eta_1, \\eta_2,…,\\eta_k)^T$ M개의 parameter가 있지만 $\\sum_{k=1}^{M}{\\mu_k}=1$ 이라는 제약때문에 M-1개의 값이 정해지면 마지막 M개는 저절로 정해진다. 이를 이용할 것이다. $$\\exp \\{\\sum_{k=1}^{M}x_k\\ln\\mu_k \\} = \\exp \\{\\sum_{k=1}^{M-1}x_k\\ln\\mu_k + \\left(1-\\sum_{k=1}^{M-1}x_k\\right)\\ln\\left(1-\\sum_{k=1}^{M-1}\\mu_k\\right) \\}\\\\ = \\exp\\{\\sum_{k=1}^{M-1}x_k\\ln\\left(\\frac{\\mu_k}{1-\\sum_{j=1}^{M-1}\\mu_j}\\right)+\\ln\\left(1-\\sum_{k=1}^{M-1}\\mu_k\\right)\\}$$ $$\\therefore \\eta_k = \\ln\\left(\\frac{\\mu_k}{1-\\sum_{j \\neq k} \\mu_j}\\right)$$ 똑같이 $$\\mu_k=\\dfrac{\\exp(\\eta_k)}{1+\\sum_{j \\neq k}\\exp(\\eta_j)}$$ 위의 식과 같은 형태의 함수를 softmax function (normalized exponential) 이라고 부른다. ","date":"2021-11-26","objectID":"/prml-chap02-4/:1:0","tags":["Exponential Family","Non parametric"],"title":"[PRML] Chapter2 - Probability Distribution (4)","uri":"/prml-chap02-4/"},{"categories":["PRML"],"content":"2.4.1 Maximum likelihood and sufficient statistics $\\eta$가 어떤 것인지 알았으니 이제 이를 MLE로 estimate해보자. exponential form을 $\\eta$에 대해 미분하면 $$\\nabla g({\\pmb \\eta})\\int h({\\pmb x})\\exp{ {\\pmb \\eta}^T {\\pmb u}({\\pmb x})}d{\\pmb x} + g({\\pmb \\eta})\\int h({\\pmb x})\\exp{ {\\pmb \\eta}^T{\\pmb u}({\\pmb x})}{\\pmb u}({\\pmb x})d{\\pmb x} = 0$$ $g({\\pmb \\eta}) \\int h({\\pmb x})\\exp{ {\\pmb \\eta}^T{\\pmb u} ({\\pmb x}) } d {\\pmb x}=1$ 을 이용하여 $$-\\frac{1}{g({\\pmb \\eta})} \\nabla g({\\pmb \\eta}) = g({\\pmb \\eta})\\int h({\\pmb x})\\exp{ {\\pmb \\eta}^T{\\pmb u}({\\pmb x})}{\\pmb u}({\\pmb x})d{\\pmb x}=E[{\\pmb u}({\\pmb x})]$$ 최종적으로는 $$-\\nabla \\ln g({\\pmb \\eta}) = E[{\\pmb u}({\\pmb x})] $$ 이제 iid인 data를 통해 likelihood function을 만들면 $$p({\\pmb X}|{\\pmb \\eta}) = \\left(\\prod_{n=1}^{N}h({\\pmb x} _ n)\\right) g({\\pmb \\eta})^N \\exp\\{ {\\pmb \\eta}^T\\sum_{n=1}^{N}{\\pmb u}({\\pmb x}_n)\\} $$ log를 취한 뒤에 $\\eta$에 대해 미분하여 0을 갖도록 하면 아래와 같은 식을 얻을 수 있다. $$-\\nabla \\ln g({\\pmb \\eta} _ {ML}) = \\frac{1}{N}\\sum_{n=1}^{N}{\\pmb u}({\\pmb x}_n)$$ 이를 통해 우리는 MLE solution이 오직 $\\sum_{n=1}^{N} \\textbf{u}(\\textbf{x}_n)$에 달려 있다는 것을 알 수 있다. 이는 sufficient statistics of the distribution 이라고 부른다. parameter에 대한 정보가 여기 다 들어 있어서 충분하다! 라고 이해할 수 있다. 따라서 우리는 MLE를 구하는 과정에 있어서 각 data를 모두 알고 있을 필요가 없이 충분통계량만 알면 된다. $N \\rightarrow \\infty$이면 우항은 $E[\\textbf{u}(\\textbf{x})]$이 되고 ${\\pmb \\eta}_{ML}$은 true값으로 수렴한다는 것을 알 수 있다. ","date":"2021-11-26","objectID":"/prml-chap02-4/:1:1","tags":["Exponential Family","Non parametric"],"title":"[PRML] Chapter2 - Probability Distribution (4)","uri":"/prml-chap02-4/"},{"categories":["PRML"],"content":"2.4.2 Conjugate priors exponential family인 prior distribution은 $$p({\\pmb \\eta} | {\\pmb \\chi}, v) = f({\\pmb \\chi}, v)g({\\pmb \\eta})^v \\exp\\{v{\\pmb \\eta}^T{\\pmb \\chi}\\}$$ 여기에 위에서 보았던 likelihood function을 곱하여 posterior distribution을 구하면 $$p({\\pmb \\eta}|{\\pmb X}, {\\pmb \\chi}, v) \\propto g({\\pmb \\eta})^{v+N}\\exp\\{ {\\pmb \\eta}^T\\left(\\sum_{n=1}^{N}{\\pmb u}({\\pmb x})+v{\\pmb \\chi}\\right)\\}$$ conjugacy를 확인할 수 있다. 또한 parameter $v$는 effective nunber of pseudo-observation 이라고 이해할 수 있다. ","date":"2021-11-26","objectID":"/prml-chap02-4/:1:2","tags":["Exponential Family","Non parametric"],"title":"[PRML] Chapter2 - Probability Distribution (4)","uri":"/prml-chap02-4/"},{"categories":["PRML"],"content":"2.4.3 Noninformative priors posterior를 만들기 위해 사전의 정보가 충분하면 상관없지만 그렇지 않은 경우, 우리는 prior의 영향을 최소화하고 싶을 것이다. 이런 prior를 Noninformative prior 라고 부른다. $p(x|\\lambda)$ distribution이 있을 때, prior distribution $p(\\lambda)=\\text{const}$ 가 적절한 prior가 될 것이다. 만약에 $\\lambda$가 $K$ states를 갖는 discrete이면 prior 는 $1/K$로 하면 된다. 하지만 continous하고 domain이 unbounded하면 prior distribution은 합이 1이 되지 않는다 (integral diverge, not correctly normalized). 이런 prior를 improper prior 라고 한다. 적분값이 1이 아닌 diverge하는 모든 분포에 해당하는 것은 아니다. prior는 improper해도 posterior는 적절한 pdf가 되어야 한다. ","date":"2021-11-26","objectID":"/prml-chap02-4/:1:3","tags":["Exponential Family","Non parametric"],"title":"[PRML] Chapter2 - Probability Distribution (4)","uri":"/prml-chap02-4/"},{"categories":["PRML"],"content":"2.5 Nonparametric Methods 말 그대로 비모수적인 방법들이다. 이전까지는 parameter를 추정하여 density를 추정하였다면 아래의 방법들은 parameter를 추정할 필요가 없는 data oriented한 방법이라고 생각할 수 있다. ","date":"2021-11-26","objectID":"/prml-chap02-4/:2:0","tags":["Exponential Family","Non parametric"],"title":"[PRML] Chapter2 - Probability Distribution (4)","uri":"/prml-chap02-4/"},{"categories":["PRML"],"content":"Histogram 주로 같은 크기의 bin으로 해당 data를 나눈 뒤에 해당 bin에 들어가는 data의 수를 통해 density를 파악한다. 기본적인 것으로 저차원에서 시각화용으로만 사용해야 할 것 같다. (Probability 식) : x를 크기 $\\Delta$로 나누고 각 bin i에 들어가는 data의 수를 $n_i$라고 하면 각 bin i의 확률값은 (각 bin의 넓이는 $\\frac{n_i}{N} * \\Delta$ 이고 histogram 전체 넓이는 1이라) $$p_i = \\frac{n_i}{N \\Delta}$$ density는 bin의 크기가 커질수록 smooth해지고 작아질수록 복잡해진다. ","date":"2021-11-26","objectID":"/prml-chap02-4/:2:1","tags":["Exponential Family","Non parametric"],"title":"[PRML] Chapter2 - Probability Distribution (4)","uri":"/prml-chap02-4/"},{"categories":["PRML"],"content":"Kernel density estimators D-dimension의 probability density $p({\\pmb x})$ 있고 우리는 이 값을 추정하려고 한다. data set은 이 분포에서 나온 $N$개의 observation $R$은 data가 들어있는 어떤 지역 이 지역의 probability mass는 $$P=\\int_R p({\\pmb x})d{\\pmb x}$$ 여기서 이 지역에 들어가는 data의 수는 $K$라고 하면 이는 binomial distribution을 따를 것이다. $$Bin(K/N, P) = \\dfrac{N!}{K!(N-K)!}P^K(1-P)^{1-K}$$ data의 수 $N$이 커지면 $K \\approx NP$일 것이다. $R$이 충분히 작아서 density $p({\\pmb x})$는 해당 지역에서 거의 constant하면 $P \\approx p({\\pmb x}) V$ 임을 알 수 있다. ($V$는 volume of $R$) 따라서 density estimate하면 $$p({\\pmb X}) = \\frac{K}{NV}$$ $V$를 fix : Kernel approach $K$를 fix : K-nearest-neighbour 조금 더 자세히 살펴보자. $R$을 우리가 구하고 싶은 probability density의 point ${\\pmb x}$가 가운데에 있는 작은 hypercube라고 하자. 해당 지역에 들어있는 data 수 $K$를 위해 다음과 같은 함수를 생각해보자. 이 함수는 kernel function 의 한 예시이다. 따라서 $$K = \\sum_{n=1}^{N}k\\left(\\frac{ {\\pmb x}-{\\pmb x}_n}{h}\\right) $$ 이를 이용하여 density at ${\\pmb x}$를 구하면 $$p({\\pmb x}) = \\frac{1}{N}\\sum_{n=1}^{N}\\frac{1}{h^D}k\\left(\\frac{ {\\pmb x}-{\\pmb x}_n}{h}\\right)$$ $v = h^D$ 위 식은 함수 $k({\\pmb u})$의 대칭성을 생각하여, single cube centered on ${\\pmb x}$가 아니라 N cubes centered on the N data point ${\\pmb x_n}$ 이라고 이해할 수 있다. 하지만 이는 여전히 불연속적인 단점이 있기에 좀 더 업그레이드해보자. kernel function을 Gaussian으로 정하면 $$p({\\pmb x}) = \\frac{1}{N}\\sum_{n=1}^N\\frac{1}{(2\\pi h^2)^{D/2}}\\exp\\{-\\frac{|{\\pmb x}-{\\pmb x}_n|^2}{2h^2}\\}$$ kernel function은 다양하게 정할 수 있다. 단, 조건은 $k(x) \\ge 0$ $\\int k(x)dx = 1$ density는 h가 커지면 smooth해지고 h가 작아지면 더 복잡해진다. 우리는 적절하나 h를 잘 찾아야 하는데 이미 최선의 h는 밝혀져 있다. 아울러 가장 좋은 kernel function도 이미 밝혀져있다. ","date":"2021-11-26","objectID":"/prml-chap02-4/:2:2","tags":["Exponential Family","Non parametric"],"title":"[PRML] Chapter2 - Probability Distribution (4)","uri":"/prml-chap02-4/"},{"categories":["PRML"],"content":"Nearest-neighbour methods 이번에는 $K$를 미리 정한 뒤에 이에 적절한 $V$를 찾는 것이다. density는 $K$가 커지면 smooth해지고 작아지면 복잡해진다. KNN classification이 잘 알려져있다. 지금까지 Nonparametric 방법론을 살펴보았다. 전체 data를 저장하고 있어야 하는 단점이 존재한다. data가 너무 많으면 계산에 어려움이 생기고 너무 적으면 다소 부정확한 근사치를 만들 수 있다. ","date":"2021-11-26","objectID":"/prml-chap02-4/:2:3","tags":["Exponential Family","Non parametric"],"title":"[PRML] Chapter2 - Probability Distribution (4)","uri":"/prml-chap02-4/"},{"categories":["PRML"],"content":"Gaussian Distribution과 관련한 내용을 알아보자. ","date":"2021-11-26","objectID":"/prml-chap02-3/:0:0","tags":["Gaussian Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (3)","uri":"/prml-chap02-3/"},{"categories":["PRML"],"content":"2.3.6 Bayesian inference for the Gaussian 이번에는 Bayesian의 방법으로 접근해보자. $\\sigma^2$ is known, inferring the mean $\\mu$ likelihood function은 $$p({\\bf x} | \\mu) = \\prod_{n=1}^{N}p(x_n | \\mu) = \\dfrac{1}{(2\\pi\\sigma^2)^{N/2}}\\exp \\{-\\frac{1}{2\\sigma^2}\\sum_{n=1}^{N}(x_n-\\mu)^2 \\}$$ Gaussian의 conjugate prior는 Gaussian이다. 따라서 prior distribution은 $$p(\\mu) = N(\\mu | \\mu_0, \\sigma_0^2)$$ posterior distribution은 $$p(\\mu |{\\bf x}) \\propto p({\\bf x}|\\mu)p(\\mu) = N(\\mu | \\mu_N, \\sigma_N^2)$$ $\\mu_N = \\frac{\\sigma^2}{N\\sigma_0^2+\\sigma^2}\\mu_0 + \\frac{N\\sigma_0^2}{N\\sigma_0^2+\\sigma^2}\\mu_{ML}$ $\\frac{1}{\\sigma_N^2}=\\frac{1}{\\sigma_0^2}+\\frac{N}{\\sigma^2}$ 위의 결론을 통해 평균과 분산에 대해 좀 더 살펴보자. posterior mean prior mean $\\mu_0$ 와 MLE solution $\\mu_{ML}$ 사이의 값을 갖는다. $N=0$이면 prior mean쪽으로 $N \\rightarrow \\infty$이면 MLE solution쪽을 가까워 진다. posterior variance 해석의 편의를 위해 precision으로 표현하였다. data의 수가 늘어날수록 precision이 커지고 따라서 posterior variance는 작아진다. $N=0$이면 prior variance의 값과 같다. $N \\rightarrow \\infty$이면 variance가 0으로 가까워진다. 이번에는 $\\mu$ is known, inferring the variance $\\sigma^2$ $$p({\\bf x} | \\lambda) = \\prod_{n=1}^{N} N(x_n | \\mu, \\lambda^{-1}) \\propto \\lambda^{N/2} \\exp \\{ -\\frac{\\lambda}{2} \\sum_{n=1}^{N}(x_n-\\mu)^2 \\}$$ precision의 posterior의 conjugate prior는 gamma distribution이다. $$Gam(\\lambda | a,b)=\\frac{1}{\\Gamma(a)}b^a\\lambda^{a-1}\\exp(-b\\lambda) $$ 이를 이용하여 posterior를 구하면 $$p({\\bf x} | \\lambda) \\propto \\lambda^{a_0-1}\\lambda^{N/2} \\exp \\{-b_0\\lambda-\\frac{\\lambda}{2}\\sum_{n=1}^{N}(x_n-\\mu)^2\\}$$ $a_N = a_0 + \\frac{N}{2}$ $b_N = b_0 + \\frac{1}{2}\\sum_{n=1}^{N}(x_n-\\mu)^2 = b_0 + \\frac{N}{2}\\sigma_{ML}^2$ precision이 아닌 covariance를 바로 이용하는 경우 gamma distribution이 아니라 inverse gamma distribution을 이용한다. 이번에는 $\\mu, \\sigma^2$ 둘 다 모른다고 하자 $$p({\\bf x} | \\mu, \\lambda) = \\prod_{n=1}^{N} (\\frac{\\lambda}{2\\pi} )^{1/2} \\exp \\{-\\frac{\\lambda}{2}(x_n-\\mu)^2\\} \\\\ \\propto [\\lambda^{1/2}\\exp (-\\frac{\\lambda\\mu^2}{2})]^N\\exp\\{\\lambda\\mu\\sum_{n=1}^{N}x_n-\\frac{\\lambda}{2}\\sum_{n=1}^{N}x_n^2\\} $$ parameter가 2개이기에 prior가 $p(\\mu, \\lambda)$일 것이다. likelihood function의 모양과 $p(\\mu, \\lambda) = p(\\mu |\\lambda)p(\\lambda)$를 이용하면 Normal-Gamma distribution $$p(\\mu, \\lambda) = N(\\mu|\\mu_0, (\\beta\\lambda)^{-1})Gam(\\lambda|a,b) $$ 을 구할 수 있다. independent한 두 식을 곱한게 아니다. Normal의 precision이 $\\lambda$에 dependent하다. D-dimension인 경우, Wishart distribution을 이용한다. ","date":"2021-11-26","objectID":"/prml-chap02-3/:0:1","tags":["Gaussian Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (3)","uri":"/prml-chap02-3/"},{"categories":["PRML"],"content":"2.3.7 Student’s t-distribution 위에서 gaussian precision과 관련하여 gamma prior을 이용했다. 이때 $x$에 대한 marginal distribution을 구해보자. $$p(x/\\mu,a,b) = \\int_{0}^{\\infty}N(x/\\mu, \\tau^{-1})Gam(\\tau/a,b)d\\tau \\\\ =\\int_{0}^{\\infty}\\frac{b^a e^{(-b\\tau)}\\tau^{(a-1)}}{\\Gamma(a)}(\\frac{\\tau}{2\\pi})^{1/2}\\exp \\{-\\frac{\\tau}{2}(x-\\mu)^2 \\}d\\tau \\\\ = \\frac{b^a}{\\Gamma(a)}(\\frac{1}{2\\pi})^{1/2}[b+\\frac{(x-\\mu)^2}{2}]^{-a-1/2}\\Gamma(a+1/2) $$ $z = \\tau[b+(x-\\mu)^2/2]$로 놓고 식을 전개하면 $$St(x/\\mu,\\lambda,v) = \\frac{\\Gamma(v/2+1/2)}{\\Gamma(v/2)}\\left(\\frac{\\lambda}{\\pi v}\\right)^{1/2}\\left[1+\\frac{\\lambda(x-\\mu)^2}{v}\\right]^{-v/2-1/2} $$ 이를 Student’s t-distribution 이라고 한다. $v$는 자유도이며 이 값이 무한대로 갈수록 gaussian distribution에 가까워진다. 이 분포의 특징 중 하나는 robustness 라는 것이다. 분포모양이 gaussian distribution과 비슷하지만 (좌우대칭) 더 긴 꼬리를 갖고 있다. 이 때문에 outlier(이상치)에 대해 덜 민감하다. ","date":"2021-11-26","objectID":"/prml-chap02-3/:0:2","tags":["Gaussian Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (3)","uri":"/prml-chap02-3/"},{"categories":["PRML"],"content":"2.3.8 Periodic variables skip ","date":"2021-11-26","objectID":"/prml-chap02-3/:0:3","tags":["Gaussian Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (3)","uri":"/prml-chap02-3/"},{"categories":["PRML"],"content":"2.3.9 Mixtures of Gaussians mixture distribution : linear combination of basic distribution K개의 gaussian distribution을 중첩하면 $$p({\\bf x}) = \\sum_{k=1}^{K}\\pi_k N({\\bf x} | {\\bf \\mu}_k, \\Sigma_k) $$ 이를 Mixture of Gaussian 이라고 부른다. 이 때 각 $N({\\bf x} | {\\bf \\mu}_k, \\Sigma_k)$ 는 component, $\\pi_k$는 mixing coefficients 라고 부른다. $\\pi_k$은 0과 1 사이의 값을 갖고 합이 1이다. 따라사 이를 확률로 이해할 수 있다. 이를 통해 다시 marginal distribution을 전개하면 $$p({\\bf x}) = \\sum_{k=1}^{K}p(k)p({\\bf x}|k)$$ 그렇다면 이제 parameter 추정을 해보자. prameter는 $\\pi, \\mu,\\Sigma$ $$\\ln p({\\bf X}|{\\bf \\pi}, {\\bf \\mu}, \\Sigma) = \\sum_{n=1}^{N}\\ln \\{\\sum_{k=1}^{K} \\pi_k N({\\bf x}_n|{\\bf \\mu}_k, \\Sigma_k) \\}$$ 위의 식에서 MLE를 구하기는 쉽지 않다. log 안에 summation이 있기 때문이다. (미분이 어려움) 이를 구하는 방법은 EM algorithm이다. 나중에 배운다. ","date":"2021-11-26","objectID":"/prml-chap02-3/:0:4","tags":["Gaussian Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (3)","uri":"/prml-chap02-3/"},{"categories":["PRML"],"content":"Gausisan distribution의 성질을 알아보자. ","date":"2021-11-26","objectID":"/prml-chap02-2/:0:0","tags":["Gaussian Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (2)","uri":"/prml-chap02-2/"},{"categories":["PRML"],"content":"2.3 Gaussian distribution Multivariate Gaussian distribution D 차원의 vector $\\textbf{x}$에 대한 distribution entropy가 가장 큰 분포가 gaussian이고 multivariate gaussian도 해당한다. ${\\Sigma}$ : D*D의 covariance matrix $$N(\\pmb{x} | \\pmb{\\mu}, \\pmb{\\Sigma}) = \\frac{1}{(2\\pi)^{D/2}} \\frac{1}{ | \\pmb{\\Sigma} |^{1/2} } \\exp{ -\\frac{1}{2}(\\pmb{x} - \\pmb{\\mu})^T \\pmb{\\Sigma}^{-1}(\\pmb{x} - \\pmb{ \\mu})}$$ Gaussian distribution은 상당히 중요한 특징들을 갖고 있다 하나씩 살펴보자. $$\\Delta^2 = ({\\bf x}-{\\pmb \\mu})^T{\\bf \\Sigma}^{-1}({\\bf x}-{\\pmb \\mu}) $$ $\\Delta$ : Mahalanobis distance from $\\pmb{\\mu}$ to $\\textbf{x}$ $\\pmb{\\Sigma}$가 identity이면 Euclidean distance $\\pmb{\\Sigma}$는 (실수)대칭행렬이므로 고윳값이 실수 고유벡터들은 orthonomal하게 가능 고유대각화가 가능하고 아울어 직교대각화가 가능하다. $${\\bf \\Sigma}=\\sum_{i=1}^{D}{\\pmb \\Lambda}_i{\\bf u}_i{\\bf u}_i^T = U{\\pmb \\Lambda} U^{-1}$$ $${\\bf \\Sigma}^{-1}=\\sum_{i=1}^{D}\\dfrac{1}{\\pmb \\Lambda}_i{\\bf u}_i{\\bf u}_i^T = U {\\pmb \\Lambda}^{-1} U^{-1}$$ 이를 위에 대입하면 $$\\Delta^2 = \\sum_{i=1}^{D}\\frac{y_i^2}{\\pmb \\Lambda}_i $$ $y_i={\\bf u}_i^T({\\bf x}-{\\pmb \\mu})$ 우리는 ${y_i}$를 orthonomal vector $\\textbf{u}_i$에 의해 새롭게 정의된 coordinate system이라고 이해할 수 있다. multivariate gaussian의 평균과 분산은 $E[\\textbf{x}] = {\\pmb \\mu}$ $cov[\\textbf{x}] = {\\pmb \\Sigma}$ : 공분산행렬 (covariance matrix) multivariate gaussian은 유용한 분포지만 한계점도 있다. 공분산행렬의 parameter 개수 공분산행렬의 parameter는 $D(D+3)/2$ 개 이다. 차원이 커짐에 따라 parameter가 quadratic하게 커진다. 이를 위한 해결책은 2가지가 있는데 공분산행렬은 대각행렬로 생각한다. 즉, ${\\pmb \\Sigma} = diag(\\sigma_i^2)$ 공분산행렬을 isotropic covariance로 만든다. 즉, ${\\pmb \\Sigma} = \\sigma^2{\\pmb I}$ 물론 이런 제약이 생기면 data간의 correlation을 못 잡는 경우가 발생한다. gaussian은 unimodal 하기에 multimodal distribution을 잘 approximation하기 어렵다. 이에 대해 해결책은 나중에 뒤에서 배운다. (Mixture 등등) ","date":"2021-11-26","objectID":"/prml-chap02-2/:1:0","tags":["Gaussian Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (2)","uri":"/prml-chap02-2/"},{"categories":["PRML"],"content":"2.3.1 Conditional Gaussian distributions conditional distribution의 경우를 살펴보자. $\\textbf{x}$는 Gaussian distribution $N(\\textbf{x} | {\\pmb \\mu, \\Sigma})$의 D-차원 vector이다. 이를 두 부분으로 나누어 $\\textbf{x}_a, \\textbf{x}_b$ 라고 하자. D*D covariance matrix는 대칭행렬이다. $$\\textbf{x} = \\begin{pmatrix} \\textbf{x}_a \\\\ \\textbf{x}_b \\end{pmatrix}, {\\pmb \\mu} = \\begin{pmatrix} {\\pmb \\mu}_a \\\\ {\\pmb \\mu}_b \\end{pmatrix}$$ $${\\pmb \\Sigma} = \\begin{pmatrix} \\Sigma_{aa} \u0026 \\Sigma_{ab} \\\\ \\Sigma_{ba} \u0026 \\Sigma_{bb} \\end{pmatrix}$$ precision matrix $${\\pmb \\Lambda} \\equiv {\\pmb \\Sigma}^{-1} = \\begin{pmatrix} {\\pmb \\Lambda} _ {aa} \u0026 {\\pmb \\Lambda} _ {ab} \\\\ {\\pmb \\Lambda} _ {ba} \u0026 {\\pmb \\Lambda}_{bb} \\end{pmatrix}$$ 이제 우리는 conditional distribution $p(\\textbf{x}_a | \\textbf{x}_b)$ 을 살펴보자. (gaussian은 quadratic form in the exponent를 주의깊게 살펴보자) $\\textbf{x}_b$는 fixed 되었으며 exp 안의 부분을 나눠서보면 $$-\\frac{1}{2}({\\bf x}-{\\pmb \\mu})^T\\Sigma^{-1}({\\bf x}-{\\pmb \\mu})=$$ $$ -\\frac{1}{2}({\\bf x}_a - {\\pmb \\mu}_a)^T{\\pmb \\Lambda} _ {aa}({\\bf x}_a-{\\pmb \\mu}_a) - \\frac{1}{2}({\\bf x}_a - {\\pmb \\mu}_a)^T {\\pmb \\Lambda} _ {ab}({\\bf x}_b-{\\pmb \\mu}_b)$$ $$-\\frac{1}{2}({\\bf x}_b-{\\pmb \\mu}_b)^T{\\pmb \\Lambda} _ {ba}({\\bf x}_a-{\\pmb \\mu}_a) - \\frac{1}{2}({\\bf x}_b - {\\pmb \\mu}_b)^T{\\pmb \\Lambda} _ {bb}({\\bf x}_b-{\\pmb \\mu}_b) $$ 위 식을 보면 $\\textbf{x}_a$ 에 대한 함수이고 quadratic form 임을 알 수 있다. 즉 conditional dist는 Gaussian인 것이다. 이제 평균과 분산을 구하는 과정을 살펴보자. 먼저, $\\textbf{x}_a$의 second order인 부분을 먼저보면 $$-\\frac{1}{2}\\textbf{x}^T_a {\\pmb \\Lambda}_{aa} \\textbf{x}_a$$ 따라서 우리는 conditional distribution $p(\\textbf{x}_a | \\textbf{x}_b)$의 covariance 가 $${\\pmb \\Sigma_{a|b} = {\\pmb \\Lambda}_{aa}^{-1}}$$ 임을 알 수 있다. 다음은 $\\textbf{x}_a$에 linear한 부분을 보면 $$\\textbf{x}_a^T { {\\pmb \\Lambda} _ {aa} {\\pmb \\mu}_a - {\\pmb \\Lambda} _ {ab}(\\textbf{x}_a - {\\pmb \\mu}_b)}$$ 이를 이용하여 우리는 평균을 구할 수 있다. $${\\pmb \\mu} _ {a|b} = {\\pmb \\Sigma}_{a|b} [ {\\pmb \\Lambda} _ {aa}{\\pmb \\mu}_a - {\\pmb \\Lambda} _ {ab}({\\bf x}_b-{\\pmb \\mu}_b) ] = {\\pmb \\mu}_a -{\\pmb \\Lambda} _ {aa}^{-1}{\\pmb \\Lambda} _ {ab}({\\bf x}_b-{\\pmb \\mu}_b) $$ 다음으로 공분산행렬을 구하면 $${\\pmb \\Sigma}_{a|b} = {\\pmb \\Sigma} _ {aa} - {\\pmb \\Sigma} _ {ab}{\\pmb \\Sigma} _ {bb}^{-1}{\\pmb \\Sigma} _ {ba} $$ [참고] 아래의 공식을 이용하여 구한다. $$$$ $$M = (A-BD^{-1}C)^{-1} $$ 결론 : conditional distribution도 Gaussian distribution이다 mean은 linear function of $\\textbf{x}_b$ covariance은 independent of $\\textbf{x}_b$ ","date":"2021-11-26","objectID":"/prml-chap02-2/:1:1","tags":["Gaussian Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (2)","uri":"/prml-chap02-2/"},{"categories":["PRML"],"content":"2.3.2 Mariginal Gaussian distributions $$p({\\bf x}_a) = \\int p({\\bf x}_a, {\\bf x}_b)d{\\bf x}_b $$ joint distribution에서 integrate out $x_b$하면 된다. 이번에도 마찬가지로 quadratic form을 이용하여 문제를 해결한다. 위에서 봤던 joint distribution의 exp부분을 이번에는 $\\textbf{x}_b$에 대해 전개하면 $$-\\dfrac{1}{2}{\\bf x}_b^{T}{\\pmb \\Lambda} _ {bb}{\\bf x}_b + {\\bf x}_b^T{\\bf m} = -\\dfrac{1}{2}({\\bf x}_b- {\\pmb \\Lambda} _ {bb}^{-1}{\\bf m})^T {\\pmb \\Lambda} _ {bb}({\\bf x}_b- {\\pmb \\Lambda} _ {bb}^{-1}{\\bf m}) + \\dfrac{1}{2}{\\bf m}^T {\\pmb \\Lambda} _ {bb}^{-1}{\\bf m}$$ $$\\text{where}\\;{\\bf m} = {\\pmb \\Lambda}_{bb}{\\pmb \\mu} _ b - {\\pmb \\Lambda} _ {ba}({\\bf x}_a-{\\pmb \\mu}_a)$$ 위의 식 우항에서 첫번째 부분은 quadratic form으로 만들었다. integrate하면 exp부분을 제외한 Gaussian distribution의 normalization constant가 나온다. 이는 첫번째항의 covariance determinant만 관련이 있고 $\\textbf{x}_a$와 independent하다. 결국 중요한건 $\\textbf{x}_a$와 dependent한 뒷부분인데 이를 정리하면 ${\\bf x}_a$에 대한 marginal gaussian distribution가 된다. $$\\dfrac{1}{2}[{\\pmb \\Lambda} _ {bb}{\\pmb \\mu}_b-{\\pmb \\Lambda} _ {ba}({\\bf x}_a-{\\pmb \\mu}_a)]^T {\\pmb \\Lambda} _ {bb}^{-1}[{\\pmb \\Lambda} _ {bb}{\\pmb \\mu}_b-{\\pmb \\Lambda} _ {ba}({\\bf x}_a-{\\pmb \\mu}_a)]$$ $$- \\dfrac{1}{2}{\\bf x}_a^T{\\pmb \\Lambda} _ {aa}{\\bf x}_a + {\\bf x}_a^T({\\pmb \\Lambda} _ {aa}{\\pmb \\mu}_a+{\\pmb \\Lambda} _ {ab}{\\pmb \\mu}_b) + const$$ $$= - \\dfrac{1}{2}{\\bf x}_a^T({\\pmb \\Lambda} _ {aa}-{\\pmb \\Lambda} _ {ab}{\\pmb \\Lambda} _ {bb}^{-1}{\\pmb \\Lambda} _ {ba}){\\bf x}_a + {\\bf x}_a^T({\\pmb \\Lambda} _ {aa}-{\\pmb \\Lambda} _ {ab}{\\pmb \\Lambda} _ {bb}^{-1}{\\pmb \\Lambda} _ {ba}){\\pmb \\mu}_a+const $$ 이를 이용하여 marginal distribution을 구하면 된다. 먼저, covariance는 $${\\pmb \\Sigma}_a = ({\\pmb \\Lambda} _ {aa}-{\\pmb \\Lambda} _ {ab}{\\pmb \\Lambda} _ {bb}^{-1}{\\pmb \\Lambda} _ {ba})^{-1} = {\\pmb \\Sigma} _ {aa}$$ mean은 아래와 같다. $${\\pmb \\Sigma}_a({\\pmb \\Lambda} _ {aa}-{\\pmb \\Lambda} _ {ab}{\\pmb \\Lambda} _ {bb}^{-1}{\\pmb \\Lambda} _ {ba}){\\pmb \\mu}_a = {\\pmb \\mu}_a$$ 결론 : Marginal distribution도 Gaussian distribution이다. $E[\\textbf{x}_a] = {\\pmb \\mu}_a$ $cov[\\textbf{x}_a] = \\Sigma _{aa}$ 직관과 거의 일치한다. (partitioned한 부분) ","date":"2021-11-26","objectID":"/prml-chap02-2/:1:2","tags":["Gaussian Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (2)","uri":"/prml-chap02-2/"},{"categories":["PRML"],"content":"2.3.3 Bayes' theorem for Gaussian variables Gaussian marginal distribution $p(\\textbf{x})$ , Gaussian conditional distribution $p(\\textbf{y} | \\textbf{x})$가 주어진 상태이다. (2.3.1과 2.3.2에서 알게된 사실을 토대로) $$p({\\bf x}) = N({\\bf x}|{\\pmb \\mu}, {\\pmb \\Lambda}^{-1}) $$ $$p({\\bf y}|{\\bf x}) = N({\\bf y}|{\\bf A} {\\bf x}+{\\bf b} , \\textbf{L}^{-1}) $$ 우리는 Gaussian marginal distribution $p(\\textbf{y})$ , Gaussian conditional distribution $p(\\textbf{x} | \\textbf{y})$를 구하고자 한다. 먼저 joint distribution을 구한 뒤에 구해보자. $${\\bf z} = \\dbinom{ {\\bf x} }{ {\\bf y} }$$ $$\\ln p({\\bf z}) = \\ln p({\\bf x}) + \\ln p({\\bf y}) \\\\ = -\\frac{1}{2}({\\bf x}-{\\pmb \\mu})^T{\\pmb \\Lambda}({\\bf x}-{\\pmb \\mu}) -\\frac{1}{2}({\\bf y}-{\\bf A}{\\bf x}-{\\bf b})^T {\\bf L}({\\bf y}-{\\bf A}{\\bf x}-{\\bf b})+const $$ 위의 식은 quadratic 형태의 함수라는 것을 알수 있고 따라서 Gaussian distribution의 함수일 것이다. 위의 식을 전개하여 이차항을 살펴보면 (for covariance) $$-\\frac{1}{2} {\\bf x}^T ({\\pmb \\Lambda} + {\\bf A}^T {\\pmb \\Lambda} {\\bf A}) {\\bf x} - \\frac{1}{2} {\\bf y}^T {\\bf L}{\\bf y} + \\frac{1}{2} {\\bf x}^T {\\bf A}{\\bf L}{\\bf y}$$ $$ = -\\frac{1}{2} \\dbinom{ {\\bf x} }{ {\\bf y} }^T \\left(\\begin{array}{cc}{\\pmb \\Lambda}+{\\bf A}^T{\\bf L}{\\bf A} \u0026 -{\\bf A}^T{\\bf L} \\\\ - {\\bf L}{\\bf A} \u0026 {\\bf L}\\end{array} \\right) \\dbinom{ {\\bf x} }{ {\\bf y} } = -\\frac{1}{2}{\\bf z}^T{\\bf R}{\\bf z}$$ 따라서 precision matrix는 $${\\bf R} = \\left(\\begin{array}{cc}{\\pmb \\Lambda}+{\\bf A}^T{\\bf L}{\\bf A} \u0026 -{\\bf A}^T{\\bf L}\\-{\\bf L}{\\bf A} \u0026 {\\bf L}\\end{array}\\right)$$ 임을 알 수 있다. 이를 inverse하여 covariance matrix를 구하면 $$cov[{\\bf z}]={\\bf R}^{-1} = \\left(\\begin{array}{cc}{\\pmb \\Lambda}^{-1} \u0026 {\\pmb \\Lambda}^{-1}{\\bf A}^T \\ {\\bf A}{\\pmb \\Lambda}^{-1} \u0026 {\\bf L}^{-1}+{\\bf A}{\\pmb \\Lambda}^{-1}{\\bf A}^T \\end{array}\\right)$$ 이전의 방법을 이용하여 mean을 구할 수 있다. $${\\bf x}^T{\\pmb \\Lambda}{\\pmb \\mu} - {\\bf x}^T{\\bf A}^T{\\bf L}{\\bf b} + {\\bf y}^T{\\bf L}{\\bf b} = \\dbinom{ {\\bf x} }{ {\\bf y} }^T \\dbinom {\\pmb \\Lambda}{\\pmb \\mu}-{\\bf A}^T{\\bf L}{\\bf b} {\\bf L}{\\bf b} $$ $$E[{\\bf z}] = {\\bf R}^{-1}\\dbinom{ {\\bf x} }{ {\\bf y} }^T\\dbinom {\\pmb \\Lambda}{\\pmb \\mu}-{\\bf A}^T{\\bf L}{\\bf b} {\\bf L}{\\bf b}$$ 전개하면 최종적으로 mean은 $$E[{\\bf z}] = \\dbinom{ {\\pmb \\mu} }{ {\\bf A} {\\pmb \\mu} - {\\bf b}}$$ 결과 $$E[{\\bf y}] = {\\bf A}{\\pmb \\mu} + {\\bf b}$$ $$cov[{\\bf y}] = {\\bf L}^T + {\\bf A}{\\pmb \\Lambda}^{-1}{\\bf A}^T $$ 다음은 conditional distribution $p(\\textbf{x}| \\textbf{y})$ 의 mean, covariance를 구하면 $$\\Sigma_{a|b}={\\pmb \\Lambda} _ {aa}^{-1} \\ {\\pmb \\mu}_{a|b}={\\pmb \\mu}_a - {\\pmb \\Lambda} _ {aa}^{-1}{\\pmb \\Lambda} _ {ab}({\\bf x}_b-{\\pmb \\mu}_b)$$ $$E[{\\bf x}|{\\bf y}] = ({\\pmb \\Lambda}+{\\bf A}^T{\\bf L}{\\bf A})^{-1}{ {\\bf A}^T{\\bf L}({\\bf y}-{\\bf b})+{\\pmb \\Lambda}{\\pmb \\mu}} $$ $$cov[{\\bf x}|{\\bf y}] = ({\\pmb \\Lambda}+{\\bf A}^T{\\bf L}{\\bf A})^{-1} $$ ","date":"2021-11-26","objectID":"/prml-chap02-2/:1:3","tags":["Gaussian Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (2)","uri":"/prml-chap02-2/"},{"categories":["PRML"],"content":"2.3.4 Maximum likelihood for the Gaussian Log likelihood $$\\ln p({\\bf X}|{\\pmb \\mu}, \\Sigma) = -\\frac{ND}{2}\\ln(2\\pi) - \\frac{N}{2}\\ln|\\Sigma|-\\frac{1}{2}\\sum_{n=1}^{N}({\\bf x}_n-{\\pmb \\mu})^T\\Sigma^{-1}({\\bf x}_n-{\\pmb \\mu})$$ (과정 생략) $${\\pmb \\mu} _ {ML} = \\frac{1}{N}\\sum_{i=1}^{N}{\\bf x}_i = \\bar{\\bf x}$$ $${ \\pmb \\Sigma} _ {ML} = \\frac{1}{N}\\sum_{i=1}^{N}({\\bf x}_i-\\mu)({\\bf x}_i-\\mu)^T$$ ","date":"2021-11-26","objectID":"/prml-chap02-2/:1:4","tags":["Gaussian Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (2)","uri":"/prml-chap02-2/"},{"categories":["PRML"],"content":"2.3.5 Sequential estimation data sample이 하나 들어오면 바로 계산하고 버린다. MLE를 구하는 예시를 살펴보자. $${\\pmb \\mu} _ {ML}^{(N)} = \\frac{1}{N} \\sum_{n=1}^{N}{\\bf x}_n = \\frac{1}{N}{\\bf x} _ N + \\frac{1}{N} \\sum _ {n=1}^{N-1}{\\bf x}_n$$ $$= \\frac{1}{N}{\\bf x}_N + \\frac{N-1}{N}{\\pmb \\mu} _ {ML}^{(N-1)}={\\pmb \\mu} _ {ML}^{(N-1)}+\\frac{1}{N}({\\bf x}_N-{\\pmb \\mu} _ {ML}^{(N-1)}) $$ 이전에 구한 parameter를 ‘error signal’ $(\\textbf{x} _N - {\\pmb \\mu} _{ML}^{(N-1)})$ 쪽으로 1/N에 비례하도록 수정하여 parameter를 업데이트한다. $N$이 커질수록 새로운 data의 영향은 작아진다. 이번에는 이런 Sequential estimation에서 사용되는 일반적인 방법에 대해 살펴보자. 바로 Robbins-Monro algorithm이다. random variables $\\theta, z$가 있다. conditional expectation은 $$f(\\theta)\\equiv E[z|\\theta] = \\int zp(z|\\theta)dz $$ 이고 이러한 형태를 regression function이라고 부른다. 우리의 목표는 $f(\\theta^{ * }) = 0$을 만족하는 root $\\theta^{ * }$를 찾는 것이다. 몇가지 가정을 살펴보면 data가 많으면 한번에 regression function을 만들고 root를 estimation할 수 있겠지만 지금은 Sequential하게 data가 하나씩 구해진다고 가정한다. $E[(z-f)^2 | \\theta]\u003c\\infty$ : conditional variance는 finite하다고 가정한다. $\\theta \u003e \\theta^{ * } \\rightarrow f(\\theta) \u003e 0$ $\\theta \u003c \\theta^{ * } \\rightarrow f(\\theta) \u003c 0$ Robbins-Monro의 방법은 $$\\theta^{(N)} = \\theta^{(N-1)} - a_{N-1} z(\\theta^{N-1}) $$ 여기서 $z(\\theta^{(N)})$은 N번째의 $\\theta$가 들어왔을 때, $z$의 값을 의미한다. $a_N$은 양의 실수이며 다음과 같은 조건을 갖는다. $\\lim_{N\\rightarrow\\infty}a_N=0 $ : $\\theta$가 특정값에 수렴 $\\sum_{N=1}^{\\infty}a_N=\\infty $ : root를 찾기도 전에 다른 값에 수렵하지 않도록 $% $ : 축적되는 noise가 finite하여 수렴을 방해하지 않는다. 이제 이 방법을 통해 이전에 구했던 MLE의 예시에 적용해보자. $$\\frac{\\partial}{\\partial\\theta}{-\\frac{1}{N}\\sum_{n=1}^{N}\\ln p(x_n|\\theta)}_ {\\theta_{MLE}}=0$$ MLE는 위처럼 log likelihood function을 미분하여 0으로 만드는 값니다. as $N \\rightarrow \\infty$ $$-\\lim_{n\\rightarrow\\infty}\\frac{1}{N}\\sum_{n=1}^{N}\\frac{\\partial}{\\partial\\theta}\\ln p(x_n|\\theta) = E_x\\left[-\\frac{\\partial}{\\partial\\theta}\\ln p(x|\\theta)\\right] $$ 이제 Robbins-Monro의 방법을 적용하면 $$\\theta^{(N)} = \\theta^{(N-1)} - a_{N-1}\\frac{\\partial}{\\partial\\theta^{(N-1)}}\\left[-\\ln p(x_N/\\theta^{(N-1)})\\right] $$ $$z=\\frac{\\partial}{\\partial\\mu_{ML}}[-\\ln p(x|\\mu_{ML}, \\sigma^2)]=-\\frac{1}{\\sigma^2}(x-\\mu_{ML}) $$ 따라서 $\\textbf{x}_N$을 대입하고 $a_N = \\sigma^1 / N$을 대입하면 처음에 구한 결과와 같다. ","date":"2021-11-26","objectID":"/prml-chap02-2/:1:5","tags":["Gaussian Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (2)","uri":"/prml-chap02-2/"},{"categories":["PRML"],"content":"이번 장은 주어진 데이터를 이용하여 Distribution을 만드는 것을 배울 것이다. density estimation을 하는 것이다. 이에 대한 방법으로 크게 parametric, nonparmetric 방법으로 나눌 수 있다. 추가로 몇가지 중요한 분포들에 대해 살펴볼 것이다. ","date":"2021-11-26","objectID":"/prml-chap02-1/:0:0","tags":["Bayesian","Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (1)","uri":"/prml-chap02-1/"},{"categories":["PRML"],"content":"2.1 Binary Variables 동전던지기와 같이 random variable이 딱 두가지의 값을 가지는 경우 ($x \\in {0,1}$) 에 대해 살펴보자. Bernoulli distribution $x=1$의 확률을 $p(x=1 | \\mu) = \\mu$ 라고 하자. ($0\\le \\mu \\le 1$) $E[x] = \\mu, Var[x] = \\mu(1-\\mu)$ parameter를 MLE로 추정하면 $\\mu_{ML} = \\frac{1}{N}\\sum_{n=1}^{N}{x_n}$ $$Bern(x | \\mu) = \\mu^x (1- \\mu)^{1-x}$$ MLE의 문제점을 여기서 볼 수 있다. 만약에 동전을 3번 던져서 모두 앞면이 나왔다고 하자. 이 data를 기반으로 동전이 앞면이 나올 확률을 MLE로 추정한다면 1일 것이다. 이처럼 극단적으로 overfitting이 되는 경우가 생길 수 있다. 이에 대한 해결책으로는 더 많은 data를 수집하거나 bayesian의 관점으로 접근해야 한다. Binomial distribution N번 중 $\\mu$의 확률로 사건이 $x$개 발생한 경우 (Bernoulli trial이 N번 발생) $$Bin(x | sN,\\mu) = \\begin{pmatrix} N \\ x \\end{pmatrix}\\mu^x (1-\\mu)^{N-x}$$ $$E[x] =N \\mu, Var[x] =N \\mu(1-\\mu)$$ ","date":"2021-11-26","objectID":"/prml-chap02-1/:1:0","tags":["Bayesian","Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (1)","uri":"/prml-chap02-1/"},{"categories":["PRML"],"content":"2.1.1 The beta distribution 위의 분포를 보고 bayesian의 접근방식을 생각해보자. parameter $\\mu$에 대한 prior를 만들어보자. conjugacy (prior와 posterior가 같은 분포를 갖는) 의 성질을 이용하면 Beta distribution을 생각할 수 있다. prior도 Beta이고 posterior도 Beta distribution의 모습을 보이도록 만들어준다. conjugacy를 이용하면 계산, 해석적인 측면에서 상당히 유용하다. $$Beta(\\mu | a,b) = \\frac{\\Gamma(a+b)}{\\Gamma (a) \\Gamma (b)}\\mu^{a-1}(1-\\mu)^{b-1}$$ $$E[\\mu] = \\frac{a}{a+b}, Var[\\mu] = \\frac{ab}{(a+b)^2(a+b+1)}$$ Binomial likelihood function과 Beta prior를 곱하여 posterior dist of $\\mu$ 를 만들면 $$p(\\mu | x,l,a,b) \\propto \\mu^{x+a-1} (1-\\mu)^{N-x+b-1}$$ 합이 1이 되게 constant를 만들지 않아도 posterior가 beta distribution임을 파악할 수 있다. posterior에서 $a$와 $b$는 각각 $x=1$, $x=0$ 인 data의 수와 같은 의미(역할)임을 알 수 있다. 우리는 prior를 beta로 이용했고 posterior가 beta로 나왔다. 그렇다면 나온 posterior를 다시 prior로 이용할 수 있을 것이다. 이처럼 sequential한 접근이 가능해진다. 우리의 목표는 predict이므로 predictive distribution을 구해보자. $$p(x=1 | D) = \\int_{0}^{1} p(x=1,\\mu | D)d\\mu$$ $$= \\int_{0}^{1} p(x=1 | \\mu)p(\\mu | D)d\\mu = \\int_{0}^{1}\\mu p(\\mu | D)d\\mu = E[\\mu | D]$$ 여기서 posterior dist의 평균을 구하면 $$p(x=1|D) = \\frac{x+a}{x+a+N-x+b}$$ 이고 데이터의 수가 많아지면 posterior mean은 MLE와 같아진다. 또한, uncertainty도 줄어들며 likelihood function의 모양과 가까워진다. 물론, 반대로 prior의 정보가 강하다면 prior와 비슷해진다. prior가 강하거나 data수가 많아 likelihood가 강해지면 uncertainty가 줄면서 posterior distribution의 모양이 뾰족해진다. 수리통계학에서 배웠던 공식을 이용하여 살펴보면 $E_{\\theta}[\\theta] = E_{D}[E_{\\theta}[\\theta|D]]$ D에 대해 averaged over된 posterior mean of $\\theta$ = prior mean of $\\theta$ $V_{\\theta}[\\theta] = E_{D}[V_{\\theta}[\\theta|D]]+V_{D}[E_{\\theta}[\\theta|D]]$ 평균적으로 posterior variance of $\\theta$가 prior variance보다 더 작다. ","date":"2021-11-26","objectID":"/prml-chap02-1/:1:1","tags":["Bayesian","Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (1)","uri":"/prml-chap02-1/"},{"categories":["PRML"],"content":"2.2 Multinomial Variables 이번에는 확률변수가 2가지의 값을 갖는게 아닌 K개의 값을 갖는 경우를 살펴보자. 이를 위해 우리는 vector로 확률변수를 표현한다. 예를 들어, 주사위를 던졌더니 3이란 수가 나왔다. $\\textbf{x} = (0,0,1,0,0,0)^T$ 이렇게 표현한다. 각 원소 $x_k$들의 합은 1이다. $x_k=1$인 확률을 parameter $\\mu_k$로 표현하면, $\\textbf{x}$의 distribution은 $$p(\\textbf{x} | {\\pmb \\mu}) = \\prod_{k=1}^{K}\\mu_{k}^{x_k}$$ $\\sum \\mu_k = 1, 0\\le\\mu_k\\le 1$ 이다. expectation은 $$E[{\\bf x}|{\\pmb \\mu}] = \\sum_{\\bf x}p({\\bf x}|{\\pmb \\mu}){\\bf x} = (\\mu_1, …, \\mu_K)^T = {\\pmb \\mu}$$ 으로 구할 수 있다. 그렇다면 이제 likelihood function을 구해보자. $$p(D|{\\pmb \\mu}) = \\prod_{n=1}^{N}\\prod_{k=1}^{K}\\mu_k^{x_{nk}} = \\prod_{k=1}^{K}\\mu_k^{\\sum_n x_{nk}}=\\prod_{k=1}^{K}\\mu_k^{m_k}$$ $m_k = \\sum_{n} x_{nk}$ : 전체 data에서 k값을 가지는 data 갯수 이 likelihood function을 이용하여 parameter ${\\pmb \\mu}$를 구해보자. constraint $\\sum_{k=1}^{K}{\\mu_k} = 1$ 에서 log likelihood 를 최대화 해야 한다. Lagrange multiplier $\\lambda$를 이용하여 아래 식을 최대화하면 된다. (Lagrange method) $$\\sum_{k=1}^{K}{m_k \\ln \\mu_k} + \\lambda (\\sum_{k=1}^{K}{\\mu_k}-1) $$ $\\mu_k$에 대해 미분하면 $\\mu_k = - m_k / \\lambda$ 이고 constraint때문에 $\\lambda = - N$ 이라는 것을 파악할 수 있다. 따라서 MLE는 $$\\mu_k = \\frac{m_k}{N}$$ Multinomial distribution $\\sum \\mu_k = 1, 0\\le\\mu_k\\le 1$ $\\sum m = N$ $$\\text{Multi}(m_1,m_2, … , m_K | \\mu, N) = \\frac{N!}{m_1! m_2! … m_K!}\\prod_{k=1}^{K}{\\mu_k^{m_k}}$$ ","date":"2021-11-26","objectID":"/prml-chap02-1/:2:0","tags":["Bayesian","Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (1)","uri":"/prml-chap02-1/"},{"categories":["PRML"],"content":"2.2.1 The Dirichlet distribution $$Dir(\\boldsymbol{\\mu} | \\boldsymbol{\\alpha}) = \\frac{\\Gamma (\\alpha_0)}{\\Gamma (\\alpha_1) \\Gamma(\\alpha_2)…\\Gamma(\\alpha_K)}\\prod_{k=1}^{K}{\\mu_k^{\\alpha_k - 1}}$$ $\\sum \\mu_k = 1, 0\\le\\mu_k\\le 1$ Multinomial의 conjugate prior K = 2이면 beta 분포이다. Binomial의 일반화된 분포가 Multinomial이듯 Beta의 일반화된 분포가 Dirichlet 분포라고 할 수 있다. posterior $$p({\\pmb \\mu}|D, {\\pmb \\alpha}) \\propto p(D|{\\pmb \\mu})p({\\pmb \\mu}|{\\pmb \\alpha}) \\propto \\prod_{k=1}^{K} \\mu_k^{\\alpha_k+m_k-1}$$ 이전에 봤듯이 prior의 $a_k$는 data에서 ‘observation of $x_k=1$’ 의 갯수와 같은 의미(역할)이라고 할 수 있다. ","date":"2021-11-26","objectID":"/prml-chap02-1/:2:1","tags":["Bayesian","Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (1)","uri":"/prml-chap02-1/"},{"categories":["PRML"],"content":"Information Theory에 대해 알아봅시다. ","date":"2021-11-26","objectID":"/prml-chap01-3/:0:0","tags":["Information Theory"],"title":"[PRML] Chapter1 - Introduction (3)","uri":"/prml-chap01-3/"},{"categories":["PRML"],"content":"1.6 Information Theory 일단 entropy에 대해 두 가지의 시선으로 살펴볼 예정이다. 일단 discrete random variable $x$와 이 variable의 specific value를 알아내면서 얻는 정보의 양이 얼마나 되는지로부터 시작한다. 어떤 사건이 일어날 확률이 큰 경우보다 일어날 확률이 작은 사건이 더 정보가 많다고 한다. 이에 따라 우리는 information content ($h(x)$ 라고 하자) 를 측정하는 방법이 필요하다. 그 방법의 조건은 확률 $p(x)$에 대해 monotonic function 두 개의 사건이 독립적이면 information gain은 두 information의 합으로 표현 이런 조건을 만족시키기 위해 우리는 logarithm을 이용한다. ($\\log_2$인 이유는 2진수 bit단위의 정보전달의 측면에서 접근하기 위해) $$h(x) = - \\log_2 p(x)$$ information은 0이상의 값을 갖기에 음수부호를 붙여서 사용한다. 이제 sender가 receiver에게 random variable의 값을 전달해야하는 상황이라고 가정하자. 그들이 전달하는 정보의 평균적인 양은 $$H[x] = - \\sum_{x}{p(x)\\log_2 p(x)}$$ 이를 우리는 entropy of the random variable x 라고 부른다. (예시는 생략) nonuniform distribution은 uniform distribution보다 더 작은 entropy값을 갖는다. entropy의 값을 정보전달의 측면 (bit단위라고 생각) 에서 생각해보자. 예를 들면, A집단의 entropy가 2, B집단의 entropy가 3의 값을 가진다. A의 내용을 전달하기 위해서는 최소 2bit, B는 최소 3bit가 필요한 것을 의미하고 이처럼 entropy는 the state of a random variable을 전달하기 위해 필요한 bits 수의 lower bound이다. 이번에는 entropy에 대해 다른 시각으로 살펴보자. N개의 물체를 bin에 나누어 담아야 한다. $i^{th}$ bin 에는 $n_i$개의 물체가 들어간다. 물체를 나누어 담는 경우의 수 $W$ 를 생각해보면 $$W = \\frac{N!}{\\prod_i n_i !}$$ 이를 multiplicity 라고 부른다. entropy를 만들기 위해 logarithm과 적절한 scaled 취하면 $$H = \\frac{1}{N}\\ln w = \\frac{1}{N} \\ln N! - \\frac{1}{N}\\sum_{i} \\ln n_i !$$ N이 무한대로 가고 $n_i / N$은 fixed 된다. 그리고 Stirling’s approximation을 이용하면 $\\ln N ! \\approx N \\ln N - N$ $\\ln n_i ! \\approx n_i \\ln n_i - n_i$ 이를 대입하면 $$H = - \\lim_{N \\rightarrow \\infty} \\sum_{i} \\frac{n_i}{N} \\ln \\frac{n_i}{N} = - \\sum_{i}{p_i \\ln p_i}$$ $\\sum_i n_i = N$ $p_i = \\lim_{N \\rightarrow \\infty} (n_i / N)$ : 물체가 i bin에 들어갈 확률 우리는 bin을 random variable X의 state $x_i$ 라고 할 수 있다. 따라서 random variable X의 entropy는 $$H[p] = - \\sum_{i}{p(x_i)\\ln p(x_i)}$$ 우리는 Lagrange를 이용하여 위의 식의 최댓값을 구할수 있고 최댓값은 Uniform distribution 일 때이다. 이제 continuos variable에서도 생각해보자. (과정 생략) continuos variable의 entropy는 아래 값을 가진다. $$H[x] = - \\int p(x) \\ln p(x) dx$$ 이를 differential entropy 라고 부른다. discrete의 경우에서와 마찬가지로 continuos에서는 어떤 distribution이 가장 큰 entropy를 가질까? (과정 생략, 똑같이 Lagrange 사용) 정답은 Gaussian distribution 인 경우이다. ","date":"2021-11-26","objectID":"/prml-chap01-3/:1:0","tags":["Information Theory"],"title":"[PRML] Chapter1 - Introduction (3)","uri":"/prml-chap01-3/"},{"categories":["PRML"],"content":"1.6.1 Relative entropy and mutual information 우리가 모르는 distribution $p(x)$가 있다고 가정해보자. 이를 approximation하는 $q(x)$를 모델링하였다. 이전에 정보전달에서의 측면에서 생각해보면 우리는 approximation 했기에 random variable 의 value 전달을 위해 추가적으로 리소스 bit가 더 필요하다. 더 필요한 정도는 $$KL(p| q) = - \\int p(\\textbf{x}) \\ln q(\\textbf{x})d\\textbf{x} - (- \\int p(\\textbf{x}) \\ln p(\\textbf{x})d\\textbf{x}) \\ = - \\int p(\\textbf{x})\\ln \\frac{p(\\textbf{x})}{q(\\textbf{x})}d\\textbf{x}$$ 이를 Kullbak-Leibler divergence (Relative entropy) between $p(\\textbf{x})$ and $q(\\textbf{x})$ 라고 부른다. 그리고 아래와 같은 특징을 갖는다. (이러한 특징을 통해 Kullbak-Leibler divergence는 measure of the dissimilarity of the two distributions $p(\\textbf{x}), q(\\textbf{x})$ 라고 할 수 있다.) $KL(p| q) \\ge 0$ $KL(p| q) = 0$, if and only if, $p(\\textbf{x}) = q(\\textbf{x})$ 증명은 Jensen’s inequality로 쉽게 할 수 있다. convex function $f(x)$는 $$f(\\sum_{i=1}^{M}{\\lambda_i x_i}) \\le \\sum_{i=1}^{M}{\\lambda_i f(x_i)}$$ $\\lambda \\ge 0$ $\\sum_i \\lambda_i = 1$ 의 특징을 갖는다. 위에서 $\\lambda_i$를 x의 확률분포라고 생각하면 $f(E[x]) \\le E[f(x)]$ 이다. 따라서 ($f$ 를 -log라고 생각하면 된다) $$KL[p|q] = - \\int p(\\textbf{x}) \\ln \\frac{q(\\textbf{x})}{p(\\textbf{x})}d\\textbf{x} \\ge - \\ln \\int q(\\textbf{x}) d\\textbf{x} = 0 $$ KL divergence를 최소화하는 것은 결국 likelihood function을 최대화하는 것과 같은데 이에 대해 살펴보자. 우리가 모르는 (approximation해야하는) 분포 $p(\\textbf{x})$에서 data가 generate되었다고 하자. 우리는 어떤 parametric distribution $q(\\textbf{x} | \\theta)$ 를 통해 approximation하고자 한다. $\\theta$를 정하는 방법은 $\\theta$에 대해 KL divergence를 최소화하는 것을 찾는 것이다. 그런데 우리는 $p(\\textbf{x})$를 모르는 상황이기에 directly할 수 없다. 대신 N개의 train data가 존재하므로 이를 이용하면 $$KL(p|q) \\approx \\sum_{n=1}^{N}{{ - \\ln q (\\textbf{x}_n | {\\bf \\theta}) + \\ln p(\\textbf{x}_n)} }$$ 우변의 두번째항은 parameter와 independent하다. 첫번째항은 negative log likelihood function for $\\theta$ of under the distribution $q(\\textbf{x} | \\theta)$ (train data를 통해 만들어진 분포) 이므로 KL divergence를 최소화하는 것은 likelihood function을 최대화하는 것이다. 이번에는 joint distribution을 생각해보자. 두 변수가 independent이면 $p(\\textbf{x}\\textbf{y}) = p(\\textbf{x})p(\\textbf{y})$ 이다. 하지만 independent가 아닌 경우, 우리는 KL divergence를 통해 얼마나 independent와 가까운지 생각해볼수 있다. $$I[\\textbf{x}, \\textbf{y}] \\equiv KL(p(\\textbf{x}, \\textbf{y}) | p(\\textbf{x})p(\\textbf{y})) = - \\int \\int p(\\textbf{x}, \\textbf{y}) \\ln \\frac{p(\\textbf{x})p(\\textbf{y})}{p(\\textbf{x}, \\textbf{y})}d\\textbf{x} d\\textbf{y}$$ 이를 mutual information between the variable x and y 라고 부른다. conditional entropy의 측면에서 $I[\\textbf{x}, \\textbf{y}] = H[\\textbf{x}] - H[\\textbf{x}|\\textbf{y}] = H[\\textbf{y}] - H[\\textbf{y}/\\textbf{x}]$ 따라서 MI는 y를 알고 난 뒤에 x의 uncertainty가 줄어든 정도 (반대도 성립) 라고 할 수 있다. Bayesian의 입장에서는 $p(\\textbf{x})$가 pior이고 $p(\\textbf{x} | \\textbf{y})$는 y data를 얻은 후의 posterior이다. 따라서 MI는 새로운 observation y의 등장으로 줄어든 x의 uncertainty라고 할 수 있다. ","date":"2021-11-26","objectID":"/prml-chap01-3/:1:1","tags":["Information Theory"],"title":"[PRML] Chapter1 - Introduction (3)","uri":"/prml-chap01-3/"},{"categories":["PRML"],"content":"Decision Theory에 대해 알아봅시다. ","date":"2021-11-26","objectID":"/prml-chap01-2/:0:0","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"1.5 Decision Theory Decision Theory는 크게 두 가지의 과정으로 이루어져 있다. Determining $p(x,t)$ from a training data set : inference 이를 통하여 새로운 데이터에 대해 결정(분류,회귀) : decision Decision Theory의 목표는 적절한 Probability들을 이용하여 optimal한 decision을 내리는 것이다. 2-class classification의 상황을 예시로 뒤의 내용을 진행한다. 우리는 input data를 통해 해당 data의 class를 구분하고 싶기에 $p(C_k / \\textbf{x})$를 구해야 한다. Bayes' theorem을 생각해보면 posterior를 구해야 하는 것이다. $$p(C_k | \\textbf{x}) = \\frac{p(\\textbf{x} | C_k)p(C_k)}{p(\\textbf{x})}$$ 우리는 misclassfication을 최소화하기 위해서 둘 중 더 큰 posterior probability갖는 class에 input data를 분류한다. ","date":"2021-11-26","objectID":"/prml-chap01-2/:1:0","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"1.5.1 Minimizing the misclassfication rate 우리의 목표가 misclassfication을 최소화하는게 목표라고 하자. 각 $\\textbf{x}$를 class에 분류해야하고 이를 위해 rule이 필요하다. 그 rule에 따라 input space를 region $R_k$로 나눠야 한다. 이 region을 decision regions 라고 한다. ($R_k$에 속한 data는 class k라고 분류) decision region간의 경계선을 decision boundary, decision surface 라고 부른다. misclassfication의 확률은 $$P(mistake) = P(\\textbf{x} \\in R_1, C_2) + P(\\textbf{x} \\in R_2, C_1) = \\int_{R_1} p(\\textbf{x}, C_2)d\\textbf{x}+ \\int_{R_2} p(\\textbf{x}, C_1)d\\textbf{x}$$ mistake의 확률을 최소화하기 위해서는 각 integral의 값을 최소화해야 한다. 따라서 만약 $p(\\textbf{x}, C_1) \u003e p(\\textbf{x}, C_2)$의 경우, data를 class1으로 분류해야한다. $p(\\textbf{x}, C_k) = p(\\textbf{x}) p(C_k | \\textbf{x})$ 이고 우변의 $p(\\textbf{x})$는 공통된 부분이므로 우리는 $p(C_k | \\textbf{x})$만 고려하면 된다. ","date":"2021-11-26","objectID":"/prml-chap01-2/:1:1","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"1.5.2 Minimizing the expected loss 위에서 misclassfication rate를 줄이는 부분에 대해서 살펴봤다. 하지만 실제로 분류를 할 때는 이 접근으로는 부족하다. 예를 들어, 암환자를 분류하는 문제라고 생각해보자. 암이 걸리지 않은 환자를 걸렸다고 잘못 판단하는 것과 암이 걸렸는데 걸리지 않았다고 판단하는 것. 둘 중 후자가 훨씬 심각한 문제이다. 이런 경우 후자에 대해 더 가중치가 있어야 하지 않을까? loss function (cost function) : overall measure of loss incurred in taking any of the available decisions or actions $L_{kj}$ : (k인데 j로 분류한 경우) loss matrix의 element를 의미한다. misclassfication에 대한 loss라고 이해하면 된다. 예를 들면 암환자의 loss matrix는 아래와 같은 모양이다. $$\\begin{bmatrix} 0 \u0026 100 \\\\ 1 \u0026 0 \\end{bmatrix}$$ (inference가 끝난 뒤에 decision하는 과정에 해당) optimal solution은 loss function을 최소화하는 것이다. 하지만 loss function은 true class을 알아야 계산할 수 있다. 우리는 true class를 모른다. (예를 들어, 환자의 신상데이터가 있고 이를 통해 암환자인지 아닌지 찾아야하는 상황) 따라서 우리는 expected (average) loss를 최소화하는 방법을 선택한다. $$E[L] = \\sum_{k} \\sum_{j} \\int_{R_j} L_{kj} p(\\textbf{x}, C_k) d\\textbf{x}$$ 우리의 목표는 expected loss를 최소로 만드는 적절한 $R_j$를 찾는 것이고 이는 각 데이터 $\\textbf{x}$가 $\\sum_{k} L_{kj}p(\\textbf{x}, C_k)$를 최소화 한다는 것을 의미한다. 최종적으로 expected loss를 최소화 하기 위해서는 $\\textbf{x}$를 값 $$\\sum_{k}{L_{kj} p(C_k|\\textbf{x})}= E[L(C_k, \\hat{C}_k) | X=\\textbf{x}]$$ 이 최소가 되는 class $j$로 분류하는 것이다. ","date":"2021-11-26","objectID":"/prml-chap01-2/:1:2","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"1.5.3 The reject option class에 따라 posterior의 비교를 통해 결정하기 애매한 상황이 생긴다. 이런 경우에는 probability에 따라 결정하기 보다는 다른 방법을 사용하는 것이 적절할 수도 있다. (예를 들면, 해당 데이터를 model이 아니라 전문가가 판단하는 방법) 이런 경우 regect option 이 있다고 할 수 있는 것이다. ","date":"2021-11-26","objectID":"/prml-chap01-2/:1:3","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"1.5.4 Inference and decision decision 문제를 해결하는 방법을 3가지로 분류할 수 있다. 앞쪽의 방법일수록 복잡한 방법이다. generative model 아래 식에서 posterior를 구하기 위해서는 분자, 분모를 다 구해야 한다. 한마디로 approachs that explicitly or implicitly model the distribution of inputs as well as outputs. 다른 표현으로는, joint distribution $p(\\textbf{x}, C_k)$을 구해서 marginalize하여 분모도 구하여 posterior를 구한다. $$p(C_k | x) = \\frac{p(x | C_k)p(C_k)}{p(x)}$$ discriminative model approachs that model the posterior probabilities directly 예를 들면 SVM, Tree models, KNN 등등 discriminative function maps each input x directly onto a class label 따라서 확률을 고려하지 않는다. inference와 decision stage를 하나로 묶은 것이다. 각각 장단점이 존재한다. 예를 들면, 1번에서 prior $p(\\textbf{x})$를 구했으므로 해당 값이 너무 작은 새로운 data는 무시하는 판단을 할 수 있다. (outlier detection하는 것처럼) 그렇다면 이제 (1,2번 선호) posterior를 구하면 어떤 장점이 있는지 알아보자. Minimizing risk 이전에 봤던 loss matrix를 수정하여 decision criterion을 수정하기 쉽다. 확률의 threshold를 조정하여 decision criterion을 수정하기 쉽다. Reject option expected loss뿐만 아니라 misclassfication rate를 최소화하는 rejection criterion을 정할 수 있게 해준다. Compensating for class priors posterior는 prior에 비례하므로 prior를 적절하게 바꿔줌으로서 posterior를 보완할 수 있다. Combing models 특정 문제를 subproblem으로 나누어서 생각할 수 있다. 예를 들면, naive bayes model과 같이 independent를 이용하여 posterior를 나누어서 생각할 수 있는 장점이 생긴다. ","date":"2021-11-26","objectID":"/prml-chap01-2/:1:4","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"1.5.5 Loss functions for regression 이전까지 classification에 대해 살펴봤으므로 이번에는 regression에 대해 살펴보자. expected (average) loss는 $$E[L] = \\int \\int L(t, y(\\textbf{x})) p(\\textbf{x}, t) d\\textbf{x}dt$$ 이다. regression에서 주로 사용하는 loss function은 squared loss이고 이를 통해 다시 쓰면 $$E[L] = \\int \\int {y(\\textbf{x}) - t}^2 p(\\textbf{x}, t) d\\textbf{x} dt$$ 이다. 우리는 이를 최소화하는 $y(\\textbf{x})$를 찾는 것이 목표이므로 미분하여 구할 수 있다. $$\\frac{dE[L]}{dy(\\textbf{x})} = 2\\int { y(\\textbf{x}) - t}p(\\textbf{x}, t) dt = 0$$ $$y(\\textbf{x}) = \\frac{\\int t p(\\textbf{x}, t)dt}{p(\\textbf{x})} = \\int t p(t | \\textbf{x})dt = E_t [t | \\textbf{x}]$$ 이는 우리가 알고 있는 regression function의 모양이다. (conditional average of t conditioned on x) 이를 이용하여 추가적인 접근을 해보자면 $${y(\\textbf{x}) - t}^2 = {y(\\textbf{x}) - E[t | \\textbf{x}] + E[t | \\textbf{x}] - t }^2$$ $$E[L] = \\int {y(\\textbf{x}) - E[t | \\textbf{x}]}^2 p(\\textbf{x})d\\textbf{x} + \\int {E[t | \\textbf{x}] - t}^2 p (\\textbf{x}) d\\textbf{x} $$ 두번째 항은 variance of the distribution of t, averaged over x 이다. 따라서 이는 irreducible minumum value of the loss function을 의미한다. ","date":"2021-11-26","objectID":"/prml-chap01-2/:1:5","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"+ Decision Theory 추가 monk의 강의에서 decision theory를 다루는데 해당 내용을 추가하고자 한다. 일단, loss function은 “0-1 loss” 으로 생각하자. true = prediction : 0 true != prediction : 1 두 가지 상황으로 나누어서 살펴보자. 하지만 두 경우 모두의 공통적인 결론은 $p(y/x)$ 가 핵심이라는 것이다. ","date":"2021-11-26","objectID":"/prml-chap01-2/:2:0","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"1. Minimizing conditional expected loss : Given $x$, minimize $L(y, \\hat{y})$ … but don’t know true class $y$ $(X, Y) \\sim P$ : discrete $$E[L(Y, \\hat{y}) | X = x] = \\sum_{y} L(y, \\hat{y}) P(y | x) = \\sum_{y \\neq \\hat{y} } 1*P(y | x) = 1 - P(\\hat{y} | x)$$ $$\\therefore \\hat{y} = argmin_y E[L(Y,\\hat{y}) | x] = argmax_y P(y | x)$$ ","date":"2021-11-26","objectID":"/prml-chap01-2/:2:1","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"2. Choosing f to minimize expected loss : Choose $f(f(x) = y)$ to minimize $L(y, f(x))$ but don’t know $x$ or $y$ $$E[L(Y, \\hat{Y})] = E[L(Y, f(X))] = \\sum_{x,y}L(y, f(x))P(x,y)$$ $$ = \\sum_{x}{\\sum_y L(y, f(x))P(y | x)}P(x) = \\sum_{x}g(x,f(x))p(x) = E_x[g(x,f(x))]$$ suppose for some $x', t$ $g(x', f(x')) \\ge g(x', t)$ $f_0(x) =$ if $x \\neq x', f(x)$ if $x = x', t$ 모든 $x,; g(x,f(x)) \\ge g(x, f_0(x))$ $$\\therefore E_x [g(x, f(x))] \\ge E_x[g(x,f_0(x))]$$ Choose f to min $g(x,f(x))$ $$f(x) = argmin_t g(x,t)$$ ","date":"2021-11-26","objectID":"/prml-chap01-2/:2:2","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"Big picture ","date":"2021-11-26","objectID":"/prml-chap01-2/:2:3","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"Generative model estimate $p(x,y)$ using data and then $p(y|x) = \\frac{p(x,y)}{p(x)}$ parameter / latent : $\\theta$ 라고 하자 $\\theta$는 distribution에 관한 parameter / latent $D$는 random (new data) $$p(y|x,D) = \\int p(y|x,D,\\theta) p(\\theta | x,D) d\\theta$$ $p(y|x,D)$ : predictive distribution $p(\\theta |x,D)$ : posterior distribution $p(y|x,D,\\theta)$ 이 부분은 주로 closed form(eg. regression y=wx)으로 구해지며 어렵지 않다. 하지만 posterior 부분은 closed form으로 못 구하는 경우가 많다. 또한 integral 부분도 계산이 어려운 경우가 많다. 그렇다면 이를 어떻게 해결할까? 크게 4가지의 방법을 살펴보자. exact inference Multivariate Gaussian, Conjugate prior, Graphical model point estimate MLE, MAP (1.2.5를 보면 integral 없이 계산) optimization, EM deteministic approximation Laplace approximation, Variational method, Expectation propagation stochastic approximation Sampling 기법들 (eg. MCMC) ","date":"2021-11-26","objectID":"/prml-chap01-2/:2:4","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"Probability Theory에 대해 알아봅시다. ","date":"2021-11-26","objectID":"/prml-chap01-1/:0:0","tags":null,"title":"[PRML] Chapter1 - Introduction (1)","uri":"/prml-chap01-1/"},{"categories":["PRML"],"content":"1.1 Example : polynomial curve fitting 예를 들어, 회귀에서 error function이 quadratic function of w이면 w에 대한 미분은 w에 linear하고 unique한 closed form의 해를 구할 수 있다. 모델의 overfitting을 항상 조심하고 데이터의 수가 늘어날수록 그 정도는 약해진다. MLE 방법은 overfitting에 취약하며 Bayesian 모델링으로 보완할 수 있다. ridge와 같이 error function에 패널티항을 추가하여 overfitting을 막는 방법도 있다. 이를 shrinkage 방법이라 부른다. (딥러닝에서는 weight decay) 이런 모델의 복잡한 정도를 정하는 데에 validation data set을 만들기도 하는데 이는 다소 낭비이므로 다른 방법을 공부할 것이다. (아마 Bayesian approach일듯) ","date":"2021-11-26","objectID":"/prml-chap01-1/:1:0","tags":null,"title":"[PRML] Chapter1 - Introduction (1)","uri":"/prml-chap01-1/"},{"categories":["PRML"],"content":"1.2 Probability Theory 패턴인식에서 가장 중요한 컨셉은 uncertainty이다. Probability Theory는 이런 uncertainty을 quantification하고 manipulation하는 방법을 제시한다. (확률을 이용하여) The rules of Probability sum rule : $p(X) = \\sum_{Y}{p(X,Y)}$ product rule : $p(X,Y) = p(Y|X)p(X)$ Bayes' Throrem (rule) $p(Y|X) = \\frac{p(X|Y)p(Y)}{p(X)}$ $p(Y)$ : prior probability $p(Y|X)$ : posterior probability ","date":"2021-11-26","objectID":"/prml-chap01-1/:2:0","tags":null,"title":"[PRML] Chapter1 - Introduction (1)","uri":"/prml-chap01-1/"},{"categories":["PRML"],"content":"1.2.1 Probability densities probability density : if the probability of a real-valued variable $x $ falling in the interval $(x, x+\\delta x )$ is given by $p(x)\\delta x$ for $\\delta x \\rightarrow 0$, then $p(x)$ is called the probability density 값은 항상 0 이상, 합하면 1을 가진다. ","date":"2021-11-26","objectID":"/prml-chap01-1/:2:1","tags":null,"title":"[PRML] Chapter1 - Introduction (1)","uri":"/prml-chap01-1/"},{"categories":["PRML"],"content":"1.2.2 Expectations and covariances expection of $f(x)$ : $E[f(x)] = \\int{p(x)f(x)dx}$ it can be approximated as $$E[f] \\approx \\frac{1}{N}\\sum_{n=1}^{N}{f(x_n)}$$ $E_x [f(x,y)]$는 y에 대한 함수이다. x에 대해 averaged over 된 것이다. conditional expection : $E[f(x)|y] = \\int{p(x|y)f(x)dx}$ variance of $f(x)$ : $var[f] = E[(f(x) - E[f(x)])^2]$ $f(x)$가 mean 주위에서 얼마나 variability가 있는지 보여준다. ","date":"2021-11-26","objectID":"/prml-chap01-1/:2:2","tags":null,"title":"[PRML] Chapter1 - Introduction (1)","uri":"/prml-chap01-1/"},{"categories":["PRML"],"content":"1.2.3 Bayesian probabilities 우리가 일반적으로 알고 있는 확률(probability)은 frequentist의 견해이다. bayesian은 frequentist와는 아예 다른 접근법을 갖는다. Frequentist 분모가 되는 전체 사건이 무한대로 일어나고 우리가 궁금한 사건이 그 중 몇번 일어나는지를 확률로 생각한다. parameter 추정이 목표이며 parameter는 fixed 되어 있다고 생각한다. 주로 estimator로서 likelihood function을 최대화하는 MLE로 사용한다. Bayesian 확률 : uncertainty를 quantification한 것으로 생각한다. parameter는 fixed 된 것이 아니라 (probability) distribution을 갖는 것이라고 생각한다. posterior distribution을 찾는 것이 목표이다. Bayes' theorem $$p(\\textbf{w} | D) = \\frac{p(D | \\textbf{w})p(\\textbf{w})}{p(D)}$$ parameter에 대해 원래 갖고 있던 믿음을 data D에 대한 정보를 얻은 뒤에 posterior probability로 업데이트 한다. (분모는 posterior가 합이 1이 되기 위한 normalization constant) prior probability : $p(w)$ likelihood function : $p(D/w)$ posterior probability : $p(w/D)$ posterior $\\propto$ likelihood * prior ","date":"2021-11-26","objectID":"/prml-chap01-1/:2:3","tags":null,"title":"[PRML] Chapter1 - Introduction (1)","uri":"/prml-chap01-1/"},{"categories":["PRML"],"content":"1.2.4 The Gaussian distribution $$N(x | \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi \\sigma^2}}exp{ - \\frac{(x-\\mu)^2}{2 \\sigma^2} }$$ mean : $\\mu$ variance : $\\sigma^2$ standard deviation : $\\sigma$ precision : $\\beta = 1/ \\sigma^2$ normal (gaussian) 분포는 mode와 mean이 같다. i.i.d (independent and identically distributed : data point가 독립적이고 같은 분포에서 나왔다) 인 경우, likelihood function은 $$p(\\textbf{x} | \\mu, \\sigma^2) = \\prod_{n=1}^{N}{N(x_n | \\mu, \\sigma^2)}$$ 이고 이를 최대화하는 mean과 variance의 MLE는 sample mean, sample variance이다. MLE를 구하는 방법은 likelihood function에 log를 취한 후 미분하여 0을 만족하는 parameter를 찾으면 된다. 이때 단점은 maximum likelihood 접근법이 분포의 variance를 underestimate한다(bias 발생)는 점이다. N이 커지면 문제가 없지만 복잡한 모델에서는 이런 bias때문에 문제가 발생할 수 있다. (나중에 공부한다) ","date":"2021-11-26","objectID":"/prml-chap01-1/:2:4","tags":null,"title":"[PRML] Chapter1 - Introduction (1)","uri":"/prml-chap01-1/"},{"categories":["PRML"],"content":"1.2.5 Curve fitting re-visted data를 통해 polynomial curve를 fitting해보자. target t에 대한 uncertainty를 probability를 통해 표현하면 (under gaussian noise distribution) $$p(t | x, \\textbf{w}, \\beta) = N(t | y(x,\\textbf{w}), \\beta^{-1})$$ 위의 식을 이용하여 우리는 parameter $\\textbf{w}$ 추정한다. likelihood를 최대로 하는 MLE를 찾으면 되는 것이다. log likelihood function은 아래와 같은 모양을 갖는다. $$\\ln p(\\textbf{t} | \\textbf{x}, \\textbf{w}, \\beta) = - \\frac{\\beta}{2}\\sum_{n=1}^{N}{{ y(x_n, \\textbf{w}) - t_n }^2} + \\frac{N}{2}\\ln \\beta - \\frac{N}{2}\\ln (2 \\pi)$$ 위 값을 최대화 하는 $\\textbf{w}_{ML}$을 찾으면 된다. 이는 결국 least square 방법과 동일한 의미를 갖는다. (추정선과 target의 차이를 최소화해야되므로) parameter를 추정한 뒤에 이제 prediction을 해야한다. 우리는 확률모델을 갖고 있기에 t에 대한 point estimate만이 아니라 predictive distribution을 만들 수 있다. $$p(t | x, \\textbf{w} _ {ML}, \\beta _ {ML}) = N(y(x,\\textbf{w} _ {ML}), \\beta _ {ML}^{-1})$$ 지금까지는 frequentist의 영역이였다면 Bayesian들은 어떤 접근을 하는지 살펴보자. 일단 우리가 추정해야하는 parameter에 대한 prior를 갖고 있다. prior distribution를 gaussian 분포로 가정하면 아래와 같이 나타낼 수 있다. (Mth order의 polynomial) $$p(\\textbf{w} | \\alpha) = N(\\textbf{0}, \\alpha^{-1}\\textbf{I}) = (\\frac{\\alpha}{2\\pi})^{(M+1)/2} \\exp { -\\frac{\\alpha}{2} \\textbf{w}^T \\textbf{w}}$$ 이를 통해 우리는 posterior distribution를 구할 수 있다. posterior는 likelihood와 prior의 곱에 비례하므로 $$p(\\textbf{w} | \\textbf{x}, \\textbf{t}, \\alpha, \\beta) \\propto p(\\textbf{t} | \\textbf{x}, \\textbf{w}, \\beta)p(\\textbf{w} | \\alpha)$$ 위의 posterior distribution을 최대화로 만드는 parameter를 MAP (MLE에 대응되는 point estimate)라고 부른다. posterior distribution에 negative log를 취한다. posterior를 최대로 만드는 것은 아래를 최소화 하는 것과 같다. $$\\frac{\\beta}{2}\\sum_{n=1}^{N}{{ y(x_n, \\textbf{w}) - t_n }^2} + \\frac{\\alpha}{2}\\textbf{w}^T\\textbf{w}$$ 위 결과를 통해 posterior distribution를 maximizing하는 것은 regularized sum-of-squares error function을 minimizing하는 것과 동일하다는 것을 알 수 있다.. (L2 regularization, Ridge regression) ","date":"2021-11-26","objectID":"/prml-chap01-1/:2:5","tags":null,"title":"[PRML] Chapter1 - Introduction (1)","uri":"/prml-chap01-1/"},{"categories":["PRML"],"content":"1.2.6 Bayesian curve fitting 위의 Bayesian 접근법은 point estimate를 구했기 때문에 살짝 아쉽다. 좀 더 Bayesian적인 방법은 $\\textbf{w}$의 모든 값에 대해 integral over하는 것이다. $\\textbf{w}$에 대해 marginalize하면 되는데 이는 뒤에 자주 나오는 방법이므로 잘 기억하자. 이제 predictive distribution을 구해보자. training data : $\\textbf{x},\\textbf{t}$ new data : $x$ hyperparameter (assume we know) : $\\alpha, \\beta$ (아래식에서는 생략) $$p(t | x, \\textbf{x}, \\textbf{t}) = \\int p(t | x, \\textbf{w})p(\\textbf{w} | \\textbf{x}, \\textbf{t}) d\\textbf{w} = N(t| \\mu(x), s^2(x))$$ $$\\mu (x) = \\beta \\phi (x)^T \\textbf{S} \\sum_{n=1}^{N}{\\phi (x_n)} t_n $$ $$s^2 (x) = \\beta^{-1} + \\phi (x)^T \\textbf{S} \\phi (x)$$ $$\\textbf{S}^{-1} = \\alpha \\textbf{I} + \\beta \\sum_{n=1}^{N}{\\phi (x_n) \\phi (x)^T}$$ vector $\\phi (x)$ : element $\\phi_i (x) = x^i$ for $i = 0, … M$ ","date":"2021-11-26","objectID":"/prml-chap01-1/:2:6","tags":null,"title":"[PRML] Chapter1 - Introduction (1)","uri":"/prml-chap01-1/"},{"categories":["PRML"],"content":"1.3 Model Selection 여러 가지 모델을 선택할 때, train score로 model을 선택하는 것은 적절하지 않다. 그래서 validation set을 이용한다. 하지만 validation set에 overfitting하는 경우도 있기에 test set으로 최종 점검까지 하는 것이다. data가 제한적인 경우 cross validation의 방법을 사용한다. 하지만 이는 상당히 computationally expensive하다. ","date":"2021-11-26","objectID":"/prml-chap01-1/:3:0","tags":null,"title":"[PRML] Chapter1 - Introduction (1)","uri":"/prml-chap01-1/"},{"categories":["PRML"],"content":"1.4 The Curse of Dimensionalty 차원의 저주를 보여주는 몇가지 예시들 nearest neighborhood 알고리즘에 해당하는 부분 : sample space를 cubic형태로 나눈다고 생각했을 때, 차원이 커짐에 따라 지수적으로 cubic의 갯수가 많아진다. 따라서 cubic에 data가 텅 비지 않으려면 많은 양의 데이터가 필요하다. polynomial 의 경우 : Mth order의 polynomial 모델을 사용한다고 하면 $D^M$ 으로 parameter의 수가 증가한다. data를 sphere하게 생각해보자. 차원이 높아질수록 sphere의 표면쪽에 data가 몰려있다. 즉, 중심쪽이 sparse해지는 것이다. ","date":"2021-11-26","objectID":"/prml-chap01-1/:4:0","tags":null,"title":"[PRML] Chapter1 - Introduction (1)","uri":"/prml-chap01-1/"}]