[{"categories":["PRML"],"content":"Bayesian Optimization으로 모델의 성능을 올려보자. ","date":"2021-11-29","objectID":"/prml-chap06-3/:0:0","tags":["Bayesian Optimization"],"title":"[PRML] Bayesian Optimization","uri":"/prml-chap06-3/"},{"categories":["PRML"],"content":"Bayesian Optimization with Gaussian Process 어떤 sequence of experiments를 한다고 생각해보자. 다음은 몇 가지 가정사항이다. Interested in finding a global maximizer(minimizer) of $f(\\bf{x})$ 우리는 experiments result를 만드는 underlying function $f(\\bf{x})$를 모른다. input은 우리가 다 알고 조절할 수 있다. result have a stochastic element $y_t \\sim N(f,\\sigma^2_{noise})$ results and input are continuous 일반적인 경우는 continous를 고려하지만 discrete, hybrid의 경우도 존재한다. 다양한 task에서 사용할 수 있지만 우리는 주로 hyperparameter tuning을 할 때 사용하게 된다. Grid search no learning of underlying function Binary search learning of constraints, not the function 위와 같은 방법들이 많이 사용되었다. 이와 다르게 BOP는 learning underlying function with surrogate model selecting the next sampling input 같은 task를 통해서 최적의 결과를 얻어내고자 하는 것이다. 그렇다면 어떤 과정으로 최적의 결과를 얻어낼까? GPR은 모든 data point에서 predicted mean, predicted std를 알려준다. input을 넣고 underlying function을 만든다 (GPR을 fitting하는 것). 그 후에 mean과 variance를 통해 exploitation or exploration를 결정하여 next sampling input을 결정한다. (그리고 다시 underlying function을 만든다. 이를 반복한다.) Exploitation : result값이 높은 곳(underlying function mean이 큰) 탐색 Exploration : 관측지가 적은 곳(variance가 큰) 탐색 이떄, 이에 대한 판단 기준이 필요하다. acquisition function을 이용한다. 이에 대해 한번 더 정리하자면 Surrogate model : Compute $p(f|D_{1})$, yielding $\\mu_{1}({\\bf x})$ and $\\sigma_{1}({\\bf x})$. Acquisition function: Choose ${\\bf{x}} _ {2}$ such that ${\\bf x} _ {2}=argmax_{ {\\bf x} \\in \\mathcal{X} } a ({\\bf x}|\\mathcal{M}_{1})$ Augment data, $D_2 = D_1 \\cup \\{ ({\\bf x}_{2}, y _ {2}) \\}$ Surrogate model : Compute $p(f|D_2)$, yielding $\\mu_{2}({\\bf x})$ and $\\sigma_{2}({\\bf x})$. Acquisition function: Choose ${\\bf x} _ 3$ such that ${\\bf x} _ {3}=argmax_{ {\\bf x} \\in \\mathcal{X} }a({\\bf x}|\\mathcal{M}_{3})$ Augment data, $D_ 3 = D_2 \\cup \\{ ({\\bf x} _ {3},y _ {3}) \\}$ Repeat theses till the final round T, to compute $\\mu_{T}({\\bf x})$ ${\\bf x}^{*} = argmax_{ {\\bf x} \\in {\\bf x}_1,…,{\\bf x} _ T } \\mu _ {T}({\\bf x})$ ","date":"2021-11-29","objectID":"/prml-chap06-3/:1:0","tags":["Bayesian Optimization"],"title":"[PRML] Bayesian Optimization","uri":"/prml-chap06-3/"},{"categories":["PRML"],"content":"surrogate model 다양한 모델을 사용할 수 있다. 하지만 해당 point의 mean, variance를 알 수 있는 stochastic한 모델이여야 할 것이다. Random Forest Empirical하게 mena, variance를 구할 수 있다. scable, faster continuous, discrete 변수 모두 handle 가능하다. (GP는 kernel을 따로 design해야 한다고 함) extrapolation을 잘 못한다. GP regression Nonparameteric Bayesian Regression Not scalable 10dim이 넘어가면 standard GP로는 힘들다. sample dsata의 수가 많아져도 힘들다. ","date":"2021-11-29","objectID":"/prml-chap06-3/:1:1","tags":["Bayesian Optimization"],"title":"[PRML] Bayesian Optimization","uri":"/prml-chap06-3/"},{"categories":["PRML"],"content":"Acquisition Function Acquisition Function은 다양하다. 몇 가지만 간단히 알아보고 코드를 통해 실습을 진행해보자. Maximum Probability of Improvement (PI) 현재 optimized value $y_{max}$를 어떤 margin m 이상으로 올려줄 확률이 가장 높은 input을 sampling한다. grid search처럼 value를 계산하는 것이 아니라 확률만 계산하여 진행한다. $D$는 기존 data, 이를 통해 GPR을 만들수 있겠다. $y \\sim N(\\mu, \\sigma^2)$ 이는 GPR로 만들어진 것이다. $$MPI(x|D) = \\argmax_x P(y \\ge (1+m)y_{max} | x, D)$$ $$y\\sim N(\\mu, \\sigma^2) = \\argmax_x P(\\frac{y-\\mu}{\\sigma} \\ge \\frac{(1+m)y_{max}-\\mu}{\\sigma})$$ $$= \\argmax_x \\Phi (\\frac{\\mu - (1+m)y_{max}}{\\sigma})$$ 그런데 PI는 잘 안쓴다고 한다. Maximum Expected Improvement (EI) MPI를 조금 더 디벨롭시킨 것이다. MPI에서는 m을 고려해야했다. 그렇게 하지 말고 0부터 infinite으로 고려하면 되지 않을까? 라는 접근을 한다. 구체적으로 식을 구하는 과정은 생략한다. expected improvement w.r.t. the best observed objective value $y_{b}$ so far is defined as $$EI = E _ y [ \\max (y - y_{b} ,0) ]$$ $$=\\int \\max (y-y_{b}) N (y | \\bar{y}, \\sigma^{2})dy$$ $$=(\\bar{y} - y_b) \\Phi ( \\frac{\\bar{y}-y_b}{\\sigma} ) + \\sigma \\phi ( \\frac{\\bar{y} - y_b}{\\sigma} )$$ Gaussian Process-Upper Confidence Bound (GP-UCB) posterior mean과 variance의 적절한 trade-off를 고려하여 data point를 선택한다. 아래의 수식에 따라서 point를 선택한다. $\\beta_t$ : appropriate constants $\\nu$ : hyperparameter involving the degree of exploration $$\\bf{x} _ t = \\argmax_{\\bf{x}} ( \\mu_{t-1}(\\bf{x}) + \\sqrt{\\nu \\beta_t} \\sigma_{t-1}(\\bf{x}))$$ Thompson Sampling posterior에서 function을 sampling하는 방법이다. ","date":"2021-11-29","objectID":"/prml-chap06-3/:1:2","tags":["Bayesian Optimization"],"title":"[PRML] Bayesian Optimization","uri":"/prml-chap06-3/"},{"categories":["PRML"],"content":"이해를 위한 코드 # NHN cloud # https://www.youtube.com/watch?v=PTxqPfG_lXY import numpy as np from scipy.stats import norm from sklearn.gaussian_process import GaussianProcessRegressor from sklearn.gaussian_process.kernels import RBF # Acquisition function def expected_improvement(mean, std, max): z = (mean - max) / std return (mean - max) * norm.cdf(z) + std * norm.pdf(z) # Objective function def f(x): return x * np.sin(x) # hyperparameter space min_x, max_x = -2, 10 # Observation data X = np.random.uniform(min_x, max_x, 3).reshape(-1, 1) y = f(X).ravel() # GP model gp_model = GaussianProcessRegressor(kernel=RBF(1.0)) for i in np.arange(10): # surrogate model fit gp_model.fit(X, y) # predict -\u003e mean, std 계산 xs = np.random.uniform(min_x, max_x, 10000) mean, std = gp_model.predict(xs.reshape(-1, 1), return_std=True) # acq 계산 acq = expected_improvement(mean, std, y.max()) # acq가 가장 큰 값 선택 x_new = xs[acq.argmax()] y_new = f(x_new) # 데이터에 추가 X = np.append(X, np.array([x_new])).reshape(-1, 1) y = np.append(y, np.array([y_new])) ","date":"2021-11-29","objectID":"/prml-chap06-3/:1:3","tags":["Bayesian Optimization"],"title":"[PRML] Bayesian Optimization","uri":"/prml-chap06-3/"},{"categories":["PRML"],"content":"Reference 문일철 교수님 강의 NHN cloud 발표 paper Taking the Human Out of the Loop: A Review of Bayesian Optimization (2016) A tutorial on Bayesian optimization (2018) ","date":"2021-11-29","objectID":"/prml-chap06-3/:2:0","tags":["Bayesian Optimization"],"title":"[PRML] Bayesian Optimization","uri":"/prml-chap06-3/"},{"categories":["PRML"],"content":"Gaussian Process에 대해 정리하였다. ","date":"2021-11-29","objectID":"/prml-chap06-2/:0:0","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"6.4 Gaussian Processes 이 부분은 카이스트 문일철 교수님의 유투브영상을 보고 정리하였습니다. ","date":"2021-11-29","objectID":"/prml-chap06-2/:1:0","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Continuous Domain Data GP는 continuous domain data 분석에 유용하다. Time, Space, Spatio-Temporal… 어떻게 분석, 모델링? Estimating on the underlying function (ex. Autoregression) Prediction on the unexpected point (ex. extrapolation with autoregression) ","date":"2021-11-29","objectID":"/prml-chap06-2/:1:1","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Underlying Function and Observations $Y = sinc(x)$ 라는 함수를 underlying function이라고 하자. 여기서 gaussian noise를 추가하여 observation들을 생성했다. 지금 그림은 없지만 그림1은 x에 따라 분산이 동일하고 그림2는 x에 따라 분산이 변화(x가 클수록 분산이 커짐)한다. underlying function을 구해야하므로 mean function을 찾는 것은 당연하고 추가로 variance(or precision) function도 중요하다. $$\\mu(t), \\sigma(t)^2$$ ","date":"2021-11-29","objectID":"/prml-chap06-2/:1:2","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Simple Analyses without Domain Correlation mean function을 domain correlation없이 estimate한다고 하자. 즉, 특정 1개의 point에서 mean과 variance를 계산하는 것이다. 그런데 continuous domain에서 사실 같은 $x(t)$에 대해 multiple obsevation이 나올 수 없다. 약간의 discretize라고 할 수 있다. 해당 domain point에서 observation이 많으면 어느 정도 smooth하게 mean function을 구할 수 있다. 하지만 반대의 경우 좋은 estimation이 어렵다. 그래서 우리는 주위의 다른 domain data point도 사용하는게 좋지 않을까 라는 생각을 할 수 있다. ","date":"2021-11-29","objectID":"/prml-chap06-2/:1:3","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Simple Analyses with Domain Correlation Moving average time window(특정 구간)를 설정하고 평균 급격하게 변화하는 구간은 잘 안 맞을 수도 있다. time window에 따라 변화 window가 커질수록 smooth해진다. $$MA(x) = \\frac{1}{N} \\sum_{x \\in W} y_i$$ 그런데 모든 data point에 동일한 가중치를 주는게 다르게 주면 어떨까? 예를 들면, Squared Exponential $L$이 커지면 window가 커지는 역할 위에서 window 크기처럼 $L$을 적절히 선택해야한다. $$k(x,x_i;L) = exp(-\\frac{|x-x_i|^2}{L^2})$$ 위처럼 domain correlation을 다르게 생각하고 거리에 따라 가중치를 다르게 주는 것이다. 가까울수록 큰 가중치! $$MA(x) = \\frac{1}{\\sum_{x_i \\in D} k(x,x_i)}\\sum_{x_i \\in D} k(x,x_i) y_i$$ ","date":"2021-11-29","objectID":"/prml-chap06-2/:1:4","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Random Process Random process(=Stochastic process) An infinite indexed collection of random variables ${ X(w,t) , t \\in T }$ index paramter : $t$ (time, space…) A function $X(t,\\omega), t \\in T ;\\text{and}; \\omega \\in \\Omega$ outcome : $\\omega$ Fixed $t \\rightarrow X(t,\\omega)$ is a random variable over $\\Omega$ Fixed $\\omega \\rightarrow X(t,\\omega)$ is a deterministic function of $t$ ; sample function ","date":"2021-11-29","objectID":"/prml-chap06-2/:2:0","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Gaussian Process GP는 Random Process의 한 종류 For any set S, a GP on S is a set of random variable ($z_t : t \\in S$) such that vector $[z_{t_1}, z_{t_2},…,z_{t_n}]$ is multivariate gaussian $$P(T) = N(0, (\\beta I_N)^{-1} + K) \\ K_{nm} = k(x_n, x_m) = \\theta_0 \\exp(-\\frac{\\theta_1}{2}||x_n - x_m||^2) + \\theta_2 + \\theta_3 x_n^T x_m$$ ","date":"2021-11-29","objectID":"/prml-chap06-2/:3:0","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Derivation of Gaussian Process 일단 linear regression으로 접근하고 GP에 대해 알아본다. gaussian process regression : a nonparametric bayesian regression method using the properties of Gaussian processes ","date":"2021-11-29","objectID":"/prml-chap06-2/:4:0","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Mapping Functions non-linearly separable data set이 있다고 가정하자. 이를 위해 basis space를 증가시키면 될 것이다. mapping function $\\phi$를 통해 확장시킨다. ","date":"2021-11-29","objectID":"/prml-chap06-2/:4:1","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Linear regression with basis function $$y(x) = w^T \\phi (x)$$ 여기서 $w$를 deterministic value가 아니라 probabilistically distributed value라고 생각하자. (Bayesian linear regression의 방법론) $$P(w) = N(0, \\alpha^{-1} I)$$ Y의 확률분포(joint distribution)에 대해 생각해보자. ($w$가 확률분포가 있으니까) $Y$도 normal 이겠구나 (multivariate gaussian) $$Y = (y_1, y_2,…,y_n)$$ $K$ : Gram matrix $$E[Y] = E[\\Phi w] = \\Phi E[w] = 0$$ $$cov(Y) = E[YY^T] = E[\\Phi w w^T \\Phi^T]$$ $$= \\Phi E[ww^T]\\Phi^T = \\frac{1}{\\alpha} \\Phi \\Phi^T$$ $$K_{nm} = k(x_n,x_m) = \\frac{1}{\\alpha} \\phi (x_n)^T \\phi (x_m)$$ $$\\therefore P(Y) = N(0,K)$$ 분산이 kernel function을 이용한다는 점을 기억하자 이제 $Y$에 대한 분포를 파악했으니 이를 통해 prediction을 해보자. ","date":"2021-11-29","objectID":"/prml-chap06-2/:4:2","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Modeling Noise with Gaussian distribution $t_n$ : observed value with noise $y_n$ : Latent, error-free value $e_n$ : Error term distributed by following the gaussian distribution $$t_n = y_n + e_n \\ (t_n = f(x_n)+e_n)$$ $$P(T|Y) = N(Y, \\beta^{-1} I)$$ $\\beta$ : hyperparameter of the error precision error term들이 independent라고 가정하기에 variance 부분에 $I$이 된다. $$P(T) = \\int P(T|Y)P(Y) dY = \\int N(Y,\\beta^{-1} I) N(0,K) dY$$ 위의 곱해지는 두 분포 모두 multivariate gaussian distribution 이므로 이를 이용하여 구할 것이다. $$P(T|Y)P(Y) = P(T,Y) = P(Z)$$ $$\\ln P(Z) = \\ln P(T|Y) + \\ln P(Y) \\ = - \\frac{1}{2} Y^TK^{-1}Y - \\frac{1}{2}(T-Y)^T \\beta I (T-Y) + const$$ 여기서 변수는 $T,Y$이다. 여기서 second order term을 보면 (second order term을 찾으면 covariance를 찾을 수 있기에) $$ = \\frac{1}{2} \\begin{pmatrix} Y \\\\ T \\end{pmatrix}^T \\begin{pmatrix} K^{-1} + \\beta I \u0026 -\\beta I \\\\ - \\beta I \u0026 \\beta I \\end{pmatrix} \\begin{pmatrix} Y \\\\ T \\end{pmatrix} = \\frac{1}{2}Z^T R Z$$ $R$은 precision matrix가 된다. 이를 inverse 하면 (공식이용) $$R^{-1} = \\begin{pmatrix} K \u0026 K \\\\ K \u0026 (\\beta I)^{-1} + K \\end{pmatrix}$$ $\\ln (Z)$의 first order term은 없다. mean이 0라는 것을 알 수 있다. 따라서 최종 결과는 $$P(Z) = N(0, R^{-1})$$ 이제 PRML chapter 2에서 봤었던 공식을 이용하면 marginal distribution을 구할 수 있다. $$P(T) = N(0, (\\beta I)^{-1} + K)$$ 이제 우리가 관찰한 N개의 data를 통해 $P(T)$를 알게 되었다. 그렇다면 이제 prediction해보자. $t_{N+1}$을 알아내야 한다. $$P(t_{N+1}|T_N)$$ 이를 구하기 위해 N+1의 joint를 구하고 conditional disribution을 만들면 된다. ","date":"2021-11-29","objectID":"/prml-chap06-2/:4:3","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Sampling of $P(T)$ Sampling T of 101 dimension when points $x_n = [-1,-0.98,…,1]$ : 101개의 data point mean $0$ : 101 dim zero vector cov $(\\beta I_N)^{-1} + K$ : 101 * 101 dim cov $$P(T) = N(0, (\\beta I_N)^{-1} + K)$$ kernel의 parameter와 $\\beta$값에 따라서 sampling data들이 이루는 모습이 달라진다. ","date":"2021-11-29","objectID":"/prml-chap06-2/:4:4","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Mean and Covariance of $P(t_{N+1} | T_N)$ $$P(t_{N+1}|T_N) = P(T_{N+1}) / P(T_N)$$ $$P(T_{N+1}) = N(0, cov_{N+1})$$ mean은 1차원이 늘어난 zero vector이고 cov는 행과 열이 하나씩 들어간 형태일 것이다. 이는 kernel function과 $\\beta$를 통해 어렵지 않게 구할 수 있다. $$cov_{N+1} = \\begin{pmatrix} cov_N \u0026 k \\\\ k^T \u0026 K_{(N+1)(N+1)}+\\beta^{-1} \\end{pmatrix}$$ 이제 joint distribution을 구했으니 conditional distribution을 구할 수 있다. (공식 PRML chap2에 나온다) $$P(t_{N+1}|T_N) = N(0+k^T cov_N^{-1}(T_N-0),K_{(N+1)(N+1)}+\\beta^{-1} -k^Tcov_N^{-1} k )$$ 이는 결국 regression을 한 것이다. predictive distribution을 구한 것이다. 평균과 분산 모두 new data $x_{N+1}$에 depend하다. 분산에서 inverse가 computationally 오래걸려서 approximation하는 방법들이 있다고 한다. $$\\mu_{t_{N+1}} = k^T cov_N^{-1} T_N \\ \\sigma^2_{t_{N+1}} = K_{(N+1)(N+1)}+\\beta^{-1} -k^Tcov_N^{-1} k$$ 우리가 알고 있는 일반적인 regression과는 조금 다른 형태이다. 각 feature들의 weight들이 어디있는지 궁금할 수 있는데 kernel function안의 parameter로 들어갔다. ","date":"2021-11-29","objectID":"/prml-chap06-2/:4:5","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Hyperparameter of Gaussian Process Regression 위에서 linear regression에서 parameter optimization을 하는 방법을 알아보자. 아래의 kernel hyperparameter를 추정해야 하는 것이다. $$ K_{nm} = k(x_n, x_m) = \\theta_0 \\exp(-\\frac{\\theta_1}{2}||x_n - x_m||^2) + \\theta_2 + \\theta_3 x_n^T x_m$$ $$P(T;\\theta) = N(0, (\\beta I_N)^{-1} + K)$$ $\\theta$를 추정하기 위해 likelihood를 최대한 높이는 방법을 택한다. $\\theta$에 대해 미분하여 구하면 된다. $$\\frac{\\partial}{\\partial \\theta_i} \\log P(T;\\theta) \\overset{let}{=}0$$ 그런데 closed form은 존재하지 않는다. 그래서 approximation해야 한다. (너무 복잡해서 derivation 생략) 우리는 pytorch와 같은 framework의 도움을 받아서 구한다. ","date":"2021-11-29","objectID":"/prml-chap06-2/:4:6","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Gaussian Process Classifier 아래와 같이 일반적인 logistic regression과 거의 동일하다. Gaussian process classifier : sigmoid function + Gaussian process Gaussian process : $f(x;\\theta)$ Gaussian process classifier : $y=\\sigma (f(x;\\theta))$ if $t \\in {0,1}$, objective function to optimize : $$P(t | \\theta) = \\sigma (f(x;\\theta))^t (1-\\sigma (f(x;\\theta)))^{1-t}$$ ","date":"2021-11-29","objectID":"/prml-chap06-2/:5:0","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"PRML에서 Naive bayes 와 Logistic regression에 대해 공부하였는데 이 둘의 관계에 대해 간단히 정리해보고자 한다. (문일철 교수님의 강의에 대해 정리하였습니다.) 몇 가지 가정(constraint)가 더해지면 Naive bayes와 Logistic regression이 같아진다. ","date":"2021-11-26","objectID":"/prml-chap04-3/:0:0","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (3)","uri":"/prml-chap04-3/"},{"categories":["PRML"],"content":"Gaussian Naive Bayes Naive Bayes에 대해서는 이전에 공부하였다. 이번에는 거기에 조금 더 추가하여 각 conditional distribution들이 Gaussian distribution이라고 가정해보자. $$f_{NB} = \\arg\\max_{Y=y}P(Y=y)\\prod_{i=1}^{D}P(X_i=x_i|Y=y)$$ $$P(Y=k) = \\pi_k$$ $$P(X_i=x_i|Y=y) = \\frac{1}{c \\sigma_k^i } \\exp(- \\frac{1}{2}(\\frac{x_i - \\mu_k^i}{\\sigma_k^i})^2)$$ 이제 Naive bayes classifier이 Logistic regression의 형태가 되는 과정을 살펴볼 것이다. Logistic regression : $P(Y=k | X)$ Naive Bayes : $\\frac{P(X|Y=k)P(Y=k)}{P(X)}$ generative 방법의 Naive bayes로 부터 Discriminative한 Logistic regression으로 가보자 $$ = \\frac{p(Y=k)\\prod_{i=1}^D P(X_i|Y=y)}{p(Y=k)\\prod_{i=1}^D P(X_i|Y=k) + p(Y=k^C)\\prod_{i=1}^D P(X_i|Y=k^C)}$$ $$= 1/[1 + \\frac{\\pi_2 \\prod \\frac{1}{c \\sigma_{not;k}^i } \\exp(- \\frac{1}{2}(\\frac{x_i - \\mu_{\\text{not};k}^i}{\\sigma_{\\text{not};k}^i})^2) }{\\pi_1 \\prod \\frac{1}{c \\sigma_{k}^i } \\exp(- \\frac{1}{2}(\\frac{x_i - \\mu_{k}^i}{\\sigma_{k}^i})^2) }]$$ 여기서 $\\sigma_{not ; k} = \\sigma_{k}= \\sigma$라고 가정하면 $$=1/[1+\\frac{\\pi_2 \\prod \\exp(- \\frac{1}{2}(\\frac{x_i - \\mu_{not;k}^i}{\\sigma^i})^2) }{\\pi_1 \\prod \\exp(- \\frac{1}{2}(\\frac{x_i - \\mu_{k}^i}{\\sigma^i})^2) }] $$ $$ = 1/[1+exp(-\\frac{1}{2 {\\sigma^i}^2} \\sum { 2(\\mu_{not;k}^i-\\mu_k^i)x_i + {\\mu_{not; k}^i}^2 - {\\mu_k^i}^2 + \\log\\pi_2 - \\log\\pi_1 }] $$ 최종식을 보면 sigmoid function에 $w^T x$가 들어가있는 형태이다. 즉, Logistic regression이 되는 것이다. Naive Bayes의 conditional independent 가정 conditional한 상황에서 각 feature들이 Gaussian이고 분산이 같다는 가정 ","date":"2021-11-26","objectID":"/prml-chap04-3/:1:0","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (3)","uri":"/prml-chap04-3/"},{"categories":["PRML"],"content":"Classification에 대해 알아보자. ","date":"2021-11-26","objectID":"/prml-chap04-2/:0:0","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (2)","uri":"/prml-chap04-2/"},{"categories":["PRML"],"content":"4.3 Probabilistic Discriminative Models 이전과 다르게 parameter 추정을 $p(C_k|x)$에서 Maximum likelihood 를 이용하여 directly 하고자 한다. 이전에 본 generative한 방법에 비해 parameter가 더 적다 class-conditional density 가정이 잘못되면 성능이 좋지 않을 수 있다 ","date":"2021-11-26","objectID":"/prml-chap04-2/:1:0","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (2)","uri":"/prml-chap04-2/"},{"categories":["PRML"],"content":"4.3.1 Fixed basis functions 이제부터는 basis function $\\phi ({\\bf x})$을 사용할 것이다. basis function이 비선형이라 decision boudary는 original space에 linear하지 않을 것이다. basis function에는 $\\phi ({\\bf x})=1$ bias를 기본적으로 넣는다. original이 아닌 basis function을 사용했다고 항상 결과가 좋은 것은 아니다. ","date":"2021-11-26","objectID":"/prml-chap04-2/:1:1","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (2)","uri":"/prml-chap04-2/"},{"categories":["PRML"],"content":"4.3.2 Logistic regression 2-class의 경우로 시작해보자. 이전에 공부했듯이 일반적인 가정하에서 posterior는 sigmoid에 linear function of $\\phi$ (feature vector) 가 들어간 형태이다. $$p(C_1 | \\phi) = y(\\phi) = \\sigma ({\\bf w}^T \\phi)$$ logistic regression 의 장점 (2 class) M 차원이라고 가정하면 M개의 parameter가 있을 것이다. 반면에 generative한 상황을 생각하면 Gaussian class conditional density 의 경우 2M개의 평균, M(M+1) / 2개의 covariance matrix, prior 까지 총 M(M+5)/2+1 개의 parameter가 필요하다. interpretable하다. parameter estimation에 있어 computationally efficient 하다. multiclass도 가능하다. 단점 prediction performance가 좋은 편은 아니다. basis가 fixed되어 있다. likelihood로 parameter를 추정하는 과정을 살펴보자. Given : $D = [({\\bf x}_1,y_1),({\\bf x}_2,y_2),..,({\\bf x}_n,y_n)]$ model : $t_i \\sim^{iid} \\text{Bern}[\\sigma({\\bf w}^T \\phi({\\bf x}_i))]$ $$y_n = p(C_1 | \\phi_n)=\\sigma({\\bf w}^T \\phi({\\bf x}_n))$$ $$p(\\textbf{t}|{\\bf w}) = \\prod_{n=1}^{N}{y_n^{t_n}(1-y_n)^{1-t_n}}$$ $\\textbf{t} = (t_1,…t_N)^T$ : true target cross-entropy error function : $$E({\\bf w}) = - \\ln p(\\textbf{t} | {\\bf w}) = - \\sum{ { t_n \\log y_n + (1-t_n)\\log(1-y_n) } }$$ ${\\bf w}$에 대해 미분하면 $$\\bigtriangledown E({\\bf w}) = \\sum_{n=1}^{N}{(y_n - t_n)\\phi_n}$$ 이를 구하는 방법은 chain rule을 사용한다. 아래의 값들을 곱하면 위의 식이 나온다. $$\\frac{\\partial E}{\\partial y_n} = \\frac{1-t_n}{1-y_n} - \\frac{t_n}{y_n} = \\frac{y_n-t_n}{y_n(1-y_n)}$$ $$\\frac{\\partial y_n}{\\partial a_n} = \\frac{\\partial \\sigma(a_n)}{\\partial a_n} = \\sigma(a_n)(1-\\sigma(a_n)) = y_n(1-y_n)$$ $$ \\frac{\\partial a_n}{\\partial {\\bf w}} = \\phi_n$$ 이전에 linear regression과는 다르게 MLE가 closed form으로 존재하지 않는다. 따라서 approximation하는 방법이 필요하다. 이를 Gradient descent 방법을 통해 답을 구할 수도 있다. 하지만 뒤에서는 약간 다른 방법으로 해결해본다. (전통적인 통계방법) ","date":"2021-11-26","objectID":"/prml-chap04-2/:1:2","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (2)","uri":"/prml-chap04-2/"},{"categories":["PRML"],"content":"4.3.3 Iterative reweighted least squares +일단은 교재의 내용을 보기 전에 이해를 돕기 위해 추가 설명을 한다. 우리는 logL를 미분했을 때, 이를 0으로 만드는 MLE를 찾고싶다. $g'(x)$ 는 미분가능 $g''(x) \\neq 0$ 위의 조건을 만족하는 경우 taylor expansion을 이용하여 (1차 근사) $$0 = g'(x) \\approx g'(x^{t}) + (x-x^t)g''(x^t)$$ 이를 정리하면 $$x = x^t - \\frac{g'(x^t)}{g''(x^t)}$$ 이제 교재의 내용을 살펴보자. logisitc regression은 sigmoid function의 non-linearlity 때문에 closed-form의 해를 구할 수 없다. 그래서 우리는 error function의 최소화하는 방법으로 Newton-Raphson iterative opimization algorithm을 사용한다. $${\\bf w}^{new} = {\\bf w}^{old} - {\\bf H}^{-1} \\bigtriangledown E({\\bf w})$$ ${\\bf H}$ : hessian matrix whose elements comprise the second derivatives of $E({\\bf w})$ with respect to the component of ${\\bf w}$ $$\\bigtriangledown E({\\bf w}) = \\sum_{n=1}^{N}{(y_n - t_n)\\phi_n} = \\Phi ^T (\\textbf{y}-\\textbf{t})$$ $${\\bf H} = \\bigtriangledown \\bigtriangledown E({\\bf w}) = \\sum_{n=1}^{N}{y_n(1-y_n)\\phi_n \\phi_n^T} = \\Phi^T\\textbf{R}\\Phi$$ $\\Phi^T\\textbf{R}^{1/2} \\textbf{R}^{1/2} \\Phi =(\\textbf{R}^{1/2} \\Phi)^T (\\textbf{R}^{1/2} \\Phi)$ 이기에 positive semi definite이고 이를 통해 $E({\\bf w})$가 convex하다는 것을 알 수 있다. $\\textbf{R}$ : N*N diagonal matrix with elements $R_{nn} = y_n(1-y_n)$ $y_n$의 식이므로 parameter ${\\bf w}$에 dependent하다. 따라서 ${\\bf R}$에 대해서도 iterative하게 업데이트가 필요하다. 아래처럼 iterative하게 parameter를 업데이트 한다. $${\\bf w}^{(new)} = {\\bf w}^{(old)} - (\\Phi^T{\\bf R}\\Phi)^{-1}\\Phi^T({\\bf y}-{\\bf t})$$ $$= (\\Phi^T{\\bf R}\\Phi)^{-1}\\{\\Phi^T{\\bf R}\\Phi{\\bf w}^{(old)}-\\Phi^T({\\bf y}-{\\bf t})\\}$$ $$= (\\Phi^T{\\bf R}\\Phi)^{-1}\\Phi^T{\\bf R}{\\bf z}$$ $${\\bf z} = \\Phi{\\bf w}^{(old)} - {\\bf R}^{-1}({\\bf y}-{\\bf t})$$ 마지막 줄을 보면 이 형태는 weighted least-square 문제에서의 normal equation의 형태이다. 하지만 ${\\bf R}$이 상수가 아니기에 iterative하게 답을 구해야 하고 이러한 이유로 iterative reweighted least square 라고 부른다. ${\\bf R}$의 대각성분을 variance라고 해석할 수도 있다. 대각성분이 $y_n(1-y_n)$ 인데 이는 $t_n$의 variance이기 때문이다. ","date":"2021-11-26","objectID":"/prml-chap04-2/:1:3","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (2)","uri":"/prml-chap04-2/"},{"categories":["PRML"],"content":"4.3.4 Multiclass logistic regression 위에서 본 binary와 똑같이 할 수 있다. multiclass에서는 softmax function을 이용한다. $$p(C_k|\\phi) = y_k(\\phi) = \\frac{\\exp(a_k)}{\\sum_j \\exp(a_j)}$$ likelihood function을 구하면 $$p({\\bf T}|{\\bf w} _ 1,…{\\bf w} _ K) = \\prod_{n=1}^{N}\\prod_{k=1}^{K} p(C_k|\\phi_n)^{t_{nk}} = \\prod_{n=1}^{N}\\prod_{k=1}^{K}y_{nk}^{t_{nk}}$$ negative log를 취하면 $$E({\\bf w} _ 1, …, {\\bf w} _ K) = -\\ln p({\\bf T}|{\\bf w} _ 1, …,{\\bf w} _ K) = - \\sum_{n=1}^{N} \\sum_{k=1}^{K} t_{nk} \\ln(y_{nk})$$ 똑같이 미분을 취하고 Gradient descent나 IRLS 방법을 통해 parameter를 추정한다. $$\\nabla_{ {\\bf w} _ j } E({\\bf w} _ 1, …, {\\bf w} _ K) = \\sum_{n=1}^{N} (y _ {nj} - t _ {nj}) \\phi_n $$ ","date":"2021-11-26","objectID":"/prml-chap04-2/:1:4","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (2)","uri":"/prml-chap04-2/"},{"categories":["PRML"],"content":"4.3.5 Probit regression 이전과 마찬가지로 generalized linear model의 형태 $$p(t=1|a)=f(a)=f({\\bf w}^T \\phi)$$ 를 유지하지만 조금 다른 activation function을 알아보자. link function으로 noisy threshold model을 생각해보면 $t_n = 1 \\text{ if } a_n\\ge \\theta $ $t_n=0 \\text{ otherwise}$ $\\theta$는 random variable이고 probability density가 $p(\\theta)$라고 하자. 이에 따라 activation function을 CDF형태 $$f(a) = \\int_{-\\infty}^{a}p(\\theta)d\\theta$$ 로 표현할 수 있다. probability density를 $N(0,1)$로 가정하면 $$\\Phi(a) = \\int_{-\\infty}^{a}N(0, 1)d\\theta $$ 이고 이를 probit function이라고 한다. 모양은 sigmoid function과 거의 유사하다. 이를 모델에서 사용할 때는 약간 다른 모습을 이용한다. (계산의 편리함 때문인듯) erf function 은 $$erf(a) = \\frac{2}{\\sqrt{\\pi}} \\int_{0}^{a} \\exp(-\\theta^2) d\\theta$$ 이를 통해 탄생한 generalized linear model을 probit regression 이라고 한다. $$\\Phi(a) = \\frac{1}{2} \\{1+erf\\left(\\frac{a}{\\sqrt{2}}\\right)\\}$$ probit은 뒤에 나올 Bayesian logistic regression에서 사용된다. logistic, probit regression 모두 outlier에 취약한 편이다. 근데 probit은 $exp(-x^2)$이 있어서 더 취약하다. data가 mislabelling된 경우, 새로운 probability $\\epsilon$을 추가하여 사용할 수 있다. $$p(t|{\\bf x}) = (1-\\epsilon)\\sigma({\\bf x}) + \\epsilon(1-\\sigma({\\bf x})) = \\epsilon + (1-2\\epsilon)\\sigma({\\bf x})$$ ","date":"2021-11-26","objectID":"/prml-chap04-2/:1:5","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (2)","uri":"/prml-chap04-2/"},{"categories":["PRML"],"content":"4.4 The Laplace Approximation 4.5장에서 logistic regression에 Bayesian 방법을 사용하고자 한다. 근데 ${\\bf w}$의 posterior가 더 이상 Gaussian이 아니기 때문에 integrate하기가 어렵다. 따라서 특정 범위에 있는 함수를 Gaussian으로 approximation하는 방법을 이용하고자 한다. 먼저 single variable의 경우부터 살펴보자. Suppose the distribution $p(z)$ is defined by $$p(z) = \\frac{1}{Z}f(z),;; Z = \\int f(z)dz$$ 우리의 목표는 $p(z)$의 mode를 중앙(평균)으로 갖는 Gaussian distribution을 approximation하는 것이다. 먼저, mode를 찾아야한다. $$p'(z_0) = 0$$ Taylor expansion $$\\ln f(z) \\simeq \\ln f(z_0) - \\frac{1}{2}A(z-z_0)^2$$ $$A=-\\left.\\dfrac{d^2}{dz^2}\\ln f(z)\\right|_ {z=z_0} $$ 따라서 $$f(z) \\simeq f(z_0) \\exp { - \\frac{A}{2}(z-z_0)^2}$$ $$q(z) = (\\frac{A}{2\\pi})^{1/2} \\exp { -\\frac{A}{2}(z-z_0)^2 }$$ 우리는 $p(z)$를 approximate한 Gaussian $q(z)$를 찾을 수 있다! 이 과정이 Laplace approximation 이다. Gaussian approximation에서 ($f(z)$를 두 번 미분하여 $z_0$를 대입) precision $A$는 양수이다. 따라서 $z_0$는 local maximum이다. 이제 다차원의 형태로 살펴보자. Hessian Matrix $\\textbf{A} = - \\bigtriangledown \\bigtriangledown \\ln f(\\textbf{z}_0)$ $f(\\textbf{z}) \\simeq f(\\textbf{z}_0) \\exp { -\\frac{1}{2} (\\textbf{z} - \\textbf{z}_0)^T \\textbf{A} (\\textbf{z}-\\textbf{z}_0) }$ $$q({\\bf z}) = \\dfrac{|{\\bf A}|^{1/2}}{(2\\pi)^{M/2}}\\exp\\{-\\dfrac{1}{2}({\\bf z}-{\\bf z}_0)^T{\\bf A}({\\bf z}-{\\bf z}_0)\\} = N( {\\bf z}_0, {\\bf A}^{-1})$$ Laplace approximation 특징 Mutimodal인 distribution은 다양한 Laplace approximation이 생길 수 있다. CLT에 의해 Laplace approximation은 data가 많을수록 좋다. 위에서 알 수 있는이 $Z$에 대해 알 필요가 없다. Gaussian에 기반하므로 실수 변수에만 사용이 가능하다. global한 특징을 잡기 어렵다. ","date":"2021-11-26","objectID":"/prml-chap04-2/:2:0","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (2)","uri":"/prml-chap04-2/"},{"categories":["PRML"],"content":"4.4.1 Model comparison and BIC normalization constraint $Z$에 대해 approximation해보자. $$Z = \\int f({\\bf z})d{\\bf z} \\simeq f({\\bf z}_0)\\int\\exp\\{\\dfrac{1}{2}({\\bf z}-{\\bf z}_0)^T{\\bf A}({\\bf z}-{\\bf z}_0)\\}d{\\bf z}=f({\\bf z}_0)\\dfrac{(2\\pi)^{M/2}}{|{\\bf A}|^{1/2}}$$ 우리는 이 결과를 통해 이전에 공부했던 Bayesian model comparison에서 model evidence를 approximation해볼 것이다. model evidence $p(D|M_i)$ $M_i$ 생략 $$p(D)=\\int p(D|{\\pmb \\theta})p({\\pmb \\theta})d{\\pmb \\theta}$$ 아래와 같이 정의하고 우리는 model evidence를 approximation하면 $f({\\pmb \\theta}) = p(D|{\\pmb \\theta})p({\\pmb \\theta})$ $Z = p(D)$ $$\\ln p(D)\\simeq \\ln p(D|{\\pmb \\theta} _ {MAP}) + \\ln p({\\pmb \\theta} _ {MAP}) + \\dfrac{M}{2}\\ln(2\\pi) - \\dfrac{1}{2}\\ln|{\\bf A}| $$ 첫번째 term은 log likelihood evaluated using the optimized parameters 두번째 term부터 마지막 term까지 Occam factor 라고 부른다. penalizes model complexity ${\\pmb \\theta}_{MAP}$ : mode of posterior distribution ${\\bf A}$ : Hessian matrix $${\\bf A} = - \\nabla\\nabla p(D|{\\pmb \\theta} _ {MAP})p({\\pmb \\theta} _ {MAP}) = -\\nabla\\nabla\\ln p({\\pmb \\theta} _ {MAP}|D)$$ model evidence를 approximation한 식에서 Gaussian prior가 broad하고 Hessian이 full rank이면 우리는 해당 식을 더 간단하게 (의미없는 상수 생략) $$\\ln p(D) \\simeq \\ln p(D|{\\bf \\theta}_{MAP}) - \\frac{1}{2}M\\ln N$$ 이는 BIC(Baysian Information Criterion) 이다. $M$은 parameter의 갯수, $N$은 data의 수를 의미한다. AIC보다 더 간단한 모델을 추구한다. BIC를 쉽게 계산할 수 있지만 full rank라는 가정이 만족하기 쉽지 않아서 한계가 존재한다. ","date":"2021-11-26","objectID":"/prml-chap04-2/:2:1","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (2)","uri":"/prml-chap04-2/"},{"categories":["PRML"],"content":"4.5 Bayesian Logistic Regression Logistic regression에 Bayesian적으로 접근해보자. ","date":"2021-11-26","objectID":"/prml-chap04-2/:3:0","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (2)","uri":"/prml-chap04-2/"},{"categories":["PRML"],"content":"4.5.1 Laplace approximation 일단 prior는 Gaussian으로 가정한다. $$p({\\bf w}) = N( \\textbf{m}_0 , \\textbf{S}_0)$$ 이제 posterior를 구해보자. $$p(\\textbf{w}| \\textbf{t}) \\propto p(\\textbf{w})p(\\textbf{t}|\\textbf{w})$$ 양변에 log를 취하면 $$\\ln p(\\textbf{w} | \\textbf{t}) = - \\frac{1}{2}(\\textbf{w}-\\textbf{m} _ 0)^T \\textbf{S} _ 0^{-1} (\\textbf{w} - \\textbf{m} _ 0 )$$ $$+ \\sum_{n=1}^{N}{\\{ t_n \\ln y_n + (1-t_n)\\ln (1-y_n) \\}+ const}$$ posterior에 대한 Gaussian approximation하였다고 가정하자. maximize하는 parameter를 ${\\bf w}_{MAP}$라고 하고 covariance는 $${\\bf S}_N^{-1} = -\\nabla\\nabla \\ln p({\\bf w}|{\\bf t}) = {\\bf S} _ 0^{-1} + \\sum _ {n=1}^{N} y_n(1-y_n)\\phi_n\\phi_n^T$$ 따라서 Gaussian approximation한 posterior distribution의 form은 $$q(\\textbf{w}) = N(\\textbf{w}_{MAP} , \\textbf{S}_N)$$ 이제 approximation하여 구한 posterior로 Predictive를 구해보자. ","date":"2021-11-26","objectID":"/prml-chap04-2/:3:1","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (2)","uri":"/prml-chap04-2/"},{"categories":["PRML"],"content":"4.5.2 Predictive distribution 2-class의 경우라고 가정하자. predictive distribution은 $$p(C_1 | \\phi, \\textbf{t} ) = \\int p(C_1 | \\phi, \\textbf{w})p(\\textbf{w} | \\textbf{t}) \\simeq \\int \\sigma (\\textbf{w}^T\\phi) q(\\textbf{w})d\\textbf{w}$$ Funtion $\\sigma ({\\bf w}^T \\phi)$ depends on w only through tis projection onto $\\phi$ (교재에 설명이 다소 빈약) 그냥 아래처럼 변형 $$\\sigma({\\bf w}^T\\phi) = \\int \\delta(a-{\\bf w}^T\\phi)\\sigma(a)da$$ 이를 predictive distribution에 대입하면 $$\\int \\sigma({\\bf w}^T\\phi)q({\\bf w})d{\\bf w} = \\int \\sigma(a)p(a)da$$ $$p(a) = \\int \\delta(a-{\\bf w}^T\\phi)q({\\bf w})d{\\bf w}$$ $p(a)$는 Gaussian distribution이 되는데 delta function ($\\delta$) imposes a linear constraint on ${\\bf w}$이고 $q({\\bf w})$ 는 정의에 의해 Gaussian distribution Gaussian의 marginal도 Gaussian $$\\mu_a = E[a] = \\int p(a)a da = \\int q({\\bf w}){\\bf w}^T \\phi d{\\bf w} = {\\bf w}_{MAP}^T\\phi$$ $$\\sigma_a^2 = var[a] = \\int p(a){ a^2 - E[a]^2 }da $$ $$= \\int q({\\bf w}) {({\\bf w}^T\\phi)^2 - ({\\bf m}_N^T\\phi)^2 }d{\\bf w} = \\phi^T{\\bf S}_N\\phi$$ 따라서 predictive distribution은 $$p(C_1|{\\bf t}) = \\int \\sigma(a)p(a)da = \\int \\sigma(a)N(\\mu_a, \\sigma_a^2)da$$ sigmoid-gaussian을 analytically 구할 수 없기 때문에 이 또한 approximation을 해야한다. sigmoid와 비슷한 모양을 가지는 Probit function을 이용한다. ($\\sigma(a) \\approx \\Phi(\\lambda a) ,\\lambda^2 = \\pi / 8$) probit function을 이용한 approximation의 장점은 Gaussian과 만나서 analytically 또 probit function으로 아래와 같은 결과가 나온다. $$\\int \\Phi (\\lambda a )N ( \\mu, \\sigma^2)da = \\Phi (\\frac{\\mu}{( \\lambda^{-2}+\\sigma^2 ) ^{1/2}})$$ $$\\int \\sigma(a) N(\\mu,\\sigma^2)da \\simeq \\sigma (k(\\sigma^2)\\mu)$$ $k(\\sigma^2) = (1+\\pi \\sigma^2 / 8)^{-1/2}$ 최종 결과 approximate predictive distribution은 $$p(C_1 | \\phi, \\textbf{t}) = \\sigma (k(\\sigma^2_a)\\mu_a)$$ ","date":"2021-11-26","objectID":"/prml-chap04-2/:3:2","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (2)","uri":"/prml-chap04-2/"},{"categories":["PRML"],"content":"Classification에 대해 알아보자. input space는 decision regions 로 나눠지는데 이는 decision boundaries(decision surfaces) 에 의해 나눠진다. 이번 챕터에서는 분류 선형모델에 대해 공부하는데 이는 decision surfaces가 input x의 linear function 이라는 것을 의미한다. D차원의 input space가 D-1 차원의 hyperplane으로 나눠지는 것이다. 크게 3가지로 나누어서 공부한다. Discriminant function generative Discriminative classification에서는 discrete class labels 이나 각 class가 될 probability를 target으로 예측한다. 후자의 경우 (0,1) 사이의 값을 가질 것이다. 따라서 우리는 linear function of ${\\bf w}$를 nonlinear function을 이용하여 transform한다. $$y({\\bf x}) = f({\\bf w}^T {\\bf x} + w_0)$$ machine learning에서는 $f$를 activation function 이라고 부른다. 통계학에서는 inverse of link function 으로 부른다. 따라서 이전에 봤던 regression model과는 다르게 더이상 parameter에 linear하지 않는 성질을 가진다. ","date":"2021-11-26","objectID":"/prml-chap04-1/:0:0","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (1)","uri":"/prml-chap04-1/"},{"categories":["PRML"],"content":"4.1 Discriminant Functions discriminant : a function that takes an input vector ${\\bf x}$ and assigns it to one of $K$ class 이번 chapter에서는 linear discriminant ( : decision surfaces are hyperplane) 로 한정지어 공부할 것이다. ","date":"2021-11-26","objectID":"/prml-chap04-1/:1:0","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (1)","uri":"/prml-chap04-1/"},{"categories":["PRML"],"content":"4.1.1 two classes 가장 간단한 linear discriminant function을 보면 $$y({\\bf x}) = {\\bf w}^T {\\bf x} + w_0$$ $y({\\bf x}) \\ge 0$ 이면 class 1이고 반대면 class 2 이다. 따라서 decision boundary는 $y({\\bf x}) = 0$ 이고 $(D-1)$차원의 hyperplane이다. decision surface 위에 두 점 ${\\bf x}_A , {\\bf x}_B$ 이 있다고 가정하면 ${\\bf w}^T({\\bf x}_A - {\\bf x}_B)=0$ 이므로 vector ${\\bf w}$는 decision surface에 있는 모든 점들과 orthogonal하다. 이는 ${\\bf w}$가 decision surface의 orientation을 결정한다는 의미이다. 똑같이 ${\\bf x}$가 decision surface 위의 점이라고 하고 원점과 decision surface의 거리를 계산하면 아래와 같다. 여기서 ${\\bf w}_0$는 decision surface의 위치를 결정한다. $$\\frac{\\textbf{w}^T \\textbf{x}}{\\left|| \\textbf{w} \\right||} = - \\frac{ \\textbf{w}_0}{\\left|| \\textbf{w} \\right||}$$ ","date":"2021-11-26","objectID":"/prml-chap04-1/:1:1","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (1)","uri":"/prml-chap04-1/"},{"categories":["PRML"],"content":"4.1.2 Multiple classes $K$ 가 2보다 큰 multiple class를 분류하는 상황을 생각해보자. linear discriminant로 분류하는 방법은 크게 두 가지로 나눌 수 있다. one vs the rest one vs one 두 방법 모두 class를 결정하는데 있어 애매한 상황이 발생한다. hyperplane이라는 제약때문에 그 어떤 class에도 속하지 못하는 지역이 발생한다. (PRML figure 4.2 에 잘 보여줌) 이를 해결하기 위해 아래와 같은 $K$개의 linear function을 $K$-class discriminant로 사용한다. $$y_k(x) = w^T_kx + w_{k0}$$ $y_k({\\bf x}) \\ge y_j ({\\bf x})$ 인 경우, ${\\bf x}$는 $k$로 분류한다. 즉, 큰 값을 가지는 쪽으로! 여기서 만들어지는 decision region은 항상 singly connected and convex하다. decision region $R_k$에 들어있는 두 점 ${\\bf x}_A, {\\bf x}_B$ 이 두 점을 연결한 선 위에 점 $\\hat{ {\\bf x} }$이 있다고 가정하자. 이를 표현하면 ($0 \\le \\lambda \\le 1$) $$\\hat{\\bf x}=\\lambda{\\bf x}_A + (1-\\lambda){\\bf x}_B$$ 따라서 discriminant function은 다음을 만족한다. $$y_k(\\hat{ {\\bf x} })={\\lambda}y_k({\\bf x}_A) + (1-\\lambda)y_k({\\bf x}_B) $$ $y_k({\\bf x}_A) \u003e y_j({\\bf x}_A) , y_k({\\bf x}_B) \u003e y_j({\\bf x}_B)$ 을 만족하기에 $y_k({\\hat {\\bf x}}) \u003e y_j({\\hat {\\bf x}})$ 도 성립한다. 따라서, ${\\hat {\\bf x}}$은 항상 $R_k$에 속한다. 이제 linear discriminant function의 parameter를 학습하는 방법에 대해 배울 것이다. least square Fisher’s linear discriminant perceptron algorithm ","date":"2021-11-26","objectID":"/prml-chap04-1/:1:2","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (1)","uri":"/prml-chap04-1/"},{"categories":["PRML"],"content":"4.1.3 Least squares for classification 이전의 sum of squares error function을 그대로 이용한다. target은 1-of-K binary coding하여 vector ${\\bf t}$ 이다. (해당하는 class는 1 나머지 class는 0으로 표현) 각 class 마다 $y_k({\\bf x}) = {\\bf w}_k^T {\\bf x} + w _ {k0}$ , 이를 합쳐서 표현하면 $$\\textbf{y} (\\textbf{x}) = \\widetilde{ \\textbf{W} }^T \\widetilde{ {\\bf x} }$$ $\\widetilde{\\textbf{W}}$ : 각 컬럼이 $\\widetilde{\\textbf{w}}_k = ({\\bf w} _ {k0}, {\\bf w}_k^T)$ $\\widetilde{\\textbf{W}}_k^T \\widetilde{ {\\bf x}}$가 가장 큰 값(class)에 input ${\\bf x}$를 할당한다. normal equation으로 parameter를 구하면 $$\\widetilde{\\textbf{W}}=(\\widetilde{\\textbf{W}}^T \\widetilde{\\textbf{W}})^{-1}\\widetilde{\\textbf{W}}^T\\widetilde{\\textbf{T}}=\\widetilde{\\textbf{W}}^{\\dagger}\\widetilde{\\textbf{T}}$$ 특징 exact closed-form의 solution이 나온다. output이 확률의 범위 (0,1) 을 넘어가는 경우가 존재한다. (우리는 output이 확률값이길 원한다) least square의 단점인 outlier에 취약하다. input data에 따라서 decision이 급변하다. ","date":"2021-11-26","objectID":"/prml-chap04-1/:1:3","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (1)","uri":"/prml-chap04-1/"},{"categories":["PRML"],"content":"4.1.4 Fisher’s linear discriminant 차원 축소의 역할로 많이 쓰이는데 classification으로도 사용가능하다. 일단은 2-class의 경우만 고려해보자. $D$ 차원의 input vector $\\textbf{W}$를 1차원에 project한다고 생각하자. $$y = \\textbf{w}^T \\textbf{x}$$ 이렇게 할 수 있다. 하지만 overlapping되니까 class seperation을 최대화하는 projection을 하는 것이다. 각 class의 평균을 $\\textbf{m}_1, \\textbf{m}_2$이라고 하면 아래의 값을 최대로 하는 ${\\bf w}$를 찾아야 한다. ${\\bf m_1}=1 / N_1\\sum_{n \\in C_1}\\textbf{x}_n$ ${\\bf m_2}=1 / N_2\\sum_{n \\in C_2}\\textbf{x}_n$ $$m_2 - m_1 = \\textbf{w}^T (\\textbf{m}_1 - \\textbf{m}_2),\\quad where; m_k = \\textbf{w}^T \\textbf{m}_k$$ ${\\bf w}$를 계속 키우면 커지기 때문에 제약식 $\\sum {\\bf w}_i^2 = 1$을 두고 라그랑지로 풀면 $${\\bf w} \\propto (\\textbf{m}_2 - \\textbf{m}_1)$$ 의 결론을 얻는다. 이에 추가적으로 Fisher는 within class의 varinace를 최소화 하고자 했다. 반면에 between class의 variance는 최대화 한다. class $C_k$의 within variance는 $y_n = {\\bf w}^T {\\bf x}_n$ $m_k = {\\bf w}^T {\\bf m}_k$ $$s_k^2=\\sum_{n \\in C_k}(y_n-m_k)^2$$ 전체 class의 within variance는 $s_1^2+s_2^2$ 이를 통해 Fisher criterion (ratio of the between-class variance to the within-class variance)은 $$J(\\textbf{w}) = \\frac{(m_2 - m_1)^2}{s_1^2+s_2^2}$$ Fisher criterion을 다시 쓰면 $$J(\\textbf{w}) = \\frac{\\textbf{w}^T {\\bf S}_B \\textbf{w}}{\\textbf{w}^T {\\bf S}_W \\textbf{w}}$$ $${\\bf S}_B = (\\textbf{m}_2 - \\textbf{m}_1)(\\textbf{m}_2 - \\textbf{m}_1)^T$$ 이 값은 between-class covariance matrix이다. $$\\textbf{S} _ W = \\sum_{n \\in C_1} (\\textbf{x} _ n - \\textbf{m} _ 1)(\\textbf{x} _ n - \\textbf{m} _ 1)^T + \\sum_{n \\in C_2} ({\\bf x}_n - \\textbf{m}_2)({\\bf x}_n-\\textbf{m}_2)^T$$ 이 값은 total within-class covariance matrix이다. w에 대해 미분하고 위의 값을 최대화하는 값을 찾으면 $\\textbf{w} \\propto {\\bf S}_W^{-1} (\\textbf{m}_2 - \\textbf{m}_1)$ . 이 결과를 Fisher’s linear discriminant 라고 한다. 1차원에 projection한 뒤에 특정 threshold값을 정해 classification할 수 있다. ","date":"2021-11-26","objectID":"/prml-chap04-1/:1:4","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (1)","uri":"/prml-chap04-1/"},{"categories":["PRML"],"content":"4.1.5 Relation to least squares Fisher criterion은 least square의 특별한 경우이다. target을 1-of-K encoding의 방법이 아닌 class 1은 $N / N_1$ class 2는 $-N / N_2$ 으로 encoding 하면 된다. 이렇게 한 뒤에 least square의 방법대로 parameter를 구하면 Fisher criterion이 나온다. (과정은 생략) ","date":"2021-11-26","objectID":"/prml-chap04-1/:1:5","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (1)","uri":"/prml-chap04-1/"},{"categories":["PRML"],"content":"4.1.6 Fisher’s discriminant for multiple classes skip ","date":"2021-11-26","objectID":"/prml-chap04-1/:1:6","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (1)","uri":"/prml-chap04-1/"},{"categories":["PRML"],"content":"4.1.7 The perceptron algorithm perceptron 특징 2 class에서만 사용가능하다. based on linear combination of fixed basis function target을 이전에는 주로 1,0 으로 했는데 여기서는 -1, 1 로 코딩한다. perceptron criterion (error function) $$E_p ({\\bf w}) = -\\sum_{n \\in M}{\\textbf{w}^T \\phi_n t_n}$$ $M$은 잘못분류한 케이스를 의미한다. 우리는 이 criterion을 최소화 하고자 한다. $\\textbf{w}^T \\phi_n \u003e 0$ 이면 1로 분류 $\\textbf{w}^T \\phi_n \u003c 0$ 이면 -1로 분류 따라서 분류를 잘못하면 ${\\textbf{w}^T \\phi_n t_n} \u003c 0$ 이고 error가 커지는 것이다. 위 perceptron criterion을 SGD로 iterative하게 계산하면 $${\\bf w}^{(\\tau+1)}={\\bf w}^{(\\tau)}-\\eta\\triangledown E_p({\\bf w})={\\bf w}^{(\\tau)}+\\eta\\phi_n{t_n}$$ ($\\eta$는 learning rate) 이다. 이를 쉽게 해석하면 분류가 맞으면 놔두고 틀리면 그 $\\phi_n$ 만큼 더하고 빼고 하는 것이다. 양변에 $-\\phi_n t_n$을 곱하면 에러가 줄어듬(parameter가 converge)을 알 수 있다. $$-{\\bf w}^{(\\tau+1)T}{\\phi}_n{t_n} = -{\\bf w}^{(\\tau)T}{\\phi_n}{t_n}-(\\phi_n{t_n})^T\\phi_n{t_n} \u003c -{\\bf w}^{(\\tau)T}\\phi_n{t_n}$$ perceptron convergence theorem training data set is linearly separable 하면 perceptron algorithm수렴한다 (반드시 해당하는 decision boundary를 찾을 수 있다) . 아니면 수렴이 안된다. 수렴하기 전까지 이게 non separable 문제인지 아니면 수렴이 천천히 되는 건지 파악하기 어렵다. ","date":"2021-11-26","objectID":"/prml-chap04-1/:1:7","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (1)","uri":"/prml-chap04-1/"},{"categories":["PRML"],"content":"4.2 Probabilistic Generative Models data의 분포에 대한 가정을 갖는 decision boundary에 대해 공부해보자. $p(x|C_k), p(C_k)$로 베이즈정리를 이용하여 posterior를 계산한다. (일단 binary classification의 경우) posterior probability for class 1 : $$p(C_1 | {\\bf x}) = \\frac{p({\\bf x}|C_1)p(C_1)}{p({\\bf x}|C_1)p(C_1)+p({\\bf x}|C_2)p(C_2)}$$ $$ = \\frac{1}{1+\\frac{p({\\bf x}|C_2)p(C_2)}{p({\\bf x}|C_1)p(C_1)}} = \\frac{1}{1+exp(-a) } = \\sigma (a)$$ $$\\text{where}\\; a = \\ln \\frac{p(x|C_1)p(C_1)}{p(x|C_2)p(C_2)}$$ $\\sigma (x) = \\frac{1}{1+exp(-x) }$ 이 식은 logistic sigmoid function 이다. 이의 inverse는 $x=\\ln (\\frac{\\sigma}{1-\\sigma})$ 이고 logit function이라고 한다. 이번에는 일반적인 경우에 대해 살펴보자. multi class의 경우 $$p(C_k | {\\bf x}) = \\frac{p({\\bf x}|C_k)p(C_k)}{\\sum p({\\bf x}|C_j)p(C_j)} = \\frac{exp(a_k)}{\\sum_j exp(a_j)}$$ $$\\text{where}\\; a_k = \\ln p({\\bf x}|C_k)p(C_k)$$ 이를 normalized exponential or softmax function 이라고 한다. ","date":"2021-11-26","objectID":"/prml-chap04-1/:2:0","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (1)","uri":"/prml-chap04-1/"},{"categories":["PRML"],"content":"4.2.1 Continuous inputs class-conditional density를 Gaussian이라고 가정하고 posterior를 살펴보자. 단 모든 class는 같은 covariance matrix를 가진다. (2-class) $$p({\\bf x}|C_k) = \\dfrac{1}{(2\\pi)^{D/2}|\\Sigma|^{1/2}}\\exp \\{-\\dfrac{1}{2}({\\bf x} - {\\pmb \\mu}_k)^T\\Sigma^{-1}({\\bf x} - {\\pmb \\mu}_k)\\} $$ 이므로 이를 이용해 위에서 구한 posterior를 계산하면 $a = \\ln \\frac{p(x|C_1)p(C_1)}{p(x|C_2)p(C_2)}$ $$p(C_1 | {\\bf x}) =\\sigma (a) = \\sigma ({\\bf w}^T {\\bf x} + w_0)$$ $${\\bf w} = \\Sigma^{-1}({\\pmb \\mu_1}-{\\pmb \\mu_2})$$ $$w_0 = -\\frac{1}{2}{\\pmb \\mu_1}^T\\Sigma^{-1}{\\pmb \\mu_1} + \\frac{1}{2}{\\pmb \\mu_2}^T\\Sigma^{-1}{\\pmb\\mu_2} + \\ln{\\frac{p(C_1)}{p(C_2)}}$$ 의 형태가 나온다. class-conditional density를 Gaussian이라고 가정하였기 때문에 logistic sigmoid안에서 ${\\bf x}$ 의 linear function의 형태가 나온다. K-class의 경우 $$a_k({\\bf x})=\\ln(p({\\bf x}|C_k)p(C_k)) = {\\bf w}^T_k {\\bf x}+w_0$$ $${\\bf w}_k = \\Sigma^{-1}{\\pmb \\mu}_k$$ $$w_{k0} = -\\frac{1}{2}{\\pmb \\mu}_{k}^{T} \\Sigma^{-1}{\\pmb \\mu}_k + \\ln p(C_k)$$ posterior의 decision boundary는 input space에 linear하다. (공분산이 동일하다는 가정하에서) 공분산을 각 class마다 다르다고 가정하면 우리는 quadratic function of ${\\bf x}$를 얻게 되고 이는 quadratic discriminant 이다. 이처럼 posterior probability는 $$p({\\bf x}|C_k) = f(\\text{linear of}\\;{\\bf x})$$ 의 형태가 된다. ","date":"2021-11-26","objectID":"/prml-chap04-1/:2:1","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (1)","uri":"/prml-chap04-1/"},{"categories":["PRML"],"content":"4.2.2 Maximum likelihood solution MLE를 통해 prameter들을 추정해보자. class-conditional에서 Gaussian을 가정하였는데 그에 해당하는 parameter들 이다. prior : $p(C_1) = \\pi , p(C_2) = 1- \\pi$ $p(x_n,C_1) = p(C_1)p({\\bf x}_n|C_1) = \\pi N({\\bf x}_n | {\\pmb \\mu}_1,{\\pmb \\Sigma})$ $p(x_n,C_2) = p(C_2)p({\\bf x}_n|C_2) =(1- \\pi) N({\\bf x}_n | {\\pmb \\mu}_2,{\\pmb \\Sigma})$ Class 1은 1, Class 2는 0 으로 target coding likelihood function : $$p(\\textbf{t} | \\pi, {\\pmb \\mu}_1,{ \\pmb \\mu}_2, {\\pmb \\Sigma} ) = \\prod [\\pi N({\\bf x}_n | {\\pmb \\mu}_1, {\\pmb \\Sigma})]^{t_n}[(1-\\pi)N({\\bf x}_n | {\\pmb \\mu}_2, {\\pmb \\Sigma})]^{1-t_n}$$ 이를 log 취하고 미분하여 MLE를 구하면 (K-class도 동일한 방법으로 구할 수 있다) $$\\pi = \\frac{1}{N} \\sum_{n=1}^{N}{t_n} = \\frac{N_1}{N_1 + N_2}$$ $${\\pmb \\mu} _ 1 = \\frac{1}{N_1} \\sum_{n=1}^{N}t_n {\\bf x} _ n, {\\pmb \\mu} _ 2 = \\frac{1}{N_2}\\sum_{n=1}^{N}(1-t_n){\\bf x}_n$$ $${\\pmb \\Sigma} = {\\bf S} = \\frac{N_1}{N}{\\bf S}_1 + \\frac{N_2}{N}{\\bf S}_2$$ ","date":"2021-11-26","objectID":"/prml-chap04-1/:2:2","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (1)","uri":"/prml-chap04-1/"},{"categories":["PRML"],"content":"4.2.3 Discrete features 각 input data feature가 2가지의 값을 갖는 discrete feature들이라고 가정해보자. 그러면 총 $2^D$의 경우 수가 생긴다. 이를 추정하기에는 너무 복잡하다. 따라서 naive bayes의 가정을 이용하면 $$p({\\bf x}|C_k) = \\prod_{i=1}^{D}\\mu_{ki}^{x_i}(1-\\mu_{ki})^{1-x_i} $$ $$a_k({\\bf x})=\\ln(p({\\bf x}|C_k)p(C_k))$$ $$a_k({\\bf x})=\\sum_{i=1}^{D}\\{x_i\\ln \\mu_{ki}+(1-x_i)\\ln(1-\\mu_{ki})\\}+\\ln p(C_k)$$ 이 또한 linear한 형태이다. ","date":"2021-11-26","objectID":"/prml-chap04-1/:2:3","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (1)","uri":"/prml-chap04-1/"},{"categories":["PRML"],"content":"4.2.4 Exponential Family 위에서 알 수 있듯이 input이 Gaussian이던 discrete이던지 우리에게 가장 중요한 posterior class probability는 generalized linear model과 sigmoid, softmax activation function에 의해 결정된다. 이러한 특징은 class-conditional density가 exponential family의 경우 해당한다. $$p({\\bf x};|\\lambda_k) = h({\\bf x})g(\\lambda_k)\\exp(\\lambda_k^T u({\\bf x})) $$ 여기서 제약을 위한 parameter $s$를 추가하고 (잘 이해못함) $$p({\\bf x};|\\lambda_k, s) = \\dfrac{1}{s}h\\left(\\dfrac{1}{s}{\\bf x}\\right)g\\left(\\lambda_k\\right)\\exp \\left(\\dfrac{1}{s}\\lambda_k^T u({\\bf x})\\right)$$ linear function을 구할 수 있다. $$a({\\bf x})=\\dfrac{1}{s}(\\lambda_1-\\lambda_2)^T{\\bf x}+\\ln g(\\lambda_1) - \\ln g(\\lambda_2) + \\ln p(C_1) - \\ln p(C_2)$$ $$a_k({\\bf x}) = \\dfrac{1}{s}\\lambda_k^T{\\bf x}+\\ln g(\\lambda_k) + \\ln p(C_k)$$ link function과 exp fam의 관계 EX) Bernoulli dist $$L(\\theta) = \\prod \\theta^{x_i}(1-\\theta)^{1-x_i}= \\exp {\\sum{x_i \\log \\theta}+ \\sum{(1-x_i)\\log (1-\\theta)} } $$ $$=\\exp { \\sum{x_i} \\log(\\frac{\\theta}{1-\\theta}) }(1-\\theta)^n$$ 위의 식에서 $\\log (\\frac{\\theta}{1-\\theta})$ 가 link function이다. $\\log (\\frac{\\theta}{1-\\theta}) = \\beta_0 + \\beta_1 x_1+…+\\beta_n x_n$ 이 이제 배울 logistic regression 이다. ","date":"2021-11-26","objectID":"/prml-chap04-1/:2:4","tags":["Classification"],"title":"[PRML] Chapter4 - Linear Models For Classification (1)","uri":"/prml-chap04-1/"},{"categories":["PRML"],"content":"Regression에 대해 알아보자. ","date":"2021-11-26","objectID":"/prml-chap03-2/:0:0","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (2)","uri":"/prml-chap03-2/"},{"categories":["PRML"],"content":"3.3 Bayesian Linear Regression 이전에 우리는 maximum likelihood 방법을 통해 linear regression 의 parameter를 구하는 방법을 공부했다. 이는 몇 가지 특징(단점)이 있는데 MLE 는 overfitting의 위험이 있다. 적절한 model complexity를 정해야 한다. by basis function의 수 regularization coefficient 우리는 한정적인 dataset을 갖고 있기에 적절한 model complexity를 정하기 위해서는 cross validation과 같은 computationally expensive한 방법을 사용해야한다. 위와 같은 단점들을 해결하기 위해 우리는 Bayesian 방법론을 사용할 것이다. MAP는 uncertainty를 표현할 수 없기 때문에 distribution을 이용한다. ","date":"2021-11-26","objectID":"/prml-chap03-2/:1:0","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (2)","uri":"/prml-chap03-2/"},{"categories":["PRML"],"content":"3.3.1 Parameter distribution 이전에 likelihood function $p(t|{\\bf w})$ 이 Gaussian 이었다. 이에 대한 conjugate prior로 Gaussian을 가정한다. prior distribution은 $$p({\\bf w}) = N({\\bf m}_0, {\\bf S}_0) $$ likelihood function과 prior를 곱해 posterior를 계산하면 (계산과정은 생략, monk영상을 보면 된다) $$p({\\bf w}|{\\bf t}) = N({\\bf m}_N, {\\bf S}_N)$$ ${\\bf m}_N = {\\bf S}_N({\\bf S}_0^{-1} {\\bf m}_0 + \\beta { \\bf \\Phi}^T {\\bf t})$ ${\\bf S}_N^{-1} = {\\bf S}_0^{-1}+\\beta {\\bf \\Phi}^T {\\bf \\Phi}$ $\\beta$ : (target error term) noise precision parameter (assume known) Gaussian은 mean과 mode(최빈값)가 같은 값을 갖기 때문에 ${\\bf w}_{MAP} = {\\bf m}_N$ 이다. 만약 infinite broad prior인 경우 (${\\bf S}_0 = \\alpha^{-1}{\\bf I},\\alpha \\rightarrow 0$) 수식을 전개해보면 ${\\bf m}_N \\rightarrow {\\bf m} _ {ML}$ 반대로 $N \\rightarrow 0$ 이면 posterior 는 prior로 가까워진다. 복잡해 보이는 prior를 다소 간단한 형태로 정하면 $p({\\bf w}|\\alpha) = N(0, \\alpha^{-1}I)$ 으로 생각할 수 있다. 이 prior에서 posterior의 mean, precision은 $${\\bf m}_N = \\beta {\\bf S}_N {\\bf \\Phi}^T {\\bf t}$$ $${\\bf S}_N^{-1} = \\alpha {\\bf I} + \\beta {\\bf \\Phi}^T {\\bf \\Phi}$$ log of posterior distribution (log of likelihood function과 log of prior의 합) 은 $$\\ln p({\\bf w}|{\\bf t}) = -\\frac{\\beta}{2}\\sum_{n=1}^{N}{t_n-{\\bf w}^T\\phi({\\bf x}_n)}^2 - \\frac{\\alpha}{2}{\\bf w}^T{\\bf w}+const$$ 이는 결국 minimization of the sum of square with quadratic regulrarization($\\lambda = \\frac{\\alpha}{\\beta}$) 과 같은 수식이다. ","date":"2021-11-26","objectID":"/prml-chap03-2/:1:1","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (2)","uri":"/prml-chap03-2/"},{"categories":["PRML"],"content":"3.3.2 Predictive distribution 우리의 최종 목표는 predictive distribution 이다. $$p(t|{\\bf t}, \\alpha, \\beta) = \\int p(t|{\\bf w}, \\beta)p({\\bf w}|{\\bf t}, \\alpha, \\beta)d{\\bf w} $$ predictive distribution을 보면 target의 conditional distribution $p(t | w,\\beta)=N(t | y(w,x), \\beta^{-1})$ 와 weight parameter ${\\bf w}$의 posterior distribution으로 만들어졌다. 이를 토대로 정리하면 $$p(t|{\\bf t}, \\alpha, \\beta) = N({\\bf m}_N^T\\phi({\\bf x}), \\sigma_N^2({\\bf x})) $$ variance : $\\sigma_N^2({\\bf x}) = \\frac{1}{\\beta} + \\bf \\phi({\\bf x})^T {\\bf S}_N\\phi({\\bf x})$ 이 variance에서 첫번째 항은 data의 noise이고 (앞부분을 찾아보자) 뒷부분이 ${\\bf w}$의 uncertainty를 나타낸다. noise와 ${\\bf w}$ distribution은 independent하기에 두 값을 더한게 variance가 된것이다. N이 커질수록 posterior는 narrow해지므로 뒷부분은 0으로 간다. ","date":"2021-11-26","objectID":"/prml-chap03-2/:1:2","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (2)","uri":"/prml-chap03-2/"},{"categories":["PRML"],"content":"3.3.3 Equivalent kernel 위에 $w$에 대해 구한 값을 토대로 mean of predictive distribution은 $$y({\\bf x}, {\\bf m} _ N) = {\\bf m} _ N^T\\phi({\\bf x}) = \\beta \\phi({\\bf x})^T {\\bf S} _ N \\Phi^T {\\bf t} \\\\ = \\sum_{n=1}^N \\beta \\phi({\\bf x})^T {\\bf S}_N \\phi({\\bf x}_n)t_n $$ 특정 ${\\bf x}$에 대한 mean of predictive dist 은 결국 training set target t의 linear combination 이다. 이를 다르게 표현하면 $$y({\\bf x}, {\\bf m} _ N) = \\sum_{n=1}^N k({\\bf x}, {\\bf x}_n)t_n$$ $k({\\bf x}, {\\bf x}') = \\beta \\phi({\\bf x})^T {\\bf S}_N \\phi({\\bf x}')$ : 이 식을 smoother matrix or equvalent kernel 라고 부른다. 따라서 mean of predictive distribution at $x$ 은 $x$와 (비슷한)가까운 data에 해당하는 $t$에 높은 가중치를 준다. equvalent kernel에 대해서 covariance의 측면으로 살펴보자. $$cov[y({\\bf x}), y({\\bf x}')] = cov[\\phi({\\bf x})^T{\\bf w}, {\\bf w}^T\\phi({\\bf x}')] = \\phi({\\bf x})^T{\\bf S}_N\\phi({\\bf x}')=\\beta^{-1}k({\\bf x}, {\\bf x}') $$ equvalent kernel의 형태에서 근처의 points들의 predictive mean는 상관관계가 높다는 것을 알 수 있다. ","date":"2021-11-26","objectID":"/prml-chap03-2/:1:3","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (2)","uri":"/prml-chap03-2/"},{"categories":["PRML"],"content":"3.4 Bayesian Model Comparison Bayesian의 입장에서 model selection을 바라보고자 한다. 모델을 선택하는 과정에 있어서 확률적인 내용을 많이 사용한다. maximum likelihood와 관련한 overfitting 문제는 marginalizing over the model parameters instead of making point estimates of their values 로 해결 할 수 있다. 모델은 training data를 통해 바로 정할 수 있으므로 validation set이 필요없다. 따라서 모든 데이터를 학습시킬 수 있고 불필요한 검증과정을 없앨 수 있다. 이제 L개의 ${M_i}$ model이 있다고 하자. 이제 이 model들을 random variable으로 생각하고 model에 대한 uncertainty는 확률로 표현한다. $$p(M_i | D) \\propto p(M_i)p(D | M_i) $$ 일단 model에 대한 prior는 다 같다고 가정하자. 따라서 우리의 주 관심은 model evidence(=marginal likelihood) : $p(D/M_i)$ model을 이루는 parameter들이 marginalized out 되었기에 marginal likelihood라고도 부름 (뒷 부분에 나옴) Bayes factor ratio of model evidence s $p(D|M_i)p(D|M_j)$ model의 posterior를 알고 이를 이용하여 predictive distribution을 구하면 $$p(t|{\\bf x}, D) = \\sum_{i=1}^{L} p(t|{\\bf x}, M_i, D)p(M_i|D)$$ 이다. (mixture distribution의 모습) 이는 model posterior를 가중치로 하여 평균을 낸 것으로 볼 수 있다. 위와 같은 model averaging의 값과 가장 근사하는 좋은 model 하나를 찾고자 한다. 이를 model selection 이라고 한다. model evidence (${\\bf w}$는 model에 관한 parameter) 이를 sampling 측면에서 바라보면, marginal likelihood는 data set D를 생성하는 probability로 볼 수 있는데 여기서 D는 prior로 부터 random하게 뽑힌 parameter들로 이루어진 model에서 만들어진 것이다. 또한, evidence는 Bayes' Them에서 분모에 해당하는 normalizing term을 의미하기도 한다 : $p({\\bf w}| D, M_i) = \\frac{p(D | {\\bf w}, M_i) p({\\bf w} | M_i)}{p(D | M_i)}$ $$p(D|M_i) = \\int p(D|{\\bf w}, M_i)p({\\bf w}|M_i)d{\\bf w}$$ 이제 model evidence에 대해 더 알아보자. model이 single parameter $w$ 를 갖고 있다고 가정 notation $M_i$는 생략 $w$의 posterior는 $p(D|w)p(w)$에 비례 posterior는 $w_{MAP}$ 에서 peaked 된 상태이고 그 때 width는 $\\vartriangle w_{posterior}$ 라고 가정 prior는 flat with width $\\vartriangle w_{prior}$, 따라서 $p(w) = 1/\\vartriangle w_{prior}$ $$p(D) = \\int p(D | w)p(w)dw \\simeq p(D | w_{MAP}) \\frac{1}{\\vartriangle w_{prior}} \\vartriangle w_{posterior}$$ log를 씌우면 $$\\ln p(D) \\simeq \\ln p(D|w_{MAP}) + \\ln (\\frac{\\vartriangle w_{posterior}}{\\vartriangle w_{prior}})$$ 첫번째 항 : 이 data를 가장 잘 표현하는 파라미터에 대한 확률값으로 log likelihood 의미 두번째 항 : model complexity에 대한 penalty 항 우리는 $\\ln p(D|M_i)$ 가 가장 큰 model($M_i$)을 찾는 것이 목표이다. complex가 높은 model를 구하면 첫번째 항이 커질 것이지만 두번째 항은 $\\vartriangle w_{posterior}$ 이 narrow 해지면서 음수가 되고 점점 작아진다. trade-off 관계인 것이다. 따라서 적절한 complexity가 있는 model을 선택하게 된다. $\\ln p(D | M_i) = accuracy(M_i) - complexity(M_i)$ 느낌 AIC, BIC를 예시로 생각할 수 있다. M 개의 parameter가 있을 경우 위에서 설명한 부분과 같다. 뒷 부분에 M이 추가되어 M이 커지면서 더 penalty를 준다. $$\\ln p(D | \\textbf{w} _ {MAP}) + M \\ln (\\frac{\\vartriangle w_{posterior}}{\\vartriangle w_{prior}})$$ optimal model complexity (model selection) 는 maximum evidence 으로 정해진다는 것 을 기억하자. ","date":"2021-11-26","objectID":"/prml-chap03-2/:2:0","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (2)","uri":"/prml-chap03-2/"},{"categories":["PRML"],"content":"3.5 The Evidence Approximation linear basis model에서 완전한 Bayesian 접근법을 위해서 ${\\bf w}$에 대한 hyperparameter $\\alpha, \\beta$의 prior를 고려해보자. predictive distribution은 아래와 같이 구할 수 있다. (${\\bf x}$ 표시는 생략) $p(t|{\\bf w})$ : distribution of target ($=N(y(x,{\\bf w}), \\beta^{-1})$) $p({\\bf w}|{\\bf t}, \\alpha, \\beta)$ : posterior of ${\\bf w}$ $p(\\alpha, \\beta | {\\bf t})$ : posterior of $\\alpha, \\beta$ $$p(t|{\\bf t}) = \\iiint p(t|{\\bf w}, \\beta) p({\\bf w}|{\\bf t}, \\alpha, \\beta) p(\\alpha, \\beta | {\\bf t}) d{\\bf w}d\\alpha d\\beta $$ 하지만 여기서 문제가 발생한다. 위처럼 모든 변수에 대해 marginalize하는 것은 항상 가능한 것이 아니다 (analytically intractable). 그래서 우리는 hyperparameter를 특정한 값으로 approximation한다. 그 방법은 maximizing marginal likelihood function이다. 이러한 방법론을 evidence approximation (통계에서는 emprical Bayes, type 2 maximum likelihood, generalized maximum likelihood) 라고 부른다. 만약에 posterior distribution $p(\\alpha, \\beta | {\\bf t})$ 가 특정한 값 $\\hat{\\alpha}, \\hat{\\beta}$에서 가장 높은 값(peaked)을 가진다면 predictive distribution은 ${\\bf w}$에 대해서만 marginalize해서 구할 수 있을 것이다. $$p(t|{\\bf t}) \\simeq p(t|{\\bf t}, \\hat{\\alpha}, \\hat{\\beta}) = \\int p(t|{\\bf w}, \\hat{\\beta})p({\\bf w}|{\\bf t}, \\hat{\\alpha}, \\hat{\\beta})d{\\bf w}$$ posterior distribution for $\\alpha, \\beta$ 는 $$p(\\alpha, \\beta | {\\bf t}) \\propto p({\\bf t}|\\alpha, \\beta) p(\\alpha, \\beta) $$ prior는 flat 하다고 가정하자. 따라서 우리는 $\\hat{\\alpha}, \\hat{\\beta}$를 구하기 위해서 marginal likelihood function $p({\\bf t} | \\alpha, \\beta)$ 을 최대로 만드는 찾으면 된다. 이를 통해 우리는 cross validation과 같은 방법이 아니라 한 번에 hyperparameter를 찾을 수 있다. 찾는 방법은 미분을 이용하는 방법, EM 알고리즘을 이용하는 방법이 있다. 전자는 이제 살펴볼 것이고 후자는 9장에서 배운다. ","date":"2021-11-26","objectID":"/prml-chap03-2/:3:0","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (2)","uri":"/prml-chap03-2/"},{"categories":["PRML"],"content":"3.5.1 Evaluation of the evidence function marginal likelihood function은 parameter ${\\bf w}$를 marginalize해서 얻을 수 있다. $p({\\bf t}|{\\bf w}, \\beta)$ : likelihood function $p({\\bf w}|\\alpha)$ : prior of w $$p({\\bf t}|\\alpha, \\beta) = \\int p({\\bf t}|{\\bf w}, \\beta) p({\\bf w}|\\alpha) d{\\bf w}$$ 위의 식을 Gaussian의 형태를 이용하여 정리해보자. (과정은 생략, PRML 연습문제에 있다) $$p({\\bf t}|\\alpha, \\beta) = \\left(\\frac{\\beta}{2\\pi}\\right)^{N/2}\\left(\\frac{\\alpha}{2\\pi}\\right)^{M/2} \\int \\exp{-E({\\bf w})}d{\\bf w}$$ $$E({\\bf w}) = \\beta E_D({\\bf w}) + \\alpha E_w({\\bf w}) = \\frac{\\beta}{2}|{\\bf t} - \\Phi{\\bf w}|^2 + \\frac{\\alpha}{2}{\\bf w}^T{\\bf w} $$ $$E({\\bf w}) = E({\\bf m}_N)+\\frac{1}{2}({\\bf w}-{\\bf m}_N)^T {\\bf A} ({\\bf w} - {\\bf m}_N) $$ ${\\bf A} = \\alpha {\\bf I} + \\beta \\Phi^T\\Phi$ ${\\bf m}_N = \\beta {\\bf A}^{-1}\\Phi^T{\\bf t}$ 이제 이를 이용하면 $$\\int \\exp\\left(-E({\\bf w})\\right) d{\\bf w} = \\exp(-E({\\bf m}_N))\\int \\exp \\{ -\\frac{1}{2}({\\bf w}-{\\bf m}_N)^T {\\bf A} ({\\bf w}-{\\bf m}_N) \\} d { \\bf w} \\\\ = \\exp\\{-E({\\bf m}_N)\\}(2\\pi)^{M/2}|{\\bf A}|^{-1/2}$$ 이를 이용하여 최종적으로 log marginal likelihood function을 구하면 $$\\ln p({\\bf t}|\\alpha, \\beta) = \\frac{M}{2}\\ln \\alpha + \\frac{N}{2}\\ln \\beta - E({\\bf m}_n) - \\frac{1}{2}\\ln |{\\bf A}| - \\frac{N}{2}\\ln(2\\pi)$$ ","date":"2021-11-26","objectID":"/prml-chap03-2/:3:1","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (2)","uri":"/prml-chap03-2/"},{"categories":["PRML"],"content":"3.5.2 Maximizing the evidence function $\\ln p({\\bf t} | \\alpha, \\beta)$을 최대화하는 $\\alpha, \\beta$를 구하기 위해 미분을 이용해보자. $(\\beta \\Phi^T \\Phi) {\\bf \\mu}_i = \\lambda_i{\\bf \\mu}_i$ 라고 하면 ${\\bf A}$의 eigenvalue는 $\\alpha + \\lambda_i$ 이다. 따라서 $$\\frac{d}{d\\alpha}\\ln |{\\bf A}| = \\frac{d}{d\\alpha}\\ln \\prod_{i}(\\lambda_i+\\alpha) = \\frac{d}{d\\alpha}\\sum_i \\ln(\\lambda_i+\\alpha) = \\sum_i \\frac{1}{\\lambda_i + \\alpha}$$ $\\alpha$에 대해 미분 $$0 = \\frac{M}{2\\alpha} - \\frac{1}{2}{\\bf m}_N^T{\\bf m}_N - \\frac{1}{2}\\sum_i \\frac{1}{\\lambda_i+\\alpha}$$ $$\\alpha {\\bf m} _ N^T {\\bf m} _ N = M - \\alpha \\sum_{i=1}^{M} \\frac{1}{\\lambda_i+\\alpha} = \\gamma$$ 이를 다시 정리하면 $$\\gamma = \\sum_{i=1}^{M} \\frac{\\lambda_i}{\\alpha + \\lambda_i}$$ 최종적으로 $\\alpha$에 대해 정리하면 $$\\alpha = \\frac{\\gamma}{ {\\bf m}_N^T{\\bf m}_N} $$ 그런데 $\\gamma, {\\bf m}_N$ 모두 $\\alpha$에 depend한다. 따라서 이를 위해서 iterative한 방법을 사용한다. 임의의 수로 $\\alpha$를 시작하고 $\\gamma, {\\bf m}_N$을 구한다. 다시 이 두 값으로 $\\alpha$를 구한다. 이렇게 수렴할 때까지 반복하는 것이다. $\\beta$에 대해 미분 $$\\frac{d}{d\\beta} \\ln |{\\bf A}| = \\frac{d}{d\\beta}\\sum_i \\ln(\\lambda_i+\\alpha) = \\frac{1}{\\beta}\\sum_i\\frac{\\lambda_i}{\\lambda_i+\\alpha} = \\frac{\\gamma}{\\beta}$$ $$0 = \\frac{N}{2\\beta} - \\frac{1}{2}\\sum_{n=1}^N{t_n-{\\bf m}_N^T\\phi({\\bf x}_n)}^2 - \\frac{\\gamma}{2\\beta} $$ $$\\frac{1}{\\beta} = \\frac{1}{N-\\gamma}\\sum_{n=1}^N {t_n-{\\bf m}_N^T\\phi({\\bf x}_N)}^2 $$ 이도 마찬가지도 iterative하게 구한다. cross validation과 같은 추가적인 computation이 없이 한 번에 train data set을 모두 이용하여 model complexity를 정할 수 있다 는 점을 기억하자. ","date":"2021-11-26","objectID":"/prml-chap03-2/:3:2","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (2)","uri":"/prml-chap03-2/"},{"categories":["PRML"],"content":"3.5.3 Effective number of parameters 이 부분은 ridge regression의 내용 (data의 고윳값이 작은 방향의 parameter가 0에 가까워진다) 과 같다. ESL 책의 linear regression부분을 보면 알 수 있다. $\\alpha$에 대한 Bayesian의 접근에 대해 조금 더 살펴보자. $\\beta \\Phi^T \\Phi$는 positive definite matrix이므로 eigenvalue가 모두 0이상의 값을 갖는다. 따라서 $0 \\le \\lambda_i /(\\lambda_i + \\alpha) \\le 1$ $0 \\le \\gamma \\le 1$ 임을 알 수 있다. $\\lambda_i » \\alpha$ 인 경우는 이에 해당하는 parameter $w_i$가 maximum likelihood의 값과 가까워지고 $\\lambda_i /(\\lambda_i + \\alpha)$ 이 1에 가까워진다. 반대의 경우는 $w_i, \\lambda_i /(\\lambda_i + \\alpha)$ 모두 0에 가까워진다. 따라서 $\\gamma$는 measures the effective total number of well determined parameters 다음은 $\\beta$에 대해 알아보자. 위에서 보았듯이 effective number of parameter는 $\\gamma$이고 나머지 $M-\\gamma$개의 parameters 들이 prior에 의해 작은 값을 갖는다. 이것이 variance에서 $\\frac{1}{N-\\gamma}$로 나타나고 bias of maximum likelihood result를 바로 잡아준다. 만약에 $N » M$의 상황인 경우, 대부분의 parameter들이 well determined될 것이고 data size에 따라 eigenvalue도 커지게 된다. 그러면 $\\gamma = M$이 되고 evidence approximation도 아래 값을 이용해 간단해진다. (data 많은게 짱이다) $$\\alpha = \\frac{M}{2E_W({\\bf m}_N)}$$ $$\\beta = \\frac{N}{2E_D({\\bf m}_N)}$$ ","date":"2021-11-26","objectID":"/prml-chap03-2/:3:3","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (2)","uri":"/prml-chap03-2/"},{"categories":["PRML"],"content":"3.6 Limitations of Fixed Basis Functions 장점 nonlinear basis functions의 linear combination이니까 해석이 쉽다. closed form의 해가 존재한다. 단점 basis function이 training data를 보기 전에 이미 fixed되서 시작한다. 차원의 저주 input간의 correlation 때문에 보다 작은 차원에 nonlinear manifold에 데이터가 분포할 수 있다. ","date":"2021-11-26","objectID":"/prml-chap03-2/:4:0","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (2)","uri":"/prml-chap03-2/"},{"categories":["PRML"],"content":"Regression에 대해 알아보자. 목표는 predictive distribution $p(t|x)$를 찾는 것 주로 loss funciton은 squared loss를 사용하며 이 때 optimal solution은 conditional expectation of t : $E[t|x]$ ","date":"2021-11-26","objectID":"/prml-chap03-1/:0:0","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (1)","uri":"/prml-chap03-1/"},{"categories":["PRML"],"content":"3.1 Linear Basis Function Models 가장 기본적인 linear model for regression은 $$y(x,w) = w_0+w_1x_1+…+w_D x_D$$ 의 형태일 것이다. 하지만 basis function $\\phi_ j(\\textbf{x})$을 이용하여 nonlinear의 성질을 추가할 수 있다. basis function은 다양하다. gaussian distribution의 형태 polynomial의 형태 원래의 input data를 마음대로 변화가능 $$y(\\textbf{w},\\textbf{x}) = w_0 + \\sum_{j=1}^{M-1}{w_j \\phi_j(\\textbf{x})} = \\textbf{w}^T {\\pmb \\phi}( \\textbf{x})$$ 하지만 여전히 linear model이다. 여기서 linear의 의미는 계수 w에 linear하다는 의미이기 때문이다. 그렇기에 여전히 interpretation에 대한 장점은 갖고 있다. 단점은 너무 단순하다는 것이다. ","date":"2021-11-26","objectID":"/prml-chap03-1/:1:0","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (1)","uri":"/prml-chap03-1/"},{"categories":["PRML"],"content":"3.1.1 Maximum likelihood and least sqaures $t$ : target variable $y(\\textbf{x}, \\textbf{w})$ : deterministic funciton $\\epsilon \\sim N(0, \\beta^{-1})$ : noise $$t = y(\\textbf{x}, \\textbf{w})+ \\epsilon$$ $$p(t | \\textbf{x},\\textbf{w},\\beta) = N(y(\\textbf{x}, \\textbf{w}), \\beta^{-1})$$ 위의 gaussian 가정에서는 parameter $w$를 추정할 때, likelihood를 이용하는 것과 least square의 방법을 이용하는 것이 똑같다. (그 과정은 직접 해보면 쉽게 파악가능, chapter1에도 있다) optimal prediction은 conditional mean of the target variable 이므로 unimodal이라는 한계가 존재 $$E[t | {\\bf x}] = \\int tp(t | {\\bf x})dt = y({\\bf x}, {\\bf w}) $$ 이제 likelihood function을 통해 MLE를 구하는 과정을 간단히 살펴보자. $$\\ln{p({\\bf t}|{\\bf w}, \\beta)} = \\sum_{n=1}^{N}\\ln{N( {\\bf w}^T{\\pmb \\phi}(x_n), \\beta^{-1})}\\\\ =\\dfrac{1}{2}\\ln{\\beta}-\\dfrac{1}{2}\\ln{2\\pi}-\\beta{E_D({\\bf w})}$$ $$E_D({\\bf w})=\\dfrac{1}{2}\\sum_{n=1}^{N}{t_n-{\\bf w}^T {\\pmb \\phi}(x_n)}^2$$ 위의 식을 미분하고 정리하면 ($\\Phi$ : N*M design matrix) normal equation을 얻는다. $${\\bf w}_{ML} = (\\Phi^T\\Phi)^{-1}\\Phi^T{\\bf t} $$ bias : $w_0 = \\bar{t} - \\sum_{j=1}^{M-1}{w_j \\bar{\\phi}_j}$ 실제 얻어지는 샘플들의 타겟 값들의 평균과, 이 때 basis function에 parameter를 곱하여 얻어진 결과의 평균값의 차이를 보정하는 역할 noise precision : $\\frac{1}{\\beta_{ML}} = \\frac{1}{N}\\sum_{n=1}^{N}{{ t_n - w_{ML}^T \\phi(x_n)}^2}$ ","date":"2021-11-26","objectID":"/prml-chap03-1/:1:1","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (1)","uri":"/prml-chap03-1/"},{"categories":["PRML"],"content":"3.1.2 Geometry of least squares least square의 방법에서 우리가 prediction한 값의 의미를 기하학적으로 살펴보자. 증명의 과정은 ESL에 잘 나와있다. 물론 봐도 이해하기는 어렵다. 결론만 언급하자면 “input vector가 span하는 space에 true t의 값을 orthorgonal하게 projection한 값이 우리가 예측한 t의 값이다” 추가적으로 multicolinearity에 대한 해결책으로는 PCA, SVD와 같은 방법으로 input들을 orthorgonal하게 만들어주는 것과 ridge regression과 같이 regulrarization 항이 있는 모델을 쓰는 것이다. ","date":"2021-11-26","objectID":"/prml-chap03-1/:1:2","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (1)","uri":"/prml-chap03-1/"},{"categories":["PRML"],"content":"3.1.3 Sequential learning 이 부분에서는 parameter를 최적화하는 과정에 있어서 gradient descent의 방법을 말하고 있다. 그게 Sequential하게 update하는 것이라 그런 것 같다. 데이터의 크기가 크면 normal equation의 방법이 오래걸리는 단점을 보완할 수도 있다. $$\\textbf{w}^{\\tau+1}=\\textbf{w}^{(\\tau)}+{\\eta}(t_n-{\\bf w}^{(\\tau)T}{\\pmb \\phi}_n) {\\pmb \\phi}_n$$ ","date":"2021-11-26","objectID":"/prml-chap03-1/:1:3","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (1)","uri":"/prml-chap03-1/"},{"categories":["PRML"],"content":"3.1.4 Regularized least squares 기존의 error function에 regularization term을 추가하여서 parameter shrinkage를 하고자 한다. 이를 통해 overfitting을 완화시킨다. lasso 같은 경우 sparse한 model을 만들어서 feature selection의 역할도 한다. regularized error takes the form 아래 식에서 q가 1이면 lasso, 2이면 ridge regression이다. $\\lambda$가 커질수록 model complexity가 낮아진다. $$\\frac{1}{2}\\sum_{n=1}^{N}{{t_n - \\textbf{w}^T{\\pmb \\phi}(x_n)}^2}+ \\frac{\\lambda}{2}\\sum_{j=1}^{M}{ \\left| \\textbf{w}_j\\right|^q }$$ ridge의 경우 error function이 $\\textbf{w}$에 대해 quadratic form이라서 closed form으로 solution이 존재한다. $$w_{ridge} = (\\Phi^T \\Phi + \\lambda I)^{-1}\\Phi^T t$$ ","date":"2021-11-26","objectID":"/prml-chap03-1/:1:4","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (1)","uri":"/prml-chap03-1/"},{"categories":["PRML"],"content":"3.2 The Bias-Variance Decomposition 모델링을 할 때 overfitting을 피하기 위해 제약을 두면 complexity를 못 잡을 수도 있다. 너무 모델을 복잡하게 하면 overfitting이 될 수도 있다. 이는 상당히 어려운 문제이다. 이 부분에 있어서 frequentist의 입장에서 바라보는 bias-variance trade off 관계를 공부하고자 한다. 이해를 위해 square loss (regression)의 경우의 예시를 살펴보자. square loss function 에서 optimal solution : $$E[t | \\textbf{x}] = \\int t p(t | \\textbf{x})dt = h(\\textbf{x})$$ expected squared loss : $$E[L] = \\int { y(\\textbf{x}) - h(\\textbf{x})}^2 p(\\textbf{x})d\\textbf{x} + \\int {h(\\textbf{x}) - t}^2 p(\\textbf{x},t)d\\textbf{x}dt$$ 우리는 우항의 첫번째를 최대한 작게하는 $y(\\textbf{x})$을 만들고자 한다. 위의 식에서 우항의 두번째는 우리가 줄일 수 없는 intrinsic noise이다. 첫 번째 항을 decompose 해보자. 일단 ${ y(\\textbf{x};D) - h(\\textbf{x})}^2$ 값은 특정한 dataset $D$에 대한 값이다. 이제 dataset이 여러개가 있다고 가정하고 이에 대해 average한 경우를 생각해보자. $E_D[y(\\textbf{x};D)]$ 을 더하고 빼서 $$E_D[{ y(\\textbf{x};D)-h(\\textbf{x}) }^2] =\\ {E_D[y(\\textbf{x};D)] -h(\\textbf{x})}^2+ E_D[{ y(\\textbf{x};D) - E_D[y(\\textbf{x};D)]}^2]$$ 이렇게 나타낼 수 있다. 즉, expected loss = (bias)^2 + variance +noise 인 것이다. bias 의미 : average prediction over all datasets 이 우리가 알고 싶은 true (regression) function과 차이나는 정도 variance 의미 : 해당 하나의 dataset이 average 와 차이나는 정도, function $y(\\textbf{x};D)$이 특정한 dataset에 얼마나 민감한지 이 둘은 trade-off 관계 : 한쪽이 커지면 한쪽이 작아진다. 하지만 이런 bias-variance의 관계는 average에 기반을 한 개념이기 때문에(bias, variance의 계산하는 과정이 D에 대해 평균) 한계점이 분명 존재 한다. 우리가 가지고 있는 데이터는 한정적이기 때문이다. 독립적인 데이터가 여러 개이면 각 데이터로 복잡한 모델을 만들어서 평균을 내면 좋은 결과를 얻을 수 있지만 우리는 데이터가 부족하다. 그래서 저자는 Bayesian 접근법을 소개한다. ","date":"2021-11-26","objectID":"/prml-chap03-1/:2:0","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (1)","uri":"/prml-chap03-1/"},{"categories":["PRML"],"content":"+ monk의 설명 정의 MSE of an estimate $\\hat{\\theta} = f(D)$ for $\\theta$ is $$MSE(\\hat{\\theta}) = E[(\\hat{\\theta} - \\theta)^2 | \\theta]$$ $bias(\\hat{\\theta}) = E[\\hat{\\theta}] - \\theta$ $var(\\hat{\\theta}) = E[(\\hat{\\theta}-E[\\hat{\\theta}])^2]$ $$MSE(\\hat{\\theta}) = bias^2(\\hat{\\theta}) + var(\\hat{\\theta})$$ (proof) let $\\mu = E[\\hat{\\theta}]$ $$E[(\\hat{\\theta} - \\theta)^2] = E[(\\hat{\\theta} - \\mu + \\mu -\\theta)^2] \\\\ = E[(\\hat{\\theta} - \\mu)^2 + 2(\\hat{\\theta} - \\mu)(\\mu - \\theta) + (\\mu - \\theta)^2] \\\\ = (\\mu - \\theta)^2 + E[(\\hat{\\theta}-\\mu)^2] \\quad \\because E[(\\hat{\\theta} - \\mu)(\\mu - \\theta)] = 0 $$ 쉬운 예시 $X \\sim N(\\theta,1)$ $\\theta$는 non random, unknown $\\hat{\\theta}_1 = X \\rightarrow bias^2 = 0, var = 1, MSE = 1$ $\\hat{\\theta}_2 = 0 \\rightarrow bias^2 = \\theta^2, var = 0, MSE = \\theta^2$ ","date":"2021-11-26","objectID":"/prml-chap03-1/:2:1","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (1)","uri":"/prml-chap03-1/"},{"categories":["PRML"],"content":"+ 문일철 교수님의 설명 Sources of Error in ML 크게 두 가지로 나눌 수 있다 : Approximation and generalization $E_{out} \\le E_{in} + \\Omega$ $E_{out}$ : estimation error $E_{in}$ : error from approximation by the learning algorithm $\\Omega$ : error caused by the variance of the observations 뒤에서 사용할 notation에 대해 알아보자. $f$ : the target function to learn (true function) $g$ : the learning function of ML $g^{(D)}$ : the learned function by using a dataset $\\bar{g}$ : the average hypothesis of a given infinite numbers of D ( $\\bar{g}(x) = E_D [g^{(D) } (x)]$ ) 하나의 dataset D에 대한 Error는 $$E_{out}[g^{(D)}(x)] = E_x[(g^{(D)}(x) - f(x))^2]$$ 그렇다면 expected error of the infinite dataset은 $$E_D [E_{out}[g^{(D)}(x)] ] = E_D [E_x[(g^{(D)}(x) - f(x))^2]] = E_x [E_D[(g^{(D)}(x) - f(x))^2]]$$ 일단 안쪽에 있는 term부터 확인해보자. $$E_D[(g^{(D)}(x) - f(x))^2] = E_D [( g^{(D)}(x) - \\bar{g}(x) + \\bar{g}(x) - f(x) )^2]$$ $$= E_D [(g^{(D)}(x) - \\bar{g}(x) )^2] + (\\bar{g}(x) - f(x))^2$$ $$\\therefore E_D [E_{out}[g^{(D)}(x)] ] = E_D [(g^{(D)}(x) - \\bar{g}(x) )^2] + (\\bar{g}(x) - f(x))^2 $$ 여기서 우리는 variance와 bias를 정의할 수 있는데 $Var = E_D [(g^{(D)}(x) - \\bar{g}(x) )^2]$ $Bias^2 = (\\bar{g}(x) - f(x))^2$ 이들이 의미하는 바는 var는 제한적인 dataset 때문에 model을 average hypothesis로 훈련시킬 수 없는 부분을 의미 bias는 average hypothesis조차도 (true) real world hypothesis를 맞출수 없는 부분을 의미 그렇다면 var과 bias를 줄이기 위해서는? var를 줄이기 위해서는 data를 더 모은다. bias를 줄이기 위해서는 더 복잡한 model을 사용한다. 하지만 문제는 var와 bias는 trade-off 관계를 가진다. 예를 들어, 우리가 갖고 있는 dataset에 잘 맞는 복잡한 모델을 사용하면 평균적인 모델과는 차이가 커질 것이다. 간단한 model은 낮은 variance, 높은 bias를 갖는다. 복잡한 model은 높은 variance, 낮은 bias를 갖는다. 따라서 적잘한 model을 만드는 것이 관건이다. Occam’s Razor 같은 error를 갖는 모델이라면 둘 중 더 간단한 모델을 선택하라! ","date":"2021-11-26","objectID":"/prml-chap03-1/:2:2","tags":["Regression"],"title":"[PRML] Chapter3 - Linear Models For Regression (1)","uri":"/prml-chap03-1/"},{"categories":["PRML"],"content":"Exponential Family와 Nonparametric 방법론에 대해 알아보자. ","date":"2021-11-26","objectID":"/prml-chap02-4/:0:0","tags":["Exponential Family","Non parametric"],"title":"[PRML] Chapter2 - Probability Distribution (4)","uri":"/prml-chap02-4/"},{"categories":["PRML"],"content":"2.4 The Exponential Family 우리가 이전에 공부했던 대부분의 distribution은 Exponential Family에 속한다. The exponential family of distribution over $x$, given parameters $\\eta$, is defined to be the set of distributions of the form $$p({\\pmb x} | {\\pmb \\eta}) = h({\\pmb x})g({\\pmb \\eta}) \\exp ({\\pmb \\eta}^T u({\\pmb x}))$$ pdf(pmf) $p({\\pmb x} | {\\pmb \\eta})$ 을 우항과 같이 표현할 수 있다면 exponential family에 속한다. ${\\pmb x}$는 스칼라, 벡터 둘 다 가능하고 discrete, continous 모두 가능하다. ${\\pmb \\eta}$ 는 natural parameter of the distribution 이라고 한다. $g(\\pmb \\eta)$는 distribution의 normalize coefficient (적분해서 1이 되도록 만들어주는) 라고 할 수 있다. $$g({\\pmb \\eta}) \\int h({\\pmb x})\\exp{ {\\pmb \\eta}^T{\\pmb u} ({\\pmb x}) } d {\\pmb x}=1 $$ Bernoulli distribution 예시 $p(x | \\mu) = Bern(x | \\mu)=\\mu^x(1-\\mu)^{1-x}$ 이를 exponential form으로 표현해보자. $f(x)=\\exp(\\ln{f(x)})$ 을 이용하여 $$p(x | \\mu) = \\exp {x \\ln \\mu + (1-x) \\ln (1-\\mu) } \\\\ = (1-\\mu) \\exp \\{ \\ln \\left( \\frac{\\mu}{1-\\mu} \\right) x \\} \\\\ \\therefore \\eta = \\ln\\left(\\frac{\\mu}{1-\\mu}\\right) $$ 위의 형태를 $\\mu$에 대한 식으로 바꿔보면 $$\\mu=\\sigma(\\eta)=\\dfrac{1}{1+\\exp(-\\eta)} $$ 위의 식과 같은 형태의 함수를 logistic sigmoid function이라고 부른다. Multinomial distribution 예시 $p({\\pmb x} | {\\pmb \\mu}) = \\prod_{k=1}^{M}\\mu_k^{x_k}= \\exp [\\sum_{k=1}^{M}x_k \\ln \\mu_k]$ $p({\\pmb x}|{\\pmb \\eta})=\\exp({\\pmb \\eta}^T{\\pmb x})$ $\\eta_k = \\ln \\mu_k$ ${\\pmb \\eta} = (\\eta_1, \\eta_2,…,\\eta_k)^T$ M개의 parameter가 있지만 $\\sum_{k=1}^{M}{\\mu_k}=1$ 이라는 제약때문에 M-1개의 값이 정해지면 마지막 M개는 저절로 정해진다. 이를 이용할 것이다. $$\\exp \\{\\sum_{k=1}^{M}x_k\\ln\\mu_k \\} = \\exp \\{\\sum_{k=1}^{M-1}x_k\\ln\\mu_k + \\left(1-\\sum_{k=1}^{M-1}x_k\\right)\\ln\\left(1-\\sum_{k=1}^{M-1}\\mu_k\\right) \\}\\\\ = \\exp\\{\\sum_{k=1}^{M-1}x_k\\ln\\left(\\frac{\\mu_k}{1-\\sum_{j=1}^{M-1}\\mu_j}\\right)+\\ln\\left(1-\\sum_{k=1}^{M-1}\\mu_k\\right)\\}$$ $$\\therefore \\eta_k = \\ln\\left(\\frac{\\mu_k}{1-\\sum_{j \\neq k} \\mu_j}\\right)$$ 똑같이 $$\\mu_k=\\dfrac{\\exp(\\eta_k)}{1+\\sum_{j \\neq k}\\exp(\\eta_j)}$$ 위의 식과 같은 형태의 함수를 softmax function (normalized exponential) 이라고 부른다. ","date":"2021-11-26","objectID":"/prml-chap02-4/:1:0","tags":["Exponential Family","Non parametric"],"title":"[PRML] Chapter2 - Probability Distribution (4)","uri":"/prml-chap02-4/"},{"categories":["PRML"],"content":"2.4.1 Maximum likelihood and sufficient statistics $\\eta$가 어떤 것인지 알았으니 이제 이를 MLE로 estimate해보자. exponential form을 $\\eta$에 대해 미분하면 $$\\nabla g({\\pmb \\eta})\\int h({\\pmb x})\\exp{ {\\pmb \\eta}^T {\\pmb u}({\\pmb x})}d{\\pmb x} + g({\\pmb \\eta})\\int h({\\pmb x})\\exp{ {\\pmb \\eta}^T{\\pmb u}({\\pmb x})}{\\pmb u}({\\pmb x})d{\\pmb x} = 0$$ $g({\\pmb \\eta}) \\int h({\\pmb x})\\exp{ {\\pmb \\eta}^T{\\pmb u} ({\\pmb x}) } d {\\pmb x}=1$ 을 이용하여 $$-\\frac{1}{g({\\pmb \\eta})} \\nabla g({\\pmb \\eta}) = g({\\pmb \\eta})\\int h({\\pmb x})\\exp{ {\\pmb \\eta}^T{\\pmb u}({\\pmb x})}{\\pmb u}({\\pmb x})d{\\pmb x}=E[{\\pmb u}({\\pmb x})]$$ 최종적으로는 $$-\\nabla \\ln g({\\pmb \\eta}) = E[{\\pmb u}({\\pmb x})] $$ 이제 iid인 data를 통해 likelihood function을 만들면 $$p({\\pmb X}|{\\pmb \\eta}) = \\left(\\prod_{n=1}^{N}h({\\pmb x} _ n)\\right) g({\\pmb \\eta})^N \\exp\\{ {\\pmb \\eta}^T\\sum_{n=1}^{N}{\\pmb u}({\\pmb x}_n)\\} $$ log를 취한 뒤에 $\\eta$에 대해 미분하여 0을 갖도록 하면 아래와 같은 식을 얻을 수 있다. $$-\\nabla \\ln g({\\pmb \\eta} _ {ML}) = \\frac{1}{N}\\sum_{n=1}^{N}{\\pmb u}({\\pmb x}_n)$$ 이를 통해 우리는 MLE solution이 오직 $\\sum_{n=1}^{N} \\textbf{u}(\\textbf{x}_n)$에 달려 있다는 것을 알 수 있다. 이는 sufficient statistics of the distribution 이라고 부른다. parameter에 대한 정보가 여기 다 들어 있어서 충분하다! 라고 이해할 수 있다. 따라서 우리는 MLE를 구하는 과정에 있어서 각 data를 모두 알고 있을 필요가 없이 충분통계량만 알면 된다. $N \\rightarrow \\infty$이면 우항은 $E[\\textbf{u}(\\textbf{x})]$이 되고 ${\\pmb \\eta}_{ML}$은 true값으로 수렴한다는 것을 알 수 있다. ","date":"2021-11-26","objectID":"/prml-chap02-4/:1:1","tags":["Exponential Family","Non parametric"],"title":"[PRML] Chapter2 - Probability Distribution (4)","uri":"/prml-chap02-4/"},{"categories":["PRML"],"content":"2.4.2 Conjugate priors exponential family인 prior distribution은 $$p({\\pmb \\eta} | {\\pmb \\chi}, v) = f({\\pmb \\chi}, v)g({\\pmb \\eta})^v \\exp\\{v{\\pmb \\eta}^T{\\pmb \\chi}\\}$$ 여기에 위에서 보았던 likelihood function을 곱하여 posterior distribution을 구하면 $$p({\\pmb \\eta}|{\\pmb X}, {\\pmb \\chi}, v) \\propto g({\\pmb \\eta})^{v+N}\\exp\\{ {\\pmb \\eta}^T\\left(\\sum_{n=1}^{N}{\\pmb u}({\\pmb x})+v{\\pmb \\chi}\\right)\\}$$ conjugacy를 확인할 수 있다. 또한 parameter $v$는 effective nunber of pseudo-observation 이라고 이해할 수 있다. ","date":"2021-11-26","objectID":"/prml-chap02-4/:1:2","tags":["Exponential Family","Non parametric"],"title":"[PRML] Chapter2 - Probability Distribution (4)","uri":"/prml-chap02-4/"},{"categories":["PRML"],"content":"2.4.3 Noninformative priors posterior를 만들기 위해 사전의 정보가 충분하면 상관없지만 그렇지 않은 경우, 우리는 prior의 영향을 최소화하고 싶을 것이다. 이런 prior를 Noninformative prior 라고 부른다. $p(x|\\lambda)$ distribution이 있을 때, prior distribution $p(\\lambda)=\\text{const}$ 가 적절한 prior가 될 것이다. 만약에 $\\lambda$가 $K$ states를 갖는 discrete이면 prior 는 $1/K$로 하면 된다. 하지만 continous하고 domain이 unbounded하면 prior distribution은 합이 1이 되지 않는다 (integral diverge, not correctly normalized). 이런 prior를 improper prior 라고 한다. 적분값이 1이 아닌 diverge하는 모든 분포에 해당하는 것은 아니다. prior는 improper해도 posterior는 적절한 pdf가 되어야 한다. ","date":"2021-11-26","objectID":"/prml-chap02-4/:1:3","tags":["Exponential Family","Non parametric"],"title":"[PRML] Chapter2 - Probability Distribution (4)","uri":"/prml-chap02-4/"},{"categories":["PRML"],"content":"2.5 Nonparametric Methods 말 그대로 비모수적인 방법들이다. 이전까지는 parameter를 추정하여 density를 추정하였다면 아래의 방법들은 parameter를 추정할 필요가 없는 data oriented한 방법이라고 생각할 수 있다. ","date":"2021-11-26","objectID":"/prml-chap02-4/:2:0","tags":["Exponential Family","Non parametric"],"title":"[PRML] Chapter2 - Probability Distribution (4)","uri":"/prml-chap02-4/"},{"categories":["PRML"],"content":"Histogram 주로 같은 크기의 bin으로 해당 data를 나눈 뒤에 해당 bin에 들어가는 data의 수를 통해 density를 파악한다. 기본적인 것으로 저차원에서 시각화용으로만 사용해야 할 것 같다. (Probability 식) : x를 크기 $\\Delta$로 나누고 각 bin i에 들어가는 data의 수를 $n_i$라고 하면 각 bin i의 확률값은 (각 bin의 넓이는 $\\frac{n_i}{N} * \\Delta$ 이고 histogram 전체 넓이는 1이라) $$p_i = \\frac{n_i}{N \\Delta}$$ density는 bin의 크기가 커질수록 smooth해지고 작아질수록 복잡해진다. ","date":"2021-11-26","objectID":"/prml-chap02-4/:2:1","tags":["Exponential Family","Non parametric"],"title":"[PRML] Chapter2 - Probability Distribution (4)","uri":"/prml-chap02-4/"},{"categories":["PRML"],"content":"Kernel density estimators D-dimension의 probability density $p({\\pmb x})$ 있고 우리는 이 값을 추정하려고 한다. data set은 이 분포에서 나온 $N$개의 observation $R$은 data가 들어있는 어떤 지역 이 지역의 probability mass는 $$P=\\int_R p({\\pmb x})d{\\pmb x}$$ 여기서 이 지역에 들어가는 data의 수는 $K$라고 하면 이는 binomial distribution을 따를 것이다. $$Bin(K/N, P) = \\dfrac{N!}{K!(N-K)!}P^K(1-P)^{1-K}$$ data의 수 $N$이 커지면 $K \\approx NP$일 것이다. $R$이 충분히 작아서 density $p({\\pmb x})$는 해당 지역에서 거의 constant하면 $P \\approx p({\\pmb x}) V$ 임을 알 수 있다. ($V$는 volume of $R$) 따라서 density estimate하면 $$p({\\pmb X}) = \\frac{K}{NV}$$ $V$를 fix : Kernel approach $K$를 fix : K-nearest-neighbour 조금 더 자세히 살펴보자. $R$을 우리가 구하고 싶은 probability density의 point ${\\pmb x}$가 가운데에 있는 작은 hypercube라고 하자. 해당 지역에 들어있는 data 수 $K$를 위해 다음과 같은 함수를 생각해보자. 이 함수는 kernel function 의 한 예시이다. 따라서 $$K = \\sum_{n=1}^{N}k\\left(\\frac{ {\\pmb x}-{\\pmb x}_n}{h}\\right) $$ 이를 이용하여 density at ${\\pmb x}$를 구하면 $$p({\\pmb x}) = \\frac{1}{N}\\sum_{n=1}^{N}\\frac{1}{h^D}k\\left(\\frac{ {\\pmb x}-{\\pmb x}_n}{h}\\right)$$ $v = h^D$ 위 식은 함수 $k({\\pmb u})$의 대칭성을 생각하여, single cube centered on ${\\pmb x}$가 아니라 N cubes centered on the N data point ${\\pmb x_n}$ 이라고 이해할 수 있다. 하지만 이는 여전히 불연속적인 단점이 있기에 좀 더 업그레이드해보자. kernel function을 Gaussian으로 정하면 $$p({\\pmb x}) = \\frac{1}{N}\\sum_{n=1}^N\\frac{1}{(2\\pi h^2)^{D/2}}\\exp\\{-\\frac{|{\\pmb x}-{\\pmb x}_n|^2}{2h^2}\\}$$ kernel function은 다양하게 정할 수 있다. 단, 조건은 $k(x) \\ge 0$ $\\int k(x)dx = 1$ density는 h가 커지면 smooth해지고 h가 작아지면 더 복잡해진다. 우리는 적절하나 h를 잘 찾아야 하는데 이미 최선의 h는 밝혀져 있다. 아울러 가장 좋은 kernel function도 이미 밝혀져있다. ","date":"2021-11-26","objectID":"/prml-chap02-4/:2:2","tags":["Exponential Family","Non parametric"],"title":"[PRML] Chapter2 - Probability Distribution (4)","uri":"/prml-chap02-4/"},{"categories":["PRML"],"content":"Nearest-neighbour methods 이번에는 $K$를 미리 정한 뒤에 이에 적절한 $V$를 찾는 것이다. density는 $K$가 커지면 smooth해지고 작아지면 복잡해진다. KNN classification이 잘 알려져있다. 지금까지 Nonparametric 방법론을 살펴보았다. 전체 data를 저장하고 있어야 하는 단점이 존재한다. data가 너무 많으면 계산에 어려움이 생기고 너무 적으면 다소 부정확한 근사치를 만들 수 있다. ","date":"2021-11-26","objectID":"/prml-chap02-4/:2:3","tags":["Exponential Family","Non parametric"],"title":"[PRML] Chapter2 - Probability Distribution (4)","uri":"/prml-chap02-4/"},{"categories":["PRML"],"content":"Gaussian Distribution과 관련한 내용을 알아보자. ","date":"2021-11-26","objectID":"/prml-chap02-3/:0:0","tags":["Gaussian Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (3)","uri":"/prml-chap02-3/"},{"categories":["PRML"],"content":"2.3.6 Bayesian inference for the Gaussian 이번에는 Bayesian의 방법으로 접근해보자. $\\sigma^2$ is known, inferring the mean $\\mu$ likelihood function은 $$p({\\bf x} | \\mu) = \\prod_{n=1}^{N}p(x_n | \\mu) = \\dfrac{1}{(2\\pi\\sigma^2)^{N/2}}\\exp \\{-\\frac{1}{2\\sigma^2}\\sum_{n=1}^{N}(x_n-\\mu)^2 \\}$$ Gaussian의 conjugate prior는 Gaussian이다. 따라서 prior distribution은 $$p(\\mu) = N(\\mu | \\mu_0, \\sigma_0^2)$$ posterior distribution은 $$p(\\mu |{\\bf x}) \\propto p({\\bf x}|\\mu)p(\\mu) = N(\\mu | \\mu_N, \\sigma_N^2)$$ $\\mu_N = \\frac{\\sigma^2}{N\\sigma_0^2+\\sigma^2}\\mu_0 + \\frac{N\\sigma_0^2}{N\\sigma_0^2+\\sigma^2}\\mu_{ML}$ $\\frac{1}{\\sigma_N^2}=\\frac{1}{\\sigma_0^2}+\\frac{N}{\\sigma^2}$ 위의 결론을 통해 평균과 분산에 대해 좀 더 살펴보자. posterior mean prior mean $\\mu_0$ 와 MLE solution $\\mu_{ML}$ 사이의 값을 갖는다. $N=0$이면 prior mean쪽으로 $N \\rightarrow \\infty$이면 MLE solution쪽을 가까워 진다. posterior variance 해석의 편의를 위해 precision으로 표현하였다. data의 수가 늘어날수록 precision이 커지고 따라서 posterior variance는 작아진다. $N=0$이면 prior variance의 값과 같다. $N \\rightarrow \\infty$이면 variance가 0으로 가까워진다. 이번에는 $\\mu$ is known, inferring the variance $\\sigma^2$ $$p({\\bf x} | \\lambda) = \\prod_{n=1}^{N} N(x_n | \\mu, \\lambda^{-1}) \\propto \\lambda^{N/2} \\exp \\{ -\\frac{\\lambda}{2} \\sum_{n=1}^{N}(x_n-\\mu)^2 \\}$$ precision의 posterior의 conjugate prior는 gamma distribution이다. $$Gam(\\lambda | a,b)=\\frac{1}{\\Gamma(a)}b^a\\lambda^{a-1}\\exp(-b\\lambda) $$ 이를 이용하여 posterior를 구하면 $$p({\\bf x} | \\lambda) \\propto \\lambda^{a_0-1}\\lambda^{N/2} \\exp \\{-b_0\\lambda-\\frac{\\lambda}{2}\\sum_{n=1}^{N}(x_n-\\mu)^2\\}$$ $a_N = a_0 + \\frac{N}{2}$ $b_N = b_0 + \\frac{1}{2}\\sum_{n=1}^{N}(x_n-\\mu)^2 = b_0 + \\frac{N}{2}\\sigma_{ML}^2$ precision이 아닌 covariance를 바로 이용하는 경우 gamma distribution이 아니라 inverse gamma distribution을 이용한다. 이번에는 $\\mu, \\sigma^2$ 둘 다 모른다고 하자 $$p({\\bf x} | \\mu, \\lambda) = \\prod_{n=1}^{N} (\\frac{\\lambda}{2\\pi} )^{1/2} \\exp \\{-\\frac{\\lambda}{2}(x_n-\\mu)^2\\} \\\\ \\propto [\\lambda^{1/2}\\exp (-\\frac{\\lambda\\mu^2}{2})]^N\\exp\\{\\lambda\\mu\\sum_{n=1}^{N}x_n-\\frac{\\lambda}{2}\\sum_{n=1}^{N}x_n^2\\} $$ parameter가 2개이기에 prior가 $p(\\mu, \\lambda)$일 것이다. likelihood function의 모양과 $p(\\mu, \\lambda) = p(\\mu |\\lambda)p(\\lambda)$를 이용하면 Normal-Gamma distribution $$p(\\mu, \\lambda) = N(\\mu|\\mu_0, (\\beta\\lambda)^{-1})Gam(\\lambda|a,b) $$ 을 구할 수 있다. independent한 두 식을 곱한게 아니다. Normal의 precision이 $\\lambda$에 dependent하다. D-dimension인 경우, Wishart distribution을 이용한다. ","date":"2021-11-26","objectID":"/prml-chap02-3/:0:1","tags":["Gaussian Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (3)","uri":"/prml-chap02-3/"},{"categories":["PRML"],"content":"2.3.7 Student’s t-distribution 위에서 gaussian precision과 관련하여 gamma prior을 이용했다. 이때 $x$에 대한 marginal distribution을 구해보자. $$p(x/\\mu,a,b) = \\int_{0}^{\\infty}N(x/\\mu, \\tau^{-1})Gam(\\tau/a,b)d\\tau \\\\ =\\int_{0}^{\\infty}\\frac{b^a e^{(-b\\tau)}\\tau^{(a-1)}}{\\Gamma(a)}(\\frac{\\tau}{2\\pi})^{1/2}\\exp \\{-\\frac{\\tau}{2}(x-\\mu)^2 \\}d\\tau \\\\ = \\frac{b^a}{\\Gamma(a)}(\\frac{1}{2\\pi})^{1/2}[b+\\frac{(x-\\mu)^2}{2}]^{-a-1/2}\\Gamma(a+1/2) $$ $z = \\tau[b+(x-\\mu)^2/2]$로 놓고 식을 전개하면 $$St(x/\\mu,\\lambda,v) = \\frac{\\Gamma(v/2+1/2)}{\\Gamma(v/2)}\\left(\\frac{\\lambda}{\\pi v}\\right)^{1/2}\\left[1+\\frac{\\lambda(x-\\mu)^2}{v}\\right]^{-v/2-1/2} $$ 이를 Student’s t-distribution 이라고 한다. $v$는 자유도이며 이 값이 무한대로 갈수록 gaussian distribution에 가까워진다. 이 분포의 특징 중 하나는 robustness 라는 것이다. 분포모양이 gaussian distribution과 비슷하지만 (좌우대칭) 더 긴 꼬리를 갖고 있다. 이 때문에 outlier(이상치)에 대해 덜 민감하다. ","date":"2021-11-26","objectID":"/prml-chap02-3/:0:2","tags":["Gaussian Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (3)","uri":"/prml-chap02-3/"},{"categories":["PRML"],"content":"2.3.8 Periodic variables skip ","date":"2021-11-26","objectID":"/prml-chap02-3/:0:3","tags":["Gaussian Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (3)","uri":"/prml-chap02-3/"},{"categories":["PRML"],"content":"2.3.9 Mixtures of Gaussians mixture distribution : linear combination of basic distribution K개의 gaussian distribution을 중첩하면 $$p({\\bf x}) = \\sum_{k=1}^{K}\\pi_k N({\\bf x} | {\\bf \\mu}_k, \\Sigma_k) $$ 이를 Mixture of Gaussian 이라고 부른다. 이 때 각 $N({\\bf x} | {\\bf \\mu}_k, \\Sigma_k)$ 는 component, $\\pi_k$는 mixing coefficients 라고 부른다. $\\pi_k$은 0과 1 사이의 값을 갖고 합이 1이다. 따라사 이를 확률로 이해할 수 있다. 이를 통해 다시 marginal distribution을 전개하면 $$p({\\bf x}) = \\sum_{k=1}^{K}p(k)p({\\bf x}|k)$$ 그렇다면 이제 parameter 추정을 해보자. prameter는 $\\pi, \\mu,\\Sigma$ $$\\ln p({\\bf X}|{\\bf \\pi}, {\\bf \\mu}, \\Sigma) = \\sum_{n=1}^{N}\\ln \\{\\sum_{k=1}^{K} \\pi_k N({\\bf x}_n|{\\bf \\mu}_k, \\Sigma_k) \\}$$ 위의 식에서 MLE를 구하기는 쉽지 않다. log 안에 summation이 있기 때문이다. (미분이 어려움) 이를 구하는 방법은 EM algorithm이다. 나중에 배운다. ","date":"2021-11-26","objectID":"/prml-chap02-3/:0:4","tags":["Gaussian Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (3)","uri":"/prml-chap02-3/"},{"categories":["PRML"],"content":"Gausisan distribution의 성질을 알아보자. ","date":"2021-11-26","objectID":"/prml-chap02-2/:0:0","tags":["Gaussian Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (2)","uri":"/prml-chap02-2/"},{"categories":["PRML"],"content":"2.3 Gaussian distribution Multivariate Gaussian distribution D 차원의 vector $\\textbf{x}$에 대한 distribution entropy가 가장 큰 분포가 gaussian이고 multivariate gaussian도 해당한다. ${\\Sigma}$ : D*D의 covariance matrix $$N(\\pmb{x} | \\pmb{\\mu}, \\pmb{\\Sigma}) = \\frac{1}{(2\\pi)^{D/2}} \\frac{1}{ | \\pmb{\\Sigma} |^{1/2} } \\exp{ -\\frac{1}{2}(\\pmb{x} - \\pmb{\\mu})^T \\pmb{\\Sigma}^{-1}(\\pmb{x} - \\pmb{ \\mu})}$$ Gaussian distribution은 상당히 중요한 특징들을 갖고 있다 하나씩 살펴보자. $$\\Delta^2 = ({\\bf x}-{\\pmb \\mu})^T{\\bf \\Sigma}^{-1}({\\bf x}-{\\pmb \\mu}) $$ $\\Delta$ : Mahalanobis distance from $\\pmb{\\mu}$ to $\\textbf{x}$ $\\pmb{\\Sigma}$가 identity이면 Euclidean distance $\\pmb{\\Sigma}$는 (실수)대칭행렬이므로 고윳값이 실수 고유벡터들은 orthonomal하게 가능 고유대각화가 가능하고 아울어 직교대각화가 가능하다. $${\\bf \\Sigma}=\\sum_{i=1}^{D}{\\pmb \\Lambda}_i{\\bf u}_i{\\bf u}_i^T = U{\\pmb \\Lambda} U^{-1}$$ $${\\bf \\Sigma}^{-1}=\\sum_{i=1}^{D}\\dfrac{1}{\\pmb \\Lambda}_i{\\bf u}_i{\\bf u}_i^T = U {\\pmb \\Lambda}^{-1} U^{-1}$$ 이를 위에 대입하면 $$\\Delta^2 = \\sum_{i=1}^{D}\\frac{y_i^2}{\\pmb \\Lambda}_i $$ $y_i={\\bf u}_i^T({\\bf x}-{\\pmb \\mu})$ 우리는 ${y_i}$를 orthonomal vector $\\textbf{u}_i$에 의해 새롭게 정의된 coordinate system이라고 이해할 수 있다. multivariate gaussian의 평균과 분산은 $E[\\textbf{x}] = {\\pmb \\mu}$ $cov[\\textbf{x}] = {\\pmb \\Sigma}$ : 공분산행렬 (covariance matrix) multivariate gaussian은 유용한 분포지만 한계점도 있다. 공분산행렬의 parameter 개수 공분산행렬의 parameter는 $D(D+3)/2$ 개 이다. 차원이 커짐에 따라 parameter가 quadratic하게 커진다. 이를 위한 해결책은 2가지가 있는데 공분산행렬은 대각행렬로 생각한다. 즉, ${\\pmb \\Sigma} = diag(\\sigma_i^2)$ 공분산행렬을 isotropic covariance로 만든다. 즉, ${\\pmb \\Sigma} = \\sigma^2{\\pmb I}$ 물론 이런 제약이 생기면 data간의 correlation을 못 잡는 경우가 발생한다. gaussian은 unimodal 하기에 multimodal distribution을 잘 approximation하기 어렵다. 이에 대해 해결책은 나중에 뒤에서 배운다. (Mixture 등등) ","date":"2021-11-26","objectID":"/prml-chap02-2/:1:0","tags":["Gaussian Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (2)","uri":"/prml-chap02-2/"},{"categories":["PRML"],"content":"2.3.1 Conditional Gaussian distributions conditional distribution의 경우를 살펴보자. $\\textbf{x}$는 Gaussian distribution $N(\\textbf{x} | {\\pmb \\mu, \\Sigma})$의 D-차원 vector이다. 이를 두 부분으로 나누어 $\\textbf{x}_a, \\textbf{x}_b$ 라고 하자. D*D covariance matrix는 대칭행렬이다. $$\\textbf{x} = \\begin{pmatrix} \\textbf{x}_a \\\\ \\textbf{x}_b \\end{pmatrix}, {\\pmb \\mu} = \\begin{pmatrix} {\\pmb \\mu}_a \\\\ {\\pmb \\mu}_b \\end{pmatrix}$$ $${\\pmb \\Sigma} = \\begin{pmatrix} \\Sigma_{aa} \u0026 \\Sigma_{ab} \\\\ \\Sigma_{ba} \u0026 \\Sigma_{bb} \\end{pmatrix}$$ precision matrix $${\\pmb \\Lambda} \\equiv {\\pmb \\Sigma}^{-1} = \\begin{pmatrix} {\\pmb \\Lambda} _ {aa} \u0026 {\\pmb \\Lambda} _ {ab} \\\\ {\\pmb \\Lambda} _ {ba} \u0026 {\\pmb \\Lambda}_{bb} \\end{pmatrix}$$ 이제 우리는 conditional distribution $p(\\textbf{x}_a | \\textbf{x}_b)$ 을 살펴보자. (gaussian은 quadratic form in the exponent를 주의깊게 살펴보자) $\\textbf{x}_b$는 fixed 되었으며 exp 안의 부분을 나눠서보면 $$-\\frac{1}{2}({\\bf x}-{\\pmb \\mu})^T\\Sigma^{-1}({\\bf x}-{\\pmb \\mu})=$$ $$ -\\frac{1}{2}({\\bf x}_a - {\\pmb \\mu}_a)^T{\\pmb \\Lambda} _ {aa}({\\bf x}_a-{\\pmb \\mu}_a) - \\frac{1}{2}({\\bf x}_a - {\\pmb \\mu}_a)^T {\\pmb \\Lambda} _ {ab}({\\bf x}_b-{\\pmb \\mu}_b)$$ $$-\\frac{1}{2}({\\bf x}_b-{\\pmb \\mu}_b)^T{\\pmb \\Lambda} _ {ba}({\\bf x}_a-{\\pmb \\mu}_a) - \\frac{1}{2}({\\bf x}_b - {\\pmb \\mu}_b)^T{\\pmb \\Lambda} _ {bb}({\\bf x}_b-{\\pmb \\mu}_b) $$ 위 식을 보면 $\\textbf{x}_a$ 에 대한 함수이고 quadratic form 임을 알 수 있다. 즉 conditional dist는 Gaussian인 것이다. 이제 평균과 분산을 구하는 과정을 살펴보자. 먼저, $\\textbf{x}_a$의 second order인 부분을 먼저보면 $$-\\frac{1}{2}\\textbf{x}^T_a {\\pmb \\Lambda}_{aa} \\textbf{x}_a$$ 따라서 우리는 conditional distribution $p(\\textbf{x}_a | \\textbf{x}_b)$의 covariance 가 $${\\pmb \\Sigma_{a|b} = {\\pmb \\Lambda}_{aa}^{-1}}$$ 임을 알 수 있다. 다음은 $\\textbf{x}_a$에 linear한 부분을 보면 $$\\textbf{x}_a^T { {\\pmb \\Lambda} _ {aa} {\\pmb \\mu}_a - {\\pmb \\Lambda} _ {ab}(\\textbf{x}_a - {\\pmb \\mu}_b)}$$ 이를 이용하여 우리는 평균을 구할 수 있다. $${\\pmb \\mu} _ {a|b} = {\\pmb \\Sigma}_{a|b} [ {\\pmb \\Lambda} _ {aa}{\\pmb \\mu}_a - {\\pmb \\Lambda} _ {ab}({\\bf x}_b-{\\pmb \\mu}_b) ] = {\\pmb \\mu}_a -{\\pmb \\Lambda} _ {aa}^{-1}{\\pmb \\Lambda} _ {ab}({\\bf x}_b-{\\pmb \\mu}_b) $$ 다음으로 공분산행렬을 구하면 $${\\pmb \\Sigma}_{a|b} = {\\pmb \\Sigma} _ {aa} - {\\pmb \\Sigma} _ {ab}{\\pmb \\Sigma} _ {bb}^{-1}{\\pmb \\Sigma} _ {ba} $$ [참고] 아래의 공식을 이용하여 구한다. $$$$ $$M = (A-BD^{-1}C)^{-1} $$ 결론 : conditional distribution도 Gaussian distribution이다 mean은 linear function of $\\textbf{x}_b$ covariance은 independent of $\\textbf{x}_b$ ","date":"2021-11-26","objectID":"/prml-chap02-2/:1:1","tags":["Gaussian Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (2)","uri":"/prml-chap02-2/"},{"categories":["PRML"],"content":"2.3.2 Mariginal Gaussian distributions $$p({\\bf x}_a) = \\int p({\\bf x}_a, {\\bf x}_b)d{\\bf x}_b $$ joint distribution에서 integrate out $x_b$하면 된다. 이번에도 마찬가지로 quadratic form을 이용하여 문제를 해결한다. 위에서 봤던 joint distribution의 exp부분을 이번에는 $\\textbf{x}_b$에 대해 전개하면 $$-\\dfrac{1}{2}{\\bf x}_b^{T}{\\pmb \\Lambda} _ {bb}{\\bf x}_b + {\\bf x}_b^T{\\bf m} = -\\dfrac{1}{2}({\\bf x}_b- {\\pmb \\Lambda} _ {bb}^{-1}{\\bf m})^T {\\pmb \\Lambda} _ {bb}({\\bf x}_b- {\\pmb \\Lambda} _ {bb}^{-1}{\\bf m}) + \\dfrac{1}{2}{\\bf m}^T {\\pmb \\Lambda} _ {bb}^{-1}{\\bf m}$$ $$\\text{where}\\;{\\bf m} = {\\pmb \\Lambda}_{bb}{\\pmb \\mu} _ b - {\\pmb \\Lambda} _ {ba}({\\bf x}_a-{\\pmb \\mu}_a)$$ 위의 식 우항에서 첫번째 부분은 quadratic form으로 만들었다. integrate하면 exp부분을 제외한 Gaussian distribution의 normalization constant가 나온다. 이는 첫번째항의 covariance determinant만 관련이 있고 $\\textbf{x}_a$와 independent하다. 결국 중요한건 $\\textbf{x}_a$와 dependent한 뒷부분인데 이를 정리하면 ${\\bf x}_a$에 대한 marginal gaussian distribution가 된다. $$\\dfrac{1}{2}[{\\pmb \\Lambda} _ {bb}{\\pmb \\mu}_b-{\\pmb \\Lambda} _ {ba}({\\bf x}_a-{\\pmb \\mu}_a)]^T {\\pmb \\Lambda} _ {bb}^{-1}[{\\pmb \\Lambda} _ {bb}{\\pmb \\mu}_b-{\\pmb \\Lambda} _ {ba}({\\bf x}_a-{\\pmb \\mu}_a)]$$ $$- \\dfrac{1}{2}{\\bf x}_a^T{\\pmb \\Lambda} _ {aa}{\\bf x}_a + {\\bf x}_a^T({\\pmb \\Lambda} _ {aa}{\\pmb \\mu}_a+{\\pmb \\Lambda} _ {ab}{\\pmb \\mu}_b) + const$$ $$= - \\dfrac{1}{2}{\\bf x}_a^T({\\pmb \\Lambda} _ {aa}-{\\pmb \\Lambda} _ {ab}{\\pmb \\Lambda} _ {bb}^{-1}{\\pmb \\Lambda} _ {ba}){\\bf x}_a + {\\bf x}_a^T({\\pmb \\Lambda} _ {aa}-{\\pmb \\Lambda} _ {ab}{\\pmb \\Lambda} _ {bb}^{-1}{\\pmb \\Lambda} _ {ba}){\\pmb \\mu}_a+const $$ 이를 이용하여 marginal distribution을 구하면 된다. 먼저, covariance는 $${\\pmb \\Sigma}_a = ({\\pmb \\Lambda} _ {aa}-{\\pmb \\Lambda} _ {ab}{\\pmb \\Lambda} _ {bb}^{-1}{\\pmb \\Lambda} _ {ba})^{-1} = {\\pmb \\Sigma} _ {aa}$$ mean은 아래와 같다. $${\\pmb \\Sigma}_a({\\pmb \\Lambda} _ {aa}-{\\pmb \\Lambda} _ {ab}{\\pmb \\Lambda} _ {bb}^{-1}{\\pmb \\Lambda} _ {ba}){\\pmb \\mu}_a = {\\pmb \\mu}_a$$ 결론 : Marginal distribution도 Gaussian distribution이다. $E[\\textbf{x}_a] = {\\pmb \\mu}_a$ $cov[\\textbf{x}_a] = \\Sigma _{aa}$ 직관과 거의 일치한다. (partitioned한 부분) ","date":"2021-11-26","objectID":"/prml-chap02-2/:1:2","tags":["Gaussian Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (2)","uri":"/prml-chap02-2/"},{"categories":["PRML"],"content":"2.3.3 Bayes' theorem for Gaussian variables Gaussian marginal distribution $p(\\textbf{x})$ , Gaussian conditional distribution $p(\\textbf{y} | \\textbf{x})$가 주어진 상태이다. (2.3.1과 2.3.2에서 알게된 사실을 토대로) $$p({\\bf x}) = N({\\bf x}|{\\pmb \\mu}, {\\pmb \\Lambda}^{-1}) $$ $$p({\\bf y}|{\\bf x}) = N({\\bf y}|{\\bf A} {\\bf x}+{\\bf b} , \\textbf{L}^{-1}) $$ 우리는 Gaussian marginal distribution $p(\\textbf{y})$ , Gaussian conditional distribution $p(\\textbf{x} | \\textbf{y})$를 구하고자 한다. 먼저 joint distribution을 구한 뒤에 구해보자. $${\\bf z} = \\dbinom{ {\\bf x} }{ {\\bf y} }$$ $$\\ln p({\\bf z}) = \\ln p({\\bf x}) + \\ln p({\\bf y}) \\\\ = -\\frac{1}{2}({\\bf x}-{\\pmb \\mu})^T{\\pmb \\Lambda}({\\bf x}-{\\pmb \\mu}) -\\frac{1}{2}({\\bf y}-{\\bf A}{\\bf x}-{\\bf b})^T {\\bf L}({\\bf y}-{\\bf A}{\\bf x}-{\\bf b})+const $$ 위의 식은 quadratic 형태의 함수라는 것을 알수 있고 따라서 Gaussian distribution의 함수일 것이다. 위의 식을 전개하여 이차항을 살펴보면 (for covariance) $$-\\frac{1}{2} {\\bf x}^T ({\\pmb \\Lambda} + {\\bf A}^T {\\pmb \\Lambda} {\\bf A}) {\\bf x} - \\frac{1}{2} {\\bf y}^T {\\bf L}{\\bf y} + \\frac{1}{2} {\\bf x}^T {\\bf A}{\\bf L}{\\bf y}$$ $$ = -\\frac{1}{2} \\dbinom{ {\\bf x} }{ {\\bf y} }^T \\left(\\begin{array}{cc}{\\pmb \\Lambda}+{\\bf A}^T{\\bf L}{\\bf A} \u0026 -{\\bf A}^T{\\bf L} \\\\ - {\\bf L}{\\bf A} \u0026 {\\bf L}\\end{array} \\right) \\dbinom{ {\\bf x} }{ {\\bf y} } = -\\frac{1}{2}{\\bf z}^T{\\bf R}{\\bf z}$$ 따라서 precision matrix는 $${\\bf R} = \\left(\\begin{array}{cc}{\\pmb \\Lambda}+{\\bf A}^T{\\bf L}{\\bf A} \u0026 -{\\bf A}^T{\\bf L}\\-{\\bf L}{\\bf A} \u0026 {\\bf L}\\end{array}\\right)$$ 임을 알 수 있다. 이를 inverse하여 covariance matrix를 구하면 $$cov[{\\bf z}]={\\bf R}^{-1} = \\left(\\begin{array}{cc}{\\pmb \\Lambda}^{-1} \u0026 {\\pmb \\Lambda}^{-1}{\\bf A}^T \\ {\\bf A}{\\pmb \\Lambda}^{-1} \u0026 {\\bf L}^{-1}+{\\bf A}{\\pmb \\Lambda}^{-1}{\\bf A}^T \\end{array}\\right)$$ 이전의 방법을 이용하여 mean을 구할 수 있다. $${\\bf x}^T{\\pmb \\Lambda}{\\pmb \\mu} - {\\bf x}^T{\\bf A}^T{\\bf L}{\\bf b} + {\\bf y}^T{\\bf L}{\\bf b} = \\dbinom{ {\\bf x} }{ {\\bf y} }^T \\dbinom {\\pmb \\Lambda}{\\pmb \\mu}-{\\bf A}^T{\\bf L}{\\bf b} {\\bf L}{\\bf b} $$ $$E[{\\bf z}] = {\\bf R}^{-1}\\dbinom{ {\\bf x} }{ {\\bf y} }^T\\dbinom {\\pmb \\Lambda}{\\pmb \\mu}-{\\bf A}^T{\\bf L}{\\bf b} {\\bf L}{\\bf b}$$ 전개하면 최종적으로 mean은 $$E[{\\bf z}] = \\dbinom{ {\\pmb \\mu} }{ {\\bf A} {\\pmb \\mu} - {\\bf b}}$$ 결과 $$E[{\\bf y}] = {\\bf A}{\\pmb \\mu} + {\\bf b}$$ $$cov[{\\bf y}] = {\\bf L}^T + {\\bf A}{\\pmb \\Lambda}^{-1}{\\bf A}^T $$ 다음은 conditional distribution $p(\\textbf{x}| \\textbf{y})$ 의 mean, covariance를 구하면 $$\\Sigma_{a|b}={\\pmb \\Lambda} _ {aa}^{-1} \\ {\\pmb \\mu}_{a|b}={\\pmb \\mu}_a - {\\pmb \\Lambda} _ {aa}^{-1}{\\pmb \\Lambda} _ {ab}({\\bf x}_b-{\\pmb \\mu}_b)$$ $$E[{\\bf x}|{\\bf y}] = ({\\pmb \\Lambda}+{\\bf A}^T{\\bf L}{\\bf A})^{-1}{ {\\bf A}^T{\\bf L}({\\bf y}-{\\bf b})+{\\pmb \\Lambda}{\\pmb \\mu}} $$ $$cov[{\\bf x}|{\\bf y}] = ({\\pmb \\Lambda}+{\\bf A}^T{\\bf L}{\\bf A})^{-1} $$ ","date":"2021-11-26","objectID":"/prml-chap02-2/:1:3","tags":["Gaussian Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (2)","uri":"/prml-chap02-2/"},{"categories":["PRML"],"content":"2.3.4 Maximum likelihood for the Gaussian Log likelihood $$\\ln p({\\bf X}|{\\pmb \\mu}, \\Sigma) = -\\frac{ND}{2}\\ln(2\\pi) - \\frac{N}{2}\\ln|\\Sigma|-\\frac{1}{2}\\sum_{n=1}^{N}({\\bf x}_n-{\\pmb \\mu})^T\\Sigma^{-1}({\\bf x}_n-{\\pmb \\mu})$$ (과정 생략) $${\\pmb \\mu} _ {ML} = \\frac{1}{N}\\sum_{i=1}^{N}{\\bf x}_i = \\bar{\\bf x}$$ $${ \\pmb \\Sigma} _ {ML} = \\frac{1}{N}\\sum_{i=1}^{N}({\\bf x}_i-\\mu)({\\bf x}_i-\\mu)^T$$ ","date":"2021-11-26","objectID":"/prml-chap02-2/:1:4","tags":["Gaussian Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (2)","uri":"/prml-chap02-2/"},{"categories":["PRML"],"content":"2.3.5 Sequential estimation data sample이 하나 들어오면 바로 계산하고 버린다. MLE를 구하는 예시를 살펴보자. $${\\pmb \\mu} _ {ML}^{(N)} = \\frac{1}{N} \\sum_{n=1}^{N}{\\bf x}_n = \\frac{1}{N}{\\bf x} _ N + \\frac{1}{N} \\sum _ {n=1}^{N-1}{\\bf x}_n$$ $$= \\frac{1}{N}{\\bf x}_N + \\frac{N-1}{N}{\\pmb \\mu} _ {ML}^{(N-1)}={\\pmb \\mu} _ {ML}^{(N-1)}+\\frac{1}{N}({\\bf x}_N-{\\pmb \\mu} _ {ML}^{(N-1)}) $$ 이전에 구한 parameter를 ‘error signal’ $(\\textbf{x} _N - {\\pmb \\mu} _{ML}^{(N-1)})$ 쪽으로 1/N에 비례하도록 수정하여 parameter를 업데이트한다. $N$이 커질수록 새로운 data의 영향은 작아진다. 이번에는 이런 Sequential estimation에서 사용되는 일반적인 방법에 대해 살펴보자. 바로 Robbins-Monro algorithm이다. random variables $\\theta, z$가 있다. conditional expectation은 $$f(\\theta)\\equiv E[z|\\theta] = \\int zp(z|\\theta)dz $$ 이고 이러한 형태를 regression function이라고 부른다. 우리의 목표는 $f(\\theta^{ * }) = 0$을 만족하는 root $\\theta^{ * }$를 찾는 것이다. 몇가지 가정을 살펴보면 data가 많으면 한번에 regression function을 만들고 root를 estimation할 수 있겠지만 지금은 Sequential하게 data가 하나씩 구해진다고 가정한다. $E[(z-f)^2 | \\theta]\u003c\\infty$ : conditional variance는 finite하다고 가정한다. $\\theta \u003e \\theta^{ * } \\rightarrow f(\\theta) \u003e 0$ $\\theta \u003c \\theta^{ * } \\rightarrow f(\\theta) \u003c 0$ Robbins-Monro의 방법은 $$\\theta^{(N)} = \\theta^{(N-1)} - a_{N-1} z(\\theta^{N-1}) $$ 여기서 $z(\\theta^{(N)})$은 N번째의 $\\theta$가 들어왔을 때, $z$의 값을 의미한다. $a_N$은 양의 실수이며 다음과 같은 조건을 갖는다. $\\lim_{N\\rightarrow\\infty}a_N=0 $ : $\\theta$가 특정값에 수렴 $\\sum_{N=1}^{\\infty}a_N=\\infty $ : root를 찾기도 전에 다른 값에 수렵하지 않도록 $% $ : 축적되는 noise가 finite하여 수렴을 방해하지 않는다. 이제 이 방법을 통해 이전에 구했던 MLE의 예시에 적용해보자. $$\\frac{\\partial}{\\partial\\theta}{-\\frac{1}{N}\\sum_{n=1}^{N}\\ln p(x_n|\\theta)}_ {\\theta_{MLE}}=0$$ MLE는 위처럼 log likelihood function을 미분하여 0으로 만드는 값니다. as $N \\rightarrow \\infty$ $$-\\lim_{n\\rightarrow\\infty}\\frac{1}{N}\\sum_{n=1}^{N}\\frac{\\partial}{\\partial\\theta}\\ln p(x_n|\\theta) = E_x\\left[-\\frac{\\partial}{\\partial\\theta}\\ln p(x|\\theta)\\right] $$ 이제 Robbins-Monro의 방법을 적용하면 $$\\theta^{(N)} = \\theta^{(N-1)} - a_{N-1}\\frac{\\partial}{\\partial\\theta^{(N-1)}}\\left[-\\ln p(x_N/\\theta^{(N-1)})\\right] $$ $$z=\\frac{\\partial}{\\partial\\mu_{ML}}[-\\ln p(x|\\mu_{ML}, \\sigma^2)]=-\\frac{1}{\\sigma^2}(x-\\mu_{ML}) $$ 따라서 $\\textbf{x}_N$을 대입하고 $a_N = \\sigma^1 / N$을 대입하면 처음에 구한 결과와 같다. ","date":"2021-11-26","objectID":"/prml-chap02-2/:1:5","tags":["Gaussian Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (2)","uri":"/prml-chap02-2/"},{"categories":["PRML"],"content":"이번 장은 주어진 데이터를 이용하여 Distribution을 만드는 것을 배울 것이다. density estimation을 하는 것이다. 이에 대한 방법으로 크게 parametric, nonparmetric 방법으로 나눌 수 있다. 추가로 몇가지 중요한 분포들에 대해 살펴볼 것이다. ","date":"2021-11-26","objectID":"/prml-chap02-1/:0:0","tags":["Bayesian","Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (1)","uri":"/prml-chap02-1/"},{"categories":["PRML"],"content":"2.1 Binary Variables 동전던지기와 같이 random variable이 딱 두가지의 값을 가지는 경우 ($x \\in {0,1}$) 에 대해 살펴보자. Bernoulli distribution $x=1$의 확률을 $p(x=1 | \\mu) = \\mu$ 라고 하자. ($0\\le \\mu \\le 1$) $E[x] = \\mu, Var[x] = \\mu(1-\\mu)$ parameter를 MLE로 추정하면 $\\mu_{ML} = \\frac{1}{N}\\sum_{n=1}^{N}{x_n}$ $$Bern(x | \\mu) = \\mu^x (1- \\mu)^{1-x}$$ MLE의 문제점을 여기서 볼 수 있다. 만약에 동전을 3번 던져서 모두 앞면이 나왔다고 하자. 이 data를 기반으로 동전이 앞면이 나올 확률을 MLE로 추정한다면 1일 것이다. 이처럼 극단적으로 overfitting이 되는 경우가 생길 수 있다. 이에 대한 해결책으로는 더 많은 data를 수집하거나 bayesian의 관점으로 접근해야 한다. Binomial distribution N번 중 $\\mu$의 확률로 사건이 $x$개 발생한 경우 (Bernoulli trial이 N번 발생) $$Bin(x | sN,\\mu) = \\begin{pmatrix} N \\ x \\end{pmatrix}\\mu^x (1-\\mu)^{N-x}$$ $$E[x] =N \\mu, Var[x] =N \\mu(1-\\mu)$$ ","date":"2021-11-26","objectID":"/prml-chap02-1/:1:0","tags":["Bayesian","Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (1)","uri":"/prml-chap02-1/"},{"categories":["PRML"],"content":"2.1.1 The beta distribution 위의 분포를 보고 bayesian의 접근방식을 생각해보자. parameter $\\mu$에 대한 prior를 만들어보자. conjugacy (prior와 posterior가 같은 분포를 갖는) 의 성질을 이용하면 Beta distribution을 생각할 수 있다. prior도 Beta이고 posterior도 Beta distribution의 모습을 보이도록 만들어준다. conjugacy를 이용하면 계산, 해석적인 측면에서 상당히 유용하다. $$Beta(\\mu | a,b) = \\frac{\\Gamma(a+b)}{\\Gamma (a) \\Gamma (b)}\\mu^{a-1}(1-\\mu)^{b-1}$$ $$E[\\mu] = \\frac{a}{a+b}, Var[\\mu] = \\frac{ab}{(a+b)^2(a+b+1)}$$ Binomial likelihood function과 Beta prior를 곱하여 posterior dist of $\\mu$ 를 만들면 $$p(\\mu | x,l,a,b) \\propto \\mu^{x+a-1} (1-\\mu)^{N-x+b-1}$$ 합이 1이 되게 constant를 만들지 않아도 posterior가 beta distribution임을 파악할 수 있다. posterior에서 $a$와 $b$는 각각 $x=1$, $x=0$ 인 data의 수와 같은 의미(역할)임을 알 수 있다. 우리는 prior를 beta로 이용했고 posterior가 beta로 나왔다. 그렇다면 나온 posterior를 다시 prior로 이용할 수 있을 것이다. 이처럼 sequential한 접근이 가능해진다. 우리의 목표는 predict이므로 predictive distribution을 구해보자. $$p(x=1 | D) = \\int_{0}^{1} p(x=1,\\mu | D)d\\mu$$ $$= \\int_{0}^{1} p(x=1 | \\mu)p(\\mu | D)d\\mu = \\int_{0}^{1}\\mu p(\\mu | D)d\\mu = E[\\mu | D]$$ 여기서 posterior dist의 평균을 구하면 $$p(x=1|D) = \\frac{x+a}{x+a+N-x+b}$$ 이고 데이터의 수가 많아지면 posterior mean은 MLE와 같아진다. 또한, uncertainty도 줄어들며 likelihood function의 모양과 가까워진다. 물론, 반대로 prior의 정보가 강하다면 prior와 비슷해진다. prior가 강하거나 data수가 많아 likelihood가 강해지면 uncertainty가 줄면서 posterior distribution의 모양이 뾰족해진다. 수리통계학에서 배웠던 공식을 이용하여 살펴보면 $E_{\\theta}[\\theta] = E_{D}[E_{\\theta}[\\theta|D]]$ D에 대해 averaged over된 posterior mean of $\\theta$ = prior mean of $\\theta$ $V_{\\theta}[\\theta] = E_{D}[V_{\\theta}[\\theta|D]]+V_{D}[E_{\\theta}[\\theta|D]]$ 평균적으로 posterior variance of $\\theta$가 prior variance보다 더 작다. ","date":"2021-11-26","objectID":"/prml-chap02-1/:1:1","tags":["Bayesian","Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (1)","uri":"/prml-chap02-1/"},{"categories":["PRML"],"content":"2.2 Multinomial Variables 이번에는 확률변수가 2가지의 값을 갖는게 아닌 K개의 값을 갖는 경우를 살펴보자. 이를 위해 우리는 vector로 확률변수를 표현한다. 예를 들어, 주사위를 던졌더니 3이란 수가 나왔다. $\\textbf{x} = (0,0,1,0,0,0)^T$ 이렇게 표현한다. 각 원소 $x_k$들의 합은 1이다. $x_k=1$인 확률을 parameter $\\mu_k$로 표현하면, $\\textbf{x}$의 distribution은 $$p(\\textbf{x} | {\\pmb \\mu}) = \\prod_{k=1}^{K}\\mu_{k}^{x_k}$$ $\\sum \\mu_k = 1, 0\\le\\mu_k\\le 1$ 이다. expectation은 $$E[{\\bf x}|{\\pmb \\mu}] = \\sum_{\\bf x}p({\\bf x}|{\\pmb \\mu}){\\bf x} = (\\mu_1, …, \\mu_K)^T = {\\pmb \\mu}$$ 으로 구할 수 있다. 그렇다면 이제 likelihood function을 구해보자. $$p(D|{\\pmb \\mu}) = \\prod_{n=1}^{N}\\prod_{k=1}^{K}\\mu_k^{x_{nk}} = \\prod_{k=1}^{K}\\mu_k^{\\sum_n x_{nk}}=\\prod_{k=1}^{K}\\mu_k^{m_k}$$ $m_k = \\sum_{n} x_{nk}$ : 전체 data에서 k값을 가지는 data 갯수 이 likelihood function을 이용하여 parameter ${\\pmb \\mu}$를 구해보자. constraint $\\sum_{k=1}^{K}{\\mu_k} = 1$ 에서 log likelihood 를 최대화 해야 한다. Lagrange multiplier $\\lambda$를 이용하여 아래 식을 최대화하면 된다. (Lagrange method) $$\\sum_{k=1}^{K}{m_k \\ln \\mu_k} + \\lambda (\\sum_{k=1}^{K}{\\mu_k}-1) $$ $\\mu_k$에 대해 미분하면 $\\mu_k = - m_k / \\lambda$ 이고 constraint때문에 $\\lambda = - N$ 이라는 것을 파악할 수 있다. 따라서 MLE는 $$\\mu_k = \\frac{m_k}{N}$$ Multinomial distribution $\\sum \\mu_k = 1, 0\\le\\mu_k\\le 1$ $\\sum m = N$ $$\\text{Multi}(m_1,m_2, … , m_K | \\mu, N) = \\frac{N!}{m_1! m_2! … m_K!}\\prod_{k=1}^{K}{\\mu_k^{m_k}}$$ ","date":"2021-11-26","objectID":"/prml-chap02-1/:2:0","tags":["Bayesian","Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (1)","uri":"/prml-chap02-1/"},{"categories":["PRML"],"content":"2.2.1 The Dirichlet distribution $$Dir(\\boldsymbol{\\mu} | \\boldsymbol{\\alpha}) = \\frac{\\Gamma (\\alpha_0)}{\\Gamma (\\alpha_1) \\Gamma(\\alpha_2)…\\Gamma(\\alpha_K)}\\prod_{k=1}^{K}{\\mu_k^{\\alpha_k - 1}}$$ $\\sum \\mu_k = 1, 0\\le\\mu_k\\le 1$ Multinomial의 conjugate prior K = 2이면 beta 분포이다. Binomial의 일반화된 분포가 Multinomial이듯 Beta의 일반화된 분포가 Dirichlet 분포라고 할 수 있다. posterior $$p({\\pmb \\mu}|D, {\\pmb \\alpha}) \\propto p(D|{\\pmb \\mu})p({\\pmb \\mu}|{\\pmb \\alpha}) \\propto \\prod_{k=1}^{K} \\mu_k^{\\alpha_k+m_k-1}$$ 이전에 봤듯이 prior의 $a_k$는 data에서 ‘observation of $x_k=1$’ 의 갯수와 같은 의미(역할)이라고 할 수 있다. ","date":"2021-11-26","objectID":"/prml-chap02-1/:2:1","tags":["Bayesian","Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (1)","uri":"/prml-chap02-1/"},{"categories":["PRML"],"content":"Information Theory에 대해 알아봅시다. ","date":"2021-11-26","objectID":"/prml-chap01-3/:0:0","tags":["Information Theory"],"title":"[PRML] Chapter1 - Introduction (3)","uri":"/prml-chap01-3/"},{"categories":["PRML"],"content":"1.6 Information Theory 일단 entropy에 대해 두 가지의 시선으로 살펴볼 예정이다. 일단 discrete random variable $x$와 이 variable의 specific value를 알아내면서 얻는 정보의 양이 얼마나 되는지로부터 시작한다. 어떤 사건이 일어날 확률이 큰 경우보다 일어날 확률이 작은 사건이 더 정보가 많다고 한다. 이에 따라 우리는 information content ($h(x)$ 라고 하자) 를 측정하는 방법이 필요하다. 그 방법의 조건은 확률 $p(x)$에 대해 monotonic function 두 개의 사건이 독립적이면 information gain은 두 information의 합으로 표현 이런 조건을 만족시키기 위해 우리는 logarithm을 이용한다. ($\\log_2$인 이유는 2진수 bit단위의 정보전달의 측면에서 접근하기 위해) $$h(x) = - \\log_2 p(x)$$ information은 0이상의 값을 갖기에 음수부호를 붙여서 사용한다. 이제 sender가 receiver에게 random variable의 값을 전달해야하는 상황이라고 가정하자. 그들이 전달하는 정보의 평균적인 양은 $$H[x] = - \\sum_{x}{p(x)\\log_2 p(x)}$$ 이를 우리는 entropy of the random variable x 라고 부른다. (예시는 생략) nonuniform distribution은 uniform distribution보다 더 작은 entropy값을 갖는다. entropy의 값을 정보전달의 측면 (bit단위라고 생각) 에서 생각해보자. 예를 들면, A집단의 entropy가 2, B집단의 entropy가 3의 값을 가진다. A의 내용을 전달하기 위해서는 최소 2bit, B는 최소 3bit가 필요한 것을 의미하고 이처럼 entropy는 the state of a random variable을 전달하기 위해 필요한 bits 수의 lower bound이다. 이번에는 entropy에 대해 다른 시각으로 살펴보자. N개의 물체를 bin에 나누어 담아야 한다. $i^{th}$ bin 에는 $n_i$개의 물체가 들어간다. 물체를 나누어 담는 경우의 수 $W$ 를 생각해보면 $$W = \\frac{N!}{\\prod_i n_i !}$$ 이를 multiplicity 라고 부른다. entropy를 만들기 위해 logarithm과 적절한 scaled 취하면 $$H = \\frac{1}{N}\\ln w = \\frac{1}{N} \\ln N! - \\frac{1}{N}\\sum_{i} \\ln n_i !$$ N이 무한대로 가고 $n_i / N$은 fixed 된다. 그리고 Stirling’s approximation을 이용하면 $\\ln N ! \\approx N \\ln N - N$ $\\ln n_i ! \\approx n_i \\ln n_i - n_i$ 이를 대입하면 $$H = - \\lim_{N \\rightarrow \\infty} \\sum_{i} \\frac{n_i}{N} \\ln \\frac{n_i}{N} = - \\sum_{i}{p_i \\ln p_i}$$ $\\sum_i n_i = N$ $p_i = \\lim_{N \\rightarrow \\infty} (n_i / N)$ : 물체가 i bin에 들어갈 확률 우리는 bin을 random variable X의 state $x_i$ 라고 할 수 있다. 따라서 random variable X의 entropy는 $$H[p] = - \\sum_{i}{p(x_i)\\ln p(x_i)}$$ 우리는 Lagrange를 이용하여 위의 식의 최댓값을 구할수 있고 최댓값은 Uniform distribution 일 때이다. 이제 continuos variable에서도 생각해보자. (과정 생략) continuos variable의 entropy는 아래 값을 가진다. $$H[x] = - \\int p(x) \\ln p(x) dx$$ 이를 differential entropy 라고 부른다. discrete의 경우에서와 마찬가지로 continuos에서는 어떤 distribution이 가장 큰 entropy를 가질까? (과정 생략, 똑같이 Lagrange 사용) 정답은 Gaussian distribution 인 경우이다. ","date":"2021-11-26","objectID":"/prml-chap01-3/:1:0","tags":["Information Theory"],"title":"[PRML] Chapter1 - Introduction (3)","uri":"/prml-chap01-3/"},{"categories":["PRML"],"content":"1.6.1 Relative entropy and mutual information 우리가 모르는 distribution $p(x)$가 있다고 가정해보자. 이를 approximation하는 $q(x)$를 모델링하였다. 이전에 정보전달에서의 측면에서 생각해보면 우리는 approximation 했기에 random variable 의 value 전달을 위해 추가적으로 리소스 bit가 더 필요하다. 더 필요한 정도는 $$KL(p| q) = - \\int p(\\textbf{x}) \\ln q(\\textbf{x})d\\textbf{x} - (- \\int p(\\textbf{x}) \\ln p(\\textbf{x})d\\textbf{x}) \\ = - \\int p(\\textbf{x})\\ln \\frac{p(\\textbf{x})}{q(\\textbf{x})}d\\textbf{x}$$ 이를 Kullbak-Leibler divergence (Relative entropy) between $p(\\textbf{x})$ and $q(\\textbf{x})$ 라고 부른다. 그리고 아래와 같은 특징을 갖는다. (이러한 특징을 통해 Kullbak-Leibler divergence는 measure of the dissimilarity of the two distributions $p(\\textbf{x}), q(\\textbf{x})$ 라고 할 수 있다.) $KL(p| q) \\ge 0$ $KL(p| q) = 0$, if and only if, $p(\\textbf{x}) = q(\\textbf{x})$ 증명은 Jensen’s inequality로 쉽게 할 수 있다. convex function $f(x)$는 $$f(\\sum_{i=1}^{M}{\\lambda_i x_i}) \\le \\sum_{i=1}^{M}{\\lambda_i f(x_i)}$$ $\\lambda \\ge 0$ $\\sum_i \\lambda_i = 1$ 의 특징을 갖는다. 위에서 $\\lambda_i$를 x의 확률분포라고 생각하면 $f(E[x]) \\le E[f(x)]$ 이다. 따라서 ($f$ 를 -log라고 생각하면 된다) $$KL[p|q] = - \\int p(\\textbf{x}) \\ln \\frac{q(\\textbf{x})}{p(\\textbf{x})}d\\textbf{x} \\ge - \\ln \\int q(\\textbf{x}) d\\textbf{x} = 0 $$ KL divergence를 최소화하는 것은 결국 likelihood function을 최대화하는 것과 같은데 이에 대해 살펴보자. 우리가 모르는 (approximation해야하는) 분포 $p(\\textbf{x})$에서 data가 generate되었다고 하자. 우리는 어떤 parametric distribution $q(\\textbf{x} | \\theta)$ 를 통해 approximation하고자 한다. $\\theta$를 정하는 방법은 $\\theta$에 대해 KL divergence를 최소화하는 것을 찾는 것이다. 그런데 우리는 $p(\\textbf{x})$를 모르는 상황이기에 directly할 수 없다. 대신 N개의 train data가 존재하므로 이를 이용하면 $$KL(p|q) \\approx \\sum_{n=1}^{N}{{ - \\ln q (\\textbf{x}_n | {\\bf \\theta}) + \\ln p(\\textbf{x}_n)} }$$ 우변의 두번째항은 parameter와 independent하다. 첫번째항은 negative log likelihood function for $\\theta$ of under the distribution $q(\\textbf{x} | \\theta)$ (train data를 통해 만들어진 분포) 이므로 KL divergence를 최소화하는 것은 likelihood function을 최대화하는 것이다. 이번에는 joint distribution을 생각해보자. 두 변수가 independent이면 $p(\\textbf{x}\\textbf{y}) = p(\\textbf{x})p(\\textbf{y})$ 이다. 하지만 independent가 아닌 경우, 우리는 KL divergence를 통해 얼마나 independent와 가까운지 생각해볼수 있다. $$I[\\textbf{x}, \\textbf{y}] \\equiv KL(p(\\textbf{x}, \\textbf{y}) | p(\\textbf{x})p(\\textbf{y})) = - \\int \\int p(\\textbf{x}, \\textbf{y}) \\ln \\frac{p(\\textbf{x})p(\\textbf{y})}{p(\\textbf{x}, \\textbf{y})}d\\textbf{x} d\\textbf{y}$$ 이를 mutual information between the variable x and y 라고 부른다. conditional entropy의 측면에서 $I[\\textbf{x}, \\textbf{y}] = H[\\textbf{x}] - H[\\textbf{x}|\\textbf{y}] = H[\\textbf{y}] - H[\\textbf{y}/\\textbf{x}]$ 따라서 MI는 y를 알고 난 뒤에 x의 uncertainty가 줄어든 정도 (반대도 성립) 라고 할 수 있다. Bayesian의 입장에서는 $p(\\textbf{x})$가 pior이고 $p(\\textbf{x} | \\textbf{y})$는 y data를 얻은 후의 posterior이다. 따라서 MI는 새로운 observation y의 등장으로 줄어든 x의 uncertainty라고 할 수 있다. ","date":"2021-11-26","objectID":"/prml-chap01-3/:1:1","tags":["Information Theory"],"title":"[PRML] Chapter1 - Introduction (3)","uri":"/prml-chap01-3/"},{"categories":["PRML"],"content":"Decision Theory에 대해 알아봅시다. ","date":"2021-11-26","objectID":"/prml-chap01-2/:0:0","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"1.5 Decision Theory Decision Theory는 크게 두 가지의 과정으로 이루어져 있다. Determining $p(x,t)$ from a training data set : inference 이를 통하여 새로운 데이터에 대해 결정(분류,회귀) : decision Decision Theory의 목표는 적절한 Probability들을 이용하여 optimal한 decision을 내리는 것이다. 2-class classification의 상황을 예시로 뒤의 내용을 진행한다. 우리는 input data를 통해 해당 data의 class를 구분하고 싶기에 $p(C_k / \\textbf{x})$를 구해야 한다. Bayes' theorem을 생각해보면 posterior를 구해야 하는 것이다. $$p(C_k | \\textbf{x}) = \\frac{p(\\textbf{x} | C_k)p(C_k)}{p(\\textbf{x})}$$ 우리는 misclassfication을 최소화하기 위해서 둘 중 더 큰 posterior probability갖는 class에 input data를 분류한다. ","date":"2021-11-26","objectID":"/prml-chap01-2/:1:0","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"1.5.1 Minimizing the misclassfication rate 우리의 목표가 misclassfication을 최소화하는게 목표라고 하자. 각 $\\textbf{x}$를 class에 분류해야하고 이를 위해 rule이 필요하다. 그 rule에 따라 input space를 region $R_k$로 나눠야 한다. 이 region을 decision regions 라고 한다. ($R_k$에 속한 data는 class k라고 분류) decision region간의 경계선을 decision boundary, decision surface 라고 부른다. misclassfication의 확률은 $$P(mistake) = P(\\textbf{x} \\in R_1, C_2) + P(\\textbf{x} \\in R_2, C_1) = \\int_{R_1} p(\\textbf{x}, C_2)d\\textbf{x}+ \\int_{R_2} p(\\textbf{x}, C_1)d\\textbf{x}$$ mistake의 확률을 최소화하기 위해서는 각 integral의 값을 최소화해야 한다. 따라서 만약 $p(\\textbf{x}, C_1) \u003e p(\\textbf{x}, C_2)$의 경우, data를 class1으로 분류해야한다. $p(\\textbf{x}, C_k) = p(\\textbf{x}) p(C_k | \\textbf{x})$ 이고 우변의 $p(\\textbf{x})$는 공통된 부분이므로 우리는 $p(C_k | \\textbf{x})$만 고려하면 된다. ","date":"2021-11-26","objectID":"/prml-chap01-2/:1:1","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"1.5.2 Minimizing the expected loss 위에서 misclassfication rate를 줄이는 부분에 대해서 살펴봤다. 하지만 실제로 분류를 할 때는 이 접근으로는 부족하다. 예를 들어, 암환자를 분류하는 문제라고 생각해보자. 암이 걸리지 않은 환자를 걸렸다고 잘못 판단하는 것과 암이 걸렸는데 걸리지 않았다고 판단하는 것. 둘 중 후자가 훨씬 심각한 문제이다. 이런 경우 후자에 대해 더 가중치가 있어야 하지 않을까? loss function (cost function) : overall measure of loss incurred in taking any of the available decisions or actions $L_{kj}$ : (k인데 j로 분류한 경우) loss matrix의 element를 의미한다. misclassfication에 대한 loss라고 이해하면 된다. 예를 들면 암환자의 loss matrix는 아래와 같은 모양이다. $$\\begin{bmatrix} 0 \u0026 100 \\\\ 1 \u0026 0 \\end{bmatrix}$$ (inference가 끝난 뒤에 decision하는 과정에 해당) optimal solution은 loss function을 최소화하는 것이다. 하지만 loss function은 true class을 알아야 계산할 수 있다. 우리는 true class를 모른다. (예를 들어, 환자의 신상데이터가 있고 이를 통해 암환자인지 아닌지 찾아야하는 상황) 따라서 우리는 expected (average) loss를 최소화하는 방법을 선택한다. $$E[L] = \\sum_{k} \\sum_{j} \\int_{R_j} L_{kj} p(\\textbf{x}, C_k) d\\textbf{x}$$ 우리의 목표는 expected loss를 최소로 만드는 적절한 $R_j$를 찾는 것이고 이는 각 데이터 $\\textbf{x}$가 $\\sum_{k} L_{kj}p(\\textbf{x}, C_k)$를 최소화 한다는 것을 의미한다. 최종적으로 expected loss를 최소화 하기 위해서는 $\\textbf{x}$를 값 $$\\sum_{k}{L_{kj} p(C_k|\\textbf{x})}= E[L(C_k, \\hat{C}_k) | X=\\textbf{x}]$$ 이 최소가 되는 class $j$로 분류하는 것이다. ","date":"2021-11-26","objectID":"/prml-chap01-2/:1:2","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"1.5.3 The reject option class에 따라 posterior의 비교를 통해 결정하기 애매한 상황이 생긴다. 이런 경우에는 probability에 따라 결정하기 보다는 다른 방법을 사용하는 것이 적절할 수도 있다. (예를 들면, 해당 데이터를 model이 아니라 전문가가 판단하는 방법) 이런 경우 regect option 이 있다고 할 수 있는 것이다. ","date":"2021-11-26","objectID":"/prml-chap01-2/:1:3","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"1.5.4 Inference and decision decision 문제를 해결하는 방법을 3가지로 분류할 수 있다. 앞쪽의 방법일수록 복잡한 방법이다. generative model 아래 식에서 posterior를 구하기 위해서는 분자, 분모를 다 구해야 한다. 한마디로 approachs that explicitly or implicitly model the distribution of inputs as well as outputs. 다른 표현으로는, joint distribution $p(\\textbf{x}, C_k)$을 구해서 marginalize하여 분모도 구하여 posterior를 구한다. $$p(C_k | x) = \\frac{p(x | C_k)p(C_k)}{p(x)}$$ discriminative model approachs that model the posterior probabilities directly 예를 들면 SVM, Tree models, KNN 등등 discriminative function maps each input x directly onto a class label 따라서 확률을 고려하지 않는다. inference와 decision stage를 하나로 묶은 것이다. 각각 장단점이 존재한다. 예를 들면, 1번에서 prior $p(\\textbf{x})$를 구했으므로 해당 값이 너무 작은 새로운 data는 무시하는 판단을 할 수 있다. (outlier detection하는 것처럼) 그렇다면 이제 (1,2번 선호) posterior를 구하면 어떤 장점이 있는지 알아보자. Minimizing risk 이전에 봤던 loss matrix를 수정하여 decision criterion을 수정하기 쉽다. 확률의 threshold를 조정하여 decision criterion을 수정하기 쉽다. Reject option expected loss뿐만 아니라 misclassfication rate를 최소화하는 rejection criterion을 정할 수 있게 해준다. Compensating for class priors posterior는 prior에 비례하므로 prior를 적절하게 바꿔줌으로서 posterior를 보완할 수 있다. Combing models 특정 문제를 subproblem으로 나누어서 생각할 수 있다. 예를 들면, naive bayes model과 같이 independent를 이용하여 posterior를 나누어서 생각할 수 있는 장점이 생긴다. ","date":"2021-11-26","objectID":"/prml-chap01-2/:1:4","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"1.5.5 Loss functions for regression 이전까지 classification에 대해 살펴봤으므로 이번에는 regression에 대해 살펴보자. expected (average) loss는 $$E[L] = \\int \\int L(t, y(\\textbf{x})) p(\\textbf{x}, t) d\\textbf{x}dt$$ 이다. regression에서 주로 사용하는 loss function은 squared loss이고 이를 통해 다시 쓰면 $$E[L] = \\int \\int {y(\\textbf{x}) - t}^2 p(\\textbf{x}, t) d\\textbf{x} dt$$ 이다. 우리는 이를 최소화하는 $y(\\textbf{x})$를 찾는 것이 목표이므로 미분하여 구할 수 있다. $$\\frac{dE[L]}{dy(\\textbf{x})} = 2\\int { y(\\textbf{x}) - t}p(\\textbf{x}, t) dt = 0$$ $$y(\\textbf{x}) = \\frac{\\int t p(\\textbf{x}, t)dt}{p(\\textbf{x})} = \\int t p(t | \\textbf{x})dt = E_t [t | \\textbf{x}]$$ 이는 우리가 알고 있는 regression function의 모양이다. (conditional average of t conditioned on x) 이를 이용하여 추가적인 접근을 해보자면 $${y(\\textbf{x}) - t}^2 = {y(\\textbf{x}) - E[t | \\textbf{x}] + E[t | \\textbf{x}] - t }^2$$ $$E[L] = \\int {y(\\textbf{x}) - E[t | \\textbf{x}]}^2 p(\\textbf{x})d\\textbf{x} + \\int {E[t | \\textbf{x}] - t}^2 p (\\textbf{x}) d\\textbf{x} $$ 두번째 항은 variance of the distribution of t, averaged over x 이다. 따라서 이는 irreducible minumum value of the loss function을 의미한다. ","date":"2021-11-26","objectID":"/prml-chap01-2/:1:5","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"+ Decision Theory 추가 monk의 강의에서 decision theory를 다루는데 해당 내용을 추가하고자 한다. 일단, loss function은 “0-1 loss” 으로 생각하자. true = prediction : 0 true != prediction : 1 두 가지 상황으로 나누어서 살펴보자. 하지만 두 경우 모두의 공통적인 결론은 $p(y/x)$ 가 핵심이라는 것이다. ","date":"2021-11-26","objectID":"/prml-chap01-2/:2:0","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"1. Minimizing conditional expected loss : Given $x$, minimize $L(y, \\hat{y})$ … but don’t know true class $y$ $(X, Y) \\sim P$ : discrete $$E[L(Y, \\hat{y}) | X = x] = \\sum_{y} L(y, \\hat{y}) P(y | x) = \\sum_{y \\neq \\hat{y} } 1*P(y | x) = 1 - P(\\hat{y} | x)$$ $$\\therefore \\hat{y} = argmin_y E[L(Y,\\hat{y}) | x] = argmax_y P(y | x)$$ ","date":"2021-11-26","objectID":"/prml-chap01-2/:2:1","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"2. Choosing f to minimize expected loss : Choose $f(f(x) = y)$ to minimize $L(y, f(x))$ but don’t know $x$ or $y$ $$E[L(Y, \\hat{Y})] = E[L(Y, f(X))] = \\sum_{x,y}L(y, f(x))P(x,y)$$ $$ = \\sum_{x}{\\sum_y L(y, f(x))P(y | x)}P(x) = \\sum_{x}g(x,f(x))p(x) = E_x[g(x,f(x))]$$ suppose for some $x', t$ $g(x', f(x')) \\ge g(x', t)$ $f_0(x) =$ if $x \\neq x', f(x)$ if $x = x', t$ 모든 $x,; g(x,f(x)) \\ge g(x, f_0(x))$ $$\\therefore E_x [g(x, f(x))] \\ge E_x[g(x,f_0(x))]$$ Choose f to min $g(x,f(x))$ $$f(x) = argmin_t g(x,t)$$ ","date":"2021-11-26","objectID":"/prml-chap01-2/:2:2","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"Big picture ","date":"2021-11-26","objectID":"/prml-chap01-2/:2:3","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"Generative model estimate $p(x,y)$ using data and then $p(y|x) = \\frac{p(x,y)}{p(x)}$ parameter / latent : $\\theta$ 라고 하자 $\\theta$는 distribution에 관한 parameter / latent $D$는 random (new data) $$p(y|x,D) = \\int p(y|x,D,\\theta) p(\\theta | x,D) d\\theta$$ $p(y|x,D)$ : predictive distribution $p(\\theta |x,D)$ : posterior distribution $p(y|x,D,\\theta)$ 이 부분은 주로 closed form(eg. regression y=wx)으로 구해지며 어렵지 않다. 하지만 posterior 부분은 closed form으로 못 구하는 경우가 많다. 또한 integral 부분도 계산이 어려운 경우가 많다. 그렇다면 이를 어떻게 해결할까? 크게 4가지의 방법을 살펴보자. exact inference Multivariate Gaussian, Conjugate prior, Graphical model point estimate MLE, MAP (1.2.5를 보면 integral 없이 계산) optimization, EM deteministic approximation Laplace approximation, Variational method, Expectation propagation stochastic approximation Sampling 기법들 (eg. MCMC) ","date":"2021-11-26","objectID":"/prml-chap01-2/:2:4","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"Probability Theory에 대해 알아봅시다. ","date":"2021-11-26","objectID":"/prml-chap01-1/:0:0","tags":null,"title":"[PRML] Chapter1 - Introduction (1)","uri":"/prml-chap01-1/"},{"categories":["PRML"],"content":"1.1 Example : polynomial curve fitting 예를 들어, 회귀에서 error function이 quadratic function of w이면 w에 대한 미분은 w에 linear하고 unique한 closed form의 해를 구할 수 있다. 모델의 overfitting을 항상 조심하고 데이터의 수가 늘어날수록 그 정도는 약해진다. MLE 방법은 overfitting에 취약하며 Bayesian 모델링으로 보완할 수 있다. ridge와 같이 error function에 패널티항을 추가하여 overfitting을 막는 방법도 있다. 이를 shrinkage 방법이라 부른다. (딥러닝에서는 weight decay) 이런 모델의 복잡한 정도를 정하는 데에 validation data set을 만들기도 하는데 이는 다소 낭비이므로 다른 방법을 공부할 것이다. (아마 Bayesian approach일듯) ","date":"2021-11-26","objectID":"/prml-chap01-1/:1:0","tags":null,"title":"[PRML] Chapter1 - Introduction (1)","uri":"/prml-chap01-1/"},{"categories":["PRML"],"content":"1.2 Probability Theory 패턴인식에서 가장 중요한 컨셉은 uncertainty이다. Probability Theory는 이런 uncertainty을 quantification하고 manipulation하는 방법을 제시한다. (확률을 이용하여) The rules of Probability sum rule : $p(X) = \\sum_{Y}{p(X,Y)}$ product rule : $p(X,Y) = p(Y|X)p(X)$ Bayes' Throrem (rule) $p(Y|X) = \\frac{p(X|Y)p(Y)}{p(X)}$ $p(Y)$ : prior probability $p(Y|X)$ : posterior probability ","date":"2021-11-26","objectID":"/prml-chap01-1/:2:0","tags":null,"title":"[PRML] Chapter1 - Introduction (1)","uri":"/prml-chap01-1/"},{"categories":["PRML"],"content":"1.2.1 Probability densities probability density : if the probability of a real-valued variable $x $ falling in the interval $(x, x+\\delta x )$ is given by $p(x)\\delta x$ for $\\delta x \\rightarrow 0$, then $p(x)$ is called the probability density 값은 항상 0 이상, 합하면 1을 가진다. ","date":"2021-11-26","objectID":"/prml-chap01-1/:2:1","tags":null,"title":"[PRML] Chapter1 - Introduction (1)","uri":"/prml-chap01-1/"},{"categories":["PRML"],"content":"1.2.2 Expectations and covariances expection of $f(x)$ : $E[f(x)] = \\int{p(x)f(x)dx}$ it can be approximated as $$E[f] \\approx \\frac{1}{N}\\sum_{n=1}^{N}{f(x_n)}$$ $E_x [f(x,y)]$는 y에 대한 함수이다. x에 대해 averaged over 된 것이다. conditional expection : $E[f(x)|y] = \\int{p(x|y)f(x)dx}$ variance of $f(x)$ : $var[f] = E[(f(x) - E[f(x)])^2]$ $f(x)$가 mean 주위에서 얼마나 variability가 있는지 보여준다. ","date":"2021-11-26","objectID":"/prml-chap01-1/:2:2","tags":null,"title":"[PRML] Chapter1 - Introduction (1)","uri":"/prml-chap01-1/"},{"categories":["PRML"],"content":"1.2.3 Bayesian probabilities 우리가 일반적으로 알고 있는 확률(probability)은 frequentist의 견해이다. bayesian은 frequentist와는 아예 다른 접근법을 갖는다. Frequentist 분모가 되는 전체 사건이 무한대로 일어나고 우리가 궁금한 사건이 그 중 몇번 일어나는지를 확률로 생각한다. parameter 추정이 목표이며 parameter는 fixed 되어 있다고 생각한다. 주로 estimator로서 likelihood function을 최대화하는 MLE로 사용한다. Bayesian 확률 : uncertainty를 quantification한 것으로 생각한다. parameter는 fixed 된 것이 아니라 (probability) distribution을 갖는 것이라고 생각한다. posterior distribution을 찾는 것이 목표이다. Bayes' theorem $$p(\\textbf{w} | D) = \\frac{p(D | \\textbf{w})p(\\textbf{w})}{p(D)}$$ parameter에 대해 원래 갖고 있던 믿음을 data D에 대한 정보를 얻은 뒤에 posterior probability로 업데이트 한다. (분모는 posterior가 합이 1이 되기 위한 normalization constant) prior probability : $p(w)$ likelihood function : $p(D/w)$ posterior probability : $p(w/D)$ posterior $\\propto$ likelihood * prior ","date":"2021-11-26","objectID":"/prml-chap01-1/:2:3","tags":null,"title":"[PRML] Chapter1 - Introduction (1)","uri":"/prml-chap01-1/"},{"categories":["PRML"],"content":"1.2.4 The Gaussian distribution $$N(x | \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi \\sigma^2}}exp{ - \\frac{(x-\\mu)^2}{2 \\sigma^2} }$$ mean : $\\mu$ variance : $\\sigma^2$ standard deviation : $\\sigma$ precision : $\\beta = 1/ \\sigma^2$ normal (gaussian) 분포는 mode와 mean이 같다. i.i.d (independent and identically distributed : data point가 독립적이고 같은 분포에서 나왔다) 인 경우, likelihood function은 $$p(\\textbf{x} | \\mu, \\sigma^2) = \\prod_{n=1}^{N}{N(x_n | \\mu, \\sigma^2)}$$ 이고 이를 최대화하는 mean과 variance의 MLE는 sample mean, sample variance이다. MLE를 구하는 방법은 likelihood function에 log를 취한 후 미분하여 0을 만족하는 parameter를 찾으면 된다. 이때 단점은 maximum likelihood 접근법이 분포의 variance를 underestimate한다(bias 발생)는 점이다. N이 커지면 문제가 없지만 복잡한 모델에서는 이런 bias때문에 문제가 발생할 수 있다. (나중에 공부한다) ","date":"2021-11-26","objectID":"/prml-chap01-1/:2:4","tags":null,"title":"[PRML] Chapter1 - Introduction (1)","uri":"/prml-chap01-1/"},{"categories":["PRML"],"content":"1.2.5 Curve fitting re-visted data를 통해 polynomial curve를 fitting해보자. target t에 대한 uncertainty를 probability를 통해 표현하면 (under gaussian noise distribution) $$p(t | x, \\textbf{w}, \\beta) = N(t | y(x,\\textbf{w}), \\beta^{-1})$$ 위의 식을 이용하여 우리는 parameter $\\textbf{w}$ 추정한다. likelihood를 최대로 하는 MLE를 찾으면 되는 것이다. log likelihood function은 아래와 같은 모양을 갖는다. $$\\ln p(\\textbf{t} | \\textbf{x}, \\textbf{w}, \\beta) = - \\frac{\\beta}{2}\\sum_{n=1}^{N}{{ y(x_n, \\textbf{w}) - t_n }^2} + \\frac{N}{2}\\ln \\beta - \\frac{N}{2}\\ln (2 \\pi)$$ 위 값을 최대화 하는 $\\textbf{w}_{ML}$을 찾으면 된다. 이는 결국 least square 방법과 동일한 의미를 갖는다. (추정선과 target의 차이를 최소화해야되므로) parameter를 추정한 뒤에 이제 prediction을 해야한다. 우리는 확률모델을 갖고 있기에 t에 대한 point estimate만이 아니라 predictive distribution을 만들 수 있다. $$p(t | x, \\textbf{w} _ {ML}, \\beta _ {ML}) = N(y(x,\\textbf{w} _ {ML}), \\beta _ {ML}^{-1})$$ 지금까지는 frequentist의 영역이였다면 Bayesian들은 어떤 접근을 하는지 살펴보자. 일단 우리가 추정해야하는 parameter에 대한 prior를 갖고 있다. prior distribution를 gaussian 분포로 가정하면 아래와 같이 나타낼 수 있다. (Mth order의 polynomial) $$p(\\textbf{w} | \\alpha) = N(\\textbf{0}, \\alpha^{-1}\\textbf{I}) = (\\frac{\\alpha}{2\\pi})^{(M+1)/2} \\exp { -\\frac{\\alpha}{2} \\textbf{w}^T \\textbf{w}}$$ 이를 통해 우리는 posterior distribution를 구할 수 있다. posterior는 likelihood와 prior의 곱에 비례하므로 $$p(\\textbf{w} | \\textbf{x}, \\textbf{t}, \\alpha, \\beta) \\propto p(\\textbf{t} | \\textbf{x}, \\textbf{w}, \\beta)p(\\textbf{w} | \\alpha)$$ 위의 posterior distribution을 최대화로 만드는 parameter를 MAP (MLE에 대응되는 point estimate)라고 부른다. posterior distribution에 negative log를 취한다. posterior를 최대로 만드는 것은 아래를 최소화 하는 것과 같다. $$\\frac{\\beta}{2}\\sum_{n=1}^{N}{{ y(x_n, \\textbf{w}) - t_n }^2} + \\frac{\\alpha}{2}\\textbf{w}^T\\textbf{w}$$ 위 결과를 통해 posterior distribution를 maximizing하는 것은 regularized sum-of-squares error function을 minimizing하는 것과 동일하다는 것을 알 수 있다.. (L2 regularization, Ridge regression) ","date":"2021-11-26","objectID":"/prml-chap01-1/:2:5","tags":null,"title":"[PRML] Chapter1 - Introduction (1)","uri":"/prml-chap01-1/"},{"categories":["PRML"],"content":"1.2.6 Bayesian curve fitting 위의 Bayesian 접근법은 point estimate를 구했기 때문에 살짝 아쉽다. 좀 더 Bayesian적인 방법은 $\\textbf{w}$의 모든 값에 대해 integral over하는 것이다. $\\textbf{w}$에 대해 marginalize하면 되는데 이는 뒤에 자주 나오는 방법이므로 잘 기억하자. 이제 predictive distribution을 구해보자. training data : $\\textbf{x},\\textbf{t}$ new data : $x$ hyperparameter (assume we know) : $\\alpha, \\beta$ (아래식에서는 생략) $$p(t | x, \\textbf{x}, \\textbf{t}) = \\int p(t | x, \\textbf{w})p(\\textbf{w} | \\textbf{x}, \\textbf{t}) d\\textbf{w} = N(t| \\mu(x), s^2(x))$$ $$\\mu (x) = \\beta \\phi (x)^T \\textbf{S} \\sum_{n=1}^{N}{\\phi (x_n)} t_n $$ $$s^2 (x) = \\beta^{-1} + \\phi (x)^T \\textbf{S} \\phi (x)$$ $$\\textbf{S}^{-1} = \\alpha \\textbf{I} + \\beta \\sum_{n=1}^{N}{\\phi (x_n) \\phi (x)^T}$$ vector $\\phi (x)$ : element $\\phi_i (x) = x^i$ for $i = 0, … M$ ","date":"2021-11-26","objectID":"/prml-chap01-1/:2:6","tags":null,"title":"[PRML] Chapter1 - Introduction (1)","uri":"/prml-chap01-1/"},{"categories":["PRML"],"content":"1.3 Model Selection 여러 가지 모델을 선택할 때, train score로 model을 선택하는 것은 적절하지 않다. 그래서 validation set을 이용한다. 하지만 validation set에 overfitting하는 경우도 있기에 test set으로 최종 점검까지 하는 것이다. data가 제한적인 경우 cross validation의 방법을 사용한다. 하지만 이는 상당히 computationally expensive하다. ","date":"2021-11-26","objectID":"/prml-chap01-1/:3:0","tags":null,"title":"[PRML] Chapter1 - Introduction (1)","uri":"/prml-chap01-1/"},{"categories":["PRML"],"content":"1.4 The Curse of Dimensionalty 차원의 저주를 보여주는 몇가지 예시들 nearest neighborhood 알고리즘에 해당하는 부분 : sample space를 cubic형태로 나눈다고 생각했을 때, 차원이 커짐에 따라 지수적으로 cubic의 갯수가 많아진다. 따라서 cubic에 data가 텅 비지 않으려면 많은 양의 데이터가 필요하다. polynomial 의 경우 : Mth order의 polynomial 모델을 사용한다고 하면 $D^M$ 으로 parameter의 수가 증가한다. data를 sphere하게 생각해보자. 차원이 높아질수록 sphere의 표면쪽에 data가 몰려있다. 즉, 중심쪽이 sparse해지는 것이다. ","date":"2021-11-26","objectID":"/prml-chap01-1/:4:0","tags":null,"title":"[PRML] Chapter1 - Introduction (1)","uri":"/prml-chap01-1/"}]