[{"categories":["PRML"],"content":"Bayesian Optimization으로 모델의 성능을 올려보자. ","date":"2021-11-29","objectID":"/prml-chap06-3/:0:0","tags":["Bayesian Optimization"],"title":"[PRML] Bayesian Optimization","uri":"/prml-chap06-3/"},{"categories":["PRML"],"content":"Bayesian Optimization with Gaussian Process 어떤 sequence of experiments를 한다고 생각해보자. 다음은 몇 가지 가정사항이다. Interested in finding a global maximizer(minimizer) of $f(\\bf{x})$ 우리는 experiments result를 만드는 underlying function $f(\\bf{x})$를 모른다. input은 우리가 다 알고 조절할 수 있다. result have a stochastic element $y_t \\sim N(f,\\sigma^2_{noise})$ results and input are continuous 일반적인 경우는 continous를 고려하지만 discrete, hybrid의 경우도 존재한다. 다양한 task에서 사용할 수 있지만 우리는 주로 hyperparameter tuning을 할 때 사용하게 된다. Grid search no learning of underlying function Binary search learning of constraints, not the function 위와 같은 방법들이 많이 사용되었다. 이와 다르게 BOP는 learning underlying function with surrogate model selecting the next sampling input 같은 task를 통해서 최적의 결과를 얻어내고자 하는 것이다. 그렇다면 어떤 과정으로 최적의 결과를 얻어낼까? GPR은 모든 data point에서 predicted mean, predicted std를 알려준다. input을 넣고 underlying function을 만든다 (GPR을 fitting하는 것). 그 후에 mean과 variance를 통해 exploitation or exploration를 결정하여 next sampling input을 결정한다. (그리고 다시 underlying function을 만든다. 이를 반복한다.) Exploitation : result값이 높은 곳(underlying function mean이 큰) 탐색 Exploration : 관측지가 적은 곳(variance가 큰) 탐색 이떄, 이에 대한 판단 기준이 필요하다. acquisition function을 이용한다. 이에 대해 한번 더 정리하자면 Surrogate model : Compute $p(f|D_{1})$, yielding $\\mu_{1}({\\bf x})$ and $\\sigma_{1}({\\bf x})$. Acquisition function: Choose ${\\bf{x}} _ {2}$ such that ${\\bf x} _ {2}=argmax_{ {\\bf x} \\in \\mathcal{X} } a ({\\bf x}|\\mathcal{M}_{1})$ Augment data, $D_2 = D_1 \\cup \\{ ({\\bf x}_{2}, y _ {2}) \\}$ Surrogate model : Compute $p(f|D_2)$, yielding $\\mu_{2}({\\bf x})$ and $\\sigma_{2}({\\bf x})$. Acquisition function: Choose ${\\bf x} _ 3$ such that ${\\bf x} _ {3}=argmax_{ {\\bf x} \\in \\mathcal{X} }a({\\bf x}|\\mathcal{M}_{3})$ Augment data, $D_ 3 = D_2 \\cup \\{ ({\\bf x} _ {3},y _ {3}) \\}$ Repeat theses till the final round T, to compute $\\mu_{T}({\\bf x})$ ${\\bf x}^{*} = argmax_{ {\\bf x} \\in {\\bf x}_1,…,{\\bf x} _ T } \\mu _ {T}({\\bf x})$ ","date":"2021-11-29","objectID":"/prml-chap06-3/:1:0","tags":["Bayesian Optimization"],"title":"[PRML] Bayesian Optimization","uri":"/prml-chap06-3/"},{"categories":["PRML"],"content":"surrogate model 다양한 모델을 사용할 수 있다. 하지만 해당 point의 mean, variance를 알 수 있는 stochastic한 모델이여야 할 것이다. Random Forest Empirical하게 mena, variance를 구할 수 있다. scable, faster continuous, discrete 변수 모두 handle 가능하다. (GP는 kernel을 따로 design해야 한다고 함) extrapolation을 잘 못한다. GP regression Nonparameteric Bayesian Regression Not scalable 10dim이 넘어가면 standard GP로는 힘들다. sample dsata의 수가 많아져도 힘들다. ","date":"2021-11-29","objectID":"/prml-chap06-3/:1:1","tags":["Bayesian Optimization"],"title":"[PRML] Bayesian Optimization","uri":"/prml-chap06-3/"},{"categories":["PRML"],"content":"Acquisition Function Acquisition Function은 다양하다. 몇 가지만 간단히 알아보고 코드를 통해 실습을 진행해보자. Maximum Probability of Improvement (PI) 현재 optimized value $y_{max}$를 어떤 margin m 이상으로 올려줄 확률이 가장 높은 input을 sampling한다. grid search처럼 value를 계산하는 것이 아니라 확률만 계산하여 진행한다. $D$는 기존 data, 이를 통해 GPR을 만들수 있겠다. $y \\sim N(\\mu, \\sigma^2)$ 이는 GPR로 만들어진 것이다. $$MPI(x|D) = \\argmax_x P(y \\ge (1+m)y_{max} | x, D)$$ $$y\\sim N(\\mu, \\sigma^2) = \\argmax_x P(\\frac{y-\\mu}{\\sigma} \\ge \\frac{(1+m)y_{max}-\\mu}{\\sigma})$$ $$= \\argmax_x \\Phi (\\frac{\\mu - (1+m)y_{max}}{\\sigma})$$ 그런데 PI는 잘 안쓴다고 한다. Maximum Expected Improvement (EI) MPI를 조금 더 디벨롭시킨 것이다. MPI에서는 m을 고려해야했다. 그렇게 하지 말고 0부터 infinite으로 고려하면 되지 않을까? 라는 접근을 한다. 구체적으로 식을 구하는 과정은 생략한다. expected improvement w.r.t. the best observed objective value $y_{b}$ so far is defined as $$EI = E _ y [ \\max (y - y_{b} ,0) ]$$ $$=\\int \\max (y-y_{b}) N (y | \\bar{y}, \\sigma^{2})dy$$ $$=(\\bar{y} - y_b) \\Phi ( \\frac{\\bar{y}-y_b}{\\sigma} ) + \\sigma \\phi ( \\frac{\\bar{y} - y_b}{\\sigma} )$$ Gaussian Process-Upper Confidence Bound (GP-UCB) posterior mean과 variance의 적절한 trade-off를 고려하여 data point를 선택한다. 아래의 수식에 따라서 point를 선택한다. $\\beta_t$ : appropriate constants $\\nu$ : hyperparameter involving the degree of exploration $$\\bf{x} _ t = \\argmax_{\\bf{x}} ( \\mu_{t-1}(\\bf{x}) + \\sqrt{\\nu \\beta_t} \\sigma_{t-1}(\\bf{x}))$$ Thompson Sampling posterior에서 function을 sampling하는 방법이다. ","date":"2021-11-29","objectID":"/prml-chap06-3/:1:2","tags":["Bayesian Optimization"],"title":"[PRML] Bayesian Optimization","uri":"/prml-chap06-3/"},{"categories":["PRML"],"content":"이해를 위한 코드 # NHN cloud # https://www.youtube.com/watch?v=PTxqPfG_lXY import numpy as np from scipy.stats import norm from sklearn.gaussian_process import GaussianProcessRegressor from sklearn.gaussian_process.kernels import RBF # Acquisition function def expected_improvement(mean, std, max): z = (mean - max) / std return (mean - max) * norm.cdf(z) + std * norm.pdf(z) # Objective function def f(x): return x * np.sin(x) # hyperparameter space min_x, max_x = -2, 10 # Observation data X = np.random.uniform(min_x, max_x, 3).reshape(-1, 1) y = f(X).ravel() # GP model gp_model = GaussianProcessRegressor(kernel=RBF(1.0)) for i in np.arange(10): # surrogate model fit gp_model.fit(X, y) # predict -\u003e mean, std 계산 xs = np.random.uniform(min_x, max_x, 10000) mean, std = gp_model.predict(xs.reshape(-1, 1), return_std=True) # acq 계산 acq = expected_improvement(mean, std, y.max()) # acq가 가장 큰 값 선택 x_new = xs[acq.argmax()] y_new = f(x_new) # 데이터에 추가 X = np.append(X, np.array([x_new])).reshape(-1, 1) y = np.append(y, np.array([y_new])) ","date":"2021-11-29","objectID":"/prml-chap06-3/:1:3","tags":["Bayesian Optimization"],"title":"[PRML] Bayesian Optimization","uri":"/prml-chap06-3/"},{"categories":["PRML"],"content":"Reference 문일철 교수님 강의 NHN cloud 발표 paper Taking the Human Out of the Loop: A Review of Bayesian Optimization (2016) A tutorial on Bayesian optimization (2018) ","date":"2021-11-29","objectID":"/prml-chap06-3/:2:0","tags":["Bayesian Optimization"],"title":"[PRML] Bayesian Optimization","uri":"/prml-chap06-3/"},{"categories":["PRML"],"content":"Gaussian Process에 대해 정리하였다. ","date":"2021-11-29","objectID":"/prml-chap06-2/:0:0","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"6.4 Gaussian Processes 이 부분은 카이스트 문일철 교수님의 유투브영상을 보고 정리하였습니다. ","date":"2021-11-29","objectID":"/prml-chap06-2/:1:0","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Continuous Domain Data GP는 continuous domain data 분석에 유용하다. Time, Space, Spatio-Temporal… 어떻게 분석, 모델링? Estimating on the underlying function (ex. Autoregression) Prediction on the unexpected point (ex. extrapolation with autoregression) ","date":"2021-11-29","objectID":"/prml-chap06-2/:1:1","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Underlying Function and Observations $Y = sinc(x)$ 라는 함수를 underlying function이라고 하자. 여기서 gaussian noise를 추가하여 observation들을 생성했다. 지금 그림은 없지만 그림1은 x에 따라 분산이 동일하고 그림2는 x에 따라 분산이 변화(x가 클수록 분산이 커짐)한다. underlying function을 구해야하므로 mean function을 찾는 것은 당연하고 추가로 variance(or precision) function도 중요하다. $$\\mu(t), \\sigma(t)^2$$ ","date":"2021-11-29","objectID":"/prml-chap06-2/:1:2","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Simple Analyses without Domain Correlation mean function을 domain correlation없이 estimate한다고 하자. 즉, 특정 1개의 point에서 mean과 variance를 계산하는 것이다. 그런데 continuous domain에서 사실 같은 $x(t)$에 대해 multiple obsevation이 나올 수 없다. 약간의 discretize라고 할 수 있다. 해당 domain point에서 observation이 많으면 어느 정도 smooth하게 mean function을 구할 수 있다. 하지만 반대의 경우 좋은 estimation이 어렵다. 그래서 우리는 주위의 다른 domain data point도 사용하는게 좋지 않을까 라는 생각을 할 수 있다. ","date":"2021-11-29","objectID":"/prml-chap06-2/:1:3","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Simple Analyses with Domain Correlation Moving average time window(특정 구간)를 설정하고 평균 급격하게 변화하는 구간은 잘 안 맞을 수도 있다. time window에 따라 변화 window가 커질수록 smooth해진다. $$MA(x) = \\frac{1}{N} \\sum_{x \\in W} y_i$$ 그런데 모든 data point에 동일한 가중치를 주는게 다르게 주면 어떨까? 예를 들면, Squared Exponential $L$이 커지면 window가 커지는 역할 위에서 window 크기처럼 $L$을 적절히 선택해야한다. $$k(x,x_i;L) = exp(-\\frac{|x-x_i|^2}{L^2})$$ 위처럼 domain correlation을 다르게 생각하고 거리에 따라 가중치를 다르게 주는 것이다. 가까울수록 큰 가중치! $$MA(x) = \\frac{1}{\\sum_{x_i \\in D} k(x,x_i)}\\sum_{x_i \\in D} k(x,x_i) y_i$$ ","date":"2021-11-29","objectID":"/prml-chap06-2/:1:4","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Random Process Random process(=Stochastic process) An infinite indexed collection of random variables ${ X(w,t) , t \\in T }$ index paramter : $t$ (time, space…) A function $X(t,\\omega), t \\in T ;\\text{and}; \\omega \\in \\Omega$ outcome : $\\omega$ Fixed $t \\rightarrow X(t,\\omega)$ is a random variable over $\\Omega$ Fixed $\\omega \\rightarrow X(t,\\omega)$ is a deterministic function of $t$ ; sample function ","date":"2021-11-29","objectID":"/prml-chap06-2/:2:0","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Gaussian Process GP는 Random Process의 한 종류 For any set S, a GP on S is a set of random variable ($z_t : t \\in S$) such that vector $[z_{t_1}, z_{t_2},…,z_{t_n}]$ is multivariate gaussian $$P(T) = N(0, (\\beta I_N)^{-1} + K) \\ K_{nm} = k(x_n, x_m) = \\theta_0 \\exp(-\\frac{\\theta_1}{2}||x_n - x_m||^2) + \\theta_2 + \\theta_3 x_n^T x_m$$ ","date":"2021-11-29","objectID":"/prml-chap06-2/:3:0","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Derivation of Gaussian Process 일단 linear regression으로 접근하고 GP에 대해 알아본다. gaussian process regression : a nonparametric bayesian regression method using the properties of Gaussian processes ","date":"2021-11-29","objectID":"/prml-chap06-2/:4:0","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Mapping Functions non-linearly separable data set이 있다고 가정하자. 이를 위해 basis space를 증가시키면 될 것이다. mapping function $\\phi$를 통해 확장시킨다. ","date":"2021-11-29","objectID":"/prml-chap06-2/:4:1","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Linear regression with basis function $$y(x) = w^T \\phi (x)$$ 여기서 $w$를 deterministic value가 아니라 probabilistically distributed value라고 생각하자. (Bayesian linear regression의 방법론) $$P(w) = N(0, \\alpha^{-1} I)$$ Y의 확률분포(joint distribution)에 대해 생각해보자. ($w$가 확률분포가 있으니까) $Y$도 normal 이겠구나 (multivariate gaussian) $$Y = (y_1, y_2,…,y_n)$$ $K$ : Gram matrix $$E[Y] = E[\\Phi w] = \\Phi E[w] = 0$$ $$cov(Y) = E[YY^T] = E[\\Phi w w^T \\Phi^T]$$ $$= \\Phi E[ww^T]\\Phi^T = \\frac{1}{\\alpha} \\Phi \\Phi^T$$ $$K_{nm} = k(x_n,x_m) = \\frac{1}{\\alpha} \\phi (x_n)^T \\phi (x_m)$$ $$\\therefore P(Y) = N(0,K)$$ 분산이 kernel function을 이용한다는 점을 기억하자 이제 $Y$에 대한 분포를 파악했으니 이를 통해 prediction을 해보자. ","date":"2021-11-29","objectID":"/prml-chap06-2/:4:2","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Modeling Noise with Gaussian distribution $t_n$ : observed value with noise $y_n$ : Latent, error-free value $e_n$ : Error term distributed by following the gaussian distribution $$t_n = y_n + e_n \\ (t_n = f(x_n)+e_n)$$ $$P(T|Y) = N(Y, \\beta^{-1} I)$$ $\\beta$ : hyperparameter of the error precision error term들이 independent라고 가정하기에 variance 부분에 $I$이 된다. $$P(T) = \\int P(T|Y)P(Y) dY = \\int N(Y,\\beta^{-1} I) N(0,K) dY$$ 위의 곱해지는 두 분포 모두 multivariate gaussian distribution 이므로 이를 이용하여 구할 것이다. $$P(T|Y)P(Y) = P(T,Y) = P(Z)$$ $$\\ln P(Z) = \\ln P(T|Y) + \\ln P(Y) \\ = - \\frac{1}{2} Y^TK^{-1}Y - \\frac{1}{2}(T-Y)^T \\beta I (T-Y) + const$$ 여기서 변수는 $T,Y$이다. 여기서 second order term을 보면 (second order term을 찾으면 covariance를 찾을 수 있기에) $$ = \\frac{1}{2} \\begin{pmatrix} Y \\\\ T \\end{pmatrix}^T \\begin{pmatrix} K^{-1} + \\beta I \u0026 -\\beta I \\\\ - \\beta I \u0026 \\beta I \\end{pmatrix} \\begin{pmatrix} Y \\\\ T \\end{pmatrix} = \\frac{1}{2}Z^T R Z$$ $R$은 precision matrix가 된다. 이를 inverse 하면 (공식이용) $$R^{-1} = \\begin{pmatrix} K \u0026 K \\\\ K \u0026 (\\beta I)^{-1} + K \\end{pmatrix}$$ $\\ln (Z)$의 first order term은 없다. mean이 0라는 것을 알 수 있다. 따라서 최종 결과는 $$P(Z) = N(0, R^{-1})$$ 이제 PRML chapter 2에서 봤었던 공식을 이용하면 marginal distribution을 구할 수 있다. $$P(T) = N(0, (\\beta I)^{-1} + K)$$ 이제 우리가 관찰한 N개의 data를 통해 $P(T)$를 알게 되었다. 그렇다면 이제 prediction해보자. $t_{N+1}$을 알아내야 한다. $$P(t_{N+1}|T_N)$$ 이를 구하기 위해 N+1의 joint를 구하고 conditional disribution을 만들면 된다. ","date":"2021-11-29","objectID":"/prml-chap06-2/:4:3","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Sampling of $P(T)$ Sampling T of 101 dimension when points $x_n = [-1,-0.98,…,1]$ : 101개의 data point mean $0$ : 101 dim zero vector cov $(\\beta I_N)^{-1} + K$ : 101 * 101 dim cov $$P(T) = N(0, (\\beta I_N)^{-1} + K)$$ kernel의 parameter와 $\\beta$값에 따라서 sampling data들이 이루는 모습이 달라진다. ","date":"2021-11-29","objectID":"/prml-chap06-2/:4:4","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Mean and Covariance of $P(t_{N+1} | T_N)$ $$P(t_{N+1}|T_N) = P(T_{N+1}) / P(T_N)$$ $$P(T_{N+1}) = N(0, cov_{N+1})$$ mean은 1차원이 늘어난 zero vector이고 cov는 행과 열이 하나씩 들어간 형태일 것이다. 이는 kernel function과 $\\beta$를 통해 어렵지 않게 구할 수 있다. $$cov_{N+1} = \\begin{pmatrix} cov_N \u0026 k \\\\ k^T \u0026 K_{(N+1)(N+1)}+\\beta^{-1} \\end{pmatrix}$$ 이제 joint distribution을 구했으니 conditional distribution을 구할 수 있다. (공식 PRML chap2에 나온다) $$P(t_{N+1}|T_N) = N(0+k^T cov_N^{-1}(T_N-0),K_{(N+1)(N+1)}+\\beta^{-1} -k^Tcov_N^{-1} k )$$ 이는 결국 regression을 한 것이다. predictive distribution을 구한 것이다. 평균과 분산 모두 new data $x_{N+1}$에 depend하다. 분산에서 inverse가 computationally 오래걸려서 approximation하는 방법들이 있다고 한다. $$\\mu_{t_{N+1}} = k^T cov_N^{-1} T_N \\ \\sigma^2_{t_{N+1}} = K_{(N+1)(N+1)}+\\beta^{-1} -k^Tcov_N^{-1} k$$ 우리가 알고 있는 일반적인 regression과는 조금 다른 형태이다. 각 feature들의 weight들이 어디있는지 궁금할 수 있는데 kernel function안의 parameter로 들어갔다. ","date":"2021-11-29","objectID":"/prml-chap06-2/:4:5","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Hyperparameter of Gaussian Process Regression 위에서 linear regression에서 parameter optimization을 하는 방법을 알아보자. 아래의 kernel hyperparameter를 추정해야 하는 것이다. $$ K_{nm} = k(x_n, x_m) = \\theta_0 \\exp(-\\frac{\\theta_1}{2}||x_n - x_m||^2) + \\theta_2 + \\theta_3 x_n^T x_m$$ $$P(T;\\theta) = N(0, (\\beta I_N)^{-1} + K)$$ $\\theta$를 추정하기 위해 likelihood를 최대한 높이는 방법을 택한다. $\\theta$에 대해 미분하여 구하면 된다. $$\\frac{\\partial}{\\partial \\theta_i} \\log P(T;\\theta) \\overset{let}{=}0$$ 그런데 closed form은 존재하지 않는다. 그래서 approximation해야 한다. (너무 복잡해서 derivation 생략) 우리는 pytorch와 같은 framework의 도움을 받아서 구한다. ","date":"2021-11-29","objectID":"/prml-chap06-2/:4:6","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Gaussian Process Classifier 아래와 같이 일반적인 logistic regression과 거의 동일하다. Gaussian process classifier : sigmoid function + Gaussian process Gaussian process : $f(x;\\theta)$ Gaussian process classifier : $y=\\sigma (f(x;\\theta))$ if $t \\in {0,1}$, objective function to optimize : $$P(t | \\theta) = \\sigma (f(x;\\theta))^t (1-\\sigma (f(x;\\theta)))^{1-t}$$ ","date":"2021-11-29","objectID":"/prml-chap06-2/:5:0","tags":["PRML","Gassian Process"],"title":"[PRML] Chapter6 - Kernel Method (2) : GP","uri":"/prml-chap06-2/"},{"categories":["PRML"],"content":"Gausisan distribution의 성질을 알아보자. ","date":"2021-11-26","objectID":"/prml-chap02-2/:0:0","tags":["Gaussian Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (2)","uri":"/prml-chap02-2/"},{"categories":["PRML"],"content":"2.3 Gaussian distribution Multivariate Gaussian distribution D 차원의 vector $\\textbf{x}$에 대한 distribution entropy가 가장 큰 분포가 gaussian이고 multivariate gaussian도 해당한다. ${\\Sigma}$ : D*D의 covariance matrix $$N(\\pmb{x} | \\pmb{\\mu}, \\pmb{\\Sigma}) = \\frac{1}{(2\\pi)^{D/2}} \\frac{1}{ | \\pmb{\\Sigma} |^{1/2} } \\exp{ -\\frac{1}{2}(\\pmb{x} - \\pmb{\\mu})^T \\pmb{\\Sigma}^{-1}(\\pmb{x} - \\pmb{ \\mu})}$$ Gaussian distribution은 상당히 중요한 특징들을 갖고 있다 하나씩 살펴보자. $$\\Delta^2 = ({\\bf x}-{\\pmb \\mu})^T{\\bf \\Sigma}^{-1}({\\bf x}-{\\pmb \\mu}) $$ $\\Delta$ : Mahalanobis distance from $\\pmb{\\mu}$ to $\\textbf{x}$ $\\pmb{\\Sigma}$가 identity이면 Euclidean distance $\\pmb{\\Sigma}$는 (실수)대칭행렬이므로 고윳값이 실수 고유벡터들은 orthonomal하게 가능 고유대각화가 가능하고 아울어 직교대각화가 가능하다. $${\\bf \\Sigma}=\\sum_{i=1}^{D}{\\pmb \\Lambda}_i{\\bf u}_i{\\bf u}_i^T = U{\\pmb \\Lambda} U^{-1}$$ $${\\bf \\Sigma}^{-1}=\\sum_{i=1}^{D}\\dfrac{1}{\\pmb \\Lambda}_i{\\bf u}_i{\\bf u}_i^T = U {\\pmb \\Lambda}^{-1} U^{-1}$$ 이를 위에 대입하면 $$\\Delta^2 = \\sum_{i=1}^{D}\\frac{y_i^2}{\\pmb \\Lambda}_i $$ $y_i={\\bf u}_i^T({\\bf x}-{\\pmb \\mu})$ 우리는 ${y_i}$를 orthonomal vector $\\textbf{u}_i$에 의해 새롭게 정의된 coordinate system이라고 이해할 수 있다. multivariate gaussian의 평균과 분산은 $E[\\textbf{x}] = {\\pmb \\mu}$ $cov[\\textbf{x}] = {\\pmb \\Sigma}$ : 공분산행렬 (covariance matrix) multivariate gaussian은 유용한 분포지만 한계점도 있다. 공분산행렬의 parameter 개수 공분산행렬의 parameter는 $D(D+3)/2$ 개 이다. 차원이 커짐에 따라 parameter가 quadratic하게 커진다. 이를 위한 해결책은 2가지가 있는데 공분산행렬은 대각행렬로 생각한다. 즉, ${\\pmb \\Sigma} = diag(\\sigma_i^2)$ 공분산행렬을 isotropic covariance로 만든다. 즉, ${\\pmb \\Sigma} = \\sigma^2{\\pmb I}$ 물론 이런 제약이 생기면 data간의 correlation을 못 잡는 경우가 발생한다. gaussian은 unimodal 하기에 multimodal distribution을 잘 approximation하기 어렵다. 이에 대해 해결책은 나중에 뒤에서 배운다. (Mixture 등등) ","date":"2021-11-26","objectID":"/prml-chap02-2/:1:0","tags":["Gaussian Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (2)","uri":"/prml-chap02-2/"},{"categories":["PRML"],"content":"2.3.1 Conditional Gaussian distributions conditional distribution의 경우를 살펴보자. $\\textbf{x}$는 Gaussian distribution $N(\\textbf{x} | {\\pmb \\mu, \\Sigma})$의 D-차원 vector이다. 이를 두 부분으로 나누어 $\\textbf{x}_a, \\textbf{x}_b$ 라고 하자. D*D covariance matrix는 대칭행렬이다. $$\\textbf{x} = \\begin{pmatrix} \\textbf{x}_a \\\\ \\textbf{x}_b \\end{pmatrix}, {\\pmb \\mu} = \\begin{pmatrix} {\\pmb \\mu}_a \\\\ {\\pmb \\mu}_b \\end{pmatrix}$$ $${\\pmb \\Sigma} = \\begin{pmatrix} \\Sigma_{aa} \u0026 \\Sigma_{ab} \\\\ \\Sigma_{ba} \u0026 \\Sigma_{bb} \\end{pmatrix}$$ precision matrix $${\\pmb \\Lambda} \\equiv {\\pmb \\Sigma}^{-1} = \\begin{pmatrix} {\\pmb \\Lambda} _ {aa} \u0026 {\\pmb \\Lambda} _ {ab} \\\\ {\\pmb \\Lambda} _ {ba} \u0026 {\\pmb \\Lambda}_{bb} \\end{pmatrix}$$ 이제 우리는 conditional distribution $p(\\textbf{x}_a | \\textbf{x}_b)$ 을 살펴보자. (gaussian은 quadratic form in the exponent를 주의깊게 살펴보자) $\\textbf{x}_b$는 fixed 되었으며 exp 안의 부분을 나눠서보면 $$-\\frac{1}{2}({\\bf x}-{\\pmb \\mu})^T\\Sigma^{-1}({\\bf x}-{\\pmb \\mu})=$$ $$ -\\frac{1}{2}({\\bf x}_a - {\\pmb \\mu}_a)^T{\\pmb \\Lambda} _ {aa}({\\bf x}_a-{\\pmb \\mu}_a) - \\frac{1}{2}({\\bf x}_a - {\\pmb \\mu}_a)^T {\\pmb \\Lambda} _ {ab}({\\bf x}_b-{\\pmb \\mu}_b)$$ $$-\\frac{1}{2}({\\bf x}_b-{\\pmb \\mu}_b)^T{\\pmb \\Lambda} _ {ba}({\\bf x}_a-{\\pmb \\mu}_a) - \\frac{1}{2}({\\bf x}_b - {\\pmb \\mu}_b)^T{\\pmb \\Lambda} _ {bb}({\\bf x}_b-{\\pmb \\mu}_b) $$ 위 식을 보면 $\\textbf{x}_a$ 에 대한 함수이고 quadratic form 임을 알 수 있다. 즉 conditional dist는 Gaussian인 것이다. 이제 평균과 분산을 구하는 과정을 살펴보자. 먼저, $\\textbf{x}_a$의 second order인 부분을 먼저보면 $$-\\frac{1}{2}\\textbf{x}^T_a {\\pmb \\Lambda}_{aa} \\textbf{x}_a$$ 따라서 우리는 conditional distribution $p(\\textbf{x}_a | \\textbf{x}_b)$의 covariance 가 $${\\pmb \\Sigma_{a|b} = {\\pmb \\Lambda}_{aa}^{-1}}$$ 임을 알 수 있다. 다음은 $\\textbf{x}_a$에 linear한 부분을 보면 $$\\textbf{x}_a^T { {\\pmb \\Lambda} _ {aa} {\\pmb \\mu}_a - {\\pmb \\Lambda} _ {ab}(\\textbf{x}_a - {\\pmb \\mu}_b)}$$ 이를 이용하여 우리는 평균을 구할 수 있다. $${\\pmb \\mu} _ {a|b} = {\\pmb \\Sigma}_{a|b} [ {\\pmb \\Lambda} _ {aa}{\\pmb \\mu}_a - {\\pmb \\Lambda} _ {ab}({\\bf x}_b-{\\pmb \\mu}_b) ] = {\\pmb \\mu}_a -{\\pmb \\Lambda} _ {aa}^{-1}{\\pmb \\Lambda} _ {ab}({\\bf x}_b-{\\pmb \\mu}_b) $$ 다음으로 공분산행렬을 구하면 $${\\pmb \\Sigma}_{a|b} = {\\pmb \\Sigma} _ {aa} - {\\pmb \\Sigma} _ {ab}{\\pmb \\Sigma} _ {bb}^{-1}{\\pmb \\Sigma} _ {ba} $$ [참고] 아래의 공식을 이용하여 구한다. $$$$ $$M = (A-BD^{-1}C)^{-1} $$ 결론 : conditional distribution도 Gaussian distribution이다 mean은 linear function of $\\textbf{x}_b$ covariance은 independent of $\\textbf{x}_b$ ","date":"2021-11-26","objectID":"/prml-chap02-2/:1:1","tags":["Gaussian Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (2)","uri":"/prml-chap02-2/"},{"categories":["PRML"],"content":"2.3.2 Mariginal Gaussian distributions $$p({\\bf x}_a) = \\int p({\\bf x}_a, {\\bf x}_b)d{\\bf x}_b $$ joint distribution에서 integrate out $x_b$하면 된다. 이번에도 마찬가지로 quadratic form을 이용하여 문제를 해결한다. 위에서 봤던 joint distribution의 exp부분을 이번에는 $\\textbf{x}_b$에 대해 전개하면 $$-\\dfrac{1}{2}{\\bf x}_b^{T}{\\pmb \\Lambda} _ {bb}{\\bf x}_b + {\\bf x}_b^T{\\bf m} = -\\dfrac{1}{2}({\\bf x}_b- {\\pmb \\Lambda} _ {bb}^{-1}{\\bf m})^T {\\pmb \\Lambda} _ {bb}({\\bf x}_b- {\\pmb \\Lambda} _ {bb}^{-1}{\\bf m}) + \\dfrac{1}{2}{\\bf m}^T {\\pmb \\Lambda} _ {bb}^{-1}{\\bf m}$$ $$\\text{where}\\;{\\bf m} = {\\pmb \\Lambda}_{bb}{\\pmb \\mu} _ b - {\\pmb \\Lambda} _ {ba}({\\bf x}_a-{\\pmb \\mu}_a)$$ 위의 식 우항에서 첫번째 부분은 quadratic form으로 만들었다. integrate하면 exp부분을 제외한 Gaussian distribution의 normalization constant가 나온다. 이는 첫번째항의 covariance determinant만 관련이 있고 $\\textbf{x}_a$와 independent하다. 결국 중요한건 $\\textbf{x}_a$와 dependent한 뒷부분인데 이를 정리하면 ${\\bf x}_a$에 대한 marginal gaussian distribution가 된다. $$\\dfrac{1}{2}[{\\pmb \\Lambda} _ {bb}{\\pmb \\mu}_b-{\\pmb \\Lambda} _ {ba}({\\bf x}_a-{\\pmb \\mu}_a)]^T {\\pmb \\Lambda} _ {bb}^{-1}[{\\pmb \\Lambda} _ {bb}{\\pmb \\mu}_b-{\\pmb \\Lambda} _ {ba}({\\bf x}_a-{\\pmb \\mu}_a)]$$ $$- \\dfrac{1}{2}{\\bf x}_a^T{\\pmb \\Lambda} _ {aa}{\\bf x}_a + {\\bf x}_a^T({\\pmb \\Lambda} _ {aa}{\\pmb \\mu}_a+{\\pmb \\Lambda} _ {ab}{\\pmb \\mu}_b) + const$$ $$= - \\dfrac{1}{2}{\\bf x}_a^T({\\pmb \\Lambda} _ {aa}-{\\pmb \\Lambda} _ {ab}{\\pmb \\Lambda} _ {bb}^{-1}{\\pmb \\Lambda} _ {ba}){\\bf x}_a + {\\bf x}_a^T({\\pmb \\Lambda} _ {aa}-{\\pmb \\Lambda} _ {ab}{\\pmb \\Lambda} _ {bb}^{-1}{\\pmb \\Lambda} _ {ba}){\\pmb \\mu}_a+const $$ 이를 이용하여 marginal distribution을 구하면 된다. 먼저, covariance는 $${\\pmb \\Sigma}_a = ({\\pmb \\Lambda} _ {aa}-{\\pmb \\Lambda} _ {ab}{\\pmb \\Lambda} _ {bb}^{-1}{\\pmb \\Lambda} _ {ba})^{-1} = {\\pmb \\Sigma} _ {aa}$$ mean은 아래와 같다. $${\\pmb \\Sigma}_a({\\pmb \\Lambda} _ {aa}-{\\pmb \\Lambda} _ {ab}{\\pmb \\Lambda} _ {bb}^{-1}{\\pmb \\Lambda} _ {ba}){\\pmb \\mu}_a = {\\pmb \\mu}_a$$ 결론 : Marginal distribution도 Gaussian distribution이다. $E[\\textbf{x}_a] = {\\pmb \\mu}_a$ $cov[\\textbf{x}_a] = \\Sigma _{aa}$ 직관과 거의 일치한다. (partitioned한 부분) ","date":"2021-11-26","objectID":"/prml-chap02-2/:1:2","tags":["Gaussian Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (2)","uri":"/prml-chap02-2/"},{"categories":["PRML"],"content":"2.3.3 Bayes' theorem for Gaussian variables Gaussian marginal distribution $p(\\textbf{x})$ , Gaussian conditional distribution $p(\\textbf{y} | \\textbf{x})$가 주어진 상태이다. (2.3.1과 2.3.2에서 알게된 사실을 토대로) $$p({\\bf x}) = N({\\bf x}|{\\pmb \\mu}, {\\pmb \\Lambda}^{-1}) $$ $$p({\\bf y}|{\\bf x}) = N({\\bf y}|{\\bf A} {\\bf x}+{\\bf b} , \\textbf{L}^{-1}) $$ 우리는 Gaussian marginal distribution $p(\\textbf{y})$ , Gaussian conditional distribution $p(\\textbf{x} | \\textbf{y})$를 구하고자 한다. 먼저 joint distribution을 구한 뒤에 구해보자. $${\\bf z} = \\dbinom{ {\\bf x} }{ {\\bf y} }$$ $$\\ln p({\\bf z}) = \\ln p({\\bf x}) + \\ln p({\\bf y}) \\\\ = -\\frac{1}{2}({\\bf x}-{\\pmb \\mu})^T{\\pmb \\Lambda}({\\bf x}-{\\pmb \\mu}) -\\frac{1}{2}({\\bf y}-{\\bf A}{\\bf x}-{\\bf b})^T {\\bf L}({\\bf y}-{\\bf A}{\\bf x}-{\\bf b})+const $$ 위의 식은 quadratic 형태의 함수라는 것을 알수 있고 따라서 Gaussian distribution의 함수일 것이다. 위의 식을 전개하여 이차항을 살펴보면 (for covariance) $$-\\frac{1}{2} {\\bf x}^T ({\\pmb \\Lambda} + {\\bf A}^T {\\pmb \\Lambda} {\\bf A}) {\\bf x} - \\frac{1}{2} {\\bf y}^T {\\bf L}{\\bf y} + \\frac{1}{2} {\\bf x}^T {\\bf A}{\\bf L}{\\bf y}$$ $$ = -\\frac{1}{2} \\dbinom{ {\\bf x} }{ {\\bf y} }^T \\left(\\begin{array}{cc}{\\pmb \\Lambda}+{\\bf A}^T{\\bf L}{\\bf A} \u0026 -{\\bf A}^T{\\bf L} \\\\ - {\\bf L}{\\bf A} \u0026 {\\bf L}\\end{array} \\right) \\dbinom{ {\\bf x} }{ {\\bf y} } = -\\frac{1}{2}{\\bf z}^T{\\bf R}{\\bf z}$$ 따라서 precision matrix는 $${\\bf R} = \\left(\\begin{array}{cc}{\\pmb \\Lambda}+{\\bf A}^T{\\bf L}{\\bf A} \u0026 -{\\bf A}^T{\\bf L}\\-{\\bf L}{\\bf A} \u0026 {\\bf L}\\end{array}\\right)$$ 임을 알 수 있다. 이를 inverse하여 covariance matrix를 구하면 $$cov[{\\bf z}]={\\bf R}^{-1} = \\left(\\begin{array}{cc}{\\pmb \\Lambda}^{-1} \u0026 {\\pmb \\Lambda}^{-1}{\\bf A}^T \\ {\\bf A}{\\pmb \\Lambda}^{-1} \u0026 {\\bf L}^{-1}+{\\bf A}{\\pmb \\Lambda}^{-1}{\\bf A}^T \\end{array}\\right)$$ 이전의 방법을 이용하여 mean을 구할 수 있다. $${\\bf x}^T{\\pmb \\Lambda}{\\pmb \\mu} - {\\bf x}^T{\\bf A}^T{\\bf L}{\\bf b} + {\\bf y}^T{\\bf L}{\\bf b} = \\dbinom{ {\\bf x} }{ {\\bf y} }^T \\dbinom {\\pmb \\Lambda}{\\pmb \\mu}-{\\bf A}^T{\\bf L}{\\bf b} {\\bf L}{\\bf b} $$ $$E[{\\bf z}] = {\\bf R}^{-1}\\dbinom{ {\\bf x} }{ {\\bf y} }^T\\dbinom {\\pmb \\Lambda}{\\pmb \\mu}-{\\bf A}^T{\\bf L}{\\bf b} {\\bf L}{\\bf b}$$ 전개하면 최종적으로 mean은 $$E[{\\bf z}] = \\dbinom{ {\\pmb \\mu} }{ {\\bf A} {\\pmb \\mu} - {\\bf b}}$$ 결과 $$E[{\\bf y}] = {\\bf A}{\\pmb \\mu} + {\\bf b}$$ $$cov[{\\bf y}] = {\\bf L}^T + {\\bf A}{\\pmb \\Lambda}^{-1}{\\bf A}^T $$ 다음은 conditional distribution $p(\\textbf{x}| \\textbf{y})$ 의 mean, covariance를 구하면 $$\\Sigma_{a|b}={\\pmb \\Lambda} _ {aa}^{-1} \\ {\\pmb \\mu}_{a|b}={\\pmb \\mu}_a - {\\pmb \\Lambda} _ {aa}^{-1}{\\pmb \\Lambda} _ {ab}({\\bf x}_b-{\\pmb \\mu}_b)$$ $$E[{\\bf x}|{\\bf y}] = ({\\pmb \\Lambda}+{\\bf A}^T{\\bf L}{\\bf A})^{-1}{ {\\bf A}^T{\\bf L}({\\bf y}-{\\bf b})+{\\pmb \\Lambda}{\\pmb \\mu}} $$ $$cov[{\\bf x}|{\\bf y}] = ({\\pmb \\Lambda}+{\\bf A}^T{\\bf L}{\\bf A})^{-1} $$ ","date":"2021-11-26","objectID":"/prml-chap02-2/:1:3","tags":["Gaussian Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (2)","uri":"/prml-chap02-2/"},{"categories":["PRML"],"content":"2.3.4 Maximum likelihood for the Gaussian Log likelihood $$\\ln p({\\bf X}|{\\pmb \\mu}, \\Sigma) = -\\frac{ND}{2}\\ln(2\\pi) - \\frac{N}{2}\\ln|\\Sigma|-\\frac{1}{2}\\sum_{n=1}^{N}({\\bf x}_n-{\\pmb \\mu})^T\\Sigma^{-1}({\\bf x}_n-{\\pmb \\mu})$$ (과정 생략) $${\\pmb \\mu} _ {ML} = \\frac{1}{N}\\sum_{i=1}^{N}{\\bf x}_i = \\bar{\\bf x}$$ $${ \\pmb \\Sigma} _ {ML} = \\frac{1}{N}\\sum_{i=1}^{N}({\\bf x}_i-\\mu)({\\bf x}_i-\\mu)^T$$ ","date":"2021-11-26","objectID":"/prml-chap02-2/:1:4","tags":["Gaussian Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (2)","uri":"/prml-chap02-2/"},{"categories":["PRML"],"content":"2.3.5 Sequential estimation data sample이 하나 들어오면 바로 계산하고 버린다. MLE를 구하는 예시를 살펴보자. $${\\pmb \\mu} _ {ML}^{(N)} = \\frac{1}{N} \\sum_{n=1}^{N}{\\bf x}_n = \\frac{1}{N}{\\bf x} _ N + \\frac{1}{N} \\sum _ {n=1}^{N-1}{\\bf x}_n$$ $$= \\frac{1}{N}{\\bf x}_N + \\frac{N-1}{N}{\\pmb \\mu} _ {ML}^{(N-1)}={\\pmb \\mu} _ {ML}^{(N-1)}+\\frac{1}{N}({\\bf x}_N-{\\pmb \\mu} _ {ML}^{(N-1)}) $$ 이전에 구한 parameter를 ‘error signal’ $(\\textbf{x} _N - {\\pmb \\mu} _{ML}^{(N-1)})$ 쪽으로 1/N에 비례하도록 수정하여 parameter를 업데이트한다. $N$이 커질수록 새로운 data의 영향은 작아진다. 이번에는 이런 Sequential estimation에서 사용되는 일반적인 방법에 대해 살펴보자. 바로 Robbins-Monro algorithm이다. random variables $\\theta, z$가 있다. conditional expectation은 $$f(\\theta)\\equiv E[z|\\theta] = \\int zp(z|\\theta)dz $$ 이고 이러한 형태를 regression function이라고 부른다. 우리의 목표는 $f(\\theta^{ * }) = 0$을 만족하는 root $\\theta^{ * }$를 찾는 것이다. 몇가지 가정을 살펴보면 data가 많으면 한번에 regression function을 만들고 root를 estimation할 수 있겠지만 지금은 Sequential하게 data가 하나씩 구해진다고 가정한다. $E[(z-f)^2 | \\theta]\u003c\\infty$ : conditional variance는 finite하다고 가정한다. $\\theta \u003e \\theta^{ * } \\rightarrow f(\\theta) \u003e 0$ $\\theta \u003c \\theta^{ * } \\rightarrow f(\\theta) \u003c 0$ Robbins-Monro의 방법은 $$\\theta^{(N)} = \\theta^{(N-1)} - a_{N-1} z(\\theta^{N-1}) $$ 여기서 $z(\\theta^{(N)})$은 N번째의 $\\theta$가 들어왔을 때, $z$의 값을 의미한다. $a_N$은 양의 실수이며 다음과 같은 조건을 갖는다. $\\lim_{N\\rightarrow\\infty}a_N=0 $ : $\\theta$가 특정값에 수렴 $\\sum_{N=1}^{\\infty}a_N=\\infty $ : root를 찾기도 전에 다른 값에 수렵하지 않도록 $% $ : 축적되는 noise가 finite하여 수렴을 방해하지 않는다. 이제 이 방법을 통해 이전에 구했던 MLE의 예시에 적용해보자. $$\\frac{\\partial}{\\partial\\theta}{-\\frac{1}{N}\\sum_{n=1}^{N}\\ln p(x_n|\\theta)}_ {\\theta_{MLE}}=0$$ MLE는 위처럼 log likelihood function을 미분하여 0으로 만드는 값니다. as $N \\rightarrow \\infty$ $$-\\lim_{n\\rightarrow\\infty}\\frac{1}{N}\\sum_{n=1}^{N}\\frac{\\partial}{\\partial\\theta}\\ln p(x_n|\\theta) = E_x\\left[-\\frac{\\partial}{\\partial\\theta}\\ln p(x|\\theta)\\right] $$ 이제 Robbins-Monro의 방법을 적용하면 $$\\theta^{(N)} = \\theta^{(N-1)} - a_{N-1}\\frac{\\partial}{\\partial\\theta^{(N-1)}}\\left[-\\ln p(x_N/\\theta^{(N-1)})\\right] $$ $$z=\\frac{\\partial}{\\partial\\mu_{ML}}[-\\ln p(x|\\mu_{ML}, \\sigma^2)]=-\\frac{1}{\\sigma^2}(x-\\mu_{ML}) $$ 따라서 $\\textbf{x}_N$을 대입하고 $a_N = \\sigma^1 / N$을 대입하면 처음에 구한 결과와 같다. ","date":"2021-11-26","objectID":"/prml-chap02-2/:1:5","tags":["Gaussian Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (2)","uri":"/prml-chap02-2/"},{"categories":["PRML"],"content":"이번 장은 주어진 데이터를 이용하여 Distribution을 만드는 것을 배울 것이다. density estimation을 하는 것이다. 이에 대한 방법으로 크게 parametric, nonparmetric 방법으로 나눌 수 있다. 추가로 몇가지 중요한 분포들에 대해 살펴볼 것이다. ","date":"2021-11-26","objectID":"/prml-chap02-1/:0:0","tags":["Bayesian","Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (1)","uri":"/prml-chap02-1/"},{"categories":["PRML"],"content":"2.1 Binary Variables 동전던지기와 같이 random variable이 딱 두가지의 값을 가지는 경우 ($x \\in {0,1}$) 에 대해 살펴보자. Bernoulli distribution $x=1$의 확률을 $p(x=1 | \\mu) = \\mu$ 라고 하자. ($0\\le \\mu \\le 1$) $E[x] = \\mu, Var[x] = \\mu(1-\\mu)$ parameter를 MLE로 추정하면 $\\mu_{ML} = \\frac{1}{N}\\sum_{n=1}^{N}{x_n}$ $$Bern(x | \\mu) = \\mu^x (1- \\mu)^{1-x}$$ MLE의 문제점을 여기서 볼 수 있다. 만약에 동전을 3번 던져서 모두 앞면이 나왔다고 하자. 이 data를 기반으로 동전이 앞면이 나올 확률을 MLE로 추정한다면 1일 것이다. 이처럼 극단적으로 overfitting이 되는 경우가 생길 수 있다. 이에 대한 해결책으로는 더 많은 data를 수집하거나 bayesian의 관점으로 접근해야 한다. Binomial distribution N번 중 $\\mu$의 확률로 사건이 $x$개 발생한 경우 (Bernoulli trial이 N번 발생) $$Bin(x | sN,\\mu) = \\begin{pmatrix} N \\ x \\end{pmatrix}\\mu^x (1-\\mu)^{N-x}$$ $$E[x] =N \\mu, Var[x] =N \\mu(1-\\mu)$$ ","date":"2021-11-26","objectID":"/prml-chap02-1/:1:0","tags":["Bayesian","Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (1)","uri":"/prml-chap02-1/"},{"categories":["PRML"],"content":"2.1.1 The beta distribution 위의 분포를 보고 bayesian의 접근방식을 생각해보자. parameter $\\mu$에 대한 prior를 만들어보자. conjugacy (prior와 posterior가 같은 분포를 갖는) 의 성질을 이용하면 Beta distribution을 생각할 수 있다. prior도 Beta이고 posterior도 Beta distribution의 모습을 보이도록 만들어준다. conjugacy를 이용하면 계산, 해석적인 측면에서 상당히 유용하다. $$Beta(\\mu | a,b) = \\frac{\\Gamma(a+b)}{\\Gamma (a) \\Gamma (b)}\\mu^{a-1}(1-\\mu)^{b-1}$$ $$E[\\mu] = \\frac{a}{a+b}, Var[\\mu] = \\frac{ab}{(a+b)^2(a+b+1)}$$ Binomial likelihood function과 Beta prior를 곱하여 posterior dist of $\\mu$ 를 만들면 $$p(\\mu | x,l,a,b) \\propto \\mu^{x+a-1} (1-\\mu)^{N-x+b-1}$$ 합이 1이 되게 constant를 만들지 않아도 posterior가 beta distribution임을 파악할 수 있다. posterior에서 $a$와 $b$는 각각 $x=1$, $x=0$ 인 data의 수와 같은 의미(역할)임을 알 수 있다. 우리는 prior를 beta로 이용했고 posterior가 beta로 나왔다. 그렇다면 나온 posterior를 다시 prior로 이용할 수 있을 것이다. 이처럼 sequential한 접근이 가능해진다. 우리의 목표는 predict이므로 predictive distribution을 구해보자. $$p(x=1 | D) = \\int_{0}^{1} p(x=1,\\mu | D)d\\mu$$ $$= \\int_{0}^{1} p(x=1 | \\mu)p(\\mu | D)d\\mu = \\int_{0}^{1}\\mu p(\\mu | D)d\\mu = E[\\mu | D]$$ 여기서 posterior dist의 평균을 구하면 $$p(x=1|D) = \\frac{x+a}{x+a+N-x+b}$$ 이고 데이터의 수가 많아지면 posterior mean은 MLE와 같아진다. 또한, uncertainty도 줄어들며 likelihood function의 모양과 가까워진다. 물론, 반대로 prior의 정보가 강하다면 prior와 비슷해진다. prior가 강하거나 data수가 많아 likelihood가 강해지면 uncertainty가 줄면서 posterior distribution의 모양이 뾰족해진다. 수리통계학에서 배웠던 공식을 이용하여 살펴보면 $E_{\\theta}[\\theta] = E_{D}[E_{\\theta}[\\theta|D]]$ D에 대해 averaged over된 posterior mean of $\\theta$ = prior mean of $\\theta$ $V_{\\theta}[\\theta] = E_{D}[V_{\\theta}[\\theta|D]]+V_{D}[E_{\\theta}[\\theta|D]]$ 평균적으로 posterior variance of $\\theta$가 prior variance보다 더 작다. ","date":"2021-11-26","objectID":"/prml-chap02-1/:1:1","tags":["Bayesian","Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (1)","uri":"/prml-chap02-1/"},{"categories":["PRML"],"content":"2.2 Multinomial Variables 이번에는 확률변수가 2가지의 값을 갖는게 아닌 K개의 값을 갖는 경우를 살펴보자. 이를 위해 우리는 vector로 확률변수를 표현한다. 예를 들어, 주사위를 던졌더니 3이란 수가 나왔다. $\\textbf{x} = (0,0,1,0,0,0)^T$ 이렇게 표현한다. 각 원소 $x_k$들의 합은 1이다. $x_k=1$인 확률을 parameter $\\mu_k$로 표현하면, $\\textbf{x}$의 distribution은 $$p(\\textbf{x} | {\\pmb \\mu}) = \\prod_{k=1}^{K}\\mu_{k}^{x_k}$$ $\\sum \\mu_k = 1, 0\\le\\mu_k\\le 1$ 이다. expectation은 $$E[{\\bf x}|{\\pmb \\mu}] = \\sum_{\\bf x}p({\\bf x}|{\\pmb \\mu}){\\bf x} = (\\mu_1, …, \\mu_K)^T = {\\pmb \\mu}$$ 으로 구할 수 있다. 그렇다면 이제 likelihood function을 구해보자. $$p(D|{\\pmb \\mu}) = \\prod_{n=1}^{N}\\prod_{k=1}^{K}\\mu_k^{x_{nk}} = \\prod_{k=1}^{K}\\mu_k^{\\sum_n x_{nk}}=\\prod_{k=1}^{K}\\mu_k^{m_k}$$ $m_k = \\sum_{n} x_{nk}$ : 전체 data에서 k값을 가지는 data 갯수 이 likelihood function을 이용하여 parameter ${\\pmb \\mu}$를 구해보자. constraint $\\sum_{k=1}^{K}{\\mu_k} = 1$ 에서 log likelihood 를 최대화 해야 한다. Lagrange multiplier $\\lambda$를 이용하여 아래 식을 최대화하면 된다. (Lagrange method) $$\\sum_{k=1}^{K}{m_k \\ln \\mu_k} + \\lambda (\\sum_{k=1}^{K}{\\mu_k}-1) $$ $\\mu_k$에 대해 미분하면 $\\mu_k = - m_k / \\lambda$ 이고 constraint때문에 $\\lambda = - N$ 이라는 것을 파악할 수 있다. 따라서 MLE는 $$\\mu_k = \\frac{m_k}{N}$$ Multinomial distribution $\\sum \\mu_k = 1, 0\\le\\mu_k\\le 1$ $\\sum m = N$ $$\\text{Multi}(m_1,m_2, … , m_K | \\mu, N) = \\frac{N!}{m_1! m_2! … m_K!}\\prod_{k=1}^{K}{\\mu_k^{m_k}}$$ ","date":"2021-11-26","objectID":"/prml-chap02-1/:2:0","tags":["Bayesian","Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (1)","uri":"/prml-chap02-1/"},{"categories":["PRML"],"content":"2.2.1 The Dirichlet distribution $$Dir(\\boldsymbol{\\mu} | \\boldsymbol{\\alpha}) = \\frac{\\Gamma (\\alpha_0)}{\\Gamma (\\alpha_1) \\Gamma(\\alpha_2)…\\Gamma(\\alpha_K)}\\prod_{k=1}^{K}{\\mu_k^{\\alpha_k - 1}}$$ $\\sum \\mu_k = 1, 0\\le\\mu_k\\le 1$ Multinomial의 conjugate prior K = 2이면 beta 분포이다. Binomial의 일반화된 분포가 Multinomial이듯 Beta의 일반화된 분포가 Dirichlet 분포라고 할 수 있다. posterior $$p({\\pmb \\mu}|D, {\\pmb \\alpha}) \\propto p(D|{\\pmb \\mu})p({\\pmb \\mu}|{\\pmb \\alpha}) \\propto \\prod_{k=1}^{K} \\mu_k^{\\alpha_k+m_k-1}$$ 이전에 봤듯이 prior의 $a_k$는 data에서 ‘observation of $x_k=1$’ 의 갯수와 같은 의미(역할)이라고 할 수 있다. ","date":"2021-11-26","objectID":"/prml-chap02-1/:2:1","tags":["Bayesian","Distribution"],"title":"[PRML] Chapter2 - Probability Distribution (1)","uri":"/prml-chap02-1/"},{"categories":["PRML"],"content":"Information Theory에 대해 알아봅시다. ","date":"2021-11-26","objectID":"/prml-chap01-3/:0:0","tags":["Information Theory"],"title":"[PRML] Chapter1 - Introduction (3)","uri":"/prml-chap01-3/"},{"categories":["PRML"],"content":"1.6 Information Theory 일단 entropy에 대해 두 가지의 시선으로 살펴볼 예정이다. 일단 discrete random variable $x$와 이 variable의 specific value를 알아내면서 얻는 정보의 양이 얼마나 되는지로부터 시작한다. 어떤 사건이 일어날 확률이 큰 경우보다 일어날 확률이 작은 사건이 더 정보가 많다고 한다. 이에 따라 우리는 information content ($h(x)$ 라고 하자) 를 측정하는 방법이 필요하다. 그 방법의 조건은 확률 $p(x)$에 대해 monotonic function 두 개의 사건이 독립적이면 information gain은 두 information의 합으로 표현 이런 조건을 만족시키기 위해 우리는 logarithm을 이용한다. ($\\log_2$인 이유는 2진수 bit단위의 정보전달의 측면에서 접근하기 위해) $$h(x) = - \\log_2 p(x)$$ information은 0이상의 값을 갖기에 음수부호를 붙여서 사용한다. 이제 sender가 receiver에게 random variable의 값을 전달해야하는 상황이라고 가정하자. 그들이 전달하는 정보의 평균적인 양은 $$H[x] = - \\sum_{x}{p(x)\\log_2 p(x)}$$ 이를 우리는 entropy of the random variable x 라고 부른다. (예시는 생략) nonuniform distribution은 uniform distribution보다 더 작은 entropy값을 갖는다. entropy의 값을 정보전달의 측면 (bit단위라고 생각) 에서 생각해보자. 예를 들면, A집단의 entropy가 2, B집단의 entropy가 3의 값을 가진다. A의 내용을 전달하기 위해서는 최소 2bit, B는 최소 3bit가 필요한 것을 의미하고 이처럼 entropy는 the state of a random variable을 전달하기 위해 필요한 bits 수의 lower bound이다. 이번에는 entropy에 대해 다른 시각으로 살펴보자. N개의 물체를 bin에 나누어 담아야 한다. $i^{th}$ bin 에는 $n_i$개의 물체가 들어간다. 물체를 나누어 담는 경우의 수 $W$ 를 생각해보면 $$W = \\frac{N!}{\\prod_i n_i !}$$ 이를 multiplicity 라고 부른다. entropy를 만들기 위해 logarithm과 적절한 scaled 취하면 $$H = \\frac{1}{N}\\ln w = \\frac{1}{N} \\ln N! - \\frac{1}{N}\\sum_{i} \\ln n_i !$$ N이 무한대로 가고 $n_i / N$은 fixed 된다. 그리고 Stirling’s approximation을 이용하면 $\\ln N ! \\approx N \\ln N - N$ $\\ln n_i ! \\approx n_i \\ln n_i - n_i$ 이를 대입하면 $$H = - \\lim_{N \\rightarrow \\infty} \\sum_{i} \\frac{n_i}{N} \\ln \\frac{n_i}{N} = - \\sum_{i}{p_i \\ln p_i}$$ $\\sum_i n_i = N$ $p_i = \\lim_{N \\rightarrow \\infty} (n_i / N)$ : 물체가 i bin에 들어갈 확률 우리는 bin을 random variable X의 state $x_i$ 라고 할 수 있다. 따라서 random variable X의 entropy는 $$H[p] = - \\sum_{i}{p(x_i)\\ln p(x_i)}$$ 우리는 Lagrange를 이용하여 위의 식의 최댓값을 구할수 있고 최댓값은 Uniform distribution 일 때이다. 이제 continuos variable에서도 생각해보자. (과정 생략) continuos variable의 entropy는 아래 값을 가진다. $$H[x] = - \\int p(x) \\ln p(x) dx$$ 이를 differential entropy 라고 부른다. discrete의 경우에서와 마찬가지로 continuos에서는 어떤 distribution이 가장 큰 entropy를 가질까? (과정 생략, 똑같이 Lagrange 사용) 정답은 Gaussian distribution 인 경우이다. ","date":"2021-11-26","objectID":"/prml-chap01-3/:1:0","tags":["Information Theory"],"title":"[PRML] Chapter1 - Introduction (3)","uri":"/prml-chap01-3/"},{"categories":["PRML"],"content":"1.6.1 Relative entropy and mutual information 우리가 모르는 distribution $p(x)$가 있다고 가정해보자. 이를 approximation하는 $q(x)$를 모델링하였다. 이전에 정보전달에서의 측면에서 생각해보면 우리는 approximation 했기에 random variable 의 value 전달을 위해 추가적으로 리소스 bit가 더 필요하다. 더 필요한 정도는 $$KL(p| q) = - \\int p(\\textbf{x}) \\ln q(\\textbf{x})d\\textbf{x} - (- \\int p(\\textbf{x}) \\ln p(\\textbf{x})d\\textbf{x}) \\ = - \\int p(\\textbf{x})\\ln \\frac{p(\\textbf{x})}{q(\\textbf{x})}d\\textbf{x}$$ 이를 Kullbak-Leibler divergence (Relative entropy) between $p(\\textbf{x})$ and $q(\\textbf{x})$ 라고 부른다. 그리고 아래와 같은 특징을 갖는다. (이러한 특징을 통해 Kullbak-Leibler divergence는 measure of the dissimilarity of the two distributions $p(\\textbf{x}), q(\\textbf{x})$ 라고 할 수 있다.) $KL(p| q) \\ge 0$ $KL(p| q) = 0$, if and only if, $p(\\textbf{x}) = q(\\textbf{x})$ 증명은 Jensen’s inequality로 쉽게 할 수 있다. convex function $f(x)$는 $$f(\\sum_{i=1}^{M}{\\lambda_i x_i}) \\le \\sum_{i=1}^{M}{\\lambda_i f(x_i)}$$ $\\lambda \\ge 0$ $\\sum_i \\lambda_i = 1$ 의 특징을 갖는다. 위에서 $\\lambda_i$를 x의 확률분포라고 생각하면 $f(E[x]) \\le E[f(x)]$ 이다. 따라서 ($f$ 를 -log라고 생각하면 된다) $$KL[p|q] = - \\int p(\\textbf{x}) \\ln \\frac{q(\\textbf{x})}{p(\\textbf{x})}d\\textbf{x} \\ge - \\ln \\int q(\\textbf{x}) d\\textbf{x} = 0 $$ KL divergence를 최소화하는 것은 결국 likelihood function을 최대화하는 것과 같은데 이에 대해 살펴보자. 우리가 모르는 (approximation해야하는) 분포 $p(\\textbf{x})$에서 data가 generate되었다고 하자. 우리는 어떤 parametric distribution $q(\\textbf{x} | \\theta)$ 를 통해 approximation하고자 한다. $\\theta$를 정하는 방법은 $\\theta$에 대해 KL divergence를 최소화하는 것을 찾는 것이다. 그런데 우리는 $p(\\textbf{x})$를 모르는 상황이기에 directly할 수 없다. 대신 N개의 train data가 존재하므로 이를 이용하면 $$KL(p|q) \\approx \\sum_{n=1}^{N}{{ - \\ln q (\\textbf{x}_n | {\\bf \\theta}) + \\ln p(\\textbf{x}_n)} }$$ 우변의 두번째항은 parameter와 independent하다. 첫번째항은 negative log likelihood function for $\\theta$ of under the distribution $q(\\textbf{x} | \\theta)$ (train data를 통해 만들어진 분포) 이므로 KL divergence를 최소화하는 것은 likelihood function을 최대화하는 것이다. 이번에는 joint distribution을 생각해보자. 두 변수가 independent이면 $p(\\textbf{x}\\textbf{y}) = p(\\textbf{x})p(\\textbf{y})$ 이다. 하지만 independent가 아닌 경우, 우리는 KL divergence를 통해 얼마나 independent와 가까운지 생각해볼수 있다. $$I[\\textbf{x}, \\textbf{y}] \\equiv KL(p(\\textbf{x}, \\textbf{y}) | p(\\textbf{x})p(\\textbf{y})) = - \\int \\int p(\\textbf{x}, \\textbf{y}) \\ln \\frac{p(\\textbf{x})p(\\textbf{y})}{p(\\textbf{x}, \\textbf{y})}d\\textbf{x} d\\textbf{y}$$ 이를 mutual information between the variable x and y 라고 부른다. conditional entropy의 측면에서 $I[\\textbf{x}, \\textbf{y}] = H[\\textbf{x}] - H[\\textbf{x}|\\textbf{y}] = H[\\textbf{y}] - H[\\textbf{y}/\\textbf{x}]$ 따라서 MI는 y를 알고 난 뒤에 x의 uncertainty가 줄어든 정도 (반대도 성립) 라고 할 수 있다. Bayesian의 입장에서는 $p(\\textbf{x})$가 pior이고 $p(\\textbf{x} | \\textbf{y})$는 y data를 얻은 후의 posterior이다. 따라서 MI는 새로운 observation y의 등장으로 줄어든 x의 uncertainty라고 할 수 있다. ","date":"2021-11-26","objectID":"/prml-chap01-3/:1:1","tags":["Information Theory"],"title":"[PRML] Chapter1 - Introduction (3)","uri":"/prml-chap01-3/"},{"categories":["PRML"],"content":"Decision Theory에 대해 알아봅시다. ","date":"2021-11-26","objectID":"/prml-chap01-2/:0:0","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"1.5 Decision Theory Decision Theory는 크게 두 가지의 과정으로 이루어져 있다. Determining $p(x,t)$ from a training data set : inference 이를 통하여 새로운 데이터에 대해 결정(분류,회귀) : decision Decision Theory의 목표는 적절한 Probability들을 이용하여 optimal한 decision을 내리는 것이다. 2-class classification의 상황을 예시로 뒤의 내용을 진행한다. 우리는 input data를 통해 해당 data의 class를 구분하고 싶기에 $p(C_k / \\textbf{x})$를 구해야 한다. Bayes' theorem을 생각해보면 posterior를 구해야 하는 것이다. $$p(C_k | \\textbf{x}) = \\frac{p(\\textbf{x} | C_k)p(C_k)}{p(\\textbf{x})}$$ 우리는 misclassfication을 최소화하기 위해서 둘 중 더 큰 posterior probability갖는 class에 input data를 분류한다. ","date":"2021-11-26","objectID":"/prml-chap01-2/:1:0","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"1.5.1 Minimizing the misclassfication rate 우리의 목표가 misclassfication을 최소화하는게 목표라고 하자. 각 $\\textbf{x}$를 class에 분류해야하고 이를 위해 rule이 필요하다. 그 rule에 따라 input space를 region $R_k$로 나눠야 한다. 이 region을 decision regions 라고 한다. ($R_k$에 속한 data는 class k라고 분류) decision region간의 경계선을 decision boundary, decision surface 라고 부른다. misclassfication의 확률은 $$P(mistake) = P(\\textbf{x} \\in R_1, C_2) + P(\\textbf{x} \\in R_2, C_1) = \\int_{R_1} p(\\textbf{x}, C_2)d\\textbf{x}+ \\int_{R_2} p(\\textbf{x}, C_1)d\\textbf{x}$$ mistake의 확률을 최소화하기 위해서는 각 integral의 값을 최소화해야 한다. 따라서 만약 $p(\\textbf{x}, C_1) \u003e p(\\textbf{x}, C_2)$의 경우, data를 class1으로 분류해야한다. $p(\\textbf{x}, C_k) = p(\\textbf{x}) p(C_k | \\textbf{x})$ 이고 우변의 $p(\\textbf{x})$는 공통된 부분이므로 우리는 $p(C_k | \\textbf{x})$만 고려하면 된다. ","date":"2021-11-26","objectID":"/prml-chap01-2/:1:1","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"1.5.2 Minimizing the expected loss 위에서 misclassfication rate를 줄이는 부분에 대해서 살펴봤다. 하지만 실제로 분류를 할 때는 이 접근으로는 부족하다. 예를 들어, 암환자를 분류하는 문제라고 생각해보자. 암이 걸리지 않은 환자를 걸렸다고 잘못 판단하는 것과 암이 걸렸는데 걸리지 않았다고 판단하는 것. 둘 중 후자가 훨씬 심각한 문제이다. 이런 경우 후자에 대해 더 가중치가 있어야 하지 않을까? loss function (cost function) : overall measure of loss incurred in taking any of the available decisions or actions $L_{kj}$ : (k인데 j로 분류한 경우) loss matrix의 element를 의미한다. misclassfication에 대한 loss라고 이해하면 된다. 예를 들면 암환자의 loss matrix는 아래와 같은 모양이다. $$\\begin{bmatrix} 0 \u0026 100 \\\\ 1 \u0026 0 \\end{bmatrix}$$ (inference가 끝난 뒤에 decision하는 과정에 해당) optimal solution은 loss function을 최소화하는 것이다. 하지만 loss function은 true class을 알아야 계산할 수 있다. 우리는 true class를 모른다. (예를 들어, 환자의 신상데이터가 있고 이를 통해 암환자인지 아닌지 찾아야하는 상황) 따라서 우리는 expected (average) loss를 최소화하는 방법을 선택한다. $$E[L] = \\sum_{k} \\sum_{j} \\int_{R_j} L_{kj} p(\\textbf{x}, C_k) d\\textbf{x}$$ 우리의 목표는 expected loss를 최소로 만드는 적절한 $R_j$를 찾는 것이고 이는 각 데이터 $\\textbf{x}$가 $\\sum_{k} L_{kj}p(\\textbf{x}, C_k)$를 최소화 한다는 것을 의미한다. 최종적으로 expected loss를 최소화 하기 위해서는 $\\textbf{x}$를 값 $$\\sum_{k}{L_{kj} p(C_k|\\textbf{x})}= E[L(C_k, \\hat{C}_k) | X=\\textbf{x}]$$ 이 최소가 되는 class $j$로 분류하는 것이다. ","date":"2021-11-26","objectID":"/prml-chap01-2/:1:2","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"1.5.3 The reject option class에 따라 posterior의 비교를 통해 결정하기 애매한 상황이 생긴다. 이런 경우에는 probability에 따라 결정하기 보다는 다른 방법을 사용하는 것이 적절할 수도 있다. (예를 들면, 해당 데이터를 model이 아니라 전문가가 판단하는 방법) 이런 경우 regect option 이 있다고 할 수 있는 것이다. ","date":"2021-11-26","objectID":"/prml-chap01-2/:1:3","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"1.5.4 Inference and decision decision 문제를 해결하는 방법을 3가지로 분류할 수 있다. 앞쪽의 방법일수록 복잡한 방법이다. generative model 아래 식에서 posterior를 구하기 위해서는 분자, 분모를 다 구해야 한다. 한마디로 approachs that explicitly or implicitly model the distribution of inputs as well as outputs. 다른 표현으로는, joint distribution $p(\\textbf{x}, C_k)$을 구해서 marginalize하여 분모도 구하여 posterior를 구한다. $$p(C_k | x) = \\frac{p(x | C_k)p(C_k)}{p(x)}$$ discriminative model approachs that model the posterior probabilities directly 예를 들면 SVM, Tree models, KNN 등등 discriminative function maps each input x directly onto a class label 따라서 확률을 고려하지 않는다. inference와 decision stage를 하나로 묶은 것이다. 각각 장단점이 존재한다. 예를 들면, 1번에서 prior $p(\\textbf{x})$를 구했으므로 해당 값이 너무 작은 새로운 data는 무시하는 판단을 할 수 있다. (outlier detection하는 것처럼) 그렇다면 이제 (1,2번 선호) posterior를 구하면 어떤 장점이 있는지 알아보자. Minimizing risk 이전에 봤던 loss matrix를 수정하여 decision criterion을 수정하기 쉽다. 확률의 threshold를 조정하여 decision criterion을 수정하기 쉽다. Reject option expected loss뿐만 아니라 misclassfication rate를 최소화하는 rejection criterion을 정할 수 있게 해준다. Compensating for class priors posterior는 prior에 비례하므로 prior를 적절하게 바꿔줌으로서 posterior를 보완할 수 있다. Combing models 특정 문제를 subproblem으로 나누어서 생각할 수 있다. 예를 들면, naive bayes model과 같이 independent를 이용하여 posterior를 나누어서 생각할 수 있는 장점이 생긴다. ","date":"2021-11-26","objectID":"/prml-chap01-2/:1:4","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"1.5.5 Loss functions for regression 이전까지 classification에 대해 살펴봤으므로 이번에는 regression에 대해 살펴보자. expected (average) loss는 $$E[L] = \\int \\int L(t, y(\\textbf{x})) p(\\textbf{x}, t) d\\textbf{x}dt$$ 이다. regression에서 주로 사용하는 loss function은 squared loss이고 이를 통해 다시 쓰면 $$E[L] = \\int \\int {y(\\textbf{x}) - t}^2 p(\\textbf{x}, t) d\\textbf{x} dt$$ 이다. 우리는 이를 최소화하는 $y(\\textbf{x})$를 찾는 것이 목표이므로 미분하여 구할 수 있다. $$\\frac{dE[L]}{dy(\\textbf{x})} = 2\\int { y(\\textbf{x}) - t}p(\\textbf{x}, t) dt = 0$$ $$y(\\textbf{x}) = \\frac{\\int t p(\\textbf{x}, t)dt}{p(\\textbf{x})} = \\int t p(t | \\textbf{x})dt = E_t [t | \\textbf{x}]$$ 이는 우리가 알고 있는 regression function의 모양이다. (conditional average of t conditioned on x) 이를 이용하여 추가적인 접근을 해보자면 $${y(\\textbf{x}) - t}^2 = {y(\\textbf{x}) - E[t | \\textbf{x}] + E[t | \\textbf{x}] - t }^2$$ $$E[L] = \\int {y(\\textbf{x}) - E[t | \\textbf{x}]}^2 p(\\textbf{x})d\\textbf{x} + \\int {E[t | \\textbf{x}] - t}^2 p (\\textbf{x}) d\\textbf{x} $$ 두번째 항은 variance of the distribution of t, averaged over x 이다. 따라서 이는 irreducible minumum value of the loss function을 의미한다. ","date":"2021-11-26","objectID":"/prml-chap01-2/:1:5","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"+ Decision Theory 추가 monk의 강의에서 decision theory를 다루는데 해당 내용을 추가하고자 한다. 일단, loss function은 “0-1 loss” 으로 생각하자. true = prediction : 0 true != prediction : 1 두 가지 상황으로 나누어서 살펴보자. 하지만 두 경우 모두의 공통적인 결론은 $p(y/x)$ 가 핵심이라는 것이다. ","date":"2021-11-26","objectID":"/prml-chap01-2/:2:0","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"1. Minimizing conditional expected loss : Given $x$, minimize $L(y, \\hat{y})$ … but don’t know true class $y$ $(X, Y) \\sim P$ : discrete $$E[L(Y, \\hat{y}) | X = x] = \\sum_{y} L(y, \\hat{y}) P(y | x) = \\sum_{y \\neq \\hat{y} } 1*P(y | x) = 1 - P(\\hat{y} | x)$$ $$\\therefore \\hat{y} = argmin_y E[L(Y,\\hat{y}) | x] = argmax_y P(y | x)$$ ","date":"2021-11-26","objectID":"/prml-chap01-2/:2:1","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"2. Choosing f to minimize expected loss : Choose $f(f(x) = y)$ to minimize $L(y, f(x))$ but don’t know $x$ or $y$ $$E[L(Y, \\hat{Y})] = E[L(Y, f(X))] = \\sum_{x,y}L(y, f(x))P(x,y)$$ $$ = \\sum_{x}{\\sum_y L(y, f(x))P(y | x)}P(x) = \\sum_{x}g(x,f(x))p(x) = E_x[g(x,f(x))]$$ suppose for some $x', t$ $g(x', f(x')) \\ge g(x', t)$ $f_0(x) =$ if $x \\neq x', f(x)$ if $x = x', t$ 모든 $x,; g(x,f(x)) \\ge g(x, f_0(x))$ $$\\therefore E_x [g(x, f(x))] \\ge E_x[g(x,f_0(x))]$$ Choose f to min $g(x,f(x))$ $$f(x) = argmin_t g(x,t)$$ ","date":"2021-11-26","objectID":"/prml-chap01-2/:2:2","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"Big picture ","date":"2021-11-26","objectID":"/prml-chap01-2/:2:3","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"Generative model estimate $p(x,y)$ using data and then $p(y|x) = \\frac{p(x,y)}{p(x)}$ parameter / latent : $\\theta$ 라고 하자 $\\theta$는 distribution에 관한 parameter / latent $D$는 random (new data) $$p(y|x,D) = \\int p(y|x,D,\\theta) p(\\theta | x,D) d\\theta$$ $p(y|x,D)$ : predictive distribution $p(\\theta |x,D)$ : posterior distribution $p(y|x,D,\\theta)$ 이 부분은 주로 closed form(eg. regression y=wx)으로 구해지며 어렵지 않다. 하지만 posterior 부분은 closed form으로 못 구하는 경우가 많다. 또한 integral 부분도 계산이 어려운 경우가 많다. 그렇다면 이를 어떻게 해결할까? 크게 4가지의 방법을 살펴보자. exact inference Multivariate Gaussian, Conjugate prior, Graphical model point estimate MLE, MAP (1.2.5를 보면 integral 없이 계산) optimization, EM deteministic approximation Laplace approximation, Variational method, Expectation propagation stochastic approximation Sampling 기법들 (eg. MCMC) ","date":"2021-11-26","objectID":"/prml-chap01-2/:2:4","tags":["Decision Theory"],"title":"[PRML] Chapter1 - Introduction (2)","uri":"/prml-chap01-2/"},{"categories":["PRML"],"content":"Probability Theory에 대해 알아봅시다. ","date":"2021-11-26","objectID":"/prml-chap01-1/:0:0","tags":null,"title":"[PRML] Chapter1 - Introduction (1)","uri":"/prml-chap01-1/"},{"categories":["PRML"],"content":"1.1 Example : polynomial curve fitting 예를 들어, 회귀에서 error function이 quadratic function of w이면 w에 대한 미분은 w에 linear하고 unique한 closed form의 해를 구할 수 있다. 모델의 overfitting을 항상 조심하고 데이터의 수가 늘어날수록 그 정도는 약해진다. MLE 방법은 overfitting에 취약하며 Bayesian 모델링으로 보완할 수 있다. ridge와 같이 error function에 패널티항을 추가하여 overfitting을 막는 방법도 있다. 이를 shrinkage 방법이라 부른다. (딥러닝에서는 weight decay) 이런 모델의 복잡한 정도를 정하는 데에 validation data set을 만들기도 하는데 이는 다소 낭비이므로 다른 방법을 공부할 것이다. (아마 Bayesian approach일듯) ","date":"2021-11-26","objectID":"/prml-chap01-1/:1:0","tags":null,"title":"[PRML] Chapter1 - Introduction (1)","uri":"/prml-chap01-1/"},{"categories":["PRML"],"content":"1.2 Probability Theory 패턴인식에서 가장 중요한 컨셉은 uncertainty이다. Probability Theory는 이런 uncertainty을 quantification하고 manipulation하는 방법을 제시한다. (확률을 이용하여) The rules of Probability sum rule : $p(X) = \\sum_{Y}{p(X,Y)}$ product rule : $p(X,Y) = p(Y|X)p(X)$ Bayes' Throrem (rule) $p(Y|X) = \\frac{p(X|Y)p(Y)}{p(X)}$ $p(Y)$ : prior probability $p(Y|X)$ : posterior probability ","date":"2021-11-26","objectID":"/prml-chap01-1/:2:0","tags":null,"title":"[PRML] Chapter1 - Introduction (1)","uri":"/prml-chap01-1/"},{"categories":["PRML"],"content":"1.2.1 Probability densities probability density : if the probability of a real-valued variable $x $ falling in the interval $(x, x+\\delta x )$ is given by $p(x)\\delta x$ for $\\delta x \\rightarrow 0$, then $p(x)$ is called the probability density 값은 항상 0 이상, 합하면 1을 가진다. ","date":"2021-11-26","objectID":"/prml-chap01-1/:2:1","tags":null,"title":"[PRML] Chapter1 - Introduction (1)","uri":"/prml-chap01-1/"},{"categories":["PRML"],"content":"1.2.2 Expectations and covariances expection of $f(x)$ : $E[f(x)] = \\int{p(x)f(x)dx}$ it can be approximated as $$E[f] \\approx \\frac{1}{N}\\sum_{n=1}^{N}{f(x_n)}$$ $E_x [f(x,y)]$는 y에 대한 함수이다. x에 대해 averaged over 된 것이다. conditional expection : $E[f(x)|y] = \\int{p(x|y)f(x)dx}$ variance of $f(x)$ : $var[f] = E[(f(x) - E[f(x)])^2]$ $f(x)$가 mean 주위에서 얼마나 variability가 있는지 보여준다. ","date":"2021-11-26","objectID":"/prml-chap01-1/:2:2","tags":null,"title":"[PRML] Chapter1 - Introduction (1)","uri":"/prml-chap01-1/"},{"categories":["PRML"],"content":"1.2.3 Bayesian probabilities 우리가 일반적으로 알고 있는 확률(probability)은 frequentist의 견해이다. bayesian은 frequentist와는 아예 다른 접근법을 갖는다. Frequentist 분모가 되는 전체 사건이 무한대로 일어나고 우리가 궁금한 사건이 그 중 몇번 일어나는지를 확률로 생각한다. parameter 추정이 목표이며 parameter는 fixed 되어 있다고 생각한다. 주로 estimator로서 likelihood function을 최대화하는 MLE로 사용한다. Bayesian 확률 : uncertainty를 quantification한 것으로 생각한다. parameter는 fixed 된 것이 아니라 (probability) distribution을 갖는 것이라고 생각한다. posterior distribution을 찾는 것이 목표이다. Bayes' theorem $$p(\\textbf{w} | D) = \\frac{p(D | \\textbf{w})p(\\textbf{w})}{p(D)}$$ parameter에 대해 원래 갖고 있던 믿음을 data D에 대한 정보를 얻은 뒤에 posterior probability로 업데이트 한다. (분모는 posterior가 합이 1이 되기 위한 normalization constant) prior probability : $p(w)$ likelihood function : $p(D/w)$ posterior probability : $p(w/D)$ posterior $\\propto$ likelihood * prior ","date":"2021-11-26","objectID":"/prml-chap01-1/:2:3","tags":null,"title":"[PRML] Chapter1 - Introduction (1)","uri":"/prml-chap01-1/"},{"categories":["PRML"],"content":"1.2.4 The Gaussian distribution $$N(x | \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi \\sigma^2}}exp{ - \\frac{(x-\\mu)^2}{2 \\sigma^2} }$$ mean : $\\mu$ variance : $\\sigma^2$ standard deviation : $\\sigma$ precision : $\\beta = 1/ \\sigma^2$ normal (gaussian) 분포는 mode와 mean이 같다. i.i.d (independent and identically distributed : data point가 독립적이고 같은 분포에서 나왔다) 인 경우, likelihood function은 $$p(\\textbf{x} | \\mu, \\sigma^2) = \\prod_{n=1}^{N}{N(x_n | \\mu, \\sigma^2)}$$ 이고 이를 최대화하는 mean과 variance의 MLE는 sample mean, sample variance이다. MLE를 구하는 방법은 likelihood function에 log를 취한 후 미분하여 0을 만족하는 parameter를 찾으면 된다. 이때 단점은 maximum likelihood 접근법이 분포의 variance를 underestimate한다(bias 발생)는 점이다. N이 커지면 문제가 없지만 복잡한 모델에서는 이런 bias때문에 문제가 발생할 수 있다. (나중에 공부한다) ","date":"2021-11-26","objectID":"/prml-chap01-1/:2:4","tags":null,"title":"[PRML] Chapter1 - Introduction (1)","uri":"/prml-chap01-1/"},{"categories":["PRML"],"content":"1.2.5 Curve fitting re-visted data를 통해 polynomial curve를 fitting해보자. target t에 대한 uncertainty를 probability를 통해 표현하면 (under gaussian noise distribution) $$p(t | x, \\textbf{w}, \\beta) = N(t | y(x,\\textbf{w}), \\beta^{-1})$$ 위의 식을 이용하여 우리는 parameter $\\textbf{w}$ 추정한다. likelihood를 최대로 하는 MLE를 찾으면 되는 것이다. log likelihood function은 아래와 같은 모양을 갖는다. $$\\ln p(\\textbf{t} | \\textbf{x}, \\textbf{w}, \\beta) = - \\frac{\\beta}{2}\\sum_{n=1}^{N}{{ y(x_n, \\textbf{w}) - t_n }^2} + \\frac{N}{2}\\ln \\beta - \\frac{N}{2}\\ln (2 \\pi)$$ 위 값을 최대화 하는 $\\textbf{w}_{ML}$을 찾으면 된다. 이는 결국 least square 방법과 동일한 의미를 갖는다. (추정선과 target의 차이를 최소화해야되므로) parameter를 추정한 뒤에 이제 prediction을 해야한다. 우리는 확률모델을 갖고 있기에 t에 대한 point estimate만이 아니라 predictive distribution을 만들 수 있다. $$p(t | x, \\textbf{w} _ {ML}, \\beta _ {ML}) = N(y(x,\\textbf{w} _ {ML}), \\beta _ {ML}^{-1})$$ 지금까지는 frequentist의 영역이였다면 Bayesian들은 어떤 접근을 하는지 살펴보자. 일단 우리가 추정해야하는 parameter에 대한 prior를 갖고 있다. prior distribution를 gaussian 분포로 가정하면 아래와 같이 나타낼 수 있다. (Mth order의 polynomial) $$p(\\textbf{w} | \\alpha) = N(\\textbf{0}, \\alpha^{-1}\\textbf{I}) = (\\frac{\\alpha}{2\\pi})^{(M+1)/2} \\exp { -\\frac{\\alpha}{2} \\textbf{w}^T \\textbf{w}}$$ 이를 통해 우리는 posterior distribution를 구할 수 있다. posterior는 likelihood와 prior의 곱에 비례하므로 $$p(\\textbf{w} | \\textbf{x}, \\textbf{t}, \\alpha, \\beta) \\propto p(\\textbf{t} | \\textbf{x}, \\textbf{w}, \\beta)p(\\textbf{w} | \\alpha)$$ 위의 posterior distribution을 최대화로 만드는 parameter를 MAP (MLE에 대응되는 point estimate)라고 부른다. posterior distribution에 negative log를 취한다. posterior를 최대로 만드는 것은 아래를 최소화 하는 것과 같다. $$\\frac{\\beta}{2}\\sum_{n=1}^{N}{{ y(x_n, \\textbf{w}) - t_n }^2} + \\frac{\\alpha}{2}\\textbf{w}^T\\textbf{w}$$ 위 결과를 통해 posterior distribution를 maximizing하는 것은 regularized sum-of-squares error function을 minimizing하는 것과 동일하다는 것을 알 수 있다.. (L2 regularization, Ridge regression) ","date":"2021-11-26","objectID":"/prml-chap01-1/:2:5","tags":null,"title":"[PRML] Chapter1 - Introduction (1)","uri":"/prml-chap01-1/"},{"categories":["PRML"],"content":"1.2.6 Bayesian curve fitting 위의 Bayesian 접근법은 point estimate를 구했기 때문에 살짝 아쉽다. 좀 더 Bayesian적인 방법은 $\\textbf{w}$의 모든 값에 대해 integral over하는 것이다. $\\textbf{w}$에 대해 marginalize하면 되는데 이는 뒤에 자주 나오는 방법이므로 잘 기억하자. 이제 predictive distribution을 구해보자. training data : $\\textbf{x},\\textbf{t}$ new data : $x$ hyperparameter (assume we know) : $\\alpha, \\beta$ (아래식에서는 생략) $$p(t | x, \\textbf{x}, \\textbf{t}) = \\int p(t | x, \\textbf{w})p(\\textbf{w} | \\textbf{x}, \\textbf{t}) d\\textbf{w} = N(t| \\mu(x), s^2(x))$$ $$\\mu (x) = \\beta \\phi (x)^T \\textbf{S} \\sum_{n=1}^{N}{\\phi (x_n)} t_n $$ $$s^2 (x) = \\beta^{-1} + \\phi (x)^T \\textbf{S} \\phi (x)$$ $$\\textbf{S}^{-1} = \\alpha \\textbf{I} + \\beta \\sum_{n=1}^{N}{\\phi (x_n) \\phi (x)^T}$$ vector $\\phi (x)$ : element $\\phi_i (x) = x^i$ for $i = 0, … M$ ","date":"2021-11-26","objectID":"/prml-chap01-1/:2:6","tags":null,"title":"[PRML] Chapter1 - Introduction (1)","uri":"/prml-chap01-1/"},{"categories":["PRML"],"content":"1.3 Model Selection 여러 가지 모델을 선택할 때, train score로 model을 선택하는 것은 적절하지 않다. 그래서 validation set을 이용한다. 하지만 validation set에 overfitting하는 경우도 있기에 test set으로 최종 점검까지 하는 것이다. data가 제한적인 경우 cross validation의 방법을 사용한다. 하지만 이는 상당히 computationally expensive하다. ","date":"2021-11-26","objectID":"/prml-chap01-1/:3:0","tags":null,"title":"[PRML] Chapter1 - Introduction (1)","uri":"/prml-chap01-1/"},{"categories":["PRML"],"content":"1.4 The Curse of Dimensionalty 차원의 저주를 보여주는 몇가지 예시들 nearest neighborhood 알고리즘에 해당하는 부분 : sample space를 cubic형태로 나눈다고 생각했을 때, 차원이 커짐에 따라 지수적으로 cubic의 갯수가 많아진다. 따라서 cubic에 data가 텅 비지 않으려면 많은 양의 데이터가 필요하다. polynomial 의 경우 : Mth order의 polynomial 모델을 사용한다고 하면 $D^M$ 으로 parameter의 수가 증가한다. data를 sphere하게 생각해보자. 차원이 높아질수록 sphere의 표면쪽에 data가 몰려있다. 즉, 중심쪽이 sparse해지는 것이다. ","date":"2021-11-26","objectID":"/prml-chap01-1/:4:0","tags":null,"title":"[PRML] Chapter1 - Introduction (1)","uri":"/prml-chap01-1/"}]