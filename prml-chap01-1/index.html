<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1">
        <title>[PRML] Chapter1 - Introduction (1) - minsoo9506</title><meta name="Description" content="This is My New Hugo Site"><meta property="og:title" content="[PRML] Chapter1 - Introduction (1)" />
<meta property="og:description" content="Probability Theory에 대해 알아봅시다." />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://minsoo9506.github.io/prml-chap01-1/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2021-11-26T09:21:26+09:00" />
<meta property="article:modified_time" content="2021-11-26T09:21:26+09:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="[PRML] Chapter1 - Introduction (1)"/>
<meta name="twitter:description" content="Probability Theory에 대해 알아봅시다."/>
<meta name="application-name" content="minsoo9506">
<meta name="apple-mobile-web-app-title" content="minsoo9506"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="http://minsoo9506.github.io/prml-chap01-1/" /><link rel="next" href="http://minsoo9506.github.io/prml-chap01-2/" /><link rel="stylesheet" href="/lib/normalize/normalize.min.css"><link rel="stylesheet" href="/css/style.min.css"><link rel="stylesheet" href="/lib/fontawesome-free/all.min.css"><link rel="stylesheet" href="/lib/animate/animate.min.css"><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "[PRML] Chapter1 - Introduction (1)",
        "inLanguage": "en",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "http:\/\/minsoo9506.github.io\/prml-chap01-1\/"
        },"genre": "posts","wordcount":  947 ,
        "url": "http:\/\/minsoo9506.github.io\/prml-chap01-1\/","datePublished": "2021-11-26T09:21:26+09:00","dateModified": "2021-11-26T09:21:26+09:00","publisher": {
            "@type": "Organization",
            "name": "minsoo9506"},"author": {
                "@type": "Person",
                "name": "minsoo9506"
            },"description": ""
    }
    </script></head>
    <body header-desktop="auto" header-mobile="auto"><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="minsoo9506">minsoo9506 study note</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/posts/"> Posts </a><a class="menu-item" href="/tags/"> Tags </a><a class="menu-item" href="/categories/"> Categories </a><span class="menu-item delimiter"></span><span class="menu-item search" id="search-desktop">
                        <input type="text" placeholder="Search titles or contents..." id="search-input-desktop">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="Search">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="Clear">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-desktop">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </span><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                    <i class="fas fa-adjust fa-fw"></i>
                </a>
            </div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="minsoo9506">minsoo9506 study note</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><div class="search-wrapper">
                    <div class="search mobile" id="search-mobile">
                        <input type="text" placeholder="Search titles or contents..." id="search-input-mobile">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="Search">
                            <i class="fas fa-search fa-fw"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="Clear">
                            <i class="fas fa-times-circle fa-fw"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-mobile">
                            <i class="fas fa-spinner fa-fw fa-spin"></i>
                        </span>
                    </div>
                    <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
                        Cancel
                    </a>
                </div><a class="menu-item" href="/posts/" title="">Posts</a><a class="menu-item" href="/tags/" title="">Tags</a><a class="menu-item" href="/categories/" title="">Categories</a><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                <i class="fas fa-adjust fa-fw"></i>
            </a></div>
    </div>
</header>
<div class="search-dropdown desktop">
    <div id="search-dropdown-desktop"></div>
</div>
<div class="search-dropdown mobile">
    <div id="search-dropdown-mobile"></div>
</div>
<main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">Contents</h2>
            <div class="toc-content" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animated flipInX">[PRML] Chapter1 - Introduction (1)</h1><div class="post-meta">
            <div class="post-meta-line"><span class="post-author"><a href="https://github.com/minsoo9506" title="Author" target="_blank" rel="noopener noreffer author" class="author"><i class="fas fa-user-circle fa-fw"></i>minsoo9506</a></span>&nbsp;<span class="post-category">included in <a href="/categories/prml/"><i class="far fa-folder fa-fw"></i>PRML</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw"></i>&nbsp;<time datetime="2021-11-26">2021-11-26</time>&nbsp;<i class="fas fa-pencil-alt fa-fw"></i>&nbsp;947 words&nbsp;
                <i class="far fa-clock fa-fw"></i>&nbsp;5 minutes&nbsp;</div>
        </div><div class="details toc" id="toc-static"  kept="true">
                <div class="details-summary toc-title">
                    <span>Contents</span>
                    <span><i class="details-icon fas fa-angle-right"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"><nav id="TableOfContents">
  <ul>
    <li><a href="#11-example--polynomial-curve-fitting">1.1 Example : polynomial curve fitting</a></li>
    <li><a href="#12-probability-theory">1.2 Probability Theory</a>
      <ul>
        <li><a href="#121-probability-densities">1.2.1 Probability densities</a></li>
        <li><a href="#122-expectations-and-covariances">1.2.2 Expectations and covariances</a></li>
        <li><a href="#123-bayesian-probabilities">1.2.3 Bayesian probabilities</a></li>
        <li><a href="#124-the-gaussian-distribution">1.2.4 The Gaussian distribution</a></li>
        <li><a href="#125-curve-fitting-re-visted">1.2.5 Curve fitting re-visted</a></li>
        <li><a href="#126-bayesian-curve-fitting">1.2.6 Bayesian curve fitting</a></li>
      </ul>
    </li>
    <li><a href="#13-model-selection">1.3 Model Selection</a></li>
    <li><a href="#14-the-curse-of-dimensionalty">1.4 The Curse of Dimensionalty</a></li>
  </ul>
</nav></div>
            </div><div class="content" id="content"><p>Probability Theory에 대해 알아봅시다.</p>
<h2 id="11-example--polynomial-curve-fitting">1.1 Example : polynomial curve fitting</h2>
<ul>
<li>예를 들어, 회귀에서 error function이 quadratic function of w이면 w에 대한 미분은 w에 linear하고 unique한 closed form의 해를 구할 수 있다.</li>
<li>모델의 overfitting을 항상 조심하고 데이터의 수가 늘어날수록 그 정도는 약해진다. MLE 방법은 overfitting에 취약하며 Bayesian 모델링으로 보완할 수 있다.</li>
<li>ridge와 같이 error function에 패널티항을 추가하여 overfitting을 막는 방법도 있다. 이를 shrinkage 방법이라 부른다. (딥러닝에서는 weight decay)</li>
<li>이런 모델의 복잡한 정도를 정하는 데에 validation data set을 만들기도 하는데 이는 다소 낭비이므로 다른 방법을 공부할 것이다. (아마 Bayesian approach일듯)</li>
</ul>
<h2 id="12-probability-theory">1.2 Probability Theory</h2>
<p>패턴인식에서 가장 중요한 컨셉은 uncertainty이다. Probability Theory는 이런 uncertainty을 quantification하고 manipulation하는 방법을 제시한다. (확률을 이용하여)</p>
<ul>
<li>
<p>The rules of Probability</p>
<ul>
<li>sum rule : $p(X) = \sum_{Y}{p(X,Y)}$</li>
<li>product rule : $p(X,Y) = p(Y|X)p(X)$</li>
</ul>
</li>
<li>
<p>Bayes&rsquo; Throrem (rule)</p>
<ul>
<li>$p(Y|X) = \frac{p(X|Y)p(Y)}{p(X)}$</li>
<li>$p(Y)$ : prior probability</li>
<li>$p(Y|X)$ : posterior probability</li>
</ul>
</li>
</ul>
<h3 id="121-probability-densities">1.2.1 Probability densities</h3>
<ul>
<li>probability density : if the probability of a real-valued variable $x $ falling in the interval $(x, x+\delta x )$ is given by $p(x)\delta x$ for $\delta x \rightarrow 0$, then $p(x)$ is called the <em>probability density</em>
<ul>
<li>값은 항상 0 이상, 합하면 1을 가진다.</li>
</ul>
</li>
</ul>
<h3 id="122-expectations-and-covariances">1.2.2 Expectations and covariances</h3>
<ul>
<li>expection of $f(x)$ : $E[f(x)] = \int{p(x)f(x)dx}$
<ul>
<li>it can be approximated as</li>
</ul>
</li>
</ul>
<p>$$E[f] \approx \frac{1}{N}\sum_{n=1}^{N}{f(x_n)}$$</p>
<ul>
<li>$E_x [f(x,y)]$는 y에 대한 함수이다. x에 대해 averaged over 된 것이다.</li>
<li>conditional expection :  $E[f(x)|y] = \int{p(x|y)f(x)dx}$</li>
<li>variance of $f(x)$ : $var[f] = E[(f(x) - E[f(x)])^2]$
<ul>
<li>$f(x)$가 mean 주위에서 얼마나 variability가 있는지 보여준다.</li>
</ul>
</li>
</ul>
<h3 id="123-bayesian-probabilities">1.2.3 Bayesian probabilities</h3>
<p>우리가 일반적으로 알고 있는 확률(probability)은 frequentist의 견해이다. bayesian은 frequentist와는 아예 다른 접근법을 갖는다.</p>
<ul>
<li>
<p>Frequentist</p>
<ul>
<li>분모가 되는 전체 사건이 무한대로 일어나고 우리가 궁금한 사건이 그 중 몇번 일어나는지를 확률로 생각한다.</li>
<li>parameter 추정이 목표이며 parameter는 fixed 되어 있다고 생각한다.</li>
<li>주로 estimator로서 likelihood function을 최대화하는 MLE로 사용한다.</li>
</ul>
</li>
<li>
<p>Bayesian</p>
<ul>
<li>확률 : uncertainty를 quantification한 것으로 생각한다.</li>
<li>parameter는 fixed 된 것이 아니라 (probability) distribution을 갖는 것이라고 생각한다.</li>
<li>posterior distribution을 찾는 것이 목표이다.</li>
</ul>
</li>
<li>
<p>Bayes&rsquo; theorem</p>
</li>
</ul>
<p>$$p(\textbf{w} | D) = \frac{p(D | \textbf{w})p(\textbf{w})}{p(D)}$$</p>
<ul>
<li>parameter에 대해 원래 갖고 있던 믿음을 data D에 대한 정보를 얻은 뒤에 posterior probability로 업데이트 한다. (분모는 posterior가 합이 1이 되기 위한 normalization constant)</li>
<li>prior probability : $p(w)$</li>
<li>likelihood function : $p(D/w)$</li>
<li>posterior probability : $p(w/D)$</li>
<li>posterior $\propto$ likelihood * prior</li>
</ul>
<h3 id="124-the-gaussian-distribution">1.2.4 The Gaussian distribution</h3>
<p>$$N(x | \mu, \sigma^2) = \frac{1}{\sqrt{2\pi \sigma^2}}exp{ - \frac{(x-\mu)^2}{2 \sigma^2} }$$</p>
<ul>
<li>mean : $\mu$</li>
<li>variance : $\sigma^2$</li>
<li>standard deviation : $\sigma$</li>
<li>precision : $\beta = 1/ \sigma^2$</li>
<li>normal (gaussian) 분포는 mode와 mean이 같다.</li>
</ul>
<p>i.i.d (independent and identically distributed : data point가 독립적이고 같은 분포에서 나왔다) 인 경우, likelihood function은</p>
<p>$$p(\textbf{x} | \mu, \sigma^2) = \prod_{n=1}^{N}{N(x_n | \mu, \sigma^2)}$$</p>
<p>이고 이를 최대화하는 mean과 variance의 MLE는 sample mean, sample variance이다. MLE를 구하는 방법은 likelihood function에 log를 취한 후 미분하여 0을 만족하는 parameter를 찾으면 된다. 이때 단점은 maximum likelihood 접근법이 분포의 variance를 underestimate한다(bias 발생)는 점이다. N이 커지면 문제가 없지만 복잡한 모델에서는 이런 bias때문에 문제가 발생할 수 있다. (나중에 공부한다)</p>
<h3 id="125-curve-fitting-re-visted">1.2.5 Curve fitting re-visted</h3>
<p>data를 통해 polynomial curve를 fitting해보자. target t에 대한 uncertainty를 probability를 통해 표현하면 (under gaussian noise distribution)</p>
<p>$$p(t | x, \textbf{w}, \beta) = N(t | y(x,\textbf{w}), \beta^{-1})$$</p>
<p>위의 식을 이용하여 우리는 parameter $\textbf{w}$ 추정한다. likelihood를 최대로 하는 MLE를 찾으면 되는 것이다. log likelihood function은 아래와 같은 모양을 갖는다.</p>
<p>$$\ln p(\textbf{t} | \textbf{x}, \textbf{w}, \beta) = - \frac{\beta}{2}\sum_{n=1}^{N}{{ y(x_n, \textbf{w}) - t_n }^2} + \frac{N}{2}\ln \beta - \frac{N}{2}\ln (2 \pi)$$</p>
<p>위 값을 최대화 하는 $\textbf{w}_{ML}$을 찾으면 된다. 이는 결국 least square 방법과 동일한 의미를 갖는다. (추정선과 target의 차이를 최소화해야되므로) parameter를 추정한 뒤에 이제 prediction을 해야한다. 우리는 확률모델을 갖고 있기에 t에 대한 point estimate만이 아니라 predictive distribution을 만들 수 있다.</p>
<p>$$p(t | x, \textbf{w} _ {ML}, \beta _ {ML}) = N(y(x,\textbf{w} _ {ML}), \beta _ {ML}^{-1})$$</p>
<p>지금까지는 frequentist의 영역이였다면  Bayesian들은 어떤 접근을 하는지 살펴보자. 일단 우리가 추정해야하는 parameter에 대한 prior를 갖고 있다. prior distribution를 gaussian 분포로 가정하면 아래와 같이 나타낼 수 있다. (Mth order의 polynomial)</p>
<p>$$p(\textbf{w} | \alpha) = N(\textbf{0}, \alpha^{-1}\textbf{I})  = (\frac{\alpha}{2\pi})^{(M+1)/2} \exp { -\frac{\alpha}{2} \textbf{w}^T \textbf{w}}$$</p>
<p>이를 통해 우리는 posterior distribution를 구할 수 있다. posterior는 likelihood와 prior의 곱에 비례하므로</p>
<p>$$p(\textbf{w} | \textbf{x}, \textbf{t}, \alpha, \beta) \propto p(\textbf{t} | \textbf{x}, \textbf{w}, \beta)p(\textbf{w} | \alpha)$$</p>
<p>위의 posterior distribution을 최대화로 만드는 parameter를 <em>MAP</em> (MLE에 대응되는 point estimate)라고 부른다. posterior distribution에 negative log를 취한다. posterior를 최대로 만드는 것은 아래를 최소화 하는 것과 같다.</p>
<p>$$\frac{\beta}{2}\sum_{n=1}^{N}{{ y(x_n, \textbf{w}) - t_n }^2} + \frac{\alpha}{2}\textbf{w}^T\textbf{w}$$</p>
<p>위 결과를 통해 posterior distribution를 maximizing하는 것은 regularized sum-of-squares error function을 minimizing하는 것과 동일하다는 것을 알 수 있다.. (L2 regularization, Ridge regression)</p>
<h3 id="126-bayesian-curve-fitting">1.2.6 Bayesian curve fitting</h3>
<p>위의 Bayesian 접근법은 point estimate를 구했기 때문에 살짝 아쉽다. 좀 더 Bayesian적인 방법은 $\textbf{w}$의 모든 값에 대해 integral over하는 것이다. $\textbf{w}$에 대해 marginalize하면 되는데 이는 뒤에 자주 나오는 방법이므로 잘 기억하자. 이제 predictive distribution을 구해보자.</p>
<ul>
<li>training data : $\textbf{x},\textbf{t}$</li>
<li>new data : $x$</li>
<li>hyperparameter (assume we know) : $\alpha, \beta$ (아래식에서는 생략)</li>
</ul>
<p>$$p(t | x, \textbf{x}, \textbf{t}) = \int p(t | x, \textbf{w})p(\textbf{w} | \textbf{x}, \textbf{t}) d\textbf{w} = N(t| \mu(x), s^2(x))$$</p>
<p>$$\mu (x) = \beta \phi (x)^T \textbf{S} \sum_{n=1}^{N}{\phi (x_n)} t_n $$</p>
<p>$$s^2 (x) = \beta^{-1} + \phi (x)^T \textbf{S} \phi (x)$$</p>
<p>$$\textbf{S}^{-1} = \alpha \textbf{I} + \beta \sum_{n=1}^{N}{\phi (x_n) \phi (x)^T}$$</p>
<ul>
<li>vector $\phi (x)$ : element $\phi_i (x) = x^i$ for $i = 0, &hellip; M$</li>
</ul>
<h2 id="13-model-selection">1.3 Model Selection</h2>
<p>여러 가지 모델을 선택할 때, train score로 model을 선택하는 것은 적절하지 않다. 그래서 validation set을 이용한다. 하지만 validation set에 overfitting하는 경우도 있기에 test set으로 최종 점검까지 하는 것이다. data가 제한적인 경우 cross validation의 방법을 사용한다. 하지만 이는 상당히 computationally expensive하다.</p>
<h2 id="14-the-curse-of-dimensionalty">1.4 The Curse of Dimensionalty</h2>
<p>차원의 저주를 보여주는 몇가지 예시들</p>
<ul>
<li>nearest neighborhood 알고리즘에 해당하는 부분 : sample space를 cubic형태로 나눈다고 생각했을 때, 차원이 커짐에 따라 지수적으로 cubic의 갯수가 많아진다. 따라서 cubic에 data가 텅 비지 않으려면 많은 양의 데이터가 필요하다.</li>
<li>polynomial 의 경우 : Mth order의 polynomial 모델을 사용한다고 하면 $D^M$ 으로 parameter의 수가 증가한다.</li>
<li>data를 sphere하게 생각해보자. 차원이 높아질수록 sphere의 표면쪽에 data가 몰려있다. 즉, 중심쪽이 sparse해지는 것이다.</li>
</ul></div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>Updated on 2021-11-26</span>
            </div>
            <div class="post-info-license"></div>
        </div>
        <div class="post-info-line">
            <div class="post-info-md"><span>
                            <a class="link-to-markdown" href="/prml-chap01-1/index.md" target="_blank">Read Markdown</a>
                        </span></div>
            <div class="post-info-share">
                <span></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">Back</a></span>&nbsp;|&nbsp;<span><a href="/">Home</a></span>
        </section>
    </div>

    <div class="post-nav">
            <a href="/prml-chap01-2/" class="next" rel="next" title="[PRML] Chapter1 - Introduction (2)">[PRML] Chapter1 - Introduction (2)<i class="fas fa-angle-right fa-fw"></i></a></div>
</div>
</article></div>
            </main><footer class="footer">
        <div class="footer-container"><div class="footer-line">Powered by <a href="https://gohugo.io/" target="_blank" rel="noopener noreffer" title="Hugo 0.101.0">Hugo</a> | Theme - <a href="https://github.com/dillonzq/LoveIt" target="_blank" rel="noopener noreffer" title="LoveIt 0.2.10"><i class="far fa-kiss-wink-heart fa-fw"></i> LoveIt</a>
                </div><div class="footer-line"><i class="far fa-copyright fa-fw"></i><span itemprop="copyrightYear">2022</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="https://github.com/minsoo9506" target="_blank">minsoo9506</a></span></div>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="Back to Top">
                <i class="fas fa-arrow-up fa-fw"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="View Comments">
                <i class="fas fa-comment fa-fw"></i>
            </a>
        </div><link rel="stylesheet" href="/lib/katex/katex.min.css"><link rel="stylesheet" href="/lib/katex/copy-tex.min.css"><script type="text/javascript" src="/lib/smooth-scroll/smooth-scroll.min.js"></script><script type="text/javascript" src="/lib/autocomplete/autocomplete.min.js"></script><script type="text/javascript" src="/lib/lunr/lunr.min.js"></script><script type="text/javascript" src="/lib/lazysizes/lazysizes.min.js"></script><script type="text/javascript" src="/lib/clipboard/clipboard.min.js"></script><script type="text/javascript" src="/lib/katex/katex.min.js"></script><script type="text/javascript" src="/lib/katex/auto-render.min.js"></script><script type="text/javascript" src="/lib/katex/copy-tex.min.js"></script><script type="text/javascript" src="/lib/katex/mhchem.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"Copy to clipboard","maxShownLines":10},"comment":{},"math":{"delimiters":[{"display":true,"left":"$$","right":"$$"},{"display":true,"left":"\\[","right":"\\]"},{"display":false,"left":"$","right":"$"},{"display":false,"left":"\\(","right":"\\)"}],"strict":false},"search":{"highlightTag":"em","lunrIndexURL":"/index.json","maxResultLength":10,"noResultsFound":"No results found","snippetLength":30,"type":"lunr"}};</script><script type="text/javascript" src="/js/theme.min.js"></script></body>
</html>
